[
  {
    "id": 0,
    "prompt": "Properties of high-degree oscillation modes of the Sun observed with Hinode/SOT",
    "HWT": "Aims. With the Solar Optical Telescope on Hinode, we investigate the basic properties of high-degree solar oscillations observed at two levels in the solar atmosphere, in the G-band (formed in the photosphere) and in the Ca II H line (chromospheric emission). Methods. We analyzed the data by calculating the individual power spectra as well as the cross-spectral properties, i.e., coherence and phase shift. The observational properties are compared with a simple theoretical model, which includes the effects of correlated noise. Results. The results reveal significant frequency shifts between the Ca II H and G-band spectra, in particular above the acoustic cut-off frequency for pseudo-modes. The cross-spectrum phase shows peaks associated with the acoustic oscillation (p-mode) lines, and begins to increase with frequency around the acoustic cut-off. However, we find no phase shift for the (surface gravity wave) f-mode. The observed properties for the p-modes are qualitatively reproduced in a simple model with a correlated background if the correlated noise level in the Ca II H data is higher than in the G-band data. These results suggest that multi-wavelength observations of solar oscillations, in combination with the traditional intensity-velocity observations, may help to determine the level of the correlated background noise and to determine the type of wave excitation sources on the Sun.",
    "MGT": "The study of solar oscillations provides critical insights into the internal structure and dynamics of the Sun. High-degree p-modes, which have short lifetimes and are difficult to observe, offer unique information about the near-surface layers. Utilizing the unprecedented spatial resolution and stability of the Solar Optical Telescope (SOT) onboard the Hinode satellite, we investigate the properties of high-degree oscillation modes of the Sun. This study analyzes data collected over several months, focusing on oscillations with spherical harmonic degrees ranging from 300 to 3000. We employ advanced data reduction techniques to isolate the solar oscillation signal from the instrumental and environmental noise, enabling us to detect modes with greater precision than previously possible. The results reveal new insights into the mode frequencies and lifetimes, showing a clear dependence on the degree and radial order. Notably, our observations suggest the presence of localized regions with anomalous wave speeds, which may be indicative of magnetic field concentrations or other subsurface features. Furthermore, the mode amplitudes exhibit systematic variations that correlate with the solar activity cycle, suggesting a potential link between the high-degree modes and the dynamic processes occurring in the Sun's outer layers. These findings contribute to our understanding of solar surface dynamics and provide constraints for theoretical models of solar convection and magnetism. This research demonstrates the importance of high-resolution observations in advancing helioseismology and highlights the continued value of instruments like Hinode/SOT in solar physics studies."
  },
  {
    "id": 1,
    "prompt": "Bifurcation and Secondary Bifurcation of Heavy Periodic Hydroelastic Travelling Waves",
    "HWT": "The paper deals with a problem of interaction between hydrodynamics and mechanics of nonlinear elastic bodies. The existence question for two-dimensional symmetric steady waves travelling on the surface of a deep ocean beneath a heavy elastic membrane is analyzed as a problem in bifurcation theory. The behaviour of the two-dimensional cross-section of the membrane is modelled as a thin (unshearable), heavy, hyperelastic Cosserat rod, following Antman's elasticity theory, and the fluid beneath is supposed to be in steady 2D irrotational motion under gravity. Assuming that gravity and the density of the undeformed membrane are prescribed, the free parameters of the problem are the speed of the wave and drift velocity of the membrane. The analysis relies upon a conformal formulation of the hydro-elastic problem developed in previous papers; the basic tool for the study of the bifurcation picture is the implicit function theorem, under some non-resonance assumptions. The most interesting part of the final result is the existence of a symmetry-breaking 'third sheet' of solutions, which bifurcates from primary sheets, and is a hydro-elastic analogue of the phenomenon known as 'Wilton ripples' in the surface tension case.",
    "MGT": "In this study, we investigate the complex phenomena of bifurcation and secondary bifurcation in heavy periodic hydroelastic travelling waves. These waves, which are prevalent in fluid-structure interactions, particularly in marine environments, present challenges in both theoretical and applied mechanics due to their intricate nature. We employ advanced mathematical models to analyze the stability and bifurcation patterns of these waves, focusing on scenarios where traditional linear analysis falls short. Utilizing a combination of analytical techniques and numerical simulations, we identify critical parameters influencing wave behavior and delineate the bifurcation structure associated with these hydroelastic systems. Our findings reveal the presence of multiple bifurcation points, each leading to distinct secondary wave patterns. These secondary bifurcations are characterized by complex dynamical behavior, including the emergence of localized oscillatory modes and chaotic wave patterns. The results highlight the sensitivity of wave dynamics to initial conditions and parameter variations, offering new insights into the control and prediction of wave behavior in engineering applications. This research contributes to a deeper understanding of the transition mechanisms in hydroelastic wave systems and proposes potential avenues for future studies aimed at harnessing these phenomena for practical applications in wave energy extraction and marine structure design."
  },
  {
    "id": 2,
    "prompt": "Structure of the coadjoint orbits of Lie groups",
    "HWT": "We study the geometrical structure of the coadjoint orbits of an arbitrary complex or real Lie algebra ${\\mathfrak g}$ containing some ideal ${\\mathfrak n}$. It is shown that any coadjoint orbit in ${\\mathfrak g}^*$ is a bundle with the affine subspace of ${\\mathfrak g}^*$ as its fibre. This fibre is an isotropic submanifold of the orbit and is defined only by the coadjoint representations of the Lie algebras ${\\mathfrak g}$ and ${\\mathfrak n}$ on the dual space ${\\mathfrak n}^*$. The use of this fact and an application of methods of symplectic geometry give a new insight into the structure of coadjoint orbits and allow us to generalize results derived earlier in the case when ${\\mathfrak g}$ is a split extension using the Abelian ideal ${\\mathfrak n}$ (a semidirect product). As applications, a new proof of the formula for the index of Lie algebra and a necessary condition of integrality of a coadjoint orbit are obtained.",
    "MGT": "The study of coadjoint orbits of Lie groups provides profound insights into both representation theory and symplectic geometry. This paper investigates the structure of the coadjoint orbits of Lie groups, focusing on the intricate relationships between the algebraic and geometric properties that define them. We begin by examining the foundational concepts of Lie groups and their corresponding Lie algebras, emphasizing the role of the coadjoint representation. Utilizing the Kirillov-Kostant-Souriau (KKS) symplectic structure, we delve into the symplectic geometry of these orbits, elucidating their role as phase spaces in classical mechanics and their quantization in the context of quantum mechanics. Through detailed examples, such as the orbits of compact and semisimple Lie groups, we uncover the rich geometric structure inherent in these entities. This exploration is further enriched by considering the implications of the orbit method, which bridges the gap between the representations of Lie groups and the geometry of their coadjoint orbits. Additionally, we address recent advancements in the classification and characterization of these orbits, leveraging modern techniques in algebraic geometry and differential topology. Our findings contribute to a deeper understanding of the harmonic analysis on Lie groups and offer potential applications in theoretical physics, particularly in areas concerning gauge theory and string theory."
  },
  {
    "id": 3,
    "prompt": "A manifold of possible physics-laws in a universe where the planck constant and speed of light parameters vary",
    "HWT": "I assume a universe whereby the speed of light and the planck constant are not constants but instead parameters that vary locally in time-and space. When describing motion, I am able to derive a modified path integral description at the quantum level, which offers a natural extension of quantum mechanics. At the microscopic level, this path integral intuitively describes a physics with many quantum realities thus leading to a novel concept of manifold of physics, which can be looked at as a novel action principle. This paradigm reflects the notion that the observed laws of physics on any given scale are determined by the underlying distribution of the fundamental parameters (i. e Quantum Mechanics is just one point on this manifold), thus leading to many possible physical-law based behaviors. By choosing a Gaussian distribution of the parameters, a quadratic action term appears in the path-integral, which in turns leads to a complex classical action (and by continuation a new description for inertia) at the classical level. In the accompanying manuscript the classical doublet equation of motion is applied to the Newtonian gravitation field, and a MOND-like, dark-energy-like, and pioneer-anomaly-like solutions are derived.",
    "MGT": "In this study, we explore the theoretical implications of a universe where two fundamental constants—the Planck constant (ℏ) and the speed of light (c)—are not fixed but vary across a manifold of possible values. This framework challenges the traditional assumption of immutable physical laws and invites consideration of a broader spectrum of physical realities. By examining how variations in ℏ and c influence key phenomena such as the quantum mechanical uncertainty principle, relativistic energy-momentum relations, and the scaling of physical units, we construct a theoretical landscape wherein the fabric of spacetime and the behavior of matter are dependent on these dynamic parameters. Employing differential geometry and dimensional analysis, we define a manifold that encapsulates the interdependent relationships between ℏ, c, and other derived constants, such as the gravitational constant (G) and the fine-structure constant (α). Furthermore, we analyze hypothetical universes within this manifold, identifying regions where quantum mechanics, relativity, and classical physics coalesce or diverge. This approach not only broadens our understanding of the constraints underpinning physical laws but also provides insight into the potential variability of universal constants in multiverse theories or cosmological models. Our findings suggest that the interplay between ℏ and c could serve as a cornerstone for exploring alternative physical realities and expanded theories of fundamental physics."
  },
  {
    "id": 4,
    "prompt": "Stochasticity in N-body Simulations of Disc Galaxies",
    "HWT": "We demonstrate that the chaotic nature of N-body systems can lead to macroscopic variations in the evolution of collisionless simulations containing rotationally supported discs. The unavoidable stochasticity that afflicts all simulations generally causes mild differences between the evolution of similar models but, in order to illustrate that this is not always true, we present a case that shows extreme bimodal divergence. The divergent behaviour occurs in two different types of code and is independent of all numerical parameters. We identify and give explicit illustrations of several sources of stochasticity, and also show that macroscopic variations in the evolution can originate from differences at the round-off error level. We obtain somewhat more consistent results from simulations in which the halo is set up with great care compared with those started from more approximate equilibria, but we have been unable to eliminate diverging behaviour entirely because the main sources of stochasticity are intrinsic to the disc. We show that the divergence is only temporary and that halo friction is merely delayed, for a substantial time in some cases. We argue that the delays are unlikely to arise in real galaxies, and that our results do not affect dynamical friction constraints on halo density. Stochastic variations in the evolution are inevitable in all simulations of disc-halo systems, irrespective of how they were created, although their effect is generally far less extreme than we find here. The possibility of divergent behaviour complicates comparison of results from different workers.",
    "MGT": "N-body simulations have become an essential tool in understanding the complex dynamical behavior of disc galaxies. These simulations, which model the gravitational interactions of a large number of particles, provide valuable insights into the formation and evolution of galactic structures. However, the inherent stochasticity in N-body simulations poses significant challenges in interpreting their results. This study investigates the role of stochasticity in shaping the dynamical properties of disc galaxies within the framework of N-body simulations. We systematically analyze a suite of simulations with varying initial conditions, particle numbers, and integration schemes to assess the impact of stochastic variations on the emergent galactic structures. Our findings suggest that stochastic effects can lead to significant divergences in the evolution of seemingly similar systems, particularly in the development of spiral arms and bars. These discrepancies are shown to be sensitive to the choice of numerical integrators and the resolution of the simulation, with lower particle numbers exacerbating stochastic variations. We further explore the implications of these findings for the predictability of galactic dynamics and the interpretation of simulation results. Our study highlights the necessity for high-resolution simulations and robust statistical analyses to mitigate the influence of stochasticity and enhance the reliability of N-body simulation outcomes. Moreover, we discuss potential strategies to account for stochastic effects in future simulations, including the implementation of ensemble simulations and advanced noise-reduction techniques. This work underscores the importance of understanding and managing stochasticity in N-body simulations to improve our comprehension of disc galaxy dynamics and evolution, ultimately advancing our knowledge of the universe."
  },
  {
    "id": 5,
    "prompt": "Cox rings, semigroups and automorphisms of affine algebraic varieties",
    "HWT": "We study the Cox realization of an affine variety, i.e., a canonical representation of a normal affine variety with finitely generated divisor class group as a quotient of a factorially graded affine variety by an action of the Neron-Severi quasitorus. The realization is described explicitly for the quotient space of a linear action of a finite group. A universal property of this realization is proved, and some results on the divisor theory of an abstract semigroup emerging in this context are given. We show that each automorphism of an affine variety can be lifted to an automorphism of the Cox ring normalizing the grading. It follows that the automorphism group of a non-degenerate affine toric variety of dimension $\\geq 2$ has infinite dimension. We obtain a wild automorphism of the three-dimensional quadratic cone that rises to Anick's automorphism of the polynomial algebra in four variables.",
    "MGT": "The study of Cox rings has emerged as a central theme in understanding the interplay between the algebraic, geometric, and combinatorial properties of affine algebraic varieties. These graded rings encapsulate key structural information about the underlying variety, particularly when equipped with a torus action. This article investigates the connections between Cox rings, semigroup structures, and automorphism groups of affine varieties. We explore how the semigroup of effective divisor classes influences the construction and properties of the Cox ring, providing insights into the birational geometry of the variety. Furthermore, we examine how automorphism groups act on Cox rings and their associated semigroups, revealing intricate relationships between algebraic and geometric symmetries. Applications of these results are presented in the classification of automorphism groups for specific classes of affine varieties, including toric and rational surfaces. This work highlights the utility of Cox rings as a unifying framework for studying affine varieties and their automorphisms."
  },
  {
    "id": 6,
    "prompt": "The North American and Pelican Nebulae I. IRAC Observations",
    "HWT": "We present a 9 deg^2 map of the North American and Pelican Nebulae regions obtained in all four IRAC channels with the Spitzer Space Telescope. The resulting photometry is merged with that at JHKs from 2MASS and a more spatially limited $BVI$ survey from previous ground-based work. We use a mixture of color- color diagrams to select a minimally contaminated set of more than 1600 objects that we claim are young stellar objects (YSOs) associated with the star forming region. Because our selection technique uses IR excess as a requirement, our sample is strongly biased against inclusion of Class III YSOs. The distribution of IRAC spectral slopes for our YSOs indicates that most of these objects are Class II, with a peak towards steeper spectral slopes but a substantial contribution from a tail of flat spectrum and Class I type objects. By studying the small fraction of the sample that is optically visible, we infer a typical age of a few Myr for the low mass population. The young stars are clustered, with about a third of them located in eight clusters that are located within or near the LDN 935 dark cloud. Half of the YSOs are located in regions with surface densities higher than 1000 YSOs / deg^2. The Class I objects are more clustered than the Class II stars.",
    "MGT": "This study presents a comprehensive analysis of the North American and Pelican Nebulae through observations made with the Infrared Array Camera (IRAC) on the Spitzer Space Telescope. These nebulae, located in the Cygnus constellation, are prominent regions of star formation, providing insights into the processes governing stellar evolution. Our observations span a range of wavelengths from 3.6 to 8.0 micrometers, allowing us to probe the dust and gas components of these nebulae, which are obscured in visible light.\n\nWe identify numerous young stellar objects (YSOs) and map their distribution across the nebulae, categorizing them based on their infrared properties. This classification enables us to discern different stages of stellar development, from protostars to more evolved pre-main-sequence stars. The analysis reveals a complex interplay between the nebulae's structures and the embedded YSOs, highlighting regions of active star formation and potential triggers for further stellar birth.\n\nFurthermore, we examine the interaction between radiation from massive stars and the surrounding interstellar medium, shedding light on the processes of photoionization and photodissociation. Our findings underscore the dynamic nature of these nebulae, driven by feedback mechanisms from newly formed stars. This work contributes to the broader understanding of star formation in massive molecular clouds and the role of infrared observations in unveiling the hidden intricacies of these celestial phenomena. Future studies will focus on integrating these findings with complementary data from other wavelengths to construct a more detailed picture of these enigmatic regions."
  },
  {
    "id": 7,
    "prompt": "Nonlinear current-voltage behavior and electrically driven phase transition in charge frustrated LuFe2O4",
    "HWT": "Electric transport measurements of the charge frustrated LuFe2O4, in which the charge ordering (CO) and electronic ferroelectricity are found, reveal strong nonlinear electric conduction upon application of electrical field in both single crystalline and polycrystalline samples. The threshold electric fields (Et) in single crystalline LuFe2O4 are estimated respectively to be about 60V/cm and 10V/cm with E parallel and perpendicular to the c-axis direction. Experimental measurements also demonstrate that the I-V nonlinearity increases quickly with lowering temperature. Furthermore, our in-situ TEM investigations evidently reveal that the nonlinear I-V behavior is intrinsically in correlation with a current driven charge ordering insulator-metal transition, and the applied electrical field triggers a visible CO collapse recognizable as the fading of satellite spots of the CO modulations.",
    "MGT": "The layered oxide LuFe₂O₄ exhibits complex charge ordering due to frustration, resulting in intriguing electronic properties. This study investigates the nonlinear current-voltage (I-V) behavior and electrically driven phase transitions in LuFe₂O₄, revealing the interplay between charge dynamics and lattice distortions. Through temperature-dependent transport measurements, a pronounced nonlinearity in the I-V characteristics is observed, indicative of field-driven changes in the charge ordering state. Application of high electric fields induces a reversible phase transition, accompanied by abrupt shifts in electrical conductivity, suggesting a coupling between electronic and structural degrees of freedom. Complementary structural analysis confirms modifications to the charge ordering pattern under electric stress. These findings highlight LuFe₂O₄ as a model system for exploring charge frustration and field-tunable phase transitions, offering insights into potential applications in resistive switching and neuromorphic computing devices."
  },
  {
    "id": 8,
    "prompt": "Non-cooperative games for spreading code optimization, power control and receiver design in wireless data networks",
    "HWT": "This paper focuses on the issue of energy efficiency in wireless data networks through a game theoretic approach. The case considered is that in which each user is allowed to vary its transmit power, spreading code, and uplink receiver in order to maximize its own utility, which is here defined as the ratio of data throughput to transmit power. In particular, the case in which linear multiuser detectors are employed at the receiver is treated first, and, then, the more challenging case in which non-linear decision feedback multiuser receivers are adopted is addressed. It is shown that, for both receivers, the problem at hand of utility maximization can be regarded as a non-cooperative game, and it is proved that a unique Nash equilibrium point exists. Simulation results show that significant performance gains can be obtained through both non-linear processing and spreading code optimization; in particular, for systems with a number of users not larger than the processing gain, remarkable gains come from spreading code optimization, while, for overloaded systems, the largest gainscome from the use of non-linear processing. In every case, however, the non-cooperative games proposed here are shown to outperform competing alternatives.",
    "MGT": "In this work, we investigate the application of non-cooperative game theory to jointly address the challenges of spreading code optimization, power control, and receiver design in wireless data networks. The inherent decentralized and competitive nature of wireless communication networks makes game-theoretic approaches particularly suitable for resource allocation and signal optimization in such environments. We model the interactions among users as a non-cooperative game, where each user aims to maximize their individual utility, defined as a trade-off between signal quality and resource consumption. The utility functions are carefully designed to reflect practical constraints, including interference mitigation, power limitations, and the need for effective multi-user detection.\n\nOur analysis demonstrates the existence and uniqueness of Nash equilibria under specific conditions, ensuring convergence to stable and efficient operating points. To achieve these equilibria, we propose distributed algorithms that require minimal exchange of information among users, making the approach scalable and robust to network dynamics. Simulation results validate the effectiveness of the proposed framework, showing significant improvements in network performance metrics, such as signal-to-interference-plus-noise ratio (SINR), energy efficiency, and overall system throughput. This work highlights the potential of leveraging non-cooperative game theory to design adaptive and autonomous wireless networks, paving the way for more efficient and resilient next-generation communication systems."
  },
  {
    "id": 9,
    "prompt": "Galactic Small Scale Structure Revealed by the GALFA-HI Survey",
    "HWT": "The Galactic Arecibo L-band Feed Array HI (GALFA-HI) survey is mapping the entire Arecibo sky at 21-cm, over a velocity range of -700 to +700 km/s (LSR), at a velocity resolution of 0.18 km/s and an angular resolution of 3.5 arcmin. The unprecedented resolution and sensitivity of the GALFA-HI survey have resulted in the detection of many isolated, very compact HI clouds at low Galactic velocities which are distinctly separated from the HI disk emission. In the limited area of ~4600 deg$^2$ searched so far, we have detected 96 such compact clouds. The detected clouds are cold with kinetic temperature less than 300 K. Moreover, they are quite compact and faint, with median values of 5 arcmin in angular size, 0.75 K in peak brightness temperature, and $5\\times10^{18}$ cm$^{-2}$ in HI column density. From the modeling of spatial and velocity distributions of the whole compact cloud population, we find that the bulk of clouds are related to the Galactic disk, and are within a few kpc distance. We present properties of the compact clouds sample and discuss various possible scenarios for the origin of this clouds population and its role in the Galactic interstellar medium studies.",
    "MGT": "The Galactic Arecibo L-Band Feed Array H I (GALFA-HI) survey has provided an unprecedented view of small-scale structures in the neutral atomic hydrogen (H I) component of the Milky Way. By combining high angular resolution (4 arcminutes), spectral resolution (0.18 km/s), and sensitivity across 13,000 square degrees of sky, the GALFA-HI survey reveals intricate and previously unresolved features in the interstellar medium (ISM). This study presents a comprehensive analysis of these structures, focusing on the morphology, kinematics, and physical conditions of small-scale H I features. We identify a diverse population of filamentary, clumpy, and shell-like structures, with characteristic scales ranging from sub-parsec to tens of parsecs. These features are often associated with dynamic processes such as turbulence, small-scale shocks, and interactions between different ISM phases. Additionally, we detect correlations between small-scale H I structures and molecular gas, suggesting their role in the early stages of star formation. By leveraging machine-learning techniques and statistical tools, we quantify the prevalence and properties of these structures, offering new insights into the multi-phase ISM and its evolution. This work underscores the importance of high-resolution surveys in uncovering the complexity of the Galactic environment and establishes the GALFA-HI survey as a critical resource for advancing our understanding of the Milky Way’s small-scale structure and the physical processes shaping it."
  },
  {
    "id": 10,
    "prompt": "Spin Bose-Metal phase in a spin-1/2 model with ring exchange on a two-leg triangular strip",
    "HWT": "Recent experiments on triangular lattice organic Mott insulators have found evidence for a 2D spin liquid in proximity to the metal-insulator transition. A Gutzwiller wavefunction study of the triangular lattice Heisenberg model with appropriate four-spin ring exchanges has found that the projected spinon Fermi sea state has a low variational energy. This wavefunction, together with a slave particle gauge theory, suggests that such spin liquid possesses spin correlations that are singular along surfaces in momentum space (\"Bose surfaces\"). Signatures of this state, which we refer to as a \"Spin Bose-Metal\" (SBM), are expected to be manifest in quasi-1D ladder systems: The discrete transverse momenta cut through the 2D Bose surface leading to a distinct pattern of 1D gapless modes. Here we search for a quasi-1D descendant of the triangular lattice SBM state by exploring the Heisenberg plus ring model on a two-leg strip (zigzag chain). Using DMRG, variational wavefunctions, and a Bosonization analysis, we map out the full phase diagram. Without ring exchange the model is equivalent to the J_1 - J_2 Heisenberg chain, and we find the expected Bethe-chain and dimerized phases. Remarkably, moderate ring exchange reveals a new gapless phase over a large swath of the phase diagram. Spin and dimer correlations possess particular singular wavevectors and allow us to identify this phase as the hoped for quasi-1D descendant SBM state. We derive a low energy theory and find three gapless modes and one Luttinger parameter controlling all power laws. Potential instabilities out of the zigzag SBM give rise to other interesting phases such as a period-3 VBS or a period-4 Chirality order, which we discover in the DMRG; we also find an interesting SBM state with partial ferromagnetism.",
    "MGT": "We investigate the emergence of a Spin Bose-Metal (SBM) phase in a spin-1/2 model with ring exchange interactions on a two-leg triangular strip geometry. This study is motivated by the search for exotic quantum phases in low-dimensional frustrated systems, where competing interactions and quantum fluctuations can stabilize unconventional states of matter. The model includes nearest-neighbor Heisenberg exchange interactions and a four-spin ring exchange term, which captures multi-spin correlations arising from higher-order processes. Using a combination of numerical techniques, including density matrix renormalization group (DMRG) and exact diagonalization, we explore the ground state phase diagram of the system across a broad range of coupling parameters. \n\nOur results reveal the presence of a robust SBM phase, characterized by gapless spin excitations and algebraic correlations consistent with emergent one-dimensional Bose liquid behavior. The SBM phase exhibits a distinctive quasi-long-range order, with power-law decaying spin-spin correlations and a characteristic momentum structure indicative of fractionalized spinon excitations. Additionally, we identify competing phases, including magnetically ordered states and spin liquid regimes, depending on the relative strength of ring exchange and nearest-neighbor interactions. Transition points between these phases are examined, and evidence suggests the SBM phase arises from strong frustration induced by the interplay of local and multi-spin interactions.\n\nWe further analyze the entanglement properties of the SBM phase using entanglement entropy scaling, which confirms its critical nature and provides insights into its underlying conformal field theory description. The study highlights the role of ring exchange in stabilizing nontrivial quantum phases and emphasizes the potential of quasi-one-dimensional geometries for realizing exotic spin states. Our findings contribute to the broader understanding of frustrated magnetism and may guide experimental efforts in designing materials capable of hosting novel quantum phenomena."
  },
  {
    "id": 11,
    "prompt": "Assisted Common Information with Applications to Secure Two-Party Computation",
    "HWT": "Secure multi-party computation is a central problem in modern cryptography. An important sub-class of this are problems of the following form: Alice and Bob desire to produce sample(s) of a pair of jointly distributed random variables. Each party must learn nothing more about the other party's output than what its own output reveals. To aid in this, they have available a set up - correlated random variables whose distribution is different from the desired distribution - as well as unlimited noiseless communication. In this paper we present an upperbound on how efficiently a given set up can be used to produce samples from a desired distribution. The key tool we develop is a generalization of the concept of common information of two dependent random variables [Gacs-Korner, 1973]. Our generalization - a three-dimensional region - remedies some of the limitations of the original definition which captured only a limited form of dependence. It also includes as a special case Wyner's common information [Wyner, 1975]. To derive the cryptographic bounds, we rely on a monotonicity property of this region: the region of the \"views\" of Alice and Bob engaged in any protocol can only monotonically expand and not shrink. Thus, by comparing the regions for the target random variables and the given random variables, we obtain our upperbound.",
    "MGT": "This paper investigates the role of assisted common information in enhancing the security of two-party computation. We introduce a novel framework that leverages assisted common information, which refers to the shared knowledge between two parties that is augmented by an external assistant, to improve the confidentiality and efficiency of secure computations. The study begins by defining the mathematical structure of assisted common information and explores its theoretical properties in the context of cryptography. We further analyze its effectiveness in ensuring data privacy and integrity during two-party interactions.\n\nOur proposed model integrates this concept into existing cryptographic protocols, thus providing a robust mechanism for secure computation. We demonstrate that assisted common information can significantly reduce the communication overhead and computational complexity typically associated with secure protocols. To validate our approach, we conduct comprehensive simulations comparing the performance and security levels of traditional two-party computation methods with those enhanced by assisted common information.\n\nThe results reveal substantial improvements in both security and performance, highlighting the practical applicability of our framework. Moreover, we explore potential applications of this approach in various domains, such as secure voting systems, private data analysis, and confidential contract negotiations. The findings suggest that assisted common information offers a promising avenue for advancing secure two-party computation, presenting new opportunities for future research in cryptographic protocol design. This work lays the groundwork for more efficient and secure systems, driving the next generation of privacy-preserving technologies."
  },
  {
    "id": 12,
    "prompt": "Quantum fluctuations in the transverse Ising spin glass model: A field theory of random quantum spin systems",
    "HWT": "We develop a mean-field theory for random quantum spin systems using the spin coherent state path integral representation. After the model is reduced to the mean field one-body Hamiltonian, the integral is analyzed with the aid of several methods such as the semiclassical method and the gauge transformation. As an application we consider the Sherrington-Kirkpatrick model in a transverse field. Using the Landau expansion and its improved versions, we give a detailed analysis of the imaginary-time dependence of the order parameters. Integrating out the quantum part of the order parameters, we obtain the effective renormalized free energy written in terms of the classically defined order parameters. Our method allows us to obtain the spin glass-paramagnetic phase transition point $\\Gamma/J\\sim 1.62$ at T=0.",
    "MGT": "This study explores quantum fluctuations within the transverse Ising spin glass model, advancing the field theory of random quantum spin systems. Employing a combination of analytical and numerical techniques, we investigate the role of quantum fluctuations in determining the physical properties of the system. The model serves as a paradigmatic example of disordered quantum systems, where randomness and quantum mechanics interplay. Our findings reveal a nuanced understanding of phase transitions, highlighting significant deviations from classical predictions due to the presence of transverse fields. We derive a field-theoretical framework to describe these complexities, providing insights into the emergent behavior of spin glasses at zero temperature. The results have implications for understanding quantum criticality and are applicable to a wide range of disordered systems, offering pathways for future research into the quantum dynamics of complex materials."
  },
  {
    "id": 13,
    "prompt": "The Kadomtsev-Petviashvili II Equation on the Half-Plane",
    "HWT": "The KPII equation is an integrable nonlinear PDE in 2+1 dimensions (two spatial and one temporal), which arises in several physical circumstances, including fluid mechanics where it describes waves in shallow water. It provides a multidimensional generalisation of the renowned KdV equation. In this work, we employ a novel approach recently introduced by one of the authors in connection with the Davey-Stewartson equation \\cite{FDS2009}, in order to analyse the initial-boundary value problem for the KPII equation formulated on the half-plane. The analysis makes crucial use of the so-called d-bar formalism, as well as of the so-called global relation. A novel feature of boundary as opposed to initial-value problems in 2+1 is that the d-bar formalism now involves a function in the complex plane which is discontinuous across the real axis.",
    "MGT": "This study investigates the Kadomtsev-Petviashvili II (KP-II) equation within the context of a half-plane domain, aiming to expand the understanding of integrable systems in restricted geometries. The KP-II equation, a well-known non-linear dispersive partial differential equation, describes wave phenomena in various physical settings. Our research focuses on the formulation of boundary conditions appropriate for the half-plane and the implications these conditions have on the existence and uniqueness of solutions. Employing analytical techniques, we derive a set of boundary conditions that maintain the integrability of the KP-II equation and explore the influence of these constraints on soliton solutions. Furthermore, we examine the inverse scattering transform method as a tool for solving the KP-II equation in this constrained domain. The results highlight the intricate interplay between boundary conditions and soliton dynamics, offering insights into wave behavior in semi-infinite media and contributing to the broader field of mathematical physics."
  },
  {
    "id": 14,
    "prompt": "Two-loop renormalization of scalar and pseudoscalar fermion bilinears on the lattice",
    "HWT": "We compute the two-loop renormalization functions, in the RI $^\\prime$ scheme, of local bilinear quark operators $\\bar{\\psi}\\Gamma\\psi$, where $\\Gamma$ denotes the Scalar and Pseudoscalar Dirac matrices, in the lattice formulation of QCD. We consider both the flavor non-singlet and singlet operators; the latter, in the scalar case, leads directly to the two-loop fermion mass renormalization, $Z_m$. As a prerequisite for the above, we also compute the quark field renormalization, $Z_{\\psi}$, up to two loops. We use the clover action for fermions and the Wilson action for gluons. Our results are given as a polynomial in $c_{SW}$, in terms of both the renormalized and bare coupling constant, in the renormalized Feynman gauge. We also confirm the 1-loop renormalization functions, for generic gauge. Finally, we present our results in the $\\bar{MS}$ scheme, for easier comparison with calculations in the continuum. The corresponding results, for fermions in an arbitrary representation, are included in an Appendix.",
    "MGT": "We present a detailed study of the two-loop renormalization of scalar and pseudoscalar fermion bilinears in lattice quantum field theory. These operators play a crucial role in the investigation of fundamental interactions, particularly in the context of flavor physics and beyond-the-Standard-Model scenarios. Utilizing lattice regularization, we compute the renormalization constants for these bilinears up to two-loop order in perturbation theory, employing dimensional regularization as a continuum reference scheme to ensure consistency. Our calculations account for the effects of operator mixing induced by lattice artifacts and include comprehensive analyses of scheme dependencies and scaling violations. The results are derived for general gauge groups and fermion representations, ensuring broad applicability to lattice simulations across diverse theoretical frameworks. Special attention is given to the effects of nonzero quark masses and the interplay between scalar and pseudoscalar contributions. Benchmark comparisons with lower-loop results and nonperturbative determinations are provided to validate the robustness of our approach. This work offers essential inputs for high-precision lattice studies, enabling the extraction of physical observables with reduced systematic uncertainties. Moreover, the findings contribute to the refinement of theoretical predictions for processes sensitive to scalar and pseudoscalar dynamics, advancing our understanding of nonperturbative QCD effects and electroweak symmetry-breaking phenomena."
  },
  {
    "id": 15,
    "prompt": "The stubborn problem is stubborn no more (a polynomial algorithm for 3-compatible colouring and the stubborn list partition problem)",
    "HWT": "One of the driving problems in the CSP area is the Dichotomy Conjecture, formulated in 1993 by Feder and Vardi [STOC'93], stating that for any fixed relational structure G the Constraint Satisfaction Problem CSP(G) is either NP--complete or polynomial time solvable. A large amount of research has gone into checking various specific cases of this conjecture. One such variant which attracted a lot of attention in the recent years is the LIST MATRIX PARTITION problem. In 2004 Cameron et al. [SODA'04] classified almost all LIST MATRIX PARTITION variants for matrices of size at most four. The only case which resisted the classification became known as the STUBBORN PROBLEM. In this paper we show a result which enables us to finish the classification - thus solving a problem which resisted attacks for the last six years. Our approach is based on a combinatorial problem known to be at least as hard as the STUBBORN PROBLEM - the 3-COMPATIBLE COLOURING problem. In this problem we are given a complete graph with each edge assigned one of 3 possible colours and we want to assign one of those 3 colours to each vertex in such a way that no edge has the same colour as both of its endpoints. The tractability of the 3-COMPATIBLE COLOURING problem has been open for several years and the best known algorithm prior to this paper is due to Feder et al. [SODA'05] - a quasipolynomial algorithm with a n^O(log n / log log n) time complexity. In this paper we present a polynomial-time algorithm for the 3-COMPATIBLE COLOURING problem and consequently we prove a dichotomy for the k-COMPATIBLE COLOURING problem.",
    "MGT": "The stubborn list partition problem and the related 3-compatible colouring problem have long posed significant challenges in combinatorial optimization and graph theory. These problems, known for their computational hardness, arise in diverse applications such as scheduling, resource allocation, and constraint satisfaction. Despite decades of effort, no polynomial-time algorithm has been identified to solve these problems efficiently, leaving them at the forefront of unresolved questions in theoretical computer science. In this study, we present a breakthrough by developing a polynomial-time algorithm that addresses both the stubborn list partition problem and the 3-compatible colouring problem. Leveraging novel techniques in graph decomposition, constraint propagation, and structural analysis, our approach reveals hidden tractable properties within the seemingly intractable frameworks of these problems. \n\nThe algorithm operates by iteratively identifying critical substructures that dictate compatibility constraints, enabling efficient partitioning and colouring while preserving computational feasibility. Rigorous analysis demonstrates its polynomial complexity, marking a significant departure from previously known algorithms that relied on exponential or heuristic methods. Furthermore, we establish the algorithm's correctness and optimality through detailed proofs and empirical validation on benchmark datasets. Experimental results show that the proposed method not only achieves solutions in polynomial time but also scales effectively with increasing graph sizes and constraint complexity. \n\nThis work resolves a long-standing open question in combinatorial optimization and offers a unifying framework for addressing related problems in graph colouring and list partitioning. Beyond its theoretical implications, the algorithm has practical relevance for applications requiring efficient partitioning and colouring under strict compatibility constraints. With this advancement, the stubborn problem is stubborn no more, opening new avenues for exploration in polynomial-time algorithms and their applications."
  },
  {
    "id": 16,
    "prompt": "SAM Lectures on Extremal Black Holes in d=4 Extended Supergravity",
    "HWT": "We report on recent results in the study of extremal black hole attractors in N=2, d=4 ungauged Maxwell-Einstein supergravities. For homogeneous symmetric scalar manifolds, the three general classes of attractor solutions with non-vanishing Bekenstein-Hawking entropy are discussed. They correspond to three (inequivalent) classes of orbits of the charge vector, which sits in the relevant symplectic representation R_{V} of the U-duality group. Other than the 1/2-BPS one, there are two other distinct non-BPS classes of charge orbits, one of which has vanishing central charge. The complete classification of the U-duality orbits, as well as of the moduli spaces of non-BPS attractors (spanned by the scalars which are not stabilized at the black hole event horizon), is also reviewed. Finally, we consider the analogous classification for N>2-extended, d=4 ungauged supergravities, in which also the 1/N-BPS attractors yield a related moduli space.",
    "MGT": "This paper presents a comprehensive series of lectures on extremal black holes within the framework of four-dimensional extended supergravity theories. Focusing on the intricate interplay between supersymmetry, duality symmetries, and extremality conditions, the lectures aim to provide a thorough understanding of the theoretical underpinnings and physical implications of these fascinating objects. The discussion begins with a review of the basic concepts of supergravity and black hole thermodynamics, followed by an exploration of the unique properties of extremal black holes, including their near-horizon geometries and the role of attractor mechanisms. Special emphasis is placed on the STU model, a prototypical example of N=2 supergravity, which serves as a fertile ground for studying the moduli space and entropy function formalism. The lectures also delve into the holographic aspects of extremal black holes, highlighting their significance in the context of the AdS/CFT correspondence. By synthesizing recent advancements and classical results, this work aims to equip researchers and students with a robust framework for investigating extremal black holes and their applications in high-energy theoretical physics."
  },
  {
    "id": 17,
    "prompt": "Enhancing extraordinary transmission of light through a metallic nano slit with a nano cavity antenna",
    "HWT": "The extraordinary transmission of light through a nano slit in a metal film is enhanced by introducing a nano cavity antenna formed by a nearby metallic nano-strip over the slit opening. For a fixed wavelength, the width of the metallic nano-strip should be chosen to make the horizontal metal-insulator-metal waveguide of finite length resonant as a Fabry-Perot cavity. When such a cavity antenna is used to enhance the transmission through a non-resonant nano slit, the slit should be opened at a position with maximal magnetic field in the horizontal resonant cavity. It is shown that an optimized cavity antenna can enhance greatly the transmission of light through a non-resonant nano slit (by about 20 times) or a resonant nano slit (by 124%). The transmission spectrum of the nano slit can also be tuned by adjusting the width of the metallic nano-strip. Such a transmission enhancement with a nano cavity antenna is studied for the first time and the physical mechanism is explained.",
    "MGT": "Extraordinary optical transmission (EOT) through subwavelength apertures in metallic films has garnered significant interest due to its potential applications in photonics, sensing, and nano-optics. This study investigates the enhancement of EOT through a metallic nano-slit by integrating a nano-cavity antenna. The nano-cavity antenna, designed to support localized plasmonic resonances, facilitates efficient coupling between incident light and surface plasmon polaritons, leading to amplified transmission. Using rigorous numerical simulations and experimental validation, we demonstrate that the nano-cavity antenna enhances field confinement and boosts the transmission efficiency beyond traditional slit designs. The interplay of cavity geometry, material properties, and resonance conditions is systematically analyzed, revealing optimal configurations for maximizing light throughput. Results indicate that the nano-cavity antenna not only improves transmission but also enables tunability across a broad spectral range, offering versatility for various applications. This approach provides a pathway for advancing EOT-based devices, including high-resolution imaging systems, compact optical sensors, and on-chip photonic circuits, thereby contributing to the development of next-generation nanophotonic technologies."
  },
  {
    "id": 18,
    "prompt": "A universal exponential factor in the dimensional crossover from graphene to graphite",
    "HWT": "A universal exponential factor, $\\gamma_{c}=\\pi/2$, is disclosed for the dimensional crossover of few-layer graphene (FLG) from two-dimensional graphene to three-dimensional graphite. $\\gamma_{c}$ is found by analyzing available experimental data on different properties of FLG with varying thickness. A theoretical study on the phonon spectrum of the vertical acoustic mode in FLG is carried out to further check this exponential factor $\\gamma_{c}$. Interestingly, the same exponential factor appears in the dimensional crossover of the phonon mode. It turns out that the exponential factor $\\gamma_{c}$ is related to the homogeneous Helmholtz-like molal equation in the mass transfer with a first order chemical reaction. The finding should provide valuable information for experimentalists and theorists in the future investigation on thickness dependent properties of FLG.",
    "MGT": "This study investigates the dimensional crossover from two-dimensional graphene to three-dimensional graphite, focusing on the universal exponential factor that governs this transition. By employing a combination of theoretical models and experimental data, we reveal that the electronic properties of graphene layers evolve significantly upon stacking, leading to the emergence of graphite-like characteristics. The universal exponential factor is identified as a key parameter influencing the electronic band structure and interlayer interactions. Our findings demonstrate that this factor is not only pivotal in understanding the dimensional crossover but also provides insights into the tuning of electronic properties in layered materials. Through analytical derivation and numerical simulations, we establish a comprehensive framework that describes the transition mechanism, offering predictive capabilities for designing materials with desired electronic characteristics. This work enhances the fundamental understanding of dimensional transitions in layered materials and opens new avenues for the development of advanced materials with tailored properties for applications in electronics and nanotechnology."
  },
  {
    "id": 19,
    "prompt": "Shrinkage regression for multivariate inference with missing data, and an application to portfolio balancing",
    "HWT": "Portfolio balancing requires estimates of covariance between asset returns. Returns data have histories which greatly vary in length, since assets begin public trading at different times. This can lead to a huge amount of missing data--too much for the conventional imputation-based approach. Fortunately, a well-known factorization of the MVN likelihood under the prevailing historical missingness pattern leads to a simple algorithm of OLS regressions that is much more reliable. When there are more assets than returns, however, OLS becomes unstable. Gramacy, et al. (2008), showed how classical shrinkage regression may be used instead, thus extending the state of the art to much bigger asset collections, with further accuracy and interpretation advantages. In this paper, we detail a fully Bayesian hierarchical formulation that extends the framework further by allowing for heavy-tailed errors, relaxing the historical missingness assumption, and accounting for estimation risk. We illustrate how this approach compares favorably to the classical one using synthetic data and an investment exercise with real returns. An accompanying R package is on CRAN.",
    "MGT": "Shrinkage regression techniques have emerged as powerful tools for handling multivariate inference, particularly in the presence of missing data. This study explores the efficacy of shrinkage regression methods in providing robust statistical inferences when dealing with incomplete datasets. Traditional multivariate techniques often falter under the strain of missing data, leading to biased estimates and reduced predictive accuracy. By applying shrinkage methods, we aim to mitigate these issues through regularization, improving the stability and reliability of the estimates. The paper extends these methods to a practical application in portfolio balancing, a field where accurate inference is crucial for optimizing asset allocation under uncertainty. Through a series of simulations and empirical analyses, we demonstrate that shrinkage regression not only enhances inference quality but also provides superior performance in constructing risk-efficient portfolios. The results underscore the potential of shrinkage regression as a versatile approach for multivariate analysis in finance, offering a pathway to more resilient decision-making strategies in the face of incomplete information. This study contributes to the growing body of literature advocating for modern statistical techniques in finance, highlighting the need for innovative approaches to tackle the complexities of real-world data challenges."
  },
  {
    "id": 20,
    "prompt": "Galaxy Satellites and the Weak Equivalence Principle",
    "HWT": "Numerical simulations of the effect of a long-range scalar interaction (LRSI) acting only on nonbaryonic dark matter, with strength comparable to gravity, show patterns of disruption of satellites that can agree with what is seen in the Milky Way. This includes the symmetric Sagittarius stellar stream. The exception presented here to the Kesden and Kamionkowski demonstration that an LRSI tends to produce distinctly asymmetric streams follows if the LRSI is strong enough to separate the stars from the dark matter before tidal disruption of the stellar component, and if stars dominate the mass in the luminous part of the satellite. It requires that the Sgr galaxy now contains little dark matter, which may be consistent with the Sgr stellar velocity dispersion, for in the simulation the dispersion at pericenter exceeds virial. We present other examples of simulations in which a strong LRSI produces satellites with large mass-to-light ratio, as in Draco, or free streams of stars, which might be compared to \"orphan\" streams.",
    "MGT": "The study of galaxy satellites provides a unique opportunity to investigate fundamental principles of physics on astronomical scales. This paper explores the implications of the Weak Equivalence Principle (WEP) in the context of satellite galaxies orbiting larger host galaxies. The WEP, which asserts that all objects experience identical acceleration in a gravitational field regardless of their composition or internal structure, is a cornerstone of general relativity. By analyzing the motion and distribution of galaxy satellites, we assess whether their trajectories align with predictions based on WEP-compliant dynamics. Utilizing observational data from large-scale surveys and numerical simulations, we examine factors such as dark matter distribution, tidal forces, and baryonic effects. Our findings suggest that while the majority of satellite galaxies conform to WEP expectations, subtle deviations may arise due to non-gravitational interactions or environmental effects. These results provide insights into the interplay between baryonic matter and dark matter and raise intriguing questions about the limits of WEP on cosmological scales. This work highlights the importance of satellite galaxies as astrophysical laboratories for testing fundamental physics and offers critical perspectives for future observational and theoretical studies."
  },
  {
    "id": 21,
    "prompt": "Thermal and magnetic properties of a low-temperature antiferromagnet Ce$_4$Pt$_{12}$Sn$_{25}$",
    "HWT": "We report specific heat ($C$) and magnetization ($M$) of single crystalline Ce$_4$Pt$_{12}$Sn$_{25}$ at temperature down to $\\sim$50mK and in fields up to 3T. $C/T$ exhibits a sharp anomaly at 180mK, with a large $\\Delta C/T\\sim$30J/molK$^2$-Ce, which, together with the corresponding cusp-like magnetization anomaly, indicates an antiferromagnetic (AFM) ground state with a N\\'eel temperature $T_N$=180mK. Numerical calculations based on a Heisenberg model reproduce both zero-field $C$ and $M$ data, thus placing Ce$_4$Pt$_{12}$Sn$_{25}$ in the weak exchange coupling $J<J_c$ limit of the Doniach diagram, with a very small Kondo scale $T_K\\ll T_N$. Magnetic field suppresses the AFM state at $H^*\\approx$0.7T, much more effectively than expected from the Heisenberg model, indicating additional effects possibly due to frustration or residual Kondo screening.",
    "MGT": "The compound Ce$_4$Pt$_{12}$Sn$_{25}$ has been investigated as a novel low-temperature antiferromagnet with intriguing thermal and magnetic properties. Crystallizing in a complex cubic structure, this material exhibits strong electronic correlations driven by the presence of Ce$^{3+}$ ions. Magnetization measurements reveal an antiferromagnetic phase transition at $T_N = 1.3$ K, characterized by a sharp anomaly in the magnetic susceptibility and specific heat. The effective magnetic moment, derived from high-temperature susceptibility data, suggests localized Ce$^{3+}$ moments with negligible Kondo screening effects. Specific heat measurements further confirm the bulk nature of the transition, with a pronounced lambda-like peak at $T_N$ and a significant electronic contribution at lower temperatures, indicative of enhanced quasiparticle density of states. Thermal conductivity data highlight the interplay between magnetic order and phonon transport, with a suppression of thermal conductivity below $T_N$ due to spin-phonon scattering. Field-dependent magnetization studies show the stabilization of the antiferromagnetic phase up to a critical field of 0.8 T, beyond which a metamagnetic transition is observed. These results provide valuable insights into the underlying magnetic interactions and the role of spin-lattice coupling in Ce$_4$Pt$_{12}$Sn$_{25}$. The findings position this material as a promising candidate for further exploration of complex magnetic phases and quantum phenomena in f-electron systems."
  },
  {
    "id": 22,
    "prompt": "Profiles of emission lines generated by rings orbiting braneworld Kerr black holes",
    "HWT": "In the framework of the braneworld models, rotating black holes can be described by the Kerr metric with a tidal charge representing the influence of the non-local gravitational (tidal) effects of the bulk space Weyl tensor onto the black hole spacetime. We study the influence of the tidal charge onto profiled spectral lines generated by radiating tori orbiting in vicinity of a rotating black hole. We show that with lowering the negative tidal charge of the black hole, the profiled line becomes to be flatter and wider keeping their standard character with flux stronger at the blue edge of the profiled line. The extension of the line grows with radius falling and inclination angle growing. With growing inclination angle a small hump appears in the profiled lines due to the strong lensing effect of photons coming from regions behind the black hole. For positive tidal charge ($b>0$) and high inclination angles two small humps appear in the profiled lines close to the red and blue edge of the lines due to the strong lensing effect. We can conclude that for all values of $b$, the strongest effect on the profiled lines shape (extension) is caused by the changes of the inclination angle.",
    "MGT": "The study of emission line profiles offers critical insights into the physical properties and dynamics of matter in the vicinity of black holes. In this work, we explore the profiles of emission lines generated by optically thin rings of material orbiting Kerr black holes embedded in a braneworld scenario. The braneworld framework modifies General Relativity by introducing extra spatial dimensions, which can alter the geometry and gravitational properties of black holes. We investigate how these modifications influence the shape, width, and asymmetry of emission lines produced by relativistic Doppler effects and gravitational redshift. Using ray-tracing techniques, we calculate photon trajectories in the braneworld Kerr spacetime and simulate the resulting emission lines for various spin parameters, observer inclinations, and ring radii. Our results reveal distinct deviations from the standard Kerr black hole predictions, particularly in the high-spin regime and for rings located near the event horizon. The line profiles exhibit enhanced broadening and asymmetry, reflecting the altered gravitational potential and frame-dragging effects. These findings suggest that precise spectral observations of black hole accretion systems could provide a novel avenue to test the braneworld hypothesis and constrain extra-dimensional physics. This study underscores the importance of emission line analysis as a diagnostic tool for probing the fundamental nature of gravity and spacetime in the vicinity of compact objects."
  },
  {
    "id": 23,
    "prompt": "Eta Carinae and Nebulae Around Massive Stars: Similarities to Planetary Nebulae?",
    "HWT": "I discuss some observational properties of aspherical nebulae around massive stars, and conclusions inferred for how they may have formed. Whether or not these ideas are applicable to the shaping of planetary nebulae is uncertain, but the observed similarities between some PNe and bipolar nebulae around massive stars is compelling. In the well-observed case of Eta Carinae, several lines of observational evidence point to a scenario where the shape of its bipolar nebula resulted from an intrinsically bipolar explosive ejection event rather than an interacting winds scenario occurring after ejection from teh star. A similar conclusion has been inferred for some planetary nebulae. I also briefly mention bipolar nebulae around some other massive stars, such as the progenitor of SN 1987A and related blue supergiants.",
    "MGT": "Eta Carinae, one of the most massive and enigmatic stellar systems in our galaxy, is surrounded by a complex nebula, the Homunculus, formed from violent mass ejections. This study explores the morphological and dynamical characteristics of nebulae around massive stars, including Eta Carinae, and examines potential parallels to planetary nebulae, typically associated with low- to intermediate-mass stars. Despite significant differences in progenitor mass and evolutionary pathways, surprising similarities emerge, such as bipolar structures, complex ejecta morphologies, and rapid expansion velocities. These features suggest that common physical processes, such as binary interactions, stellar winds, and episodic outflows, may shape these disparate nebulae. By comparing observational data and theoretical models, this work aims to bridge the gap between massive star and planetary nebula research, offering insights into nebular formation mechanisms and the late evolutionary stages of stars across the mass spectrum."
  },
  {
    "id": 24,
    "prompt": "Sum-Capacity and the Unique Separability of the Parallel Gaussian MAC-Z-BC Network",
    "HWT": "It is known that the capacity of parallel (e.g., multi-carrier) Gaussian point-to-point, multiple access and broadcast channels can be achieved by separate encoding for each subchannel (carrier) subject to a power allocation across carriers. Recent results have shown that parallel interference channels are not separable, i.e., joint coding is needed to achieve capacity in general. This work studies the separability, from a sum-capacity perspective, of single hop Gaussian interference networks with independent messages and arbitrary number of transmitters and receivers. The main result is that the only network that is always (for all values of channel coefficients) separable from a sum-capacity perspective is the MAC-Z-BC network, i.e., a network where a MAC component and a BC component are linked by a Z component. The sum capacity of this network is explicitly characterized.",
    "MGT": "This paper investigates the sum-capacity and unique separability properties of the Parallel Gaussian Multiple Access Channel-Z-Broadcast Channel (MAC-Z-BC) network, a hybrid communication model that combines the MAC and BC frameworks with interference constraints. The study provides a comprehensive analysis of the network's achievable rate regions under Gaussian signaling and explores the conditions under which the sum-capacity is maximized. By leveraging convex optimization techniques and information-theoretic tools, the paper establishes a connection between the separability of the network and the uniqueness of its optimal rate allocation. Results demonstrate that under specific channel parameters, the network achieves unique separability, ensuring that the sum-capacity solution aligns with a single rate point in the capacity region. This property is crucial for practical applications such as resource allocation and interference management in multi-user communication systems. Numerical examples and simulations validate the theoretical findings, highlighting the performance and utility of the proposed analytical framework."
  },
  {
    "id": 25,
    "prompt": "Advances in Data Combination, Analysis and Collection for System Reliability Assessment",
    "HWT": "The systems that statisticians are asked to assess, such as nuclear weapons, infrastructure networks, supercomputer codes and munitions, have become increasingly complex. It is often costly to conduct full system tests. As such, we present a review of methodology that has been proposed for addressing system reliability with limited full system testing. The first approaches presented in this paper are concerned with the combination of multiple sources of information to assess the reliability of a single component. The second general set of methodology addresses the combination of multiple levels of data to determine system reliability. We then present developments for complex systems beyond traditional series/parallel representations through the use of Bayesian networks and flowgraph models. We also include methodological contributions to resource allocation considerations for system relability assessment. We illustrate each method with applications primarily encountered at Los Alamos National Laboratory.",
    "MGT": "The assessment of system reliability has become increasingly critical in modern engineering and computational fields, necessitating innovative methodologies for data collection, combination, and analysis. This study explores recent advancements in integrating heterogeneous data sources to provide comprehensive insights into system performance and failure mechanisms. By leveraging novel techniques in statistical modeling, machine learning, and sensor-based data acquisition, the research establishes frameworks for improved accuracy and efficiency in reliability estimation. Key developments include enhanced fusion algorithms for combining disparate datasets, scalable analytical tools for handling large volumes of reliability-related data, and adaptive methodologies tailored to dynamic system environments. These advances enable predictive assessments that proactively address potential risks and optimize system design. The findings highlight the importance of interdisciplinary approaches, bridging engineering, data science, and computational analytics to address challenges in complex systems. This work contributes to the ongoing evolution of reliability assessment, offering robust solutions for industries demanding high-performance and resilient systems."
  },
  {
    "id": 26,
    "prompt": "A celestial gamma-ray foreground due to the albedo of small solar system bodies and a remote probe of the interstellar cosmic ray spectrum",
    "HWT": "We calculate the gamma-ray albedo flux from cosmic-ray (CR) interactions with the solid rock and ice in Main Belt asteroids (MBAs), Jovian and Neptunian Trojan asteroids, and Kuiper Belt objects (KBOs) using the Moon as a template. We show that the gamma-ray albedo for the Main Belt, Trojans, and Kuiper Belt strongly depends on the small-body size distribution of each system. Based on an analysis of the Energetic Gamma Ray Experiment Telescope (EGRET) data we infer that the diffuse emission from the MBAs, Trojans, and KBOs has an integrated flux of less than ~6x10^{-6} cm^{-2} s^{-1} (100-500 MeV), which corresponds to ~12 times the Lunar albedo, and may be detectable by the forthcoming Gamma Ray Large Area Space Telescope (GLAST). If detected by GLAST, it can provide unique direct information about the number of small bodies in each system that is difficult to assess by any other method. Additionally, the KBO albedo flux can be used to probe the spectrum of CR nuclei at close-to-interstellar conditions. The orbits of MBAs, Trojans, and KBOs are distributed near the ecliptic, which passes through the Galactic center and high Galactic latitudes. Therefore, the asteroid gamma-ray albedo has to be taken into account when analyzing weak gamma-ray sources close to the ecliptic, especially near the Galactic center and for signals at high Galactic latitudes, such as the extragalactic gamma-ray emission. The asteroid albedo spectrum also exhibits a 511 keV line due to secondary positrons annihilating in the rock. This may be an important and previously unrecognized celestial foreground for the INTErnational Gamma-Ray Astrophysics Laboratory (INTEGRAL) observations of the Galactic 511 keV line emission including the direction of the Galactic center.",
    "MGT": "The study of gamma-ray emissions from celestial objects has provided key insights into cosmic ray interactions and the astrophysical processes governing the solar system. This work introduces a novel gamma-ray foreground arising from the albedo of small solar system bodies (SSSBs) due to cosmic ray bombardment. These bodies, including asteroids, Kuiper Belt objects, and comets, are continuously exposed to galactic cosmic rays, resulting in high-energy interactions that produce secondary gamma-ray emissions. By modeling the gamma-ray albedo of these SSSBs, we demonstrate that their collective contribution constitutes a diffuse gamma-ray foreground that is detectable and distinct from other astrophysical sources. \n\nA detailed analysis is conducted to characterize this gamma-ray signal, accounting for variations in the size distribution, composition, and spatial distribution of SSSBs throughout the solar system. The interplay between cosmic ray flux, energy spectrum, and the material properties of these objects is shown to govern the intensity and spectral features of this emission. Our findings suggest that this foreground is most prominent in the outer solar system, where the density of SSSBs is highest.\n\nImportantly, the gamma-ray emission from SSSB albedo serves as a remote probe of the interstellar cosmic ray spectrum. Since cosmic rays modulate the gamma-ray production, observations of this foreground can provide constraints on the energy distribution and flux of cosmic rays beyond the heliopause, where the influence of solar modulation is minimized. This indirect measurement complements direct cosmic ray observations and offers a unique perspective on the interstellar cosmic ray environment.\n\nWe propose observational strategies to detect and disentangle this faint gamma-ray signal from other diffuse emissions, emphasizing the utility of next-generation gamma-ray observatories with enhanced sensitivity and resolution. This work highlights the potential of gamma-ray studies to advance our understanding of both the small bodies within our solar system and the broader cosmic ray spectrum shaping the interstellar medium."
  },
  {
    "id": 27,
    "prompt": "Cosmological MHD simulation of a cooling flow cluster",
    "HWT": "Various observations of magnetic fields in the Intra-Cluster Medium (ICM), most of the time restricted to cluster cores, point towards field strength of the order of a few microG (synchrotron radiation from radio relics and radio halos, inverse Compton radiation in X-rays and Faraday rotation measure of polarised background sources). Both the origin and the spatial structure of galaxy clusters magnetic fields are still under debate. In particular, the radial profile of the magnetic field, from the core of clusters to their outskirts, is of great importance for cosmic rays propagation within the Cosmic Web. In this letter, we highlight the importance of cooling processes in amplifying the magnetic field in the core of galaxy clusters up to one order of magnitude above the typical amplification obtained for a pure adiabatic evolution. We have performed a \"zoom'' cosmological simulation of a 3 keV cluster, including dark matter and gas dynamics, atomic cooling, UV heating and star formation using the newly developed MHD solver in the AMR code RAMSES. Magnetic field amplification proceeds mainly through gravitational contraction. Shearing motions due to turbulence provide additional amplification in the outskirts of the cluster, while magnetic reconnection during mergers causes magnetic field dissipation in the core. Cooling processes have a strong impact on the magnetic field structure in the cluster. First, due to the sharp rise of the gas density in the centre, gravitational amplification is significantly amplified, when compared to the non--radiative run. Second, due to cooling processes, shearing motions are much stronger in the core than in the adiabatic case, leading to additional field amplification and no significant magnetic reconnection.",
    "MGT": "Cosmological simulations have become pivotal in understanding the evolution and dynamics of galaxy clusters, particularly in the context of cooling flows and their interaction with magnetic fields. This study presents a high-resolution cosmological magnetohydrodynamic (MHD) simulation of a cooling flow cluster, incorporating both physical and thermodynamic processes to investigate the role of magnetic fields in regulating cooling flows and cluster evolution. The simulation includes radiative cooling, thermal conduction, and feedback mechanisms from active galactic nuclei (AGN), allowing for a detailed exploration of how these factors influence the intracluster medium (ICM).\n\nThe results reveal that magnetic fields play a significant role in shaping the dynamics and morphology of cooling flows, suppressing thermal instabilities and redistributing energy throughout the cluster. The interplay between AGN feedback and magnetic field structures generates turbulence within the ICM, which delays catastrophic cooling and promotes quasi-stable thermal equilibrium. Furthermore, the study highlights how anisotropic thermal conduction, mediated by the magnetic field geometry, impacts the propagation of heat from hotter outer regions into cooler cores, thereby regulating cooling rates. These findings suggest that magnetic fields are essential for understanding the self-regulation mechanisms in cooling flow clusters and for resolving discrepancies between observations and theoretical predictions.\n\nIn addition, the simulation demonstrates the importance of cosmological context, as large-scale structure formation and mergers dynamically influence the magnetic field topology and energy injection into the cluster environment. The alignment of magnetic fields during structure formation appears to have a lasting impact on the evolution of the cooling core. This research provides new insights into the complex interactions between magnetohydrodynamic processes and cooling flows, offering a robust framework for interpreting observational data and refining theoretical models of cluster physics. Future studies will aim to extend this work by incorporating additional physical processes, such as cosmic ray feedback, to further improve our understanding of cluster dynamics."
  },
  {
    "id": 28,
    "prompt": "Probing the dusty environment of the Seyfert 1 nucleus in NGC 3783 with MIDI/VLTI interferometry",
    "HWT": "We present mid-IR spectro-interferometry of the Seyfert type 1 nucleus of NGC 3783. The dusty circumnuclear environment is spatially resolved and the wavelength dependence of the compact emission is discussed. The observations were carried out with the MIDI instrument at the Very Large Telescope Interferometer in the N-band. Spectra and visibilities were derived with a spectral resolution of 30 in the wavelength range from 8 to 13 micron. For the interpretation we developed a simple dusty disk model with small and variable covering factor. At baselines of 65 and 69 m, visibilities in the range of 0.4 to 0.7 were measured. The N-band spectra show a monotonic increase of the measured flux with wavelength with no apparent silicate feature around 10 micron. We find that the mid-IR emission from the nucleus can be reproduced by an extended dust disk or torus with a small covering factor of the radiating dust clouds. Our mid-IR observations of NGC 3783 are consistent with a clumpy circumnuclear dust environment. The interpretation in terms of a dusty torus with low covering factor supports a clumpy version of the unified scheme for AGN. The inferred sizes and luminosities are in good agreement with dust reverberation sizes and bolometric luminosities from optical and X-ray observations.",
    "MGT": "In this study, we present high-resolution mid-infrared observations of the Seyfert 1 galaxy NGC 3783, conducted using the MID-infrared Interferometric Instrument (MIDI) on the Very Large Telescope Interferometer (VLTI). Our primary objective is to investigate the characteristics of the dusty environment surrounding the active galactic nucleus (AGN) in NGC 3783. Through MIDI/VLTI interferometry, we achieved an unprecedented angular resolution that allows us to spatially resolve the dust emission within the nucleus. The observations reveal a complex structure in the dust distribution, characterized by an elongated morphology that aligns with the direction of the AGN's broad-line region. By modeling the interferometric data, we derive the temperature distribution and optical depth of the dust, suggesting the presence of a multi-phase medium with both hot, compact components and cooler, extended regions. The results imply that the dust is not only distributed in a toroidal structure but may also be present in outflowing winds, contributing to the obscuration variability observed in NGC 3783. Our findings support models where the dusty environment plays a crucial role in the AGN's unified scheme and add new insights into the feedback processes between the central engine and its surrounding medium. This study underscores the importance of high-resolution interferometric techniques in advancing our understanding of the complex environments of AGNs."
  },
  {
    "id": 29,
    "prompt": "On a reduction procedure for Horn inequalities in finite von Neumann algebras",
    "HWT": "We consider the analogues of the Horn inequalities in finite von Neumann algebras, which concern the possible spectral distributions of sums $a+b$ of self--adjoint elements $a$ and $b$ in a finite von Neumann algebra. It is an open question whether all of these Horn inequalities must hold in all finite von Neumann algebras, and this is related to Connes' embedding problem. For each choice of integers $1\\le r\\le n$, there is a set $T^n_r$ of Horn triples, and the Horn inequalities are in one-to-one correspondence with $\\cup_{1\\le r\\le n}T^n_r$. We consider a property P$_n$, analogous to one introduced by Therianos and Thompson in the case of matrices, amounting to the existence of projections having certain properties relative to arbitrary flags, which guarantees that a given Horn inequality holds in all finite von Neumann algebras. It is an open question whether all Horn triples in $T^n_r$ have property P$_n$. Certain triples in $T^n_r$ can be reduced to triples in $T^{n-1}_r$ by an operation we call {\\em TT--reduction}. We show that property P$_n$ holds for the original triple if property P$_{n-1}$ holds for the reduced one. We then characterize the TT--irreducible Horn triples in $T^n_3$, for arbitrary $n$, and for those LR--minimal ones (namely, those having Littlewood--Richardson coefficient equal to 1), we perform a construction of projections with respect to flags in arbitrary von Neumann algebras in order to prove property P$_n$ for them. This shows that all LR--minimal triples in $\\cup_{n\\ge3}T^n_3$ have property P$_n$, and so that the corresponding Horn inequalities hold in all finite von Neumann algebras.",
    "MGT": "In the study of operator algebras, Horn inequalities serve as fundamental tools in understanding eigenvalue distributions and spectral theory. This paper presents a novel reduction procedure for Horn inequalities specifically tailored for finite von Neumann algebras. The classical Horn inequalities, which arise in the context of Hermitian matrices, describe the possible eigenvalues of a sum of Hermitian matrices given the eigenvalues of the summands. Extending this concept to the realm of von Neumann algebras presents significant challenges due to the infinite-dimensional nature and the complex structure of these algebras.\n\nIn this work, we address these challenges by introducing a systematic reduction technique that simplifies the verification of Horn inequalities within the framework of finite von Neumann algebras. The primary innovation lies in the decomposition of complex algebraic structures into more manageable substructures, allowing for a step-by-step analysis that retains the integrity of the original inequalities. We leverage properties unique to finite von Neumann algebras, such as the trace and modular theory, to establish a coherent approach that bridges the gap between finite-dimensional matrix theory and infinite-dimensional operator algebras.\n\nOur reduction procedure is designed to be both comprehensive and efficient, facilitating the application of Horn inequalities in broader contexts within mathematical physics and quantum information theory. By constructing a series of equivalent conditions, we provide a clear pathway for researchers to verify Horn inequalities without resorting to intricate computations typical of infinite-dimensional settings. The theoretical advancements are supported by illustrative examples that demonstrate the applicability and effectiveness of the proposed method.\n\nFurthermore, this study opens avenues for future exploration in non-commutative geometry and the classification of von Neumann algebras, offering a robust framework for tackling similar inequality problems. The implications of this research extend beyond pure mathematics, potentially impacting areas such as quantum mechanics, where understanding the spectral properties of operators is crucial.\n\nIn conclusion, the reduction procedure developed in this paper not only simplifies the verification of Horn inequalities in finite von Neumann algebras but also enriches the theoretical toolkit available for researchers in the field, paving the way for further advancements in the study of operator algebras and related disciplines."
  },
  {
    "id": 30,
    "prompt": "Thermonuclear Reflect AB-Reactor",
    "HWT": "The author offers a new kind of thermonuclear reflect reactor. The remarkable feature of this new reactor is a three net AB reflector, which confines the high temperature plasma. The plasma loses part of its energy when it contacts with the net but this loss can be compensated by an additional permanent plasma heating. When the plasma is rarefied (has a small density), the heat flow to the AB reflector is not large and the temperature in the triple reflector net is lower than 2000 - 3000 K. This offered AB-reactor has significantly less power then the currently contemplated power reactors with magnetic or inertial confinement (hundreds-thousands of kW, not millions of kW). But it is enough for many vehicles and ships and particularly valuable for tunnelers, subs and space apparatus, where air to burn chemical fuel is at a premium or simply not available. The author has made a number of innovations in this reactor, researched its theory, developed methods of computation, made a sample computation of typical project. The main point of preference for the offered reactor is its likely cheapness as a power source. Key words: Micro-thermonuclear reactor, Multi-reflex AB-thermonuclear reactor, Self-magnetic AB-thermonuclear reactor, aerospace thermonuclear engine.",
    "MGT": "The Thermonuclear Reflect AB-Reactor represents a novel approach to harnessing controlled thermonuclear fusion for scalable energy production. This reactor design integrates advanced reflectometry-based plasma confinement techniques with adaptive buffer (AB) systems to optimize reaction stability and energy yield. By employing a hybrid configuration that combines magnetic mirror fields with reflect-based diagnostics, the AB-Reactor achieves precise real-time monitoring and adjustment of plasma parameters, minimizing instabilities and turbulence. The adaptive buffer system further enhances efficiency by dynamically regulating thermal and electromagnetic flux within the reactor chamber, facilitating sustained fusion conditions while reducing energy losses. Experimental simulations conducted on prototype models demonstrate the reactor’s capacity to achieve high plasma densities and temperatures with minimal material degradation, addressing key challenges in fusion reactor longevity and operational safety. Additionally, the AB-Reactor leverages cutting-edge materials science advancements to develop plasma-facing components capable of withstanding extreme conditions, thereby ensuring durability and cost-effectiveness. Initial feasibility studies suggest that this reactor design holds promise for achieving energy outputs competitive with existing nuclear and renewable technologies, while maintaining a significantly reduced environmental footprint. This research underscores the potential of integrating reflectometry and adaptive buffering systems in next-generation fusion reactors, paving the way for practical applications in sustainable energy generation and advancing the global pursuit of clean, reliable power. Further experimental validation and optimization are ongoing to refine operational parameters and scalability."
  },
  {
    "id": 31,
    "prompt": "Vacuum static compactified wormholes in eight-dimensional Lovelock theory",
    "HWT": "In this paper new exact solutions in eight dimensional Lovelock theory will be presented. These solutions are vacuum static wormhole, black hole and generalized Bertotti-Robinson space-times with nontrivial torsion. All the solutions have a cross product structure of the type $M_{5}\\times \\Sigma_{3} $ where $M_{5}$ is a five dimensional manifold and $\\Sigma_{3}$ a compact constant curvature manifold. The wormhole is the first example of a smooth vacuum static Lovelock wormhole which is neither Chern-Simons nor Born-Infeld. It will be also discussed how the presence of torsion affects the \"navigableness\" of the wormhole for scalar and spinning particles. It will be shown that the wormhole with torsion may act as \"geometrical filter\": a very large torsion may \"increase the traversability\" for scalars while acting as a \"polarizator\" on spinning particles. This may have interesting phenomenological consequences.",
    "MGT": "We investigate vacuum static wormhole solutions within the framework of eight-dimensional Lovelock gravity, focusing on compactified geometries. Lovelock theory, as a natural extension of general relativity to higher dimensions, introduces higher-order curvature terms that allow for a richer variety of spacetime solutions. In this study, we construct a class of static and spherically symmetric wormholes supported purely by the geometric effects of the Lovelock terms, without the need for exotic matter. The wormholes are compactified along specific extra-dimensional coordinates, yielding a lower-dimensional effective spacetime that could be relevant for phenomenological applications. We analyze the conditions for the existence and stability of these wormhole solutions, emphasizing the role of the Gauss-Bonnet and third-order Lovelock terms in enabling traversable configurations. The obtained solutions exhibit a throat structure consistent with the topological requirements for a wormhole, alongside a regular horizon-free geometry. Our findings highlight the potential of higher-dimensional Lovelock gravity to support non-trivial topologies and provide insights into compactified scenarios relevant to string theory and brane-world models."
  },
  {
    "id": 32,
    "prompt": "Arithmetic of N=8 Black Holes",
    "HWT": "The microscopic formula for the degeneracies of 1/8 BPS black holes in type II string theory compactified on a six dimensional torus can be expressed as a sum of several terms. One of the terms is a function of the Cremmer-Julia invariant and gives the leading contribution to the entropy in the large charge limit. The other terms, which give exponentially subleading contribution, depend not only on the Cremmer-Julia invariant, but also on the arithmetic properties of the charges, and in fact exist only when the charges satisfy special arithmetic properties. We identify the origin of these terms in the macroscopic formula for the black hole entropy, based on quantum entropy function, as the contribution from non-trivial saddle point(s) in the path integral of string theory over the near horizon geometry. These saddle points exist only when the charge vectors satisfy the arithmetic properties required for the corresponding term in the microscopic formula to exist. Furthermore the leading contribution from these saddle points in the large charge limit agrees with the leading asymptotic behaviour of the corresponding term in the degeneracy formula.",
    "MGT": "The study of black holes in string theory has provided profound insights into quantum gravity, particularly in the context of supersymmetric configurations. N=8 supergravity, which arises as the low-energy effective theory of certain string compactifications, offers a fertile ground for exploring extremal black holes due to its high degree of symmetry and rich mathematical structure. In this work, we investigate the arithmetic properties of N=8 black holes, focusing on their charge configurations, entropy formulae, and duality symmetries. Using the framework of U-duality, we identify the role of integer-valued charge lattices and their decomposition under the exceptional Lie group E7(7), which governs the symmetries of the theory. We further analyze the black hole entropy as a function of invariant polynomials, revealing connections to modular forms and automorphic representations. The interplay between the microscopic string theory description and macroscopic supergravity solutions is examined, highlighting how arithmetic structures emerge in the counting of microstates. Special attention is given to the role of attractor mechanisms and the stabilization of moduli fields in determining the physical properties of these black holes. Our findings suggest that the arithmetic of N=8 black holes not only deepens the understanding of their quantum origins but also unveils new pathways for connecting number theory and fundamental physics."
  },
  {
    "id": 33,
    "prompt": "Magnetic moments of $^{33}$Mg in time-odd relativistic mean field approach",
    "HWT": "The configuration-fixed deformation constrained relativistic mean field approach with time-odd component has been applied to investigate the ground-state properties of $^{33}$Mg with effective interaction PK1. The ground state of $^{33}$Mg has been found to be prolate deformed, $\\beta_2=0.23$, with the odd neutron in $1/2[330]$ orbital and the energy -251.85 MeV which is close to the data -252.06 MeV. The magnetic moment $- 0.9134 \\mu_\\mathrm{N}$ is obtained with the effective electromagnetic current which well reproduces the data $- 0.7456 \\mu_\\mathrm{N}$ self-consistently without introducing any parameter. The energy splittings of time reversal conjugate states, the neutron current, the energy contribution from the nuclear magnetic potential, and the effect of core polarization are discussed in detail.",
    "MGT": "The magnetic moments of exotic nuclei provide critical insights into nuclear structure and the underlying interactions governing nuclear systems. In this study, we investigate the magnetic moments of the neutron-rich isotope $^{33}$Mg within the framework of the time-odd relativistic mean field (RMF) approach. This method incorporates time-odd components of the nuclear mean field, enabling a self-consistent description of spin-dependent phenomena relevant to nuclear magnetism. By employing state-of-the-art density-dependent meson-exchange interactions, we compute the magnetic moments of $^{33}$Mg and analyze their sensitivity to nuclear deformation and pairing effects. The results are benchmarked against available experimental data and predictions from alternative theoretical models. Our findings highlight the importance of time-odd mean field contributions in reproducing the observed magnetic properties of $^{33}$Mg, while also offering predictions for isotopes in nearby regions of the nuclear chart. This work advances our understanding of nuclear magnetism in neutron-rich systems, with implications for astrophysical and fundamental physics studies."
  },
  {
    "id": 34,
    "prompt": "Counting p'-characters in finite reductive groups",
    "HWT": "This article is concerned with the relative McKay conjecture for finite reductive groups. Let G be a connected reductive group defined over the finite field F_q of characteristic p>0 with corresponding Frobenius map F. We prove that if the F-coinvariants of the component group of the center of G has prime order and if p is a good prime for G, then the relative McKay conjecture holds for G at the prime p. In particular, this conjecture is true for G^F in defining characteristic for G a simple and simply-connected group of type B_n, C_n, E_6 and E_7. Our main tools are the theory of Gelfand-Graev characters for connected reductive groups with disconnected center developed by Digne-Lehrer-Michel and the theory of cuspidal Levi subgroups. We also explicitly compute the number of semisimple classes of G^F for any simple algebraic group G.",
    "MGT": "In the study of finite reductive groups, understanding the distribution and properties of irreducible characters plays a central role in representation theory and associated fields. Among these characters, the subset of \\( p' \\)-characters—whose degrees are coprime to a fixed prime \\( p \\)—provides valuable insights into modular representation theory and the structure of the group. This paper investigates the enumeration of \\( p' \\)-characters in finite reductive groups associated with a given prime \\( p \\), leveraging the framework of Deligne-Lusztig theory and the classification of unipotent characters. The methodology incorporates combinatorial and algebraic techniques to identify and count these characters, while also exploring their relationship with \\( p \\)-local subgroups and Sylow \\( p \\)-subgroups. The results reveal new patterns in character degrees and refine existing conjectures on their distribution. Applications to modular representation theory and connections to number theory are also discussed, highlighting broader implications of the findings."
  },
  {
    "id": 35,
    "prompt": "Semiclassical dynamics of quasi-one-dimensional, attractive Bose-Einstein condensates",
    "HWT": "The strongly interacting regime for attractive Bose-Einstein condensates (BECs) tightly confined in an extended cylindrical trap is studied. For appropriately prepared, non-collapsing BECs, the ensuing dynamics are found to be governed by the one-dimensional focusing Nonlinear Schr\\\"odinger equation (NLS) in the semiclassical (small dispersion) regime. In spite of the modulational instability of this regime, some mathematically rigorous results on the strong asymptotics of the semiclassical limiting solutions were obtained recently. Using these results, \"implosion-like\" and \"explosion-like\" events are predicted whereby an initial hump focuses into a sharp spike which then expands into rapid oscillations. Seemingly related behavior has been observed in three-dimensional experiments and models, where a BEC with a sufficient number of atoms undergoes collapse. The dynamical regimes studied here, however, are not predicted to undergo collapse. Instead, distinct, ordered structures, appearing after the \"implosion\", yield interesting new observables that may be experimentally accessible.",
    "MGT": "In this study, we investigate the semiclassical dynamics of quasi-one-dimensional Bose-Einstein condensates with attractive interactions. Utilizing the Gross-Pitaevskii equation as a foundation, we explore the behavior of these condensates under varying initial conditions and interaction strengths. Our approach combines analytical techniques and numerical simulations to understand the emergence of solitonic structures and their stability within the condensate. The semiclassical approximation provides insights into the quantum-to-classical transition in the dynamics of such systems, revealing how classical soliton solutions can be modified by quantum effects. By analyzing the parameter space, we identify regimes where the condensate exhibits robust soliton behavior and others where quantum fluctuations play a significant role, leading to the breakdown of classical soliton solutions. Our findings highlight the intricate balance between nonlinearity and quantum effects in determining the dynamical properties of attractive Bose-Einstein condensates. This work contributes to the broader understanding of low-dimensional quantum gases and offers potential pathways for manipulating solitons in experimental settings, with implications for future developments in quantum technologies and condensed matter physics."
  },
  {
    "id": 36,
    "prompt": "How to prevent type-flaw attacks on security protocols under algebraic properties",
    "HWT": "Type-flaw attacks upon security protocols wherein agents are led to misinterpret message types have been reported frequently in the literature. Preventing them is crucial for protocol security and verification. Heather et al. proved that tagging every message field with it's type prevents all type-flaw attacks under a free message algebra and perfect encryption system. In this paper, we prove that type-flaw attacks can be prevented with the same technique even under the ACUN algebraic properties of XOR which is commonly used in \"real-world\" protocols such as SSL 3.0. Our proof method is general and can be easily extended to other monoidal operators that possess properties such as Inverse and Idempotence as well. We also discuss how tagging could be used to prevent type-flaw attacks under other properties such as associativity of pairing, commutative encryption, prefix property and homomorphic encryption.",
    "MGT": "Type-flaw attacks exploit discrepancies between expected and actual data types within security protocols, undermining their reliability and integrity. These attacks become particularly challenging when algebraic properties, such as associativity, commutativity, or distributivity of cryptographic operations, are considered. This paper investigates systematic methods to prevent type-flaw attacks by analyzing their behavior under algebraic assumptions. We propose a robust framework that integrates type verification, protocol design principles, and formal modeling to ensure type consistency. By leveraging symbolic analysis tools and equational reasoning, our approach identifies vulnerabilities arising from algebraic manipulations and establishes countermeasures to mitigate them. Additionally, we highlight common pitfalls in existing protocols and provide guidelines for designing stronger type-safe cryptographic systems. Experimental evaluations on widely-used protocols demonstrate the efficacy of our methods in detecting and preventing type-flaw attacks. This work contributes to enhancing the security of protocols operating in environments with complex algebraic properties, promoting resilience against sophisticated adversarial strategies."
  },
  {
    "id": 37,
    "prompt": "A dynamical classification of the range of pair interactions",
    "HWT": "We formalize a classification of pair interactions based on the convergence properties of the {\\it forces} acting on particles as a function of system size. We do so by considering the behavior of the probability distribution function (PDF) P(F) of the force field F in a particle distribution in the limit that the size of the system is taken to infinity at constant particle density, i.e., in the \"usual\" thermodynamic limit. For a pair interaction potential V(r) with V(r) \\rightarrow \\infty) \\sim 1/r^a defining a {\\it bounded} pair force, we show that P(F) converges continuously to a well-defined and rapidly decreasing PDF if and only if the {\\it pair force} is absolutely integrable, i.e., for a > d-1, where d is the spatial dimension. We refer to this case as {\\it dynamically short-range}, because the dominant contribution to the force on a typical particle in this limit arises from particles in a finite neighborhood around it. For the {\\it dynamically long-range} case, i.e., a \\leq d-1, on the other hand, the dominant contribution to the force comes from the mean field due to the bulk, which becomes undefined in this limit. We discuss also how, for a \\leq d-1 (and notably, for the case of gravity, a=d-2) P(F) may, in some cases, be defined in a weaker sense. This involves a regularization of the force summation which is generalization of the procedure employed to define gravitational forces in an infinite static homogeneous universe. We explain that the relevant classification in this context is, however, that which divides pair forces with a > d-2 (or a < d-2), for which the PDF of the {\\it difference in forces} is defined (or not defined) in the infinite system limit, without any regularization. In the former case dynamics can, as for the (marginal) case of gravity, be defined consistently in an infinite uniform system.",
    "MGT": "In this study, we present a comprehensive dynamical classification of the range of pair interactions, aiming to enhance the understanding of complex systems in various fields such as physics, chemistry, and biology. Traditional methods of classifying interactions often rely on static or equilibrium properties, which may not adequately capture the dynamic nature of interacting systems. Our approach introduces a novel framework that incorporates time-dependent behaviors and their impact on the structural and functional properties of the system.\n\nWe begin by examining the role of interaction range in determining the macroscopic properties of a system. Utilizing advanced computational techniques and analytical models, we explore a wide spectrum of interaction ranges, from short-ranged forces typical in condensed matter physics to the long-range forces seen in gravitational and electrostatic interactions. Our classification scheme is based on the temporal evolution of the system, focusing on how varying interaction ranges influence dynamical phenomena such as phase transitions, pattern formation, and synchronization.\n\nThrough detailed simulations, we demonstrate that the interaction range significantly affects the system's ability to respond to external perturbations and adapt to changing environments. Short-range interactions are found to promote local order and stability, while long-range interactions facilitate global connectivity and coherence. We also identify critical thresholds where changes in the interaction range lead to qualitative shifts in system behavior, marking transitions between different dynamical regimes.\n\nMoreover, our classification highlights the interplay between interaction range and other system parameters, such as dimensionality and the presence of disorder. By systematically varying these parameters, we uncover universal scaling laws and emergent properties that govern the dynamics of diverse systems. These findings offer new insights into the design and control of complex systems, with potential applications ranging from materials science to ecosystem management.\n\nIn conclusion, our dynamical classification of pair interaction ranges provides a robust framework for understanding the intricate balance between order and chaos in interacting systems. By emphasizing the temporal aspects of interactions, our work opens new avenues for research into non-equilibrium dynamics and offers a unifying perspective that bridges the gap between theory and experiment. This framework not only enhances our theoretical understanding but also guides practical approaches to harnessing the power of interactions in real-world applications."
  },
  {
    "id": 38,
    "prompt": "Heavy water around the L1448-mm protostar",
    "HWT": "Context: L1448-mm is the prototype of a low-mass Class 0 protostar driving a high-velocity jet. Given its bright H2O spectra observed with ISO, L1448-mm is an ideal laboratory to observe heavy water (HDO) emission. Aims: Our aim is to image the HDO emission in the protostar surroundings, the possible occurrence of HDO emission also investigating off L1448-mm, towards the molecular outflow. Methods: We carried out observations of L1448-mm in the HDO(1_10-1_11) line at 80.6 GHz, an excellent tracer of HDO column density, with the IRAM Plateau de Bure Interferometer. Results: We image for the first time HDO emission around L1448-mm. The HDO structure reveals a main clump at velocities close to the ambient one towards the the continuum peak that is caused by the dust heated by the protostar. In addition, the HDO map shows tentative weaker emission at about 2000 AU from the protostar towards the south, which is possibly associated with the walls of the outflow cavity opened by the protostellar wind. Conclusions: Using an LVG code, modelling the density and temperature profile of the hot-corino, and adopting a gas temperature of 100 K and a density of 1.5 10^8 cm^-3, we derive a beam diluted HDO column density of about 7 10^13 cm^-2, corresponding to a HDO abundance of about 4 10^-7. In addition, the present map supports the scenario where HDO can be efficiently produced in shocked regions and not uniquely in hot corinos heated by the newly born star.",
    "MGT": "We present a detailed study of heavy water (HDO) emission in the vicinity of the L1448-mm protostar, focusing on its spatial distribution, abundance, and potential formation pathways. L1448-mm, a well-studied Class 0 protostar located in the Perseus molecular cloud, provides a unique environment for exploring the chemical evolution of star-forming regions. Using high-resolution observations from the Atacama Large Millimeter/submillimeter Array (ALMA), we identify several emission lines associated with HDO and analyze their physical properties. The spatial distribution of HDO reveals a compact structure concentrated around the protostar, with evidence of enhanced abundance within the inner envelope and potential contributions from the outflowing material. Radiative transfer modeling indicates that the excitation conditions of HDO are consistent with warm gas temperatures ranging from 50 to 150 K, suggesting that thermal desorption from icy grain mantles may play a significant role in its release into the gas phase. Comparative analysis of HDO/H2O ratios in L1448-mm and other protostellar environments reveals variations that may reflect local physical conditions, initial ice compositions, and the efficiency of chemical processing during protostellar evolution. Additionally, we discuss the implications of these findings for understanding deuterium fractionation in star-forming regions, which is influenced by both cosmic-ray ionization rates and the density-temperature profiles of the surrounding molecular cloud. Our results highlight the importance of heavy water as a tracer of protostellar chemistry and provide new constraints on the interplay between gas-phase and ice-phase processes in low-mass star formation. This study deepens our understanding of the chemical complexity emerging during the earliest stages of stellar evolution and offers a foundation for future investigations into the origins of water in planetary systems."
  },
  {
    "id": 39,
    "prompt": "Towards truly simultaneous PIXE and RBS analysis of layered objects in cultural heritage",
    "HWT": "For a long time, RBS and PIXE techniques have been used in the field of cultural heritage. Although the complementarity of both techniques has long been acknowledged, its full potential has not been yet developed due to the lack of general purpose software tools for analysing the data from both techniques in a coherent way. In this work we provide an example of how the recent addition of PIXE to the set of techniques supported by the DataFurnace code can significantly change this situation. We present a case in which a non homogeneous sample (an oxidized metal from a photographic plate -heliography- made by Niepce in 1827) is analysed using RBS and PIXE in a straightforward and powerful way that can only be performed with a code that treats both techniques simultaneously as a part of one single and coherent analysis. The optimization capabilities of DataFurnace, allowed us to obtain the composition profiles for these samples in a very simple way.",
    "MGT": "This study explores advancements in the simultaneous application of Proton-Induced X-ray Emission (PIXE) and Rutherford Backscattering Spectrometry (RBS) for analyzing layered objects in cultural heritage. Traditionally, PIXE and RBS have been employed sequentially due to their differing analytical strengths; PIXE excels in elemental composition determination while RBS provides structural and depth-related information. The integration of these techniques into a unified protocol has the potential to significantly enhance the understanding of complex layered objects without compromising the integrity of the artifact. We report on the development of an innovative experimental setup and analytical approach that allows for the concurrent use of PIXE and RBS. This approach has been tested on several cultural heritage samples, demonstrating increased efficiency and improved data correlation. The results indicate that simultaneous PIXE/RBS analysis can yield comprehensive insights into material composition and stratigraphy. This advancement presents a promising pathway for non-invasive and detailed analysis of cultural heritage materials, aiding in preservation efforts and historical understanding."
  },
  {
    "id": 40,
    "prompt": "Dynamics of the entanglement between two oscillators in the same environment",
    "HWT": "We provide a complete characterization of the evolution of entanglement between two oscillators coupled to a common environment. For initial Gaussian states we identify three phases with different qualitative long time behavior: There is a phase where entanglement undergoes a sudden death (SD). Another phase (SDR) is characterized by an infinite sequence of events of sudden death and revival of entanglement. In the third phase (NSD) there is no sudden death of entanglement, which persist for long time. The phase diagram is described and analytic expressions for the boundary between phases are obtained. Numerical simulations show the accuracy of the analytic expressions. These results are applicable to a large variety of non--Markovian environments. The case of non--resonant oscillators is also numerically investigated.",
    "MGT": "This study investigates the entanglement dynamics between two harmonic oscillators coupled to a shared environment, a problem of significant interest in quantum information science and quantum thermodynamics. Using a master equation approach, we analyze how environmental factors such as temperature and dissipation influence the entanglement between the oscillators. Our findings reveal that entanglement generally decays over time, a phenomenon that is highly sensitive to the initial states of the oscillators and the specific characteristics of their interaction with the environment. We also identify conditions under which entanglement can be partially preserved or even enhanced through non-Markovian effects and engineered reservoir interactions. The results offer valuable insights into the control of quantum entanglement in realistic settings, providing guidance for the development of robust quantum technologies. This work lays the groundwork for further exploration into the manipulation of entangled states in complex environments, with implications for quantum computing and communication."
  },
  {
    "id": 41,
    "prompt": "Lie's Reduction Method and Differential Galois Theory in the Complex Analytic Context",
    "HWT": "This paper is dedicated to the differential Galois theory in the complex analytic context for Lie-Vessiot systems. Those are the natural generaliza- tion of linear systems, and the more general class of differential equations adimitting superposition laws, as recently stated in [5]. A Lie-Vessiot sys- tem is automatically translated into a equation in a Lie group that we call automorphic system. Reciprocally an automorphic system induces a hierarchy of Lie-Vessiot systems. In this work we study the global analytic aspects of a classical method of reduction of differential equations, due to S. Lie. We propose an differential Galois theory for automorphic systems, and explore the relationship between integrability in terms of Galois the- ory and the Lie's reduction method. Finally we explore the algebra of Lie symmetries of a general automorphic system.",
    "MGT": "The interplay between Lie's reduction method and differential Galois theory has proven to be a powerful framework for analyzing the solvability of differential equations, particularly in the complex analytic setting. This study explores how Lie's reduction method facilitates the systematic reduction of higher-order differential equations to simpler forms, leveraging the structural insights provided by associated symmetry groups. Simultaneously, differential Galois theory is employed to investigate the algebraic properties of the solutions, emphasizing their dependence on the monodromy and the differential field extensions. By focusing on the complex analytic context, the paper demonstrates how global analytic properties, such as singularities and branch points, influence the compatibility between these two methodologies. We illustrate the theoretical framework with explicit examples, highlighting scenarios where the synergy between Lie's method and differential Galois theory yields new insights into the exact solvability and integrability of differential equations in the complex domain."
  },
  {
    "id": 42,
    "prompt": "Generating technique for $U(1)^3 5D$ supergravity",
    "HWT": "We develop generating technique for solutions of $U(1)^3 5D$ supergravity via dimensional reduction to three dimensions. This theory, which recently attracted attention in connection with black rings, can be viewed as consistent truncation of the $T^6$ compactification of the eleven-dimensional supergravity. Its further reduction to three dimensions accompanied by dualisation of the vector fields leads to 3D gravity coupled sigma model on the homogeneous space $SO(4,4)/SO(4)\\times SO(4)$ or $SO(4,4)/SO(2,2)\\times SO(2,2)$ depending on the signature of the three-space. We construct a $8\\times 8$ matrix representation of these cosets in terms of lower-dimensional blocks. Using it we express solution generating transformations in terms of the potentials and identify those preserving asymptotic conditions relevant to black holes and black rings. As an application, we derive the doubly rotating black hole solution with three independent charges. A suitable contraction of the above cosets is used to construct a new representation of the coset $G_{2(2)}/(SL(2, R)\\times SL(2, R))$ relevant for minimal five-dimensional supergravity.",
    "MGT": "In this study, we explore a novel method for generating solutions in five-dimensional supergravity with $U(1)^3$ symmetry, which is of particular interest due to its relevance in string theory and its implications for black hole physics and holography. The framework of $U(1)^3$ five-dimensional supergravity provides a rich landscape for theoretical investigation, allowing for various compactifications that preserve supersymmetry. We employ a systematic approach to constructing solutions by utilizing techniques from harmonic analysis and algebraic geometry, which facilitate the understanding of the moduli spaces and the characteristics of the solutions. Our method involves the careful manipulation of the scalar potential and gauge fields within the theory to derive explicit expressions for solutions that exhibit desired properties such as asymptotic flatness and regular horizons. Additionally, we examine the role of dualities and symmetry transformations in extending these solutions to more complex configurations. The results provide insights into the geometric structures and physical properties inherent in $U(1)^3$ supergravity, including the interplay between topology and symmetry. By presenting this generating technique, we offer a robust tool for physicists and mathematicians interested in exploring the deeper aspects of higher-dimensional theories and their applications in modern theoretical physics. Our findings have the potential to inform future research on compactified dimensions and their role in the unification of forces within the context of supergravity and string theory."
  },
  {
    "id": 43,
    "prompt": "Detailed Spectral Analysis of the Type Ib Supernova 1999dn. Paper I: Hydrogen-free Models",
    "HWT": "We present spectral fits to five epochs of the typical Type Ib supernova 1999dn using the generalized, non-LTE, stellar atmospheres code PHOENIX. Our goal is threefold: to determine basic physical properties of the supernova ejecta, such as velocity, temperature, and density gradients; to reproduce He I absorption lines by invoking non-thermal excitation; and, to investigate possible spectral signatures of hydrogen, especially a feature around 6200 Angstrom, which has been attributed to high velocity $H_\\alpha$. Our models assume an atmosphere with uniform composition devoid of any hydrogen. Our model spectra fit the observed spectra well, successfully reproducing most of the features, including the prominent He I absorptions. The most plausible alternative to $H_\\alpha$ as the source of the 6200 Angstrom feature is a blend of Fe II and Si II lines, which can be made stronger to fit the observed feature better by increasing the metallicity of the ejecta. High-metallicity models fit well at early epochs, but not as well as solar-metallicity models after maximum light. While this blend of metal lines is a reasonable explanation of the source of the 6200 Angstrom feature, it is still important to investigate hydrogen as the source; therefore, a second paper will present models that include a thin shell of hydrogen around the main composition structure.",
    "MGT": "We present a comprehensive spectral analysis of the Type Ib supernova (SN) 1999dn, focusing on hydrogen-free models to investigate the progenitor structure and explosion dynamics. Type Ib supernovae are characterized by the absence of hydrogen in their spectra, which provides key insights into the evolutionary pathways of massive stars that have undergone significant mass loss prior to explosion. Using high-resolution spectroscopic data obtained at multiple epochs, we examine the temporal evolution of prominent absorption and emission features, including He I lines and metallic tracers such as Fe II and Ca II. The analysis incorporates non-LTE radiative transfer simulations with hydrogen-free progenitor models, enabling detailed comparisons between observed and synthetic spectra. We find that the spectral evolution is consistent with a compact Wolf-Rayet progenitor that has shed its hydrogen envelope through either stellar winds or binary interaction prior to core collapse. The inferred ejecta mass, explosion energy, and composition align with predictions from single and binary stellar evolution models, suggesting a likely origin from a helium-rich core. Additionally, we identify evidence of asymmetry in the explosion, which may contribute to the observed spectral diversity among Type Ib events. This work represents the first installment in a series aimed at systematically analyzing SN 1999dn and similar events, providing a foundation for constraining progenitor properties and refining hydrogen-free supernova models. Future studies will extend these findings to broader samples, incorporating hydrogen-rich models and exploring implications for stellar population synthesis."
  },
  {
    "id": 44,
    "prompt": "Evidence for Evolution Among Primordial Disks in the 5 Myr Old Upper Scorpius OB Association",
    "HWT": "Moderate-resolution, near-infrared spectra between 0.8 and 5.2 microns were obtained for 12 late-type (K0-M3) disk-bearing members of the ~5 Myr old Upper Scorpius OB association using SpeX on the NASA Infrared Telescope Facility. For most sources, continuum excess emission first becomes apparent between ~2.2 and 4.5 microns and is consistent with that produced by single-temperature blackbodies having characteristic temperatures ranging from ~500 to 1300 K. The near-infrared spectra for 5 of 12 Upper Scorpius sources exhibit Pa-gamma, Pa-beta and Br-gamma emission, indicators of disk accretion. Using a correlation between Pa-beta and Br-gamma emission line luminosity and accretion luminosity, mass accretion rates (Mdot) are derived for these sources that range from Mdot = 3.5 X 10^{-10} to 1.5 X 10^{-8} MSun per yr. Merging the SpeX observations with Spitzer Space Telescope mid-infrared (5.4-37.0 micron) spectroscopy and 24 and 70 micron broadband photometry, the observed spectral energy distributions are compared with those predicted by two-dimensional, radiative transfer accretion disk models. Of the 9 Upper Scorpius sources examined in this analysis, 3 exhibit spectral energy distributions that are most consistent with models having inner disk radii that substantially exceed their respective dust sublimation radii. The remaining Upper Scorpius members possess spectral energy distributions that either show significant dispersion among predicted inner disk radii or are best described by models having inner disk rims coincident with the dust sublimation radius.",
    "MGT": "The study of primordial disks around young stellar objects provides crucial insights into the early stages of planetary system formation. In this research, we investigate the evolution of such disks in the 5 Myr old Upper Scorpius OB Association, a region noted for its dense population of young stars. Utilizing a combination of observational data from the Atacama Large Millimeter/submillimeter Array (ALMA) and the Spitzer Space Telescope, we analyze the spectral energy distributions (SEDs) of a significant sample of primordial disks. Our findings reveal substantial diversity in disk properties, including varying degrees of dust mass, gas content, and disk structure, which suggest different evolutionary stages among the observed systems.\n\nWe identify correlations between disk characteristics and stellar properties such as mass and spectral type, indicating that stellar attributes play a crucial role in disk evolution. Notably, higher mass stars tend to possess less massive disks, supporting the hypothesis of faster disk dissipation in such environments. Furthermore, our analysis reveals evidence of significant dust grain growth and possible planetesimal formation in several disks, marking a pivotal step towards planet formation.\n\nAdditionally, the presence of transitional disks with inner holes suggests ongoing processes of disk clearing, potentially driven by photoevaporation or nascent planetary bodies. This study provides compelling evidence for the diverse evolutionary paths of primordial disks in the Upper Scorpius OB Association. These findings enhance our understanding of the timeline and mechanisms of planet formation, offering a broader perspective on the conditions necessary for the emergence of planetary systems similar to our own. Future research focused on high-resolution imaging and spectroscopic analysis will further elucidate these evolutionary processes."
  },
  {
    "id": 45,
    "prompt": "VLT and GTC observations of SDSS J0123+00: a type 2 quasar triggered in a galaxy encounter?",
    "HWT": "We present long-slit spectroscopy, continuum and [OIII]5007 imaging data obtained with the Very Large Telescope and the Gran Telescopio Canarias of the type 2 quasar SDSS J0123+00 at z=0.399. The quasar lies in a complex, gas-rich environment. It appears to be physically connected by a tidal bridge to another galaxy at a projected distance of ~100 kpc, which suggests this is an interacting system. Ionized gas is detected to a distance of at least ~133 kpc from the nucleus. The nebula has a total extension of ~180 kpc. This is one of the largest ionized nebulae ever detected associated with an active galaxy. Based on the environmental properties, we propose that the origin of the nebula is tidal debris from a galactic encounter, which could as well be the triggering mechanism of the nuclear activity. SDSS J0123+00 demonstrates that giant, luminous ionized nebulae can exist associated with type 2 quasars of low radio luminosities, contrary to expectations based on type 1 quasar studies.",
    "MGT": "We present a detailed study of the type 2 quasar SDSS J0123+00 based on deep optical and near-infrared observations obtained with the Very Large Telescope (VLT) and the Gran Telescopio Canarias (GTC). This obscured active galactic nucleus (AGN) is embedded in a disturbed host galaxy, showing evidence of tidal features indicative of a recent or ongoing interaction. Spectroscopic data reveal strong narrow emission lines consistent with high-ionization states, characteristic of type 2 quasars. Additionally, we detect faint extended emission associated with ionized gas, tracing a biconical outflow driven by AGN activity. Imaging analysis confirms the presence of a nearby companion galaxy, suggesting a dynamical encounter as the likely mechanism triggering the quasar. The morphology of the host galaxy, combined with kinematic modeling of the ionized gas, supports a scenario in which gravitational interactions have funneled gas into the central regions, fueling the AGN. Our findings highlight the role of galaxy mergers in activating obscured quasars and provide new insights into the co-evolution of galaxies and supermassive black holes in the early universe. Further studies are encouraged to investigate the prevalence of such encounters in triggering AGN activity."
  },
  {
    "id": 46,
    "prompt": "Reasoning in Abella about Structural Operational Semantics Specifications",
    "HWT": "The approach to reasoning about structural operational semantics style specifications supported by the Abella system is discussed. This approach uses lambda tree syntax to treat object language binding and encodes binding related properties in generic judgments. Further, object language specifications are embedded directly into the reasoning framework through recursive definitions. The treatment of binding via generic judgments implicitly enforces distinctness and atomicity in the names used for bound variables. These properties must, however, be made explicit in reasoning tasks. This objective can be achieved by allowing recursive definitions to also specify generic properties of atomic predicates. The utility of these various logical features in the Abella system is demonstrated through actual reasoning tasks. Brief comparisons with a few other logic based approaches are also made.",
    "MGT": "This article explores the application of Abella, a proof assistant for reasoning about structural operational semantics (SOS) specifications. Structural operational semantics provides a framework for defining the behavior of programming languages through transition systems. Abella, with its capabilities in higher-order logic and support for inductive and co-inductive reasoning, offers a robust environment for formalizing and verifying properties of SOS specifications. The paper demonstrates how Abella can be utilized to specify transition rules, as well as to prove properties such as determinism, bisimulation, and congruence of specified languages. Through detailed case studies, we illustrate the effectiveness of Abella in managing the complexities inherent in SOS. The results highlight the strengths of Abella in supporting modular reasoning and enabling the verification of intricate semantic properties, thereby facilitating the rigorous analysis and development of programming language semantics."
  },
  {
    "id": 47,
    "prompt": "Post-launch performance of the Fermi Large Area Telescope",
    "HWT": "The Large Area Telescope (LAT) on-board the Fermi Gamma-ray Space Telescope started nominal operations on August 13, 2008, after about 60 days of instrument checkout and commissioning and is currently performing an all-sky gamma-ray survey from 30 MeV to above 300 GeV with unprecedented sensitivity and angular resolution. The LAT pre-launch response was tuned using Monte Carlo simulations and test beam data from a campaign necessarily limited in scope. This suggested a conservative approach in dealing with systematics that affect the reconstruction analysis of the first months of data taking. The first major update of the instrument performance based on flight data is now being completed. Not only are the LAT calibrations now based on flight data, but also the ground event reconstruction has been updated to accommodate on-orbit calibrations, and response was carefully verified using real data from celestial sources. In this contribution we describe the current best knowledge of the instrument, and our plans towards releasing public response functions to support data release in year 2.",
    "MGT": "The Fermi Large Area Telescope (LAT), launched aboard the Fermi Gamma-ray Space Telescope in June 2008, has revolutionized high-energy astrophysics by providing unprecedented insight into the gamma-ray sky. This paper evaluates the post-launch performance of the LAT, focusing on its sensitivity, angular resolution, energy range, and operational stability over its extended mission duration. We compare pre-launch expectations to in-orbit performance metrics derived from calibration data, observational campaigns, and long-term monitoring. The LAT demonstrated exceptional sensitivity across its energy range of 20 MeV to over 300 GeV, enabling the detection of thousands of gamma-ray sources, including pulsars, active galactic nuclei, and gamma-ray bursts. Angular resolution and energy reconstruction capabilities exceeded initial projections, enhancing source localization and spectral analysis. The instrument's stability and resilience to the harsh space environment have ensured consistent data quality over more than a decade of operation. We also discuss challenges encountered, such as background noise mitigation and degradation of specific subsystems, and highlight the LAT's contributions to multi-messenger astrophysics. These results underscore the LAT's pivotal role in advancing our understanding of the high-energy universe and its continued value in future gamma-ray studies."
  },
  {
    "id": 48,
    "prompt": "The GASP-WEBT monitoring of 3C 454.3 during the 2008 optical-to-radio and gamma-ray outburst",
    "HWT": "Since 2001, the radio quasar 3C 454.3 has undergone a period of high optical activity, culminating in the brightest optical state ever observed, during the 2004-2005 outburst. The Whole Earth Blazar Telescope (WEBT) consortium has carried out several multifrequency campaigns to follow the source behaviour. The GLAST-AGILE Support Program (GASP) was born from the WEBT to provide long-term continuous optical-to-radio monitoring of a sample of gamma-loud blazars, during the operation of the AGILE and GLAST (now known as Fermi GST) gamma-ray satellites. The main aim is to shed light on the mechanisms producing the high-energy radiation, through correlation analysis with the low-energy emission. Thus, since 2008 the monitoring task on 3C 454.3 passed from the WEBT to the GASP, while both AGILE and Fermi detected strong gamma-ray emission from the source. We present the main results obtained by the GASP at optical, mm, and radio frequencies in the 2008-2009 season, and compare them with the WEBT results from previous years. An optical outburst was observed to peak in mid July 2008, when Fermi detected the brightest gamma-ray levels. A contemporaneous mm outburst maintained its brightness for a longer time, until the cm emission also reached the maximum levels. The behaviour compared in the three bands suggests that the variable relative brightness of the different-frequency outbursts may be due to the changing orientation of a curved inhomogeneous jet. The optical light curve is very well sampled during the entire season, which is also well covered by the various AGILE and Fermi observing periods. The relevant cross-correlation studies will be very important in constraining high-energy emission models.",
    "MGT": "The blazar 3C 454.3 underwent a significant outburst across optical-to-radio and gamma-ray wavelengths in 2008, offering a unique opportunity to investigate the mechanisms driving its variable emission. This study presents the results of an extensive monitoring campaign conducted by the GLAST-AGILE Support Program (GASP) of the Whole Earth Blazar Telescope (WEBT), which provided comprehensive data coverage of the event. Our multi-wavelength approach included observations from ground-based optical and radio telescopes, complemented by gamma-ray data from space-based observatories. The optical monitoring revealed a pronounced flare, characterized by rapid variability and a peak luminosity exceeding previous records for 3C 454.3. Concurrent radio observations demonstrated correlated flux enhancements, suggesting a common origin of the emission in these bands. The gamma-ray observations from the Fermi Large Area Telescope (LAT) and AGILE confirmed a dramatic increase in high-energy activity, peaking shortly after the optical maximum.\n\nCorrelating these data across bands, we identified a temporal sequence in the outburst, with the optical and gamma-ray flares preceding the radio emission by several days. This indicates a shock-in-jet scenario, where disturbances propagate along the jet, triggering high-energy emission before affecting the more extended radio-emitting regions. Spectral analysis reveals significant spectral hardening during the flare, with a shift in the synchrotron peak frequency, further supporting the shock-in-jet model. Our findings also highlight the importance of seed photon fields in the inverse Compton scattering process, as changes in these fields were implicated in the gamma-ray variability. The 2008 outburst of 3C 454.3 underscores the complex interplay of physical processes in blazar jets and demonstrates the critical role of coordinated multi-wavelength observations in unraveling the dynamics of these enigmatic objects."
  },
  {
    "id": 49,
    "prompt": "Right sneutrinos and the signals of a stable stop at the Large Hadron Collider",
    "HWT": "We investigate charged tracks signals of a supersymmetric scenario, where the lighter stop is the next-to-lightest supersymmetric particle (NLSP). It is found that such an NLSP is stable on the scale of the detector at the LHC if one has a right-chiral sneutrino as the lightest supersymmetric particle (LSP). After identifying some benchmark points in the parameter space of a supergravity scenario with non-universal scalar masses, we study a few specific classes of signals, namely, stop pair production and gluino pair production followed by each decaying into a stop and a top. It is shown that proper kinematic cuts remove the backgrounds in each case, and, while a few months' worth of data is sufficient to have copious events in the first case, one may require 300 $fb^{-1}$ for the other. One can also aspire to reconstruct the gluino mass, using the `visible' stable NLSP tracks.",
    "MGT": "This study investigates the potential discovery signals of a stable stop (supersymmetric partner of the top quark) at the Large Hadron Collider (LHC) within the framework of models incorporating right-handed sneutrinos. The existence of right sneutrinos, predicted by several extensions of the Standard Model, could have profound implications for particle physics, providing candidates for dark matter and influencing the decay patterns of supersymmetric particles. We explore scenarios where the lightest supersymmetric particle (LSP) is a right sneutrino, resulting in the next-to-lightest supersymmetric particle (NLSP) being a long-lived stop. The analysis focuses on the distinctive signatures that a stable stop would produce in LHC detectors, emphasizing the challenges and strategies for detection amidst complex backgrounds. Employing simulations and current experimental constraints, we delineate parameter spaces where these particles could be observed. Our findings suggest that future LHC runs, with upgraded detection capabilities, could potentially confirm or rule out these theoretical models, thereby providing critical insights into the nature of dark matter and the supersymmetry-breaking mechanism."
  },
  {
    "id": 50,
    "prompt": "The Dynamics of Dense Cores in the Perseus Molecular Cloud II: The Relationship Between Dense Cores and the Cloud",
    "HWT": "We utilize the extensive datasets available for the Perseus molecular cloud to analyze the relationship between the kinematics of small-scale dense cores and the larger structures in which they are embedded. The kinematic measures presented here can be used in conjunction with those discussed in our previous work as strong observational constraints that numerical simulations (or analytic models) of star formation should match. We find that dense cores have small motions with respect to the 13CO gas, about one third of the 13CO velocity dispersion along the same line of sight. Within each extinction region, the core-to-core velocity dispersion is about half of the total (13CO) velocity dispersion seen in the region. Large-scale velocity gradients account for roughly half of the total velocity dispersion in each region, similar to what is predicted from large-scale turbulent modes following a power spectrum of P(k) ~ k^{-4}.",
    "MGT": "This study delves into the intricate dynamics of dense cores within the Perseus Molecular Cloud, building on previous analyses to further elucidate the relationship between these dense cores and their encompassing cloud environment. Utilizing high-resolution spectral data from recent radio observations, we examine the physical properties and kinematic behaviors of dense cores, exploring their formation, evolution, and potential for star formation. Our findings indicate that the interaction between the dense cores and the broader cloud structure plays a crucial role in the accretion processes and angular momentum redistribution. By employing a combination of observational data and numerical simulations, we identify key factors influencing core stability and fragmentation. Moreover, we observe that the relative motions between dense cores and their surrounding cloud material significantly impact core lifetime and mass distribution. This research contributes to a deeper understanding of the initial conditions for star formation and the complex interplay between dense cores and molecular clouds, offering insights into the lifecycle of interstellar matter."
  },
  {
    "id": 51,
    "prompt": "Towards a Maximal Mass Model",
    "HWT": "We investigate the possibility to construct a generalization of the Standard Model, which we call the Maximal Mass Model because it contains a limiting mass $M$ for its fundamental constituents. The parameter $M$ is considered as a new universal physical constant of Nature and therefore is called the fundamental mass. It is introduced in a purely geometrical way, like the velocity of light as a maximal velocity in the special relativity. If one chooses the Euclidean formulation of quantum field theory, the adequate realization of the limiting mass hypothesis is reduced to the choice of the de Sitter geometry as the geometry of the 4-momentum space. All fields, defined in de Sitter p-space in configurational space obey five dimensional Klein-Gordon type equation with fundamental mass $M$ as a mass parameter. The role of dynamical field variables is played by the Cauchy initial conditions given at $x_5 = 0$, guarantying the locality and gauge invariance principles. The corresponding to the geometrical requirements formulation of the theory of scalar, vector and spinor fields is considered in some detail. On a simple example it is demonstrated that the spontaneously symmetry breaking mechanism leads to renormalization of the fundamental mass $M$. A new geometrical concept of the chirality of the fermion fields is introduced. It would be responsible for new measurable effects at high energies $E \\geq M$. Interaction terms of a new type, due to the existence of the Higgs boson are revealed. The most intriguing prediction of the new approach is the possible existence of exotic fermions with no analogues in the SM, which may be candidate for dark matter constituents.",
    "MGT": "In the quest to understand the fundamental limits of matter and energy, the concept of maximal mass presents a pivotal frontier in theoretical physics. This paper introduces an innovative framework for exploring maximal mass models, which pushes the boundaries of existing gravitational and quantum mechanical principles. The study begins by revisiting the classical theories of mass, notably those rooted in Einstein’s General Relativity and quantum field theory, to identify the constraints that define the upper limits of mass for celestial objects. Traditional models, while robust, face limitations when addressing phenomena such as supermassive black holes and other hypothetical massive entities beyond current observational capabilities.\n\nWe propose a novel approach that synthesizes elements of string theory, holographic principles, and loop quantum gravity to conceptualize a maximal mass model that transcends these limitations. By integrating these advanced theoretical constructs, our model accounts for higher-dimensional interactions and the role of dark matter and dark energy in influencing mass limits. The research incorporates mathematical simulations to demonstrate the potential configurations and scenarios that support such massive states, highlighting the conditions under which they might form, persist, or destabilize.\n\nPreliminary results suggest the existence of a critical mass threshold, beyond which conventional physics may break down, offering insights into the nature of singularities and the possible existence of new states of matter. The implications of this model could redefine our understanding of cosmological structures and the lifecycle of massive astronomical entities. This paper concludes by outlining the theoretical and observational challenges ahead, emphasizing the need for refined technologies and collaborative international efforts to validate or refute the predictions of this maximal mass framework. As we advance towards a more comprehensive understanding of the universe's mass dynamics, this maximal mass model invites a reevaluation of established paradigms and encourages further exploration into the unseen extremes of the cosmos."
  },
  {
    "id": 52,
    "prompt": "3-He in the Milky Way Interstellar Medium: Ionization Structure",
    "HWT": "The cosmic abundance of the 3-He isotope has important implications for many fields of astrophysics. We are using the 8.665 GHz hyperfine transition of 3-He+ to determine the 3-He/H abundance in Milky Way HII regions and planetary nebulae. This is one in a series of papers in which we discuss issues involved in deriving accurate 3-He/H abundance ratios from the available measurements. Here we describe the ionization correction we use to convert the 3-He+/H+ abundance, y3+, to the 3-He/H abundance, y3. In principle the nebular ionization structure can significantly influence the y3 derived for individual sources. We find that in general there is insufficient information available to make a detailed ionization correction. Here we make a simple correction and assess its validity. The correction is based on radio recombination line measurements of H+ and 4-He+, together with simple core-halo source models. We use these models to establish criteria that allow us to identify sources that can be accurately corrected for ionization and those that cannot. We argue that this effect cannot be very large for most of the sources in our observational sample. For a wide range of models of nebular ionization structure we find that the ionization correction factor varies from 1 to 1.8. Although large corrections are possible, there would have to be a conspiracy between the density and ionization structure for us to underestimate the ionization correction by a substantial amount.",
    "MGT": "The ionization structure of helium-3 (³He) in the interstellar medium (ISM) of the Milky Way provides critical insights into cosmic nucleosynthesis, stellar evolution, and the dynamics of galactic processes. This study examines the distribution and ionization states of ³He across various phases of the ISM, including molecular clouds, diffuse atomic regions, and ionized zones. Using high-resolution spectroscopic observations complemented by theoretical models of ionization equilibrium, we analyze the abundance ratio of ³He⁺ to ³He relative to hydrogen and other isotopes. Results indicate that the ionization fraction of ³He is strongly influenced by local conditions, such as ultraviolet radiation fields, cosmic ray fluxes, and the presence of nearby stellar winds or supernova remnants. In diffuse ionized regions, ³He⁺ is the dominant form, driven by photoionization from hot stars, whereas neutral ³He is prevalent in molecular clouds shielded from external radiation. A comparison of ³He ionization structures across different ISM environments suggests a strong correlation with metallicity gradients and galactic latitude, reflecting the historical enrichment of ³He by asymptotic giant branch (AGB) stars and other stellar processes. Additionally, this study highlights the role of cosmic rays in sustaining non-equilibrium ionization states in the ISM, offering new constraints on cosmic ray propagation models. These findings refine our understanding of ³He as a tracer of galactic chemical evolution and provide a framework for future investigations into isotopic variations across the Milky Way. The implications extend to broader studies of isotope production and destruction in the universe, advancing models of stellar and galactic lifecycle processes."
  },
  {
    "id": 53,
    "prompt": "A Hybrid Mechanism Forming a 2:1 Librating-Circulating Resonant Configuration in the Planetary System",
    "HWT": "A diversity of resonance configurations may be formed under different migration of two giant planets. And the researchers show that the HD 128311 and HD 73526 planetary systems are involved in a 2:1 mean motion resonance but not in apsidal corotation, because one of the resonance argument circulates over the dynamical evolution. In this paper, we investigate potential mechanisms to form the 2:1 librating-circulating resonance configuration. In the late stage of planetary formation, scattering or colliding among planetesimals and planetary embryos can frequently occur. Hence, in our model, we consider a planetary configuration of two giants together with few terrestrial planets. We find that both colliding or scattering events at very early stage of dynamical evolution can influence the configurations trapped into resonance. A planet-planet scattering of a moderate terrestrial planet, or multiple scattering of smaller planets in a crowded planetary system can change the resonant configuration. In addition, collision or merging can alter the masses and location of the giant planets, which also play an important role in shaping the resonant configuration during the dynamical evolution. In this sense, the librating-circulating resonance configuration is more likely to form by a hybrid mechanism of scattering and collision.",
    "MGT": "In this study, we explore a novel hybrid mechanism that leads to the formation of a 2:1 librating-circulating resonant configuration within a planetary system. Resonant configurations in multi-body systems are pivotal in understanding the dynamical evolution and long-term stability of planetary systems. Traditional resonance theories predominantly focus on either libration or circulation of resonant angles; however, this research unveils a hybrid mechanism that incorporates both dynamics, offering a comprehensive insight into resonance behavior. Utilizing numerical simulations and analytical models, we demonstrate how this hybrid mechanism manifests in a hypothetical planetary system with two giant exoplanets. The results reveal a significant range of initial conditions leading to the 2:1 librating-circulating resonance, highlighting the robustness of this configuration under varying planetary masses and orbital parameters. Our findings suggest that such hybrid resonant dynamics could be more prevalent in exoplanetary systems than previously anticipated, potentially affecting the observed orbital architectures. Furthermore, the study underscores the necessity of revisiting existing systems with this new framework to better understand their dynamical states. This research not only enhances our comprehension of resonant phenomena in celestial mechanics but also provides a foundation for future investigations into the complex interactions governing the architecture of planetary systems."
  },
  {
    "id": 54,
    "prompt": "Decidability properties for fragments of CHR",
    "HWT": "We study the decidability of termination for two CHR dialects which, similarly to the Datalog like languages, are defined by using a signature which does not allow function symbols (of arity >0). Both languages allow the use of the = built-in in the body of rules, thus are built on a host language that supports unification. However each imposes one further restriction. The first CHR dialect allows only range-restricted rules, that is, it does not allow the use of variables in the body or in the guard of a rule if they do not appear in the head. We show that the existence of an infinite computation is decidable for this dialect. The second dialect instead limits the number of atoms in the head of rules to one. We prove that in this case, the existence of a terminating computation is decidable. These results show that both dialects are strictly less expressive than Turing Machines. It is worth noting that the language (without function symbols) without these restrictions is as expressive as Turing Machines.",
    "MGT": "Constraint Handling Rules (CHR) is a declarative programming language and formalism designed for writing constraint solvers. Due to its flexibility and expressiveness, CHR has been extensively studied in theoretical computer science, particularly concerning its computational properties and logical foundations. In this paper, we investigate decidability properties of several fragments of CHR, aiming to classify subsets of the language based on their computational behavior and theoretical tractability. Specifically, we focus on identifying fragments where key questions such as termination, confluence, and applicability of rules remain decidable. By leveraging techniques from term rewriting systems, formal languages, and automata theory, we analyze structural restrictions on CHR programs that ensure decidability. Our results demonstrate that certain fragments defined by syntactic constraints—such as limited rule arity, bounded variable usage, or stratified rule dependencies—preserve decidability for critical properties. Conversely, we show that relaxing these restrictions often leads to undecidability, highlighting the delicate balance between expressiveness and computational feasibility in CHR. These findings contribute to a deeper understanding of the theoretical boundaries of CHR and provide practical guidance for designing constraint solvers with predictable behavior. The study also opens avenues for further exploration of decidability in other declarative programming paradigms."
  },
  {
    "id": 55,
    "prompt": "Temperature and fluence dependence of ultrafast phase separation dynamics in Pr0.6Ca0.4MnO3 thin films",
    "HWT": "Temperature and fluence dependence of the transient photoinduced reflectivity and the magnetooptical Kerr angle was measured in two Pr0.6Ca0.4MnO3 thin films subject to tensile and compressive substrate-induced strain. A photoinduced transient ferromagnetic metallic (TFM) phase is found to form below ~60K and ~40K in the substrate-strained and substrate-compressed film, respectively. From the hysteresis loops a difference in the TFM cluster sizes and amount of photomodulation is observed at low temperatures and low excitation fluences in the films with different strain. Surprisingly, the characteristic timescale for the TFM phase photomodulation is virtually strain independent. At high excitation fluences, the cluster sizes and amount of photomodulation are independent on the substrate-induced strain.",
    "MGT": "This study investigates the ultrafast phase separation dynamics in Pr\\(_{0.6}\\)Ca\\(_{0.4}\\)MnO\\(_3\\) (PCMO) thin films, focusing on the influence of temperature and laser fluence. Using femtosecond pump-probe spectroscopy, we explore the transient changes in the electronic and structural phases under varying thermal conditions and excitation intensities. Results indicate a pronounced dependence of phase separation dynamics on temperature, with distinct regimes identified at different thermal thresholds. Additionally, the fluence-dependent measurements reveal critical thresholds that dictate the transition kinetics and the stabilization of intermediate phases. These findings provide insight into the complex interplay between electronic correlations and lattice distortions in PCMO, advancing our understanding of phase control in correlated electron systems. Potential applications in ultrafast optical switching devices are also discussed."
  },
  {
    "id": 56,
    "prompt": "Confinement of electrons in size modulated silicon nanowires",
    "HWT": "Based on first-principles calculations we showed that superlattices of periodically repeated junctions of hydrogen saturated silicon nanowire segments having different lengths and diameters form multiple quantum well structures. The band gap of the superlattice is modulated in real space as its diameter does and results in a band gap in momentum space which is different from constituent nanowires. Specific electronic states can be confined in either narrow or wide regions of superlattice. The type of the band lineup and hence the offsets of valence and conduction bands depend on the orientation of the superlattice as well as on the diameters of the constituent segments. Effects of the SiH vacancy and substitutional impurities on the electronic and magnetic properties have been investigated by carrying out spin-polarized calculations. Substitutional impurities with localized states near band edges can make modulation doping possible. Stability of the superlattice structure was examined by ab initio molecular dynamics calculations at high temperatures.",
    "MGT": "The confinement of electrons in size-modulated silicon nanowires (SiNWs) presents a promising avenue for the development of nanoscale electronic and optoelectronic devices. In this study, we investigate the electronic properties of SiNWs with periodic modulations in diameter, using advanced computational modeling and experimental techniques. Our findings reveal that the modulation in wire dimensions induces quantum confinement effects, leading to distinct energy band structures and localized electron states. The interplay between geometric modulation and quantum confinement enhances carrier localization and alters the effective bandgap, enabling tunability of electronic and optical properties. Furthermore, the study demonstrates the critical role of modulation parameters, including periodicity and amplitude, in tailoring electron confinement and transport characteristics. These insights offer a pathway for engineering SiNW-based devices with customized electronic functionalities, such as quantum dots, transistors, and photodetectors. The results hold significant promise for the integration of silicon nanowires into next-generation, high-performance nanoscale systems while leveraging their compatibility with existing semiconductor technologies."
  },
  {
    "id": 57,
    "prompt": "Constraining the LRG Halo Occupation Distribution using Counts-in-Cylinders",
    "HWT": "The low number density of the Sloan Digital Sky Survey (SDSS) Luminous Red Galaxies (LRGs) suggests that LRGs occupying the same dark matter halo can be separated from pairs occupying distinct dark matter halos with high fidelity. We present a new technique, Counts-in-Cylinders (CiC), to constrain the parameters of the satellite contribution to the LRG Halo-Occupation Distribution (HOD). For a fiber collision-corrected SDSS spectroscopic LRG subsample at 0.16 < z < 0.36, we find the CiC multiplicity function is fit by a halo model where the average number of satellites in a halo of mass M is <Nsat(M)> = ((M - Mcut)/M1)^alpha with Mcut = 5.0 +1.5/-1.3 (+2.9/-2.6) X 10^13 Msun, M1 = 4.95 +0.37/-0.26 (+0.79/-0.53) X 10^14 Msun, and alpha = 1.035 +0.10/-0.17 (+0.24/-0.31) at the 68% and 95% confidence levels using a WMAP3 cosmology and z=0.2 halo catalog. Our method tightly constrains the fraction of LRGs that are satellite galaxies, 6.36 +0.38/-0.39, and the combination Mcut/10^{14} Msun + alpha = 1.53 +0.08/-0.09 at the 95% confidence level. We also find that mocks based on a halo catalog produced by a spherical overdensity (SO) finder reproduce both the measured CiC multiplicity function and the projected correlation function, while mocks based on a Friends-of-Friends (FoF) halo catalog has a deficit of close pairs at ~1 Mpc/h separations. Because the CiC method relies on higher order statistics of close pairs, it is robust to the choice of halo finder. In a companion paper we will apply this technique to optimize Finger-of-God (FOG) compression to eliminate the 1-halo contribution to the LRG power spectrum.",
    "MGT": "We present a novel approach to constraining the halo occupation distribution (HOD) of luminous red galaxies (LRGs) using counts-in-cylinders (CiC) statistics. The HOD framework is a powerful tool for modeling the connection between galaxies and their dark matter halos, offering insights into galaxy formation and the large-scale structure of the universe. Traditionally, HOD parameters are constrained using two-point clustering statistics; however, these methods can struggle to capture higher-order effects and small-scale clustering features. In this study, we leverage CiC—an alternative statistic that quantifies the number of galaxies within cylindrical volumes defined by a projected radius and line-of-sight depth—to provide complementary constraints on LRG populations.\n\nUsing data from the Sloan Digital Sky Survey (SDSS) and mock catalogs generated from N-body simulations, we calculate CiC distributions across a range of cylinder dimensions to probe the spatial configurations and multiplicity of LRGs within dark matter halos. Incorporating these measurements into a Markov Chain Monte Carlo (MCMC) framework, we constrain key HOD parameters, including the minimum halo mass for central galaxy occupation, the satellite fraction, and the scale of satellite clustering. Our results demonstrate that CiC statistics are particularly sensitive to the satellite occupation function, allowing us to break degeneracies present in clustering-based analyses.\n\nComparisons between CiC-derived constraints and those obtained from traditional two-point correlation functions reveal consistent results, while highlighting the added sensitivity of CiC to small-scale halo substructure. Furthermore, we show that CiC can provide robust constraints even in observational scenarios with incomplete or noisy data, underscoring its utility for future galaxy surveys. These findings establish counts-in-cylinders as a valuable complement to standard methods for modeling the galaxy-halo connection, paving the way for more precise characterizations of LRG populations and their role in cosmic structure formation. This work also opens opportunities to extend CiC applications to broader galaxy samples and alternative clustering metrics."
  },
  {
    "id": 58,
    "prompt": "Three-Dimensional Simulations of Mixing Instabilities in Supernova Explosions",
    "HWT": "We present the first three-dimensional (3D) simulations of the large-scale mixing that takes place in the shock-heated stellar layers ejected in the explosion of a 15.5 solar-mass blue supergiant star. The outgoing supernova shock is followed from its launch by neutrino heating until it breaks out from the stellar surface more than two hours after the core collapse. Violent convective overturn in the post-shock layer causes the explosion to start with significant asphericity, which triggers the growth of Rayleigh-Taylor (RT) instabilities at the composition interfaces of the exploding star. Deep inward mixing of hydrogen (H) is found as well as fast-moving, metal-rich clumps penetrating with high velocities far into the H-envelope of the star as observed, e.g., in the case of SN 1987A. Also individual clumps containing a sizeable fraction of the ejected iron-group elements (up to several 0.001 solar masses) are obtained in some models. The metal core of the progenitor is partially turned over with Ni-dominated fingers overtaking oxygen-rich bullets and both Ni and O moving well ahead of the material from the carbon layer. Comparing with corresponding 2D (axially symmetric) calculations, we determine the growth of the RT fingers to be faster, the deceleration of the dense metal-carrying clumps in the He and H layers to be reduced, the asymptotic clump velocities in the H-shell to be higher (up to ~4500 km/s for the considered progenitor and an explosion energy of 10^{51} ergs, instead of <2000 km/s in 2D), and the outward radial mixing of heavy elements and inward mixing of hydrogen to be more efficient in 3D than in 2D. We present a simple argument that explains these results as a consequence of the different action of drag forces on moving objects in the two geometries. (abridged)",
    "MGT": "Supernova explosions, among the most energetic events in the universe, play a pivotal role in the synthesis of heavy elements and their redistribution into the interstellar medium. These explosive phenomena are inherently multidimensional, driven by a complex interplay of hydrodynamic instabilities, nuclear reactions, and turbulence. In this study, we present three-dimensional simulations to investigate mixing instabilities in core-collapse supernovae. Using state-of-the-art computational models, we analyze the development and evolution of Rayleigh-Taylor (RT) and Kelvin-Helmholtz (KH) instabilities, which arise during the explosive phase as shock waves propagate outward through the progenitor star's stratified layers. \n\nOur simulations employ high-resolution adaptive mesh refinement techniques to capture the fine-scale structures of mixing and turbulent flows, ensuring accurate representation of the physical processes at play. We focus on the interaction between the expanding shock front and the progenitor's density gradients, which triggers non-linear growth of instabilities, leading to the fragmentation and mixing of material. Additionally, we examine the role of asymmetries in the explosion mechanism, such as neutrino-driven convection and the standing accretion shock instability (SASI), in amplifying these mixing processes.\n\nThe results reveal intricate three-dimensional structures that significantly impact the spatial distribution of heavy elements, including iron-group nuclei and radioactive isotopes like nickel-56. The simulations show that mixing instabilities facilitate the outward transport of these elements, which influence observable features such as supernova light curves and spectral lines. Furthermore, we find that the degree of mixing is sensitive to initial explosion asymmetries and progenitor star characteristics, highlighting the importance of multidimensional modeling in capturing these effects.\n\nThis work advances our understanding of mixing instabilities in supernova explosions and their role in shaping the chemical evolution of galaxies. By providing insights into the mechanisms driving element redistribution, our findings offer valuable constraints for interpreting supernova observations and refining theoretical models of stellar explosions."
  },
  {
    "id": 59,
    "prompt": "Bayesian orthogonal component analysis for sparse representation",
    "HWT": "This paper addresses the problem of identifying a lower dimensional space where observed data can be sparsely represented. This under-complete dictionary learning task can be formulated as a blind separation problem of sparse sources linearly mixed with an unknown orthogonal mixing matrix. This issue is formulated in a Bayesian framework. First, the unknown sparse sources are modeled as Bernoulli-Gaussian processes. To promote sparsity, a weighted mixture of an atom at zero and a Gaussian distribution is proposed as prior distribution for the unobserved sources. A non-informative prior distribution defined on an appropriate Stiefel manifold is elected for the mixing matrix. The Bayesian inference on the unknown parameters is conducted using a Markov chain Monte Carlo (MCMC) method. A partially collapsed Gibbs sampler is designed to generate samples asymptotically distributed according to the joint posterior distribution of the unknown model parameters and hyperparameters. These samples are then used to approximate the joint maximum a posteriori estimator of the sources and mixing matrix. Simulations conducted on synthetic data are reported to illustrate the performance of the method for recovering sparse representations. An application to sparse coding on under-complete dictionary is finally investigated.",
    "MGT": "Bayesian orthogonal component analysis (BOCA) is a novel statistical framework designed to address the challenges of sparse representation in high-dimensional data. Traditional component analysis methods, such as principal component analysis (PCA), often fail to incorporate sparsity and probabilistic uncertainty, limiting their applicability in scenarios where data exhibit complex structures or noise. BOCA integrates Bayesian inference with orthogonal constraints to achieve a sparse and interpretable representation of data while maintaining computational efficiency. By leveraging a hierarchical Bayesian model, BOCA imposes sparsity-inducing priors on the components, encouraging the identification of a minimal set of representative features. The orthogonality constraint ensures the components remain linearly independent, reducing redundancy and enhancing interpretability. This framework accounts for uncertainty in the data and model parameters, providing robust estimates and credible intervals for the derived components. We validate BOCA on synthetic and real-world datasets, demonstrating its superior performance in achieving sparse decompositions compared to existing methods. Results highlight BOCA’s ability to reconstruct data accurately, identify meaningful patterns, and handle noise effectively. Applications in domains such as image processing, genomics, and text analysis underscore its versatility and potential for advancing sparse representation techniques. BOCA represents a significant step forward in Bayesian approaches to component analysis, offering a powerful tool for researchers and practitioners alike."
  },
  {
    "id": 60,
    "prompt": "An analysis of the nucleon spectrum from lattice partially-quenched QCD",
    "HWT": "The chiral extrapolation of the nucleon mass, M_n, is investigated using data coming from 2-flavour partially-quenched lattice simulations. A large sample of lattice results from the CP-PACS Collaboration is analysed using the leading one-loop corrections, with explicit corrections for finite lattice spacing artifacts. The extrapolation is studied using finite range regularised chiral perturbation theory. The analysis also provides a quantitative estimate of the leading finite volume corrections. It is found that the discretisation, finite-volume and partial quenching effects can all be very well described in this framework, producing an extrapolated value of M_n in agreement with experiment. Furthermore, determinations of the low energy constants of the nucleon mass's chiral expansion are in agreement with previous methods, but with significantly reduced errors. This procedure is also compared with extrapolations based on polynomial forms, where the results are less encouraging.",
    "MGT": "This study presents a detailed analysis of the nucleon spectrum using lattice partially-quenched quantum chromodynamics (QCD). The investigation employs a computational framework where valence and sea quarks are treated with differing masses, enabling a systematic exploration of partially-quenched dynamics. By utilizing state-of-the-art lattice configurations and advanced spectral extraction techniques, we probe the mass hierarchy and structural properties of nucleons across various quark mass regimes. The partially-quenched approach provides unique insights into the interplay between quark confinement and chiral symmetry breaking, facilitating comparisons with full QCD and experimental data. Results reveal subtle dependencies of nucleon masses on quark mass variations and highlight deviations from predictions of traditional effective field theories. Additionally, the study discusses the implications of these findings for hadron phenomenology, lattice calibration, and future precision calculations. This work contributes to the broader understanding of nucleon structure and demonstrates the utility of partially-quenched frameworks in advancing lattice QCD methodologies."
  },
  {
    "id": 61,
    "prompt": "Single-photon cooling at the limit of trap dynamics: Maxwell's Demon near maximum efficiency",
    "HWT": "We demonstrate a general and efficient informational cooling technique for atoms which is an experimental realization of a one-dimensional Maxwell's Demon. The technique transfers atoms from a magnetic trap into an optical trap via a single spontaneous Raman transition which is discriminatively driven near each atom's classical turning point. In this way, nearly all of the atomic ensemble's kinetic energy in one dimension is removed. We develop a simple analytical model to predict the efficiency of transfer between the traps and provide evidence that the performance is limited only by particle dynamics in the magnetic trap. Transfer efficiencies up to 2.2% are reported. We show that efficiency can be traded for phase-space compression, and we report compression up to a factor of 350. Our results represent a 15-fold improvement over our previous demonstration of the cooling technique.",
    "MGT": "In this study, we explore the theoretical and experimental advancements in single-photon cooling within the constraints of trap dynamics, drawing parallels to Maxwell's Demon operating near its maximum efficiency. By leveraging cutting-edge quantum optics techniques, we demonstrate that single-photon interactions can significantly enhance cooling processes, pushing the limits of thermodynamic efficiency. Our research elucidates the role of trap dynamics in optimizing the cooling cycle, where the manipulation of quantum states allows for unprecedented control over energy transfer processes. We employ a combination of quantum feedback protocols and state-of-the-art trap technology to achieve cooling rates that closely approach the theoretical maximum predicted by thermodynamic laws. This work not only presents a substantial leap in quantum cooling technologies but also provides insights into the fundamental limits of energy manipulation at the quantum level. The implications of our findings extend to a wide range of applications, from quantum computing to precision measurement technologies, marking a substantial step toward achieving near-ideal energy efficiency in quantum systems."
  },
  {
    "id": 62,
    "prompt": "Evidence for primordial mass segregation in globular clusters",
    "HWT": "We have studied the dissolution of initially mass segregated and unsegregated star clusters due to two-body relaxation in external tidal fields, using Aarseth's collisional N-body code NBODY4 on GRAPE6 special-purpose computers. When extrapolating results of initially not mass segregated models to globular clusters, we obtain a correlation between the time until destruction and the slope of the mass function, in the sense that globular clusters which are closer to dissolution are more strongly depleted in low-mass stars. This correlation fits observed mass functions of most globular clusters. The mass functions of several globular clusters are however more strongly depleted in low-mass stars than suggested by these models. Such strongly depleted mass functions can be explained if globular clusters started initially mass segregated. Primordial mass segregation also explains the correlation between the slope of the stellar mass function and the cluster concentration which was recently discovered by De Marchi et al. (2007). In this case, it is possible that all globular clusters started with a mass function similar to that seen in young open clusters in the present-day universe, at least for stars below m=0.8 Msun. This argues for a near universality of the mass function for different star formation environments and metallicities in the range -2 < [Fe/H] < 0. We finally describe a novel algorithm which can initialise stationary mass segregated clusters with arbitrary density profile and amount of mass segregation.",
    "MGT": "Globular clusters, densely packed collections of stars, have long been studied to understand the processes governing their formation and evolution. One intriguing aspect of these clusters is the phenomenon of mass segregation, where more massive stars are found preferentially towards the cluster's core, while less massive stars reside in the outer regions. Traditionally, mass segregation has been considered a dynamical process that occurs over time due to gravitational interactions. However, recent theoretical and observational studies suggest the possibility of primordial mass segregation, where the initial conditions of star formation in globular clusters inherently lead to this distribution. \n\nIn this study, we present new evidence supporting the hypothesis of primordial mass segregation in globular clusters. Utilizing high-resolution simulations alongside deep photometric and spectroscopic data from a sample of well-studied clusters, we analyze the spatial distribution and kinematic properties of stars across a wide range of masses. Our findings reveal consistent patterns of mass segregation that align with predictions from primordial models, challenging the traditional view that such segregation arises solely from dynamical evolution. We further explore the implications of these results for our understanding of the initial conditions required for globular cluster formation, as well as the broader context of star formation in the early universe. \n\nThis study not only provides compelling evidence for primordial mass segregation but also opens new avenues for investigating the formation and early evolution of globular clusters. Our results underscore the need to reconsider the role of initial conditions in shaping the observed properties of these ancient stellar systems, offering a novel perspective on their complex histories."
  },
  {
    "id": 63,
    "prompt": "Synchronization and entrainment of coupled circadian oscillators",
    "HWT": "Circadian rhythms in mammals are controlled by the neurons located in the suprachiasmatic nucleus of the hypothalamus. In physiological conditions, the system of neurons is very efficiently entrained by the 24-hour light-dark cycle. Most of the studies carried out so far emphasize the crucial role of the periodicity imposed by the light dark cycle in neuronal synchronization. Nevertheless, heterogeneity as a natural and permanent ingredient of these cellular interactions is seemingly to play a major role in these biochemical processes. In this paper we use a model that considers the neurons of the suprachiasmatic nucleus as chemically-coupled modified Goodwin oscillators, and introduce non-negligible heterogeneity in the periods of all neurons in the form of quenched noise. The system response to the light-dark cycle periodicity is studied as a function of the interneuronal coupling strength, external forcing amplitude and neuronal heterogeneity. Our results indicate that the right amount of heterogeneity helps the extended system to respond globally in a more coherent way to the external forcing. Our proposed mechanism for neuronal synchronization under external periodic forcing is based on heterogeneity-induced oscillators death, damped oscillators being more entrainable by the external forcing than the self-oscillating neurons with different periods.",
    "MGT": "Circadian rhythms are endogenous oscillations with a near-24-hour period that regulate a wide range of physiological and behavioral processes in living organisms. These rhythms are generated by molecular feedback loops within individual cells and are synchronized at the organismal level to ensure coherence and adaptability to environmental cues. In this study, we investigate the synchronization and entrainment dynamics of coupled circadian oscillators, using both mathematical modeling and experimental observations. We explore how intercellular coupling mechanisms, such as chemical signaling or gap junctions, influence the emergence of phase coherence among heterogeneous oscillators. The role of external zeitgebers, such as light-dark cycles, in entraining these coupled systems is analyzed, with particular attention to the interplay between internal coupling strength and external forcing. Our results reveal critical thresholds for synchronization and highlight the conditions under which phase desynchronization or arrhythmic behavior may occur. Furthermore, we identify distinct regimes of entrainment that depend on the amplitude and frequency of the external stimulus. These findings provide insights into the fundamental principles governing circadian network dynamics and have implications for understanding disorders of circadian misalignment, such as jet lag and shift work-related health problems. This work underscores the importance of coupling and entrainment in maintaining robust circadian rhythms across diverse biological systems."
  },
  {
    "id": 64,
    "prompt": "Coherent Cherenkov radio pulses from hadronic showers up to EeV energies",
    "HWT": "The Cherenkov radio pulse emitted by hadronic showers in ice is calculated for showers of energies in the EeV range. This is obtained with three dimensional simulations of both shower development and the coherent radio pulse emitted as the excess charge develops in the shower. A Monte Carlo, ZHAireS, has been developed for this purpose combining the high energy hadronic interaction capabilities of AIRES, and the dense media propagation capabilities of TIERRAS, with the precise low energy tracking and specific algorithms developed to calculate the radio emission in ZHS. A thinning technique is implemented and optimized to allow the simulation of radio pulses induced by showers up to 10 EeV in ice. The code is validated comparing the results for electromagnetic and hadronic showers to those obtained with GEANT4 and ZHS codes. The contribution to the pulse of other shower particles in addition to electrons and positrons, mainly pions and muons, is found to be below 1%. The characteristics of hadronic showers and the corresponding Cherenkov frequency spectra are compared with those from purely electromagnetic showers. The dependence of the spectra on shower energy and high-energy hadronic model is addressed and parameterizations for the radio emission in hadronic showers in ice are given for practical applications.",
    "MGT": "The study of coherent Cherenkov radio pulses generated by hadronic showers at energy scales reaching exaelectronvolts (EeV) is crucial for advancing our understanding of ultra-high-energy cosmic rays (UHECRs) and their interactions within Earth's atmosphere. This research investigates the mechanisms and characteristics of radio emissions produced during the development of hadronic showers, focusing on the coherent emission processes that facilitate the detection of these high-energy events. Utilizing advanced theoretical models and simulations, we analyze the generation, propagation, and coherence conditions of Cherenkov radio pulses in various atmospheric environments. Our findings demonstrate that at EeV energies, the Cherenkov radiation exhibits distinct temporal and spectral features that can be leveraged for improved detection and characterization of UHECRs. We explore the dependency of pulse coherence on factors such as shower geometry, particle composition, and interaction cross-sections, highlighting the role of specific hadronic interactions in enhancing radio pulse coherence. The results of this research not only contribute to the fundamental understanding of hadronic shower dynamics but also offer valuable insights for the development of next-generation radio detection arrays. By expanding the observational capabilities for UHECRs, these findings pave the way for more precise measurements of cosmic ray properties, shedding light on their sources and propagation mechanisms across vast cosmic distances."
  },
  {
    "id": 65,
    "prompt": "Angular Momentum Transport in Protoplanetary and Black-Hole Accretion Disks: The Role of Parasitic Modes in the Saturation of MHD Turbulence",
    "HWT": "The magnetorotational instability (MRI) is considered a key process for driving efficient angular momentum transport in astrophysical disks. Understanding its non-linear saturation constitutes a fundamental problem in modern accretion disk theory. The large dynamical range in physical conditions in accretion disks makes it challenging to address this problem only with numerical simulations. We analyze the concept that (secondary) parasitic instabilities are responsible for the saturation of the MRI. Our approach enables us to explore dissipative regimes that are relevant to astrophysical and laboratory conditions that lie beyond the regime accessible to current numerical simulations. We calculate the spectrum and physical structure of parasitic modes that feed off the fastest, exact (primary) MRI mode when its amplitude is such that the fastest parasitic mode grows as fast as the MRI. We argue that this \"saturation\" amplitude provides an estimate of the magnetic field that can be generated by the MRI before the secondary instabilities suppress its growth significantly. Recent works suggest that the saturation amplitude of the MRI depends mainly on the magnetic Prandtl number. Our results suggest that, as long as viscous effects do not dominate the fluid dynamics, the saturation level of the MRI depends only on the Elsasser number $\\Lambda_\\eta$. We calculate the ratio between the stress and the magnetic energy density, $\\alpha_{\\rm sat}\\beta_{\\rm sat}$, associated with the primary MRI mode. We find that for $\\Lambda_\\eta >1$ Kelvin-Helmholtz modes are responsible for saturation and $\\alpha_{\\rm sat}\\beta_{\\rm sat} = 0.4$, while for $\\Lambda_\\eta < 1$ tearing modes prevail and $\\alpha_{\\rm sat}\\beta_{\\rm sat} \\simeq 0.5 \\, \\Lambda_\\eta$. Several features of MRI simulations in accretion disks surrounding young stars and compact objects can be interpreted in terms of our findings.",
    "MGT": "In astrophysical systems, accretion disks around young stars and black holes are key environments for angular momentum transport, a process fundamental to their evolution and observational properties. Magnetohydrodynamic (MHD) turbulence, driven by the magnetorotational instability (MRI), is widely regarded as the primary mechanism enabling angular momentum redistribution in these disks. Despite significant progress in understanding MRI-driven turbulence, the saturation of this instability and the role of secondary, parasitic instabilities remain poorly quantified. This study investigates the interplay between primary MRI modes and parasitic instabilities, which compete for energy and influence the nonlinear state of MHD turbulence. Using high-resolution numerical simulations, we explore how parasitic modes, such as Kelvin–Helmholtz and tearing instabilities, emerge and evolve in both protoplanetary and black-hole accretion disks under varying physical conditions, including magnetic field strength and disk stratification.\n\nOur results reveal that parasitic modes significantly affect the saturation amplitude of the MRI and, consequently, the efficiency of angular momentum transport. We find that weak magnetic fields lead to stronger parasitic activity, suppressing the MRI and reducing turbulence intensity. Conversely, stronger magnetic fields promote MRI saturation with diminished parasitic competition, enhancing angular momentum transport. Furthermore, we show that the interplay between parasitic modes and MRI-driven turbulence varies with the disk's local magnetization and temperature gradients, which are distinct for protoplanetary versus black-hole accretion environments. In protoplanetary disks, parasitic modes contribute to a self-regulating mechanism, limiting turbulence and possibly affecting planet formation processes. In black-hole accretion disks, their influence is less pronounced but still impacts radiative and jet-launching phenomena.\n\nThis research highlights the critical role of parasitic instabilities in governing the nonlinear saturation of MRI turbulence and underscores the need for detailed modeling of these secondary processes in accretion disk studies. Our findings suggest that incorporating the dynamics of parasitic modes is essential for accurate predictions of angular momentum transport and the broader astrophysical implications of accretion disk evolution."
  },
  {
    "id": 66,
    "prompt": "Rebuttal to \"Comment by V. M. Krasnov on 'Counterintuitive consequence of heating in strongly-driven intrinsic junctions of Bi2Sr2CaCu2O8+d Mesas' \"",
    "HWT": "In our article [1], we found that with increasing dissipation there is a clear, systematic shift and sharpening of the conductance peak along with the disappearance of the higher-bias dip/hump features (DHF), for a stack of intrinsic Josephson junctions (IJJs) of intercalated Bi2Sr2CaCu2O8+{\\delta} (Bi2212). Our work agrees with Zhu et al [2] on unintercalated, pristine Bi2212, as both studies show the same systematic changes with dissipation. The broader peaks found with reduced dissipation [1,2] are consistent with broad peaks in the density-of-states (DOS) found among scanning tunneling spectroscopy [3] (STS), mechanical contact tunneling [4] (MCT) and inferred from angle (momentum) resolved photoemission spectroscopy [5] (ARPES); results that could not be ignored. Thus, sharp peaks are extrinsic and cannot correspond to the superconducting DOS. We suggested that the commonality of the sharp peaks in our conductance data, which is demonstrably shown to be heating-dominated, and the peaks of previous intrinsic tunneling spectroscopy (ITS) data implies that these ITS reports might need reinterpretation.",
    "MGT": "This article provides a detailed rebuttal to the critique presented by V. M. Krasnov regarding our original work, \"Counterintuitive consequence of heating in strongly-driven intrinsic junctions of Bi₂Sr₂CaCu₂O₈₊ₐ Mesas.\" Krasnov's comment challenges the interpretation of the thermal effects in intrinsic Josephson junctions under high current densities, asserting alternative mechanisms that purportedly account for the observed phenomena. In this rebuttal, we systematically address the points raised in Krasnov's critique, emphasizing both theoretical consistency and experimental evidence supporting our original conclusions. By re-examining the thermal modeling, we demonstrate that the peculiar behavior observed in the Bi₂Sr₂CaCu₂O₈₊ₐ mesas is indeed a direct consequence of localized heating effects rather than the mechanisms proposed by Krasnov. Additionally, we present supplementary experimental data that validate the robustness of our original analysis and further underscore the significance of thermal management in strongly-driven intrinsic junctions. Our findings reaffirm that heating plays a pivotal role in altering the physical properties of these systems, leading to counterintuitive results that are consistent with established principles of thermal and electrical transport in high-temperature superconductors. This rebuttal not only clarifies misconceptions raised in Krasnov's comment but also strengthens the understanding of thermal effects in intrinsic junctions, paving the way for further advancements in mesoscopic superconducting devices."
  },
  {
    "id": 67,
    "prompt": "Temperature dependent sound velocity in hydrodynamic equations for relativistic heavy-ion collisions",
    "HWT": "We analyze the effects of different forms of the sound-velocity function cs(T) on the hydrodynamic evolution of matter formed in the central region of relativistic heavy-ion collisions. At high temperatures (above the critical temperature Tc) the sound velocity is calculated from the recent lattice simulations of QCD, while in the low temperature region it is obtained from the hadron gas model. In the intermediate region we use different interpolations characterized by the values of the sound velocity at the local maximum (at T = 0.4 Tc) and local minimum (at T = Tc). In all considered cases the temperature dependent sound velocity functions yield the entropy density, which is consistent with the lattice QCD simulations at high temperature. Our calculations show that the presence of a distinct minimum of the sound velocity leads to a very long (about 20 fm/c) evolution time of the system, which is not compatible with the recent estimates based on the HBT interferometry. Hence, we conclude that the hydrodynamic description is favored in the case where the cross-over phase transition renders the smooth sound velocity function with a possible shallow minimum at Tc.",
    "MGT": "The study of relativistic heavy-ion collisions provides critical insights into the properties of the quark-gluon plasma (QGP), a state of matter characterized by deconfined quarks and gluons. In this work, we investigate the role of temperature-dependent sound velocity in the hydrodynamic evolution of the QGP. The sound velocity, a thermodynamic quantity directly connected to the equation of state, significantly influences the expansion dynamics and observables in heavy-ion collisions. By incorporating a temperature-dependent sound velocity derived from lattice QCD calculations into relativistic hydrodynamic equations, we perform numerical simulations for collisions at various beam energies. Our results demonstrate that the non-trivial temperature dependence of the sound velocity affects the pressure gradients, leading to modifications in the collective flow and particle spectra. In particular, we observe notable changes in radial flow and anisotropic flow coefficients compared to simulations with a constant sound velocity. These effects are more pronounced at lower beam energies, where the system spends more time in the hadronic phase. Furthermore, we analyze the implications of this temperature dependence on the extraction of transport coefficients, such as the shear viscosity to entropy density ratio. Our findings underscore the importance of accurately modeling the equation of state and its thermodynamic properties to improve the quantitative understanding of QGP dynamics in heavy-ion collisions."
  },
  {
    "id": 68,
    "prompt": "Energy spectra of cosmic-ray nuclei at high energies",
    "HWT": "We present new measurements of the energy spectra of cosmic-ray (CR) nuclei from the second flight of the balloon-borne experiment Cosmic Ray Energetics And Mass (CREAM). The instrument included different particle detectors to provide redundant charge identification and measure the energy of CRs up to several hundred TeV. The measured individual energy spectra of C, O, Ne, Mg, Si, and Fe are presented up to $\\sim 10^{14}$ eV. The spectral shape looks nearly the same for these primary elements and it can be fitted to an $E^{-2.66 \\pm 0.04}$ power law in energy. Moreover, a new measurement of the absolute intensity of nitrogen in the 100-800 GeV/$n$ energy range with smaller errors than previous observations, clearly indicates a hardening of the spectrum at high energy. The relative abundance of N/O at the top of the atmosphere is measured to be $0.080 \\pm 0.025 $(stat. )$ \\pm 0.025 $(sys. ) at $\\sim $800 GeV/$n$, in good agreement with a recent result from the first CREAM flight.",
    "MGT": "The energy spectra of cosmic-ray nuclei at high energies provide critical insights into the origins, propagation, and interactions of cosmic rays in the universe. This study investigates the spectral behavior of cosmic-ray nuclei, focusing on their flux measurements across a wide energy range. Utilizing data from advanced particle detectors and space-based observatories, we analyze the energy-dependent composition of cosmic rays, including contributions from primary and secondary nuclei. The results reveal distinct spectral features, such as power-law distributions and spectral breaks, which are indicative of acceleration mechanisms in astrophysical sources and the effects of diffusive propagation through the interstellar medium. Furthermore, the study examines the role of spallation processes and magnetic field interactions in shaping the observed spectra. Comparisons with theoretical models of galactic cosmic-ray transport highlight key discrepancies and areas for refinement. The findings suggest that high-energy cosmic-ray nuclei originate predominantly from supernova remnants and other energetic phenomena, while intergalactic propagation introduces significant modifications to their energy profiles. By elucidating these mechanisms, this work contributes to a deeper understanding of the high-energy cosmic-ray spectrum and its implications for astrophysical processes. Future research directions include improved spectral measurements at ultrahigh energies and enhanced modeling of cosmic-ray acceleration and propagation in complex astrophysical environments."
  },
  {
    "id": 69,
    "prompt": "The enigma of GCIRS 3 - Constraining the properties of the mid-infrared reference star of the central parsec of the Milky Way with optical long baseline interferometry",
    "HWT": "GCIRS3 is the most prominent MIR source in the central pc of the Galaxy. NIR spectroscopy failed to solve the enigma of its nature. The properties of extreme individual objects of the central stellar cluster contribute to our knowledge of star and dust formation close to a supermassive black hole. We initiated an interferometric experiment to understand IRS3 and investigate its properties as spectroscopic and interferometric reference star at 10um. VISIR imaging separates a compact source from diffuse, surrounding emission. The VLTI/MIDI instrument was used to measure visibilities at 10mas resolution of that compact 10um source, still unresolved by a single VLT. Photometry data were added to enable simple SED- and full radiative transfer-models of the data. The luminosity and size estimates show that IRS3 is probably a cool carbon star enshrouded by a complex dust distribution. Dust temperatures were derived. The coinciding interpretation of multiple datasets confirm dust emission at several spatial scales. The IF data resolve the innermost area of dust formation. Despite observed deep silicate absorption towards IRS3 we favor a carbon rich chemistry of the circumstellar dust shell. The silicate absorption most probably takes place in the outer diffuse dust, which is mostly ignored by MIDI measurements. This indicates physically and chemically distinct conditions of the local dust, changing with the distance to IRS3. We have demonstrated that optical long baseline interferometry at infrared wavelengths is an indispensable tool to investigate sources at the Galactic Center. Our findings suggest further studies of the composition of interstellar dust and the shape of the 10um silicate feature at this outstanding region.",
    "MGT": "In the quest to unravel the enigmatic nature of GCIRS 3, the prominent mid-infrared reference star located within the central parsec of the Milky Way, this study employs optical long baseline interferometry to derive its fundamental properties. GCIRS 3 has long captivated astronomers due to its unique position and potential role in the dynamics of the Galactic Center. Despite its prominence, its physical characteristics have remained elusive, prompting this investigation to provide new insights into its nature. Utilizing the precision of optical long baseline interferometry, we have been able to dissect the star's spatial structure with unprecedented resolution. Our observations reveal a complex morphology, suggesting that GCIRS 3 is not a simple point source but possibly a binary or a more intricate system. \n\nWe present measurements of the star's diameter, effective temperature, and luminosity, benchmarking these against theoretical models to refine our understanding of its evolutionary status. The derived parameters suggest that GCIRS 3 is a massive star in a relatively advanced evolutionary stage, potentially a red supergiant or a luminous blue variable. Furthermore, the surrounding environment exhibits significant dust emission, implicating active mass-loss processes and interactions with the dense interstellar medium of the Galactic Center. \n\nThe implications of these findings are profound, offering a recalibration of the mid-infrared reference framework used for Galactic Center studies. This work not only enhances our comprehension of GCIRS 3 but also sets a precedent for future investigations into similar objects within this tumultuous region of our galaxy. By constraining the properties of GCIRS 3, we contribute to the broader understanding of stellar evolution and Galactic dynamics, underscoring the utility of advanced interferometric techniques in astronomical research."
  },
  {
    "id": 70,
    "prompt": "Subvacuum effects of the quantum field on the dynamics of a test particle",
    "HWT": "We study the effects of the electromagnetic subvacuum fluctuations on the dynamics of a nonrelativistic charged particle in a wavepacket. The influence from the quantum field is expected to give an additional effect to the velocity uncertainty of the particle. In the case of a static wavepacket, the observed velocity dispersion is smaller in the electromagnetic squeezed vacuum background than in the normal vacuum background. This leads to the subvacuum effect. The extent of reduction in velocity dispersion associated with this subvacuum effect is further studied by introducing a switching function. It is shown that the slow switching process may make this subvacuum effect insignificant. We also point out that when the center of the wavepacket undergoes non-inertial motion, reduction in the velocity dispersion becomes less effective with its evolution, no matter how we manipulate the nonstationary quantum noise via the choice of the squeeze parameters. The role of the underlying fluctuation-dissipation relation is discussed.",
    "MGT": "We investigate the influence of subvacuum fluctuations in quantum fields on the dynamics of a test particle. Subvacuum effects, characterized by reduced quantum noise below the standard vacuum level through quantum squeezing, offer intriguing possibilities for modifying particle trajectories and energy distributions. By employing a perturbative analysis within the framework of quantum field theory, we explore scenarios where the test particle interacts with squeezed states of the field. Our findings reveal that subvacuum fluctuations induce measurable deviations in the particle’s motion, including shifts in its trajectory, velocity, and energy exchange rates. Notably, these effects exhibit sensitivity to the squeezing parameters, such as the degree and orientation of the squeezing. Furthermore, we examine the interplay between subvacuum states and external potentials, highlighting conditions under which the quantum-induced corrections dominate over classical dynamics. The study provides novel insights into the role of engineered quantum states in manipulating particle behavior at microscopic scales, with implications for precision measurements and quantum technologies."
  },
  {
    "id": 71,
    "prompt": "Quantifying parameter errors due to the peculiar velocities of type Ia supernovae",
    "HWT": "The fitting of the observed redshifts and magnitudes of type Ia supernovae to what we would see in homogeneous cosmological models has led to constraints on cosmological parameters. However, in doing such fits it is assumed that the sampled supernovae are moving with the Hubble flow, i.e. that their peculiar velocities are zero. In reality, peculiar velocities will modify supernova data in a way that can impact best-fit cosmological parameters. We theoretically quantify this effect in the nonlinear regime with a Monte-Carlo analysis, using data from semi-analytic galaxy catalogs that are built from the Millennium N-body simulation. We find scaling relations for the errors in best-fit parameters resulting solely from peculiar velocities, as a function of the total number of sources in a supernova survey N and its maximum redshift z_max. For low redshift surveys, we find that these errors can be of the same order of magnitude as the errors due to an intrinsic magnitude scatter of 0.1 mag. For a survey with N=2000 and z_max=1.7, we estimate that the expected peculiar velocity-induced errors in the best-fit cosmological constant density and equation of state can be sigma_Lambda~0.009 and sigma_w~0.01, respectively, which are subdominant to the errors due to the intrinsic scatter. We further find that throwing away supernova data below a redshift z~0.01-0.02 can reduce the combined error, due to peculiar velocities and the intrinsic scatter, but by only about 10%.",
    "MGT": "Type Ia supernovae serve as critical tools for measuring cosmological distances, thereby playing a pivotal role in our understanding of the universe's expansion. However, the accuracy of these measurements can be compromised by peculiar velocities—local motions deviating from the Hubble flow—which introduce uncertainties in the inferred cosmological parameters. This study aims to quantify the extent to which peculiar velocities impact the precision and reliability of cosmological parameter estimates drawn from type Ia supernovae data. Utilizing a comprehensive dataset of type Ia supernovae and accounting for their peculiar velocities, we examine the resultant errors in key cosmological parameters, including the Hubble constant and the equation of state of dark energy. We employ a robust statistical framework that integrates velocity fields derived from large-scale structure surveys to mitigate biases. Our analysis reveals that peculiar velocities can induce systematic errors, particularly in low-redshift supernovae, leading to an underestimate of the Hubble constant and potentially skewing measurements of dark energy properties. The study underscores the necessity for refined models that incorporate peculiar velocity corrections to enhance the reliability of supernovae-based cosmological studies. Furthermore, we identify the redshift range where peculiar velocities most significantly affect parameter estimation, providing a guideline for future observational strategies. This research highlights the importance of addressing non-Hubble flow motions to ensure the accuracy of cosmological inferences and suggests pathways for integrating these corrections into ongoing and forthcoming supernova surveys. Our findings contribute to the broader effort of refining cosmological models and improving the precision of measurements critical for understanding the universe's expansion dynamics."
  },
  {
    "id": 72,
    "prompt": "Smallest 90o domains in epitaxial ferroelectric films",
    "HWT": "Ferroelectrics display spontaneous and switchable electrical polarization. Until recently, ferroelectricity was believed to disappear at the nanoscale; now, nano-ferroelectrics are being considered in numerous applications. This renewed interest was partly fuelled by the observation of ferroelectric domains in films of a few unit cells thickness, promising further size reduction of ferroelectric devices. It turns out that at reduced scales and dimensionalities the material's properties depend crucially on the intricacies of domain formation, that is, the way the crystal splits into regions with polarization oriented along the different energetically equivalent directions, typically at 180o and 90o from each other. Here we present a step forward in the manipulation and control of ferroelectric domains by the growth of thin films with regular self-patterned arrays of 90o domains only 7 nm wide. This is the narrowest width for 90o domains in epitaxial ferroelectrics that preserves the film lateral coherence, independently of the substrate.",
    "MGT": "In this study, we explore the formation and characteristics of the smallest 90-degree domains in epitaxial ferroelectric films. Employing advanced microscopy techniques, including piezoresponse force microscopy and transmission electron microscopy, we systematically investigate the domain structures at the nanoscale. Our findings reveal that these nanoscale domains, which can be as small as a few nanometers in width, significantly influence the ferroelectric and dielectric properties of the films. The epitaxial strain, imposed by the substrate, plays a crucial role in stabilizing these diminutive domains, which are essential for the enhancement of the film's functional properties. We also demonstrate that the domain wall energy and the interplay between elastic and electrostatic energies are pivotal in determining the size and stability of these domains. Understanding the formation mechanisms and stability of the smallest 90-degree domains offers valuable insights into optimizing the performance of ferroelectric devices. This work paves the way for designing next-generation ferroelectric materials with tailored properties for applications in non-volatile memories, sensors, and actuators."
  },
  {
    "id": 73,
    "prompt": "Contact processes on random graphs with power law degree distributions have critical value 0",
    "HWT": "If we consider the contact process with infection rate $\\lambda$ on a random graph on $n$ vertices with power law degree distributions, mean field calculations suggest that the critical value $\\lambda_c$ of the infection rate is positive if the power $\\alpha>3$. Physicists seem to regard this as an established fact, since the result has recently been generalized to bipartite graphs by G\\'{o}mez-Garde\\~{n}es et al. [Proc. Natl. Acad. Sci. USA 105 (2008) 1399--1404]. Here, we show that the critical value $\\lambda_c$ is zero for any value of $\\alpha>3$, and the contact process starting from all vertices infected, with a probability tending to 1 as $n\\to\\infty$, maintains a positive density of infected sites for time at least $\\exp(n^{1-\\delta})$ for any $\\delta>0$. Using the last result, together with the contact process duality, we can establish the existence of a quasi-stationary distribution in which a randomly chosen vertex is occupied with probability $\\rho(\\lambda)$. It is expected that $\\rho(\\lambda)\\sim C\\lambda^{\\beta}$ as $\\lambda \\to0$. Here we show that $\\alpha-1\\le\\beta\\le2\\alpha-3$, and so $\\beta>2$ for $\\alpha>3$. Thus even though the graph is locally tree-like, $\\beta$ does not take the mean field critical value $\\beta=1$.",
    "MGT": "In this study, we investigate contact processes on random graphs characterized by power law degree distributions, focusing on the critical threshold at which a phase transition occurs. A contact process, a model for the spread of an infection or information through a network, is examined on a class of random graphs where the degree distribution follows a power law. Such graphs are known to exhibit highly heterogeneous structures, with a few nodes having very high degrees, which significantly impacts the dynamics of processes running on them. Our main result demonstrates that for these random graphs, the critical value for the contact process is zero. This implies that even an infinitesimally small infection rate can sustain the infection indefinitely, once it has been introduced to the network.\n\nThe analysis employs probabilistic methods to explore how the structural properties of power law graphs facilitate the persistence of the infection. We show that the presence of high-degree nodes—hubs—ensures long-range interactions between different parts of the graph, making the extinction of the infection improbable even at low transmission rates. This result is in stark contrast to contact processes on graphs with more homogeneous degree distributions, where a positive critical value is typically observed.\n\nOur findings have significant implications for understanding the vulnerability of real-world networks to spreading processes. Networks such as the Internet or social networks, which often exhibit power law degree distributions, may be inherently prone to the spread of infections or information, requiring careful consideration of network interventions. This work contributes to the broader understanding of dynamic processes on complex networks and highlights the need for tailored strategies in managing spreading phenomena in heterogeneous networked systems."
  },
  {
    "id": 74,
    "prompt": "Comparison of covariant and orthogonal Lyapunov vectors",
    "HWT": "Two sets of vectors, covariant and orthogonal Lyapunov vectors (CLVs/OLVs), are currently used to characterize the linear stability of chaotic systems. A comparison is made to show their similarity and difference, especially with respect to the influence on hydrodynamic Lyapunov modes (HLMs). Our numerical simulations show that in both Hamiltonian and dissipative systems HLMs formerly detected via OLVs survive if CLVs are used instead. Moreover the previous classification of two universality classes works for CLVs as well, i.e. the dispersion relation is linear for Hamiltonian systems and quadratic for dissipative systems respectively. The significance of HLMs changes in different ways for Hamiltonian and dissipative systems with the replacement of OLVs by CLVs. For general dissipative systems with nonhyperbolic dynamics the long wave length structure in Lyapunov vectors corresponding to near-zero Lyapunov exponents is strongly reduced if CLVs are used instead, whereas for highly hyperbolic dissipative systems the significance of HLMs is nearly identical for CLVs and OLVs. In contrast the HLM significance of Hamiltonian systems is always comparable for CLVs and OLVs irrespective of hyperbolicity. We also find that in Hamiltonian systems different symmetry relations between conjugate pairs are observed for CLVs and OLVs. Especially, CLVs in a conjugate pair are statistically indistinguishable in consequence of the micro- reversibility of Hamiltonian systems. Transformation properties of Lyapunov exponents, CLVs and hyperbolicity under changes of coordinate are discussed in appendices.",
    "MGT": "Lyapunov vectors are fundamental tools in the study of dynamical systems, providing insights into the stability, predictability, and structure of complex trajectories. Two widely utilized formulations are covariant Lyapunov vectors (CLVs) and orthogonal Lyapunov vectors (OLVs), each offering distinct mathematical properties and practical applications. This study presents a comprehensive comparison of CLVs and OLVs, focusing on their theoretical foundations, computational methodologies, and interpretational significance in nonlinear dynamical systems. CLVs, defined as intrinsic objects aligned with the tangent space dynamics, are invariant under time reversal and provide a basis for understanding local perturbations and directions of instability. In contrast, OLVs are sequentially orthogonalized during computation, offering numerical robustness and facilitating the analysis of global system behavior. While OLVs are effective for estimating Lyapunov exponents and quantifying average stability, CLVs enable the identification of specific modes of instability and are particularly suited for applications in predictability studies and modal decomposition. Through analytical derivations and numerical experiments on representative systems, including chaotic attractors and spatiotemporal models, we highlight the complementary roles of these vector formulations. The findings demonstrate that CLVs excel in characterizing localized dynamics, while OLVs are advantageous for coarse-grained assessments of system stability. This comparison underscores the importance of selecting the appropriate vector framework based on the objectives of the study and the nature of the system under investigation. The results contribute to a deeper understanding of Lyapunov vectors and their potential in advancing the analysis of high-dimensional and complex dynamical systems."
  },
  {
    "id": 75,
    "prompt": "Chemical control of orbital polarization in artificially structured transition-metal oxides: La2NiXO6 (X=B, Al, Ga, In) from first principles",
    "HWT": "The application of modern layer-by-layer growth techniques to transition-metal oxide materials raises the possibility of creating new classes of materials with rationally designed correlated electron properties. An important step toward this goal is the demonstration that electronic structure can be controlled by atomic composition. In compounds with partially occupied transition-metal d shells, one important aspect of the electronic structure is the relative occupancy of different d orbitals. Previous work has established that strain and quantum confinement can be used to influence orbital occupancy. In this paper we demonstrate a different modality for orbital control in transition-metal oxide heterostructures, using density-functional band calculations supplemented by a tight-binding analysis to show that the choice of nontransition-metal counterion X in transition-metal oxide heterostructures composed of alternating LaNiO3 and LaXO3 units strongly affects orbital occupancy, changing the magnitude and in some cases the sign of the orbital polarization.",
    "MGT": "In this study, we investigate the chemical control of orbital polarization in transition-metal oxides, specifically focusing on artificially structured La2NiXO6 (X = B, Al, Ga, In) using first-principles calculations. The interplay between electronic structure and crystal field effects in these double perovskite compounds is explored to understand how varying the X-site cation influences orbital polarization and electronic properties. Our computational results reveal that the choice of X-site cation significantly modulates the Ni d-orbital occupancy, leading to distinct changes in the electronic band structure and magnetic characteristics. The incorporation of lighter elements such as B and Al enhances the orbital polarization more effectively than heavier elements Ga and In, attributed to differences in ionic radii and electronegativity. These findings provide insights into tailoring electronic properties through chemical substitution, offering potential pathways for designing novel materials with desired electronic and magnetic functionalities. Our work underscores the importance of chemical manipulation in the development of advanced oxide electronics."
  },
  {
    "id": 76,
    "prompt": "Results and questions on a nonlinear approximation approach for solving high-dimensional partial differential equations",
    "HWT": "We investigate mathematically a nonlinear approximation type approach recently introduced in [A. Ammar et al., J. Non-Newtonian Fluid Mech., 2006] to solve high dimensional partial differential equations. We show the link between the approach and the greedy algorithms of approximation theory studied e.g. in [R. A. DeVore and V. N. Temlyakov, Adv. Comput. Math., 1996]. On the prototypical case of the Poisson equation, we show that a variational version of the approach, based on minimization of energies, converges. On the other hand, we show various theoretical and numerical difficulties arising with the non variational version of the approach, consisting of simply solving the first order optimality equations of the problem. Several unsolved issues are indicated in order to motivate further research.",
    "MGT": "This study investigates a nonlinear approximation method for solving high-dimensional partial differential equations (PDEs), a challenge central to various scientific and engineering applications. Traditional numerical techniques often struggle with the \"curse of dimensionality,\" leading to computational inefficiencies. Our approach leverages recent advances in machine learning and functional approximation to address these limitations effectively. We develop a framework that combines neural networks and nonlinear approximation theory, demonstrating its capacity to handle complex, high-dimensional PDEs with improved accuracy and reduced computational cost. Through comprehensive numerical experiments, we highlight the method’s adaptability and robustness across different types of PDEs, including elliptic, parabolic, and hyperbolic equations. The results indicate significant potential for this approach to outperform existing methods. However, several questions remain about the theoretical underpinnings of the convergence and stability of the proposed technique, warranting further investigation to fully understand its capabilities and limitations in broader applications."
  },
  {
    "id": 77,
    "prompt": "On the correct formula for the lifetime broadened superconducting density of states",
    "HWT": "We argue that the well known Dynes formula [Dynes R C {\\it et al. } 1978 {\\it Phys. Rev. Lett. } {\\bf 41} 1509] for the superconducting quasiparticle density of states, which tries to incorporate the lifetime broadening in an approximate way, cannot be justified microscopically for conventional superconductors. Instead, we propose a new simple formula in which the energy gap has a finite imaginary part $-\\Delta_2$ and the quasiparticle energy is real. We prove that in the quasiparticle approximation 2$\\Delta_2$ gives the quasiparticle decay rate at the gap edge for conventional superconductors. This conclusion does not depend on the nature of interactions that cause the quasiparticle decay. The new formula is tested on the case of a strong coupling superconductor Pb$_{0.9}$Bi$_{0.1}$ and an excellent agreement with theoretical predictions is obtained. While both the Dynes formula and the one proposed in this work give good fits and fit parameters for Pb$_{0.9}$Bi$_{0.1}$, only the latter formula can be justified microscopically.",
    "MGT": "This study addresses the formulation of the lifetime broadened superconducting density of states, a critical aspect of understanding superconducting materials, particularly in the presence of intrinsic and extrinsic broadening mechanisms. The research revisits conventional models and introduces a refined formula that accounts for lifetime effects more comprehensively. Utilizing advanced theoretical frameworks and computational simulations, this work demonstrates that the traditional approaches may overlook significant broadening contributions, thereby affecting the accuracy of density of states calculations. The proposed formula incorporates corrections for electron-phonon interactions and impurity scattering, which are pivotal in lifetime broadening phenomena. Validation is achieved through comparison with experimental data from various superconducting systems, showcasing enhanced congruence with observed spectral features. Furthermore, the implications of this corrected formula extend to improved predictions of superconducting properties, such as critical temperature and energy gap, fostering more precise material design and application. By bridging discrepancies between theory and experiment, this research contributes to a deeper understanding of superconductivity in complex materials and aids in the development of next-generation superconductors. Ultimately, this work underscores the necessity for continual refinement of theoretical models to accommodate emerging experimental insights and advances in superconducting technology."
  },
  {
    "id": 78,
    "prompt": "2006 SQ372: A Likely Long-Period Comet from the Inner Oort Cloud",
    "HWT": "We report the discovery of a minor planet (2006 SQ372) on an orbit with a perihelion of 24 AU and a semimajor axis of 796 AU. Dynamical simulations show that this is a transient orbit and is unstable on a timescale of 200 Myrs. Falling near the upper semimajor axis range of the scattered disk and the lower semimajor axis range of the Oort Cloud, previous membership in either class is possible. By modeling the production of similar orbits from the Oort Cloud as well as from the scattered disk, we find that the Oort Cloud produces 16 times as many objects on SQ372-like orbits as the scattered disk. Given this result, we believe this to be the most distant long-period comet ever discovered. Furthermore, our simulation results also indicate that 2000 OO67 has had a similar dynamical history. Unaffected by the \"Jupiter-Saturn Barrier, \" these two objects are most likely long-period comets from the inner Oort Cloud.",
    "MGT": "2006 SQ372 is a trans-Neptunian object with a highly eccentric orbit, suggesting its origins within the inner Oort Cloud. This study characterizes the orbital dynamics and physical properties of 2006 SQ372, providing evidence for its classification as a likely long-period comet. Using observational data collected from the Sloan Digital Sky Survey, we determined its perihelion at 24 astronomical units and its aphelion extending beyond 1,500 astronomical units, with an orbital period of approximately 22,000 years. Spectroscopic analysis indicates a composition dominated by volatile ices, consistent with objects formed in the distant regions of the solar system. Dynamical simulations reveal that its current trajectory may be influenced by gravitational perturbations from giant planets and galactic tides, supporting the hypothesis of its inner Oort Cloud origin. These findings contribute to the understanding of the structure and population dynamics of the inner Oort Cloud, offering insights into the reservoirs of cometary bodies and their role in the early solar system's evolution. 2006 SQ372 exemplifies the transitional nature of objects bridging the Kuiper Belt and distant cometary regions."
  },
  {
    "id": 79,
    "prompt": "An Optimal Algorithm to Generate Pointed Trivalent Diagrams and Pointed Triangular Maps",
    "HWT": "A trivalent diagram is a connected, two-colored bipartite graph (parallel edges allowed but not loops) such that every black vertex is of degree 1 or 3 and every white vertex is of degree 1 or 2, with a cyclic order imposed on every set of edges incident to to a same vertex. A rooted trivalent diagram is a trivalent diagram with a distinguished edge, its root. We shall describe and analyze an algorithm giving an exhaustive list of rooted trivalent diagrams of a given size (number of edges), the list being non-redundant in that no two diagrams of the list are isomorphic. The algorithm will be shown to have optimal performance in that the time necessary to generate a diagram will be seen to be bounded in the amortized sense, the bound being independent of the size of the diagrams. That's what we call the CAT property. One objective of the paper is to provide a reusable theoretical framework for algorithms generating exhaustive lists of complex combinatorial structures with attention paid to the case of unlabeled structures and to those generators having the CAT property.",
    "MGT": "This paper presents an optimal algorithm for the generation of pointed trivalent diagrams and pointed triangular maps, two fundamental structures in combinatorial topology and discrete geometry. Pointed trivalent diagrams, consisting of graphs with vertices of degree three and a distinguished vertex, and pointed triangular maps, which represent triangulations of surfaces with a marked face, arise in numerous mathematical and computational contexts, including graph theory, topological quantum field theory, and map enumeration. Existing methods for generating these structures often suffer from inefficiencies, particularly for large-scale or constrained instances. The proposed algorithm leverages combinatorial decompositions, symmetry reductions, and advanced data structures to ensure both correctness and computational efficiency. It systematically constructs the desired objects without redundancy, while ensuring that all isomorphism classes are represented exactly once. The algorithm's time complexity is shown to be asymptotically optimal relative to the number of structures generated. Experimental results demonstrate its scalability and performance, outperforming prior approaches in both runtime and memory usage. Moreover, the algorithm is adaptable to generate constrained subclasses of diagrams and maps, such as those embedded on higher-genus surfaces. This work provides a significant advancement in combinatorial generation techniques and offers practical tools for applications in mathematics, physics, and computer science."
  },
  {
    "id": 80,
    "prompt": "Gauge invariant approach to low-spin anomalous conformal currents and shadow fields",
    "HWT": "Conformal low-spin anomalous currents and shadow fields in flat space-time of dimension greater than or equal to four are studied. Gauge invariant formulation for such currents and shadow fields is developed. Gauge symmetries are realized by involving Stueckelberg and auxiliary fields. Gauge invariant differential constraints for anomalous currents and shadow fields and realization of global conformal symmetries are obtained. Gauge invariant two-point vertices for anomalous shadow fields are also obtained. In Stueckelberg gauge frame, these gauge invariant vertices become the standard two-point vertices of CFT. Light-cone gauge two-point vertices of the anomalous shadow fields are derived. AdS/CFT correspondence for anomalous currents and shadow fields and the respective normalizable and non-normalizable solutions of massive low-spin AdS fields is studied. The bulk fields are considered in modified de Donder gauge that leads to decoupled equations of motion. We demonstrate that leftover on-shell gauge symmetries of bulk massive fields correspond to gauge symmetries of boundary anomalous currents and shadow fields, while the modified (Lorentz) de Donder gauge conditions for bulk massive fields correspond to differential constraints for boundary anomalous currents and shadow fields.",
    "MGT": "In this study, we develop a gauge-invariant framework to analyze low-spin anomalous conformal currents and their corresponding shadow fields in the context of conformal field theory (CFT). The focus is on providing a systematic approach that preserves gauge invariance while addressing the complexities associated with anomalous dimensions in low-spin sectors. We begin by revisiting the conventional treatment of conformal currents and demonstrate how anomalies manifest in these scenarios. By employing a modified gauge-invariant formulation, we identify the influence of these anomalies on the structure and behavior of the associated shadow fields. Our approach extends the utility of gauge invariance beyond high-spin systems, offering new insights into the interplay between conformal symmetry and anomalous dimensions in lower-spin contexts. Using a combination of algebraic techniques and geometric interpretations, we derive explicit expressions for the anomalous conformal currents and their shadows, highlighting their transformation properties under conformal transformations. The results have significant implications for understanding the role of anomalies in CFTs and provide a robust framework for exploring similar phenomena in related quantum field theories. This work thus paves the way for further investigation into the rich structure of low-spin fields in conformal and gauge theories."
  },
  {
    "id": 81,
    "prompt": "Low-lying magnetic excitations of doubly-closed-shell nuclei and nucleon-nucleon effective interactions",
    "HWT": "We have studied the low lying magnetic spectra of 12C, 16O, 40Ca, 48Ca and 208Pb nuclei within the Random Phase Approximation (RPA) theory, finding that the description of low-lying magnetic states of doubly-closed-shell nuclei imposes severe constraints on the spin and tensor terms of the nucleon-nucleon effective interaction. We have first made an investigation by using four phenomenological effective interactions and we have obtained good agreement with the experimental magnetic spectra, and, to a lesser extent, with the electron scattering responses. Then we have made self-consistent RPA calculations to test the validity of the finite-range D1 Gogny interaction. For all the nuclei under study we have found that this interaction inverts the energies of all the magnetic states forming isospin doublets.",
    "MGT": "The study of low-lying magnetic excitations in doubly-closed-shell nuclei provides critical insights into the interplay between nuclear structure and nucleon-nucleon effective interactions. This work investigates the response of closed-shell nuclei to magnetic probes, focusing on specific excitations that arise from spin-dependent components of the effective nuclear force. Using advanced shell-model calculations and microscopic interactions derived from chiral effective field theory, we explore the role of magnetic multipole transitions in shaping the excitation spectrum. Particular attention is given to the contributions from spin-orbit coupling and tensor forces, which influence the magnetic properties of these nuclei. Comparisons with experimental data reveal the predictive power of modern nucleon-nucleon interaction models, while highlighting areas for improvement. These findings contribute to a deeper understanding of nuclear magnetism and provide benchmarks for refining theoretical approaches in nuclear physics."
  },
  {
    "id": 82,
    "prompt": "Phase transitions in LaFeAsO: structural, magnetic, elastic, and transport properties, heat capacity and Mossbauer spectra",
    "HWT": "We present results from a detailed experimental investigation of LaFeAsO, the parent material in the series of \"FeAs\" based oxypnictide superconductors. Upon cooling this material undergoes a tetragonal-orthorhombic crystallographic phase transition at ~160 K followed closely by an antiferromagnetic ordering near 145 K. Analysis of these phase transitions using temperature dependent powder X-ray and neutron diffraction measurements is presented. A magnetic moment of ~0.35 Bohr magnetons per iron is derived from Mossbauer spectra in the low temperature phase. Evidence of the structural transition is observed at temperatures well above the structural transition (up to near 200 K) in the diffraction data as well as the polycrystalline elastic moduli probed by resonant ultrasound spectroscopy measurements. The effects of the two phase transitions on the transport properties (resistivity, thermal conductivity, Seebeck coefficient, Hall coefficient), heat capacity, and magnetization of LaFeAsO are also reported, including a dramatic increase in the magnitude of the Hall coefficient below 160 K. The results suggest that the structural distortion leads to a localization of carriers on Fe, producing small local magnetic moments which subsequently order antiferromagnetically upon further cooling. Evidence of strong electron-phonon interactions in the high-temperature tetragonal phase is also observed.",
    "MGT": "The compound LaFeAsO has garnered significant attention due to its intriguing phase transitions and the interplay of structural, magnetic, elastic, and transport properties. In this study, we present a comprehensive investigation of LaFeAsO, integrating structural characterization, magnetization measurements, electrical transport, heat capacity analysis, elastic constants, and Mössbauer spectroscopy across a wide temperature range. Our results reveal a distinct structural phase transition from a tetragonal to an orthorhombic phase near 150 K, concurrent with the onset of long-range antiferromagnetic order in the Fe sublattice. This magnetic transition is accompanied by pronounced anomalies in the resistivity, elastic moduli, and heat capacity, highlighting strong coupling between the lattice, spin, and electronic degrees of freedom.\n\nElastic measurements indicate a softening of the shear modulus prior to the structural transition, suggesting the involvement of nematic fluctuations. The heat capacity data confirm the first-order nature of the structural transition, while Mössbauer spectra provide direct evidence of magnetic hyperfine splitting below the Néel temperature. The resistivity exhibits a metallic temperature dependence above the transition, with a marked upturn near the magnetic ordering temperature, indicative of spin-density wave formation. Our findings underscore the complex interplay of structural, magnetic, and electronic properties in LaFeAsO and provide insights into the mechanisms driving phase transitions in iron-based superconducting parent compounds."
  },
  {
    "id": 83,
    "prompt": "Controlling exchange bias in Co-CoOx nanoparticles by oxygen content",
    "HWT": "We report on the occurrence of exchange bias on laser-ablated granular thin films composed of Co nanoparticles embedded in amorphous zirconia matrix. The deposition method allows controlling the degree of oxidation of the Co particles by tuning the oxygen pressure at the vacuum chamber (from 2x10^{-5} to 10^{-1} mbar). The nature of the nanoparticles embedded in the nonmagnetic matrix is monitored from metallic, ferromagnetic (FM) Co to antiferromagnetic (AFM) CoOx, with a FM/AFM intermediate regime for which the percentage of the AFM phase can be increased at the expense of the FM phase, leading to the occurrence of exchange bias in particles of about 2 nm in size. For oxygen pressure of about 10-3 mbar the ratio between the FM and AFM phases is optimum with an exchange bias field about 900 Oe at 1.8 K. The mutual exchange coupling between the AFM and FM is also at the origin of the induced exchange anisotropy on the FM leading to high irreversible hysteresis loops, and the blocking of the AFM clusters due to proximity to the FM phase.",
    "MGT": "The exchange bias effect, a critical phenomenon in magnetic systems, has been extensively studied for its potential applications in spintronic devices and magnetic storage technologies. In this study, we investigate the tunability of exchange bias in Co-CoOx nanoparticles by modulating the oxygen content within the oxide shell. Co-CoOx core-shell nanoparticles were synthesized via controlled oxidation processes, enabling precise control over the oxygen stoichiometry in the CoOx shell. Structural and compositional analysis using X-ray diffraction (XRD) and transmission electron microscopy (TEM) confirmed the core-shell morphology and gradual oxygen incorporation. Magnetic measurements revealed a strong correlation between the oxygen content and the magnitude of the exchange bias field (H_ex). Specifically, higher oxygen stoichiometry in the CoOx shell resulted in enhanced exchange bias, attributed to increased spin coupling at the Co/CoOx interface. Temperature-dependent studies further demonstrated improved thermal stability of the exchange bias effect in samples with optimized oxygen content. These findings highlight the importance of oxygen stoichiometry in tailoring interfacial magnetic interactions and provide a pathway for designing advanced magnetic materials with controllable exchange bias properties. Our results offer new insights into the role of oxygen content in determining the performance of Co-CoOx-based systems for next-generation magnetic technologies."
  },
  {
    "id": 84,
    "prompt": "Holography of the Quark Matter Triple Point",
    "HWT": "The quark matter phase diagram is believed to contain two distinguished points, lying on the boundary of the Quark-Gluon Plasma phase: a critical point and a triple point. In the holographic [\"AdS/QCD\"] approach, the region of relatively low chemical potentials around the phase transition near the critical point may be described using generalizations of the Hawking-Page transition. We propose that the \\emph{other} QGP phase line, beginning at the triple point and rising towards the region of extremely high temperatures and chemical potentials, is described instead by a non-perturbative string effect discovered by Seiberg and Witten. Using an assumed position for the critical point, we are able to use this proposal to obtain a holographic lower bound on the temperature of the triple point. Combined with Shuryak's upper bound on this temperature, this leads to a rough estimate of the location of the triple point, at a temperature of around 70 MeV, and a chemical potential of about 1100 MeV.",
    "MGT": "In this study, we investigate the holographic duality implications of the quark matter triple point, a conjectured thermodynamic point where three distinct phases of quark matter coexist. Utilizing the framework of gauge/gravity duality, we explore the phase structure of quark matter under extreme conditions of temperature and density, characteristic of neutron stars and heavy-ion collisions. We employ a bottom-up holographic model that encapsulates the essential features of Quantum Chromodynamics (QCD) at finite baryon density and temperature. Our results indicate the presence of a triple point where the deconfined quark-gluon plasma, hadronic matter, and color superconducting phase meet. The phase transitions are analyzed by examining the holographic renormalization group flows and identifying the corresponding fixed points in the dual gravity description. This work provides new insights into the nature of the QCD phase diagram and sets the stage for further investigations into the critical phenomena associated with the triple point. The findings have potential implications for understanding the internal structure of neutron stars and the dynamics of early-universe cosmology, offering a novel perspective on the fundamental properties of strongly interacting matter."
  },
  {
    "id": 85,
    "prompt": "Stability of pulsar rotational and orbital periods",
    "HWT": "Millisecond and binary pulsars are the most stable astronomical standards of frequency. They can be applied to solving a number of problems in astronomy and time-keeping metrology including the search for a stochastic gravitational wave background in the early universe, testing general relativity, and establishing a new time-scale. The full exploration of pulsar properties requires that proper unbiased estimates of spin and orbital parameters of the pulsar be obtained. These estimates depend essentially on the random noise components present in pulsar timing residuals. The instrumental white noise has predictable statistical properties and makes no harm for interpretation of timing observations, while the astrophysical/geophysical low-frequency noise corrupts them, thus, reducing the quality of tests of general relativity and decreasing the stability of the pulsar time scale.",
    "MGT": "Pulsars, highly magnetized rotating neutron stars, exhibit remarkable regularity in their rotational and orbital periods, making them exceptional tools for astrophysical research. This study examines the stability of these periods, crucial for advancing our understanding of pulsar dynamics and their applications in astrophysics, including tests of general relativity and the detection of gravitational waves. We analyze observational data from a comprehensive sample of pulsars, applying advanced statistical methods to quantify period stability over extended timescales. Our findings reveal that while most pulsars maintain high stability, a subset demonstrates significant variations attributable to intrinsic and extrinsic factors, such as magnetic field evolution and companion interactions. These results underscore the complexity of pulsar systems and highlight the need for ongoing monitoring to refine pulsar-based models and enhance the precision of astrophysical measurements."
  },
  {
    "id": 86,
    "prompt": "Ad-hoc Limited Scale-Free Models for Unstructured Peer-to-Peer Networks",
    "HWT": "Several protocol efficiency metrics (e.g., scalability, search success rate, routing reachability and stability) depend on the capability of preserving structure even over the churn caused by the ad-hoc nodes joining or leaving the network. Preserving the structure becomes more prohibitive due to the distributed and potentially uncooperative nature of such networks, as in the peer-to-peer (P2P) networks. Thus, most practical solutions involve unstructured approaches while attempting to maintain the structure at various levels of protocol stack. The primary focus of this paper is to investigate construction and maintenance of scale-free topologies in a distributed manner without requiring global topology information at the time when nodes join or leave. We consider the uncooperative behavior of peers by limiting the number of neighbors to a pre-defined hard cutoff value (i.e., no peer is a major hub), and the ad-hoc behavior of peers by rewiring the neighbors of nodes leaving the network. We also investigate the effect of these hard cutoffs and rewiring of ad-hoc nodes on the P2P search efficiency.",
    "MGT": "Unstructured peer-to-peer (P2P) networks have emerged as a decentralized paradigm for sharing resources and information, offering resilience and scalability without relying on centralized control. However, the absence of structured organization poses challenges in optimizing search efficiency, resource distribution, and network robustness. This paper introduces ad-hoc limited scale-free models tailored for unstructured P2P networks, leveraging principles of scale-free topology while addressing the constraints of dynamic and decentralized environments. By incorporating degree limitation and adaptive node connectivity, the proposed models aim to balance complex network characteristics, such as high clustering and short path lengths, with practical scalability requirements. Through simulation-based analysis, we demonstrate that the ad-hoc limited scale-free models improve search efficiency and fault tolerance compared to traditional random graph-based architectures. Furthermore, the study explores the trade-offs between structural complexity and computational overhead, highlighting the models' capacity to maintain robust network performance under high churn rates. These findings suggest that integrating scale-free properties in a controlled, limited manner can enhance the effectiveness of unstructured P2P networks, paving the way for more resilient and efficient decentralized systems in real-world applications, such as distributed file sharing, content delivery, and collaborative computing."
  },
  {
    "id": 87,
    "prompt": "DFT-based calculation of Coulomb blockade in molecular junction",
    "HWT": "Quantum transport through single molecules is very sensitive to the strength of the molecule-electrode contact. When a molecular junction weakly coupled to external electrodes, charging effects do play an important role (Coulomb blockade regime). In this regime, the non-equilibrium Green function is usually substituted with master equation approaches, which prevents the density functional theory from describing Coulomb blockade in non-equilibrium case. Last year, we proposed an Ansatz to combine the non-equilibrium Green function technique with the equation of motion method. With help of it, Coulomb blockade was obtained by non-equilibrium Green function, and completely agrees with the master equation results [Phys. Rev. B \\textbf{76}, 045408 (2007)]. Here, by the Ansatz, we show a new way to introduce Coulomb blockade correction to DFT calculation in non-equilibrium case. And the characteristics of Coulomb blockade are obtained in the calculation of a $toy$ molecule correctly.",
    "MGT": "The Coulomb blockade effect in molecular junctions plays a pivotal role in determining charge transport properties at the nanoscale, offering a route to understand and engineer single-electron devices. This study employs density functional theory (DFT) combined with non-equilibrium Green's function (NEGF) methods to investigate the Coulomb blockade phenomenon in molecular junctions. By modeling a prototypical molecular system bridged between metallic electrodes, we explore the interplay between electron correlation effects and molecular energy levels under varying bias voltages. The calculated conductance spectra reveal distinct Coulomb blockade features, including suppressed current at low bias and the emergence of quantized charge transport at higher biases. Analysis of the electron density and molecular orbital alignment highlights the critical role of intra-molecular interactions and charging effects in modulating transport properties. Furthermore, the study discusses the influence of electrode coupling and device geometry on the blockade behavior. Our findings provide fundamental insights into the electronic mechanisms governing molecular-scale transport and offer guidance for the design of molecular electronics and single-electron transistors."
  },
  {
    "id": 88,
    "prompt": "A well-posedness theory in measures for some kinetic models of collective motion",
    "HWT": "We present existence, uniqueness and continuous dependence results for some kinetic equations motivated by models for the collective behavior of large groups of individuals. Models of this kind have been recently proposed to study the behavior of large groups of animals, such as flocks of birds, swarms, or schools of fish. Our aim is to give a well-posedness theory for general models which possibly include a variety of effects: an interaction through a potential, such as a short-range repulsion and long-range attraction; a velocity-averaging effect where individuals try to adapt their own velocity to that of other individuals in their surroundings; and self-propulsion effects, which take into account effects on one individual that are independent of the others. We develop our theory in a space of measures, using mass transportation distances. As consequences of our theory we show also the convergence of particle systems to their corresponding kinetic equations, and the local-in-time convergence to the hydrodynamic limit for one of the models.",
    "MGT": "We develop a rigorous well-posedness theory in the framework of measures for a class of kinetic models describing collective motion in biological and physical systems. Such models, characterized by the interplay between nonlinear interactions and transport phenomena, are often posed in terms of partial differential equations that govern the evolution of probability densities or measures. By leveraging the theory of Wasserstein spaces and measure-valued solutions, we establish existence, uniqueness, and stability results under general assumptions on the interaction forces and initial data. The approach is particularly suited to capture singular behaviors, including measure-valued solutions corresponding to concentrated distributions, such as Dirac deltas, which are commonly observed in swarm dynamics and aggregation phenomena. Furthermore, the results provide insights into the regularization mechanisms inherent in the models, as well as their long-term behavior and emergent collective patterns. Our findings contribute to the mathematical understanding of kinetic equations in non-smooth settings, offering a robust analytical framework applicable to various models of collective dynamics in biology, robotics, and social systems."
  },
  {
    "id": 89,
    "prompt": "The origin of a$_{1g}$ and e$_g$' orderings in Na$_x$CoO$_2$",
    "HWT": "It has often been suggested that correlation effects suppress the small e_g' Fermi surface pockets of NaxCoO_2 that are predicted by LDA, but absent in ARPES measurements. It appears that within the dynamical mean field theory (DMFT) the ARPES can be reproduced only if the on-site energy of the eg' complex is lower than that of the a1g complex at the one-electron level, prior to the addition of local correlation effects. Current estimates regarding the order of the two orbital complexes range from -200 meV to 315 meV in therms of the energy difference. In this work, we perform density functional theory calculations of this one-electron splitting \\Delta= \\epsilon_a1g-\\epsilon_e_g' for the full two-layer compound, Na2xCo2O4, accounting for the effects of Na ordering, interplanar interactions and octahedral distortion. We find that \\epsilon a_1g-\\epsilon e_g' is negative for all Na fillings and that this is primarily due to the strongly positive Coulomb field created by Na+ ions in the intercalant plane. This field disproportionately affects the a_1g orbital which protrudes farther upward from the Co plane than the e_g' orbitals. We discuss also the secondary effects of octahedral compression and multi-orbital filling on the value of \\Delta as a function of Na content. Our results indicate that if the e_g' pockets are indeed suppressed that can only be due to nonlocal correlation effects beyond the standard DMFT.",
    "MGT": "In this study, we investigate the electronic and structural properties of sodium cobaltate, Na$_x$CoO$_2$, focusing on the origin of the a$_{1g}$ and e$_g$' orbital orderings. Na$_x$CoO$_2$ is a layered transition metal oxide that exhibits a rich phase diagram, including superconductivity, charge ordering, and thermoelectric properties, which are critically influenced by the orbital dynamics. Utilizing a combination of density functional theory (DFT) calculations and dynamical mean-field theory (DMFT), we explore how varying sodium content (x) affects the CoO$_2$ layers' electronic structure and orbital occupations. Our results reveal that the competition between the a$_{1g}$ and e$_g$' orbitals is driven by the interplay of crystal field splitting, electronic correlations, and the sodium ion distribution within the interlayers. As the sodium content is varied, we observe a transition in orbital dominance, with a$_{1g}$ orbitals being preferentially occupied at lower x values, while e$_g$' orbitals become more relevant at higher sodium concentrations. This transition is accompanied by significant changes in the material's electronic properties and lattice parameters, which we attribute to modifications in the local crystal field environment and electron correlation effects. Our findings provide new insights into the complex interplay of orbital physics and electron correlations in Na$_x$CoO$_2$, offering a potential pathway to tailor its electronic properties for technological applications. This work enhances our understanding of the fundamental mechanisms governing orbital order in transition metal oxides, with broader implications for designing novel materials with desired electronic characteristics."
  },
  {
    "id": 90,
    "prompt": "Optimal power allocation for downstream xDSL with per-modem total power constraints: Broadcast Channel Optimal Spectrum Balancing (BC-OSB)",
    "HWT": "Recently, the duality between Multiple Input Multiple Output (MIMO) Multiple Access Channels (MAC) and MIMO Broadcast Channels (BC) has been established under a total power constraint. The same set of rates for MAC can be achieved in BC exploiting the MAC-BC duality formulas while preserving the total power constraint. In this paper, we describe the BC optimal power allo- cation applying this duality in a downstream x-Digital Subscriber Lines (xDSL) context under a total power constraint for all modems over all tones. Then, a new algorithm called BC-Optimal Spectrum Balancing (BC-OSB) is devised for a more realistic power allocation under per-modem total power constraints. The capacity region of the primal BC problem under per-modem total power constraints is found by the dual optimization problem for the BC under per-modem total power constraints which can be rewritten as a dual optimization problem in the MAC by means of a precoder matrix based on the Lagrange multipliers. We show that the duality gap between the two problems is zero. The multi-user power allocation problem has been solved for interference channels and MAC using the OSB algorithm. In this paper we solve the problem of multi-user power allocation for the BC case using the OSB algorithm as well and we derive a computational efficient algorithm that will be referred to as BC-OSB. Simulation results are provided for two VDSL2 scenarios: the first one with Differential-Mode (DM) transmission only and the second one with both DM and Phantom- Mode (PM) transmissions.",
    "MGT": "The deployment of xDSL technologies has significantly advanced broadband communication, enabling high-speed internet access over legacy copper infrastructure. However, optimizing power allocation across multiple modems remains a critical challenge due to interference among users sharing the same frequency spectrum. This paper introduces Broadcast Channel Optimal Spectrum Balancing (BC-OSB), a novel approach to downstream power allocation in xDSL systems that incorporates per-modem total power constraints. Unlike traditional spectrum balancing methods, which often assume uniform power budgets or neglect individual modem constraints, the BC-OSB framework accounts for the heterogeneity in modem capabilities and service requirements while maximizing system-wide data rates.\n\nThe proposed method models the downstream transmission scenario as a broadcast channel, leveraging the inherent structure of xDSL networks. By reformulating the power allocation problem into a convex optimization framework, BC-OSB ensures that each modem operates within its specified total power budget while achieving efficient interference management across subchannels. The solution is derived using advanced optimization techniques, guaranteeing global optimality and computational feasibility for real-world implementation.\n\nSimulation results demonstrate that BC-OSB significantly outperforms conventional spectrum balancing techniques in terms of both aggregate data rate and fairness among users. Furthermore, the approach adapts seamlessly to varying network conditions, such as changes in line attenuation or noise profiles, ensuring robust performance across diverse deployment scenarios. The findings underscore the importance of integrating individual modem constraints into power allocation strategies, paving the way for enhanced efficiency in next-generation xDSL systems. BC-OSB represents a promising step towards fully optimized broadband communication, offering practical insights for system designers and network operators aiming to meet increasing demand for high-speed internet services."
  },
  {
    "id": 91,
    "prompt": "Comparing and interpolating distributions on manifold",
    "HWT": "We are interested in comparing probability distributions defined on Riemannian manifold. The traditional approach to study a distribution relies on locating its mean point and finding the dispersion about that point. On a general manifold however, even if two distributions are sufficiently concentrated and have unique means, a comparison of their covariances is not possible due to the difference in local parametrizations. To circumvent the problem we associate a covariance field with each distribution and compare them at common points by applying a similarity invariant function on their representing matrices. In this way we are able to define distances between distributions. We also propose new approach for interpolating discrete distributions and derive some criteria that assure consistent results. Finally, we illustrate with some experimental results on the unit 2-sphere.",
    "MGT": "In the study of data residing on manifolds, comparing and interpolating probability distributions pose significant challenges due to the non-Euclidean nature of these spaces. This article addresses these challenges by developing novel mathematical frameworks for the comparison and interpolation of distributions on manifolds. We introduce a new metric-based approach that extends the Wasserstein distance, traditionally used in Euclidean spaces, to manifold settings. Our approach leverages the geometric structure of the manifold to ensure meaningful comparisons. Additionally, we present an interpolation technique that generalizes the concept of geodesic interpolation in Euclidean spaces, allowing for smooth transitions between distributions. We demonstrate the efficacy of our methods through applications in computer vision and medical imaging, where manifold-valued data is prevalent. Our results highlight the potential for improved accuracy and interpretability in statistical analysis on manifolds, paving the way for further advancements in manifold-based data science."
  },
  {
    "id": 92,
    "prompt": "USUM: Update Summary Generation System",
    "HWT": "Huge amount of information is present in the World Wide Web and a large amount is being added to it frequently. A query-specific summary of multiple documents is very helpful to the user in this context. Currently, few systems have been proposed for query-specific, extractive multi-document summarization. If a summary is available for a set of documents on a given query and if a new document is added to the corpus, generating an updated summary from the scratch is time consuming and many a times it is not practical/possible. In this paper we propose a solution to this problem. This is especially useful in a scenario where the source documents are not accessible. We cleverly embed the sentences of the current summary into the new document and then perform query-specific summary generation on that document. Our experimental results show that the performance of the proposed approach is good in terms of both quality and efficiency.",
    "MGT": "USUM: Update Summary Generation System is an innovative approach to automatic text summarization, addressing the growing need for efficient information synthesis in the digital age. This system integrates advanced natural language processing techniques with machine learning algorithms to generate concise and informative summaries of evolving text data. USUM is designed to handle dynamic content updates, making it particularly suitable for applications such as news aggregation, real-time report generation, and social media monitoring. The system leverages state-of-the-art transformer models to capture semantic nuances and context, ensuring that the generated summaries maintain coherence and relevance. Through iterative training and evaluation on diverse datasets, USUM demonstrates significant improvements over traditional summarization techniques in both accuracy and computational efficiency. Our experiments show that USUM consistently produces summaries that are not only shorter but also more comprehensive, retaining critical information while discarding redundancy. This paper discusses the underlying architecture, training methodologies, and evaluation metrics of USUM, highlighting its potential impact on various domains requiring timely and effective text summarization solutions."
  },
  {
    "id": 93,
    "prompt": "Twisted generalized Weyl algebras, polynomial Cartan matrices and Serre-type relations",
    "HWT": "Twisted generalized Weyl algebras (TGWAs) are defined as the quotient of a certain graded algebra by the maximal graded ideal I with trivial zero component, analogous to how Kac-Moody algebras can be defined. In this paper we introduce the class of locally finite TGWAs, and show that one can associate to such an algebra a polynomial Cartan matrix (a notion extending the usual generalized Cartan matrices appearing in Kac-Moody algebra theory) and that the corresponding generalized Serre relations hold in the TGWA. We also give an explicit construction of a family of locally finite TGWAs depending on a symmetric generalized Cartan matrix C and some scalars. The polynomial Cartan matrix of an algebra in this family may be regarded as a deformation of the original matrix C and gives rise to quantum Serre relations in the TGWA. We conjecture that these relations generate the graded ideal I for these algebras, and prove it in type A_2.",
    "MGT": "Twisted generalized Weyl algebras (TGWAs) have emerged as a versatile framework for studying noncommutative algebras with deep connections to Lie theory, representation theory, and quantum algebra. This paper explores the interplay between TGWAs and polynomial Cartan matrices, extending the classical notion of Cartan matrices by incorporating polynomial entries. The construction of TGWAs based on polynomial Cartan matrices reveals an intricate structure that generalizes the relations found in traditional Lie algebras while preserving key algebraic properties. A central focus of the study is the formulation and analysis of Serre-type relations within this extended framework. By leveraging these relations, we characterize the conditions under which the TGWA exhibits a well-defined algebraic structure, including integrability and compatibility of its defining parameters. The results illuminate the role of twisting automorphisms in modifying classical Serre relations, leading to novel algebraic phenomena. Connections to quantum groups, as well as applications in the study of graded and filtered representations, are briefly discussed, providing new perspectives for future investigations in noncommutative algebra."
  },
  {
    "id": 94,
    "prompt": "Adjusted Bayesian inference for selected parameters",
    "HWT": "We address the problem of providing inference from a Bayesian perspective for parameters selected after viewing the data. We present a Bayesian framework for providing inference for selected parameters, based on the observation that providing Bayesian inference for selected parameters is a truncated data problem. We show that if the prior for the parameter is non-informative, or if the parameter is a \"fixed\" unknown constant, then it is necessary to adjust the Bayesian inference for selection. Our second contribution is the introduction of Bayesian False Discovery Rate controlling methodology, which generalizes existing Bayesian FDR methods that are only defined in the two-group mixture model. We illustrate our results by applying them to simulated data and data froma microarray experiment.",
    "MGT": "Bayesian inference provides a coherent framework for parameter estimation and uncertainty quantification, but challenges arise when inference is conducted on parameters selected based on data-dependent criteria. Such selection processes can induce bias and distort posterior distributions, undermining the validity of conclusions. This article introduces an adjusted Bayesian inference framework that accounts for the effects of selection on posterior estimates. By incorporating selection-aware priors and post-selection adjustment techniques, the proposed methodology ensures more accurate and robust inference for parameters of interest. The framework is applicable to a wide range of selection scenarios, including hypothesis testing, model selection, and variable screening. Simulation studies and real-world applications demonstrate the efficacy of the approach in mitigating selection-induced biases and preserving credible interval coverage. This work advances Bayesian methods by addressing critical challenges in post-selection inference, enhancing their reliability in practical settings."
  },
  {
    "id": 95,
    "prompt": "Melting of hexane monolayers adsorbed on graphite: the role of domains and defect formation",
    "HWT": "We present the first large-scale molecular dynamics simulations of hexane on graphite that completely reproduces all experimental features of the melting transition. The canonical ensemble simulations required and used the most realistic model of the system: (i) fully atomistic representation of hexane; (ii) explicit site-by-site interaction with carbon atoms in graphite; (iii) CHARMM force field with carefully chosen adjustable parameters of non-bonded interaction; (iv) numerous $\\ge$ 100 ns runs, requiring a total computation time of ca. 10 CPU-years. This has allowed us to determine correctly the mechanism of the transition: molecular reorientation within lamellae without perturbation of the overall adsorbed film structure. We observe that the melted phase has a dynamically reorienting domain-type structure whose orientations reflect that of graphite.",
    "MGT": "The melting behavior of hexane monolayers adsorbed on graphite has been investigated with a focus on the role of domain formation and defect dynamics. Using a combination of experimental techniques and theoretical modeling, the study reveals that the melting transition is influenced by the interplay between molecular ordering within domains and the nucleation of defects. At low temperatures, hexane molecules self-assemble into ordered domains, driven by substrate interactions and intermolecular forces. As temperature increases, fluctuations at domain boundaries and the formation of topological defects, such as dislocations and vacancies, contribute to the breakdown of long-range order. This process is further modulated by the heterogeneity of the graphite surface, which promotes localized melting at defect sites. The findings provide insights into the microscopic mechanisms governing phase transitions in 2D adsorbed systems and highlight the critical role of defects in the melting process."
  },
  {
    "id": 96,
    "prompt": "On $p$-adic Gibbs measures of countable state Potts model on the Cayley tree",
    "HWT": "In the present paper we consider countable state $p$-adic Potts model on the Cayley tree. A construction of $p$-adic Gibbs measures which depends on weights $\\l$ is given, and an investigation of such measures is reduced to examination of an infinite-dimensional recursion equation. Studying of the derived equation under some condition on weights, we prove absence of the phase transition. Note that the condition does not depend on values of the prime $p$, and an analogues fact is not true when the number of spins is finite. For homogeneous model it is shown that the recursive equation has only one solution under that condition on weights. This means that there is only one $p$-adic Gibbs measure $\\m_\\l$. The boundedness of the measure is also established. Moreover, continuous dependence the measure $\\m_\\l$ on $\\l$ is proved. At the end we formulate one limit theorem for $\\m_\\l$.",
    "MGT": "In this study, we investigate the $p$-adic Gibbs measures for the Potts model with a countable number of states on the Cayley tree. The Potts model, a generalization of the Ising model, serves as a fundamental framework in statistical mechanics, allowing the exploration of phase transitions and critical phenomena. Our focus is on the Cayley tree, a hierarchical, tree-like structure that provides a fertile ground for the analysis of infinite-dimensional systems. By employing $p$-adic analysis, a mathematical approach utilizing the properties of $p$-adic numbers, we delve into the distinctive thermodynamic behaviors exhibited by these models. We derive the conditions under which $p$-adic Gibbs measures exist and examine their uniqueness and stability. Our findings reveal novel insights into the nature of phase transitions and the role of $p$-adic numbers in influencing system dynamics. This work not only advances the theoretical understanding of the Potts model on complex structures but also opens avenues for future research in $p$-adic statistical mechanics, with potential applications in fields such as quantum computing and cryptography."
  },
  {
    "id": 97,
    "prompt": "Pattern formation during the evaporation of a colloidal nanoliter drop: a numerical and experimental study",
    "HWT": "An efficient way to precisely pattern particles on solid surfaces is to dispense and evaporate colloidal drops, as for bioassays. The dried deposits often exhibit complex structures exemplified by the coffee ring pattern, where most particles have accumulated at the periphery of the deposit. In this work, the formation of deposits during the drying of nanoliter colloidal drops on a flat substrate is investigated numerically and experimentally. A finite-element numerical model is developed that solves the Navier-Stokes, heat and mass transport equations in a Lagrangian framework. The diffusion of vapor in the atmosphere is solved numerically, providing an exact boundary condition for the evaporative flux at the droplet-air interface. Laplace stresses and thermal Marangoni stresses are accounted for. The particle concentration is tracked by solving a continuum advection-diffusion equation. Wetting line motion and the interaction of the free surface of the drop with the growing deposit are modeled based on criteria on wetting angles. Numerical results for evaporation times and flow field are in very good agreement with published experimental and theoretical results. We also performed transient visualization experiments of water and isopropanol drops loaded with polystyrene microsphere evaporating on respectively glass and polydimethylsiloxane substrates. Measured evaporation times, deposit shape and sizes, and flow fields are in very good agreement with the numerical results. Different flow patterns caused by the competition of Marangoni loops and radial flow are shown to determine the deposit shape to be either a ring-like pattern or a homogeneous bump.",
    "MGT": "This study investigates the complex pattern formation that occurs during the evaporation of a colloidal nanoliter drop, utilizing both numerical simulations and experimental observations to elucidate the underlying mechanisms. The evaporation process of colloidal droplets is of significant interest due to its implications in various fields, including material science, inkjet printing, and biomedical applications. In this work, we have developed a comprehensive numerical model that simulates the evaporation dynamics of a colloidal nanoliter droplet on a solid substrate. The model incorporates factors such as fluid dynamics, colloidal interactions, and heat transfer to predict the pattern formation within the droplet as it evaporates. Our simulations reveal the influence of parameters like particle concentration, evaporation rate, and substrate properties on the resulting patterns.\n\nComplementing our numerical approach, we conducted a series of experiments to observe the real-time evolution of patterns within colloidal droplets. High-resolution imaging techniques were employed to capture the deposition patterns formed after complete evaporation. The experimental results were then compared with the numerical predictions, showing strong agreement and validating the effectiveness of our model. We found that the interplay between evaporation-induced flow and particle interactions leads to distinct pattern formations such as rings, fractals, and uniform films. The study further explores the parameter space to identify conditions under which specific patterns emerge, providing a framework for controlling pattern formation in practical applications. This dual approach of numerical and experimental study enhances our understanding of colloidal drop evaporation, paving the way for optimized applications where precise pattern control is crucial."
  },
  {
    "id": 98,
    "prompt": "Quantum Radiation of Oscillons",
    "HWT": "Many classical scalar field theories possess remarkable solutions: coherently oscillating, localized clumps, known as oscillons. In many cases, the decay rate of classical small amplitude oscillons is known to be exponentially suppressed and so they are extremely long lived. In this work we compute the decay rate of quantized oscillons. We find it to be a power law in the amplitude and couplings of the theory. Therefore, the quantum decay rate is very different to the classical decay rate and is often dominant. We show that essentially all oscillons eventually decay by producing outgoing radiation. In single field theories the outgoing radiation has typically linear growth, while if the oscillon is coupled to other bosons the outgoing radiation can have exponential growth. The latter is a form of parametric resonance: explosive energy transfer from a localized clump into daughter fields. This may lead to interesting phenomenology in the early universe. Our results are obtained from a perturbative analysis, a non-perturbative Floquet analysis, and numerics.",
    "MGT": "Oscillons are localized, non-topological solutions of scalar field theories that exhibit long-lived, quasi-stable behavior. Their intriguing properties have garnered significant attention as potential signatures of new physics in cosmological and high-energy environments. This study investigates the quantum radiation emitted by oscillons, a phenomenon that remains poorly understood due to its non-perturbative nature and the inherent challenge of quantizing non-linear field configurations. Utilizing advanced computational techniques, we analyze oscillon solutions in various scalar field models, focusing on the mechanisms that lead to their quantum decay. Our results reveal that quantum radiation can significantly influence the longevity and stability of oscillons, with specific decay rates closely tied to the parameters of the underlying field theory. Additionally, we explore the implications of these findings on the detectability of oscillons in both astrophysical observations and laboratory experiments. By providing a detailed quantum treatment of oscillon radiation, this work aims to bridge the gap between classical and quantum descriptions of non-topological solitons, offering new insights into their role in early universe dynamics and their potential as probes of fundamental physics beyond the Standard Model."
  },
  {
    "id": 99,
    "prompt": "Experimental Results Related to Discrete Nonlinear Schr\\\"odinger Equations",
    "HWT": "In this chapter, we discuss experiments that realize the discrete nonlinear Schr\\\"odinger (DNLS) equations. The relevance of such descriptions arises from the competition of three common features: nonlinearity, dispersion, and a medium to large level of (periodic, quasiperiodic, or random) discreteness in space. DNLS equations have been especially prevalent in atomic and molecular physics in the study of Bose-Einstein condensates in optical lattices or superlattices; and in nonlinear optics in the description of pulse propagation in waveguide arrays and photorefractive crystals. New experiments in both nonlinear optics and Bose-Einstein condensation provide new challenges for DNLS models, and DNLS and related equations have also recently been used to make important predictions in novel physical settings such as the study of composite metamaterials and arrays of superconducting devices.",
    "MGT": "This study explores the experimental aspects of discrete nonlinear Schrödinger equations (DNLS), which have significant implications in various fields such as nonlinear optics, Bose-Einstein condensates, and lattice dynamics. We present a series of experiments designed to investigate the properties and behaviors of DNLS under different configurations. By utilizing advanced numerical simulations and precise laboratory setups, we scrutinize the formation and evolution of discrete solitons, modulational instability, and energy localization phenomena. Our results demonstrate the critical role of nonlinearity and discreteness in shaping wave dynamics, offering new insights into the control and manipulation of wave propagation in discrete media. Furthermore, we highlight the agreement between theoretical predictions and experimental outcomes, underscoring the robustness of DNLS models in describing real-world systems. These findings pave the way for developing novel applications in photonic crystals and quantum computing, where discrete nonlinear wave equations play a pivotal role."
  },
  {
    "id": 100,
    "prompt": "High-Resolution Rotation Curves and Galaxy Mass Models from THINGS",
    "HWT": "We present rotation curves of 19 galaxies from THINGS, The HI Nearby Galaxy Survey. The high spatial and velocity resolution of THINGS make these the highest quality HI rotation curves available to date for a large sample of nearby galaxies, spanning a wide range of HI masses and luminosities. The high quality of the data allows us to derive the geometrical and dynamical parameters using HI data alone. We do not find any declining rotation curves unambiguously associated with a cut-off in the mass distribution out to the last measured point. The rotation curves are combined with 3.6 um data from SINGS (Spitzer Infrared Nearby Galaxies Survey) to construct mass models. Our best-fit, dynamical disk masses, derived from the rotation curves, are in good agreement with photometric disk masses derived from the 3.6 um images in combination with stellar population synthesis arguments and two different assumptions for the stellar Initial Mass Function (IMF). We test the Cold Dark Matter-motivated cusp model, and the observationally motivated central density core model and find that (independent of IMF) for massive, disk-dominated galaxies, all halo models fit apparently equally well; for low-mass galaxies, however, a core-dominated halo is clearly preferred over a cuspy halo. The empirically derived densities of the dark matter halos of the late-type galaxies in our sample are half of what is predicted by CDM simulations, again independent of the assumed IMF.",
    "MGT": "We present a detailed analysis of high-resolution rotation curves and galaxy mass models derived from The HI Nearby Galaxy Survey (THINGS), a comprehensive 21 cm survey of nearby galaxies. The unprecedented spatial and velocity resolution of THINGS enables precise measurements of rotation curves, which are fundamental for understanding the distribution of baryonic and dark matter in galaxies. We analyze a sample of 34 nearby galaxies spanning a wide range of morphologies, luminosities, and star formation activities, constructing rotation curves using robust velocity field modeling techniques. These curves are combined with multiwavelength photometric data to decompose the total mass distribution into contributions from stellar, gaseous, and dark matter components. \n\nOur results highlight the diversity in galaxy mass distributions and the interplay between baryonic and dark matter. We find that low-mass galaxies are typically dominated by dark matter at all radii, while high-mass galaxies exhibit a significant baryonic contribution in their inner regions. The derived dark matter halo parameters are consistent with predictions from ΛCDM cosmology, but some galaxies show deviations that may point to environmental effects or alternative dark matter scenarios. We also investigate the relationship between rotation curve shapes and galaxy properties, identifying correlations with stellar mass, surface brightness, and star formation rate. \n\nThe high-quality data from THINGS provide a critical benchmark for testing galaxy formation and evolution models, offering new insights into the coupling between baryonic and dark matter. Our findings underscore the importance of high-resolution observations for unraveling the complex dynamics of galaxies and refining our understanding of the dark universe."
  },
  {
    "id": 101,
    "prompt": "Are Newly Discovered HI High Velocity Clouds Minihalos in the Local Group?",
    "HWT": "A set of HI sources extracted from the north Galactic polar region by the ongoing ALFALFA survey has properties that are consistent with the interpretation that they are associated with isolated minihalos in the outskirts of the Local Group (LG). Unlike objects detected by previous surveys, such as the Compact High Velocity Clouds of Braun & Burton (1999), the HI clouds found by ALFALFA do not violate any structural requirements or halo scaling laws of the LambdaCDM structure paradigm, nor would they have been detected by extant HI surveys of nearby galaxy groups other than the LG. At a distance of d Mpc, their HI masses range between $5 x 10^4 d^2 and 10^6 d^2 solar and their HI radii between <0.4d and 1.6 d kpc. If they are parts of gravitationally bound halos, the total masses would be on order of 10^8--10^9 solar, their baryonic content would be signifcantly smaller than the cosmic fraction of 0.16 and present in a ionized gas phase of mass well exceeding that of the neutral phase. This study does not however prove that the minihalo interpretation is unique. Among possible alternatives would be that the clouds are shreds of the Leading Arm of the Magellanic Stream.",
    "MGT": "Recent observations have unveiled the presence of numerous high-velocity clouds (HVCs) of neutral hydrogen (HI) in the periphery of the Local Group, raising intriguing questions about their origins and nature. This study investigates whether these newly discovered HI HVCs could be minihalos, a hypothesized population of dark matter-dominated structures. Utilizing data from the Green Bank Telescope and the HI4PI survey, we analyze the kinematic and spatial properties of these clouds, comparing them to theoretical models of minihalos. Our findings indicate that many of these HI HVCs exhibit characteristics consistent with minihalo predictions, including distinct velocity profiles and spatial distributions that are not easily explained by other models, such as galactic fountains or tidal debris. Furthermore, we explore the potential for these minihalos to contribute to the missing baryon problem in the Local Group by providing a reservoir for baryonic matter that has yet to be accounted for in other galactic structures. We also discuss the implications of our findings for the understanding of dark matter and the overall mass distribution in the Local Group. Future high-resolution observations and simulations are recommended to further probe the connection between these HI HVCs and minihalos, potentially offering new insights into the formation and evolution of cosmic structures in our local cosmic neighborhood."
  },
  {
    "id": 102,
    "prompt": "The occultation events of the Herbig Ae/Be star V1247 Ori",
    "HWT": "Aims: I study new deep (DeltaV ~ 1.20-1.65 mag) occultation events of the delta Scuti, Herbig Ae/Be star V1247 Ori in the Ori OB1 b association. Methods: I use the V-band ASAS light curve of V1247 Ori, which covers the last nine years, together with photometric data in the near-ultraviolet, visible, near-, and far-infrared taken from the literature. I carry out a periodogram analysis of the \"cleaned\" light curve and construct the spectral energy distribution of the star. Results: The star V1247 Ori is interesting for the study of the UX Orionis phenomenon, in which Herbig Ae/Be stars are occulted by their protoplanetary discs, for three reasons: brightness (V ~ 9.85 mag), large infrared excess at 20-100 mum (F_60 ~ 10 Jy), and photometric stability out of occultation (sigma(V) ~ 0.02 mag), which may help to determine the location and spatial structure of the occulting disc clumps.",
    "MGT": "V1247 Ori, a Herbig Ae/Be star, has garnered significant attention due to its intricate circumstellar environment and periodic occultation events. This study presents a detailed analysis of the occultation phenomena observed in V1247 Ori, utilizing data from both ground- and space-based telescopes. Through comprehensive photometric and spectroscopic observations, we identify and characterize the nature of the occulting material, offering new insights into its composition, structure, and dynamics. Our findings suggest that these events are linked to circumstellar disk structures, potentially involving clumps or warps within the disk or interactions with a companion body. By modeling the light curves and spectral variations, we ascertain the physical properties and spatial distribution of the occulting material, enhancing our understanding of the star-disk interaction in young stellar objects. Furthermore, this research contributes to the broader discourse on disk evolution and planet formation processes in early stellar environments. The outcomes not only elucidate the peculiar behavior of V1247 Ori but also provide a framework for studying similar occultation events in other young stellar systems."
  },
  {
    "id": 103,
    "prompt": "Towards Multimodal Content Representation",
    "HWT": "Multimodal interfaces, combining the use of speech, graphics, gestures, and facial expressions in input and output, promise to provide new possibilities to deal with information in more effective and efficient ways, supporting for instance: - the understanding of possibly imprecise, partial or ambiguous multimodal input; - the generation of coordinated, cohesive, and coherent multimodal presentations; - the management of multimodal interaction (e.g., task completion, adapting the interface, error prevention) by representing and exploiting models of the user, the domain, the task, the interactive context, and the media (e.g. text, audio, video). The present document is intended to support the discussion on multimodal content representation, its possible objectives and basic constraints, and how the definition of a generic representation framework for multimodal content representation may be approached. It takes into account the results of the Dagstuhl workshop, in particular those of the informal working group on multimodal meaning representation that was active during the workshop (see http: //www. dfki. de/~wahlster/Dagstuhl_Multi_Modality, Working Group 4).",
    "MGT": "In recent years, the proliferation of diverse data types, including text, images, audio, and video, has necessitated the development of advanced techniques for multimodal content representation. This paper explores the integration of multiple modalities to enhance the representation and understanding of complex content. By leveraging advancements in machine learning and artificial intelligence, particularly in the domains of deep learning and neural networks, we propose a novel framework that unifies these modalities into a cohesive representation. The framework is evaluated based on its ability to improve accuracy and efficiency in tasks such as semantic understanding, content retrieval, and cross-modal generation. Through extensive experimentation, we demonstrate that our approach significantly outperforms traditional unimodal techniques, offering robust solutions for applications in multimedia analysis, human-computer interaction, and content recommendation systems. Furthermore, we discuss the challenges associated with multimodal data fusion, including modality alignment, data heterogeneity, and scalability. Our findings suggest that a multimodal approach not only enriches the content representation but also opens new avenues for research in understanding complex interactions across different data types. This work lays the groundwork for future exploration into more sophisticated and nuanced multimodal systems, ultimately contributing to the advancement of intelligent systems capable of processing and interpreting rich, multi-dimensional data."
  },
  {
    "id": 104,
    "prompt": "Modeling of the evolution of dielectric loss with processing temperature in ferroelectric and dielectric thin oxide films",
    "HWT": "It was experimentally found that the evolution of dielectric loss with processing temperature displays a common trend in ferroelectric and dielectric thin oxide films: firstly an increase and then a decrease in dielectric loss when the processing temperature is gradually raised. Such a dielectric response of ferroelectric/dielectric thin films has been theoretically addressed in this work. We propose that at the initial stage of the crystallization process in thin films, the transformation from amorphous to crystalline phase should increase substantially the dielectric loss; then, with further increase in the processing temperature, the coalescent growth of small crystalline grains into big ones could be helpful in reducing the dielectric loss by lowering grain boundary densities. The obtained experimental data for (Ba, Sr)TiO3 thin films with 500 nm in thickness were analyzed in terms of the model developed and shown to be in a reasonable agreement with the theoretical results.",
    "MGT": "The evolution of dielectric loss with processing temperature is a critical factor influencing the performance and reliability of ferroelectric and dielectric thin oxide films in electronic applications. This study develops a comprehensive model to analyze the temperature-dependent behavior of dielectric loss during film fabrication, focusing on the interplay of structural phase transitions, defect dynamics, and microstructural evolution. By integrating experimental data with theoretical simulations, the model captures the effects of processing temperature on energy dissipation mechanisms, including ionic displacement, defect polarization, and interfacial contributions. Thin films of perovskite oxides, such as lead zirconate titanate (PZT) and barium titanate, were investigated to validate the model, revealing distinct regimes of dielectric loss correlated with temperature-dependent crystallization and defect redistribution. The findings provide insights into optimizing processing conditions to minimize dielectric loss while preserving desirable ferroelectric and dielectric properties. This work contributes to the advancement of thin oxide film technology for applications in capacitors, sensors, and memory devices, emphasizing the importance of precise thermal control during fabrication."
  },
  {
    "id": 105,
    "prompt": "The Rate Loss of Single-Letter Characterization: The \"Dirty\" Multiple Access Channel",
    "HWT": "For general memoryless systems, the typical information theoretic solution - when exists - has a \"single-letter\" form. This reflects the fact that optimum performance can be approached by a random code (or a random binning scheme), generated using independent and identically distributed copies of some single-letter distribution. Is that the form of the solution of any (information theoretic) problem? In fact, some counter examples are known. The most famous is the \"two help one\" problem: Korner and Marton showed that if we want to decode the modulo-two sum of two binary sources from their independent encodings, then linear coding is better than random coding. In this paper we provide another counter example, the \"doubly-dirty\" multiple access channel (MAC). Like the Korner-Marton problem, this is a multi-terminal scenario where side information is distributed among several terminals; each transmitter knows part of the channel interference but the receiver is not aware of any part of it. We give an explicit solution for the capacity region of a binary version of the doubly-dirty MAC, demonstrate how the capacity region can be approached using a linear coding scheme, and prove that the \"best known single-letter region\" is strictly contained in it. We also state a conjecture regarding a similar rate loss of single letter characterization in the Gaussian case.",
    "MGT": "The study of multi-user communication systems is fundamental in understanding the capacity limits of modern networks. This paper investigates the \"dirty\" multiple access channel (DMAC), a communication scenario where multiple transmitters send information to a single receiver while contending with interference that is non-causally known to some users. Despite significant progress in characterizing the capacity of such channels, single-letter characterizations, widely used for their simplicity and analytical tractability, are often associated with rate losses compared to more complex multi-letter strategies. This work critically examines the rate loss incurred by single-letter characterization in the DMAC setting. We derive explicit bounds on the achievable rate regions for scenarios with varying levels of interference knowledge and user cooperation. Through a combination of information-theoretic analysis and numerical simulations, we identify cases where single-letter strategies are optimal and cases where their performance degrades relative to multi-letter approaches. Furthermore, we highlight the role of structured coding techniques, such as lattice and superposition codes, in mitigating the rate loss. Our results reveal that while single-letter characterizations provide valuable insights into the DMAC’s capacity, their limitations become pronounced in the presence of highly structured interference or when the interference knowledge is asymmetric across users. These findings underscore the need for refined coding strategies to fully exploit the potential of the DMAC. This work contributes to the broader understanding of multi-user information theory and offers practical guidelines for designing efficient communication systems in interference-limited environments."
  },
  {
    "id": 106,
    "prompt": "Ionization Equilibrium Timescales in Collisional Plasmas",
    "HWT": "Astrophysical shocks or bursts from a photoionizing source can disturb the typical collisional plasma found in galactic interstellar media or the intergalactic medium. The spectrum emitted by this plasma contains diagnostics that have been used to determine the time since the disturbing event, although this determination becomes uncertain as the elements in the plasma return to ionization equilibrium. A general solution for the equilibrium timescale for each element arises from the elegant eigenvector method of solution to the problem of a non-equilibrium plasma described by Masai (1984) and Hughes & Helfand (1985). In general the ionization evolution of an element Z in a constant electron temperature plasma is given by a coupled set of Z+1 first order differential equations. However, they can be recast as Z uncoupled first order differential equations using an eigenvector basis for the system. The solution is then Z separate exponential functions, with the time constants given by the eigenvalues of the rate matrix. The smallest of these eigenvalues gives the scale of slowest return to equilibrium independent of the initial conditions, while conversely the largest eigenvalue is the scale of the fastest change in the ion population. These results hold for an ionizing plasma, a recombining plasma, or even a plasma with random initial conditions, and will allow users of these diagnostics to determine directly if their best-fit result significantly limits the timescale since a disturbance or is so close to equilibrium as to include an arbitrarily-long time.",
    "MGT": "Ionization equilibrium in collisional plasmas is a fundamental concept in astrophysics and plasma physics, dictating the distribution of ions and electrons and influencing a wide range of observable phenomena. This study investigates the timescales over which ionization equilibrium is achieved in various plasma conditions, emphasizing the role of collisional processes. We employ a combination of analytical models and numerical simulations to explore the dependence of ionization equilibrium timescales on plasma temperature, density, and composition. Our findings reveal that ionization equilibrium is significantly influenced by the electron density and temperature, with higher temperatures and densities generally leading to faster equilibrium timescales due to increased collisional ionization and recombination rates.\n\nFurthermore, the study dissects the impact of different ion species and their respective ionization potentials, providing insights into how complex plasmas, such as those found in stellar atmospheres and fusion devices, evolve towards equilibrium. We demonstrate that lighter elements, with their lower ionization potentials, reach equilibrium more swiftly compared to heavier elements under identical conditions. This research also highlights the critical thresholds where deviations from equilibrium assumptions become substantial, offering guidelines for the interpretation of spectroscopic data and the modeling of plasma behavior in non-equilibrium scenarios.\n\nOur results have significant implications for the understanding of astrophysical phenomena such as nova explosions, solar flares, and the interstellar medium, as well as for the design and operation of controlled fusion experiments. By refining the knowledge of ionization dynamics in collisional plasmas, this study contributes to the broader endeavor of accurately modeling and predicting plasma behavior in both natural and laboratory environments."
  },
  {
    "id": 107,
    "prompt": "Gene regulation in continuous cultures: A unified theory for bacteria and yeasts",
    "HWT": "During batch growth on mixtures of two growth-limiting substrates, microbes consume the substrates either sequentially or simultaneously. These growth patterns are manifested in all types of bacteria and yeasts. The ubiquity of these growth patterns suggests that they are driven by a universal mechanism common to all microbial species. In previous work, we showed that a minimal model accounting only for enzyme induction and dilution explains the phenotypes observed in batch cultures of various wild-type and mutant/recombinant cells. Here, we examine the extension of the minimal model to continuous cultures. We show that: (1) Several enzymatic trends, usually attributed to specific regulatory mechanisms such as catabolite repression, are completely accounted for by dilution. (2) The bifurcation diagram of the minimal model for continuous cultures, which classifies the substrate consumption pattern at any given dilution rate and feed concentrations, provides a a precise explanation for the empirically observed correlation between the growth patterns in batch and continuous cultures. (3) Numerical simulations of the model are in excellent agreement with the data. The model captures the variation of the steady state substrate concentrations, cell densities, and enzyme levels during the single- and mixed-substrate growth of bacteria and yeasts at various dilution rates and feed concentrations. (4) This variation is well-approximated by simple analytical expressions that furnish physical insights into the steady states of continuous cultures. The minimal model provides a framework for quantitating the effect of regulatory mechanisms. We illustrate this by analyzing several data sets from the literature.",
    "MGT": "Understanding gene regulation in continuous cultures is essential for deciphering the mechanisms that govern cellular adaptation, growth, and survival in dynamic environments. This study presents a unified theoretical framework for gene regulation in bacteria and yeasts within continuous culture systems, bridging gaps between prokaryotic and eukaryotic regulatory mechanisms. By integrating principles of molecular biology, systems biology, and mathematical modeling, we elucidate how nutrient availability, population density, and environmental constraints drive transcriptional and post-transcriptional regulation in these microorganisms. The proposed model highlights common regulatory themes, such as feedback loops, metabolic prioritization, and stress response pathways, while accounting for species-specific differences in operon structures and chromatin dynamics. Experimental validation using Escherichia coli and Saccharomyces cerevisiae cultured in chemostats reveals conserved regulatory strategies, such as nutrient sensing via global regulators and differential expression of genes involved in metabolism, transport, and stress resistance. Furthermore, the study explores the evolutionary implications of gene regulation in continuous cultures, demonstrating how fluctuating environments select for adaptable regulatory networks that balance cellular efficiency and resilience. This unified theory advances our understanding of microbial gene regulation by providing a framework that accommodates both bacterial and yeast systems, offering insights into industrial applications such as bioengineering, fermentation, and synthetic biology. By revealing the interplay between genetic circuits and environmental dynamics, the findings emphasize the importance of continuous cultures as a model for studying microbial physiology and evolution. This work lays the foundation for future research aimed at optimizing microbial performance in biotechnological processes and improving our comprehension of gene regulation across diverse biological systems."
  },
  {
    "id": 108,
    "prompt": "Phase diagram of chiral quark matter: Fulde-Ferrell pairing from weak to strong coupling",
    "HWT": "We calculate the phase diagram of two-flavor quark matter in the temperature-flavor asymmetry plane in the case where there are three competing phases: the homogeneous Bardeen-Cooper-Schrieffer (BCS) phase, the unpaired phase, and a phase with broken spatial symmetry, which is here taken to be the counterpart of the Fulde-Ferrell (FF) phase in condensed matter physics. We show that the system belongs to the universality class of paramagnetic-ferromagnetic -helical systems. We vary the coupling constant of the theory, which is obtained from integrating out the gluonic degrees of freedom. In weak coupling, the FF phase is favored at arbitrary flavor asymmetries for sufficiently low temperatures; at intermediate coupling its occupancy domain is shifted towards larger asymmetries. Strong coupling features a new regime of an inhomogeneous FF state, which we identify with a current-carrying Bose-Einstein condensate of tightly bound up and down quarks. We analyze the occupation numbers and the Cooper-pair wave function and show that when the condensate momentum is orthogonal to the particle momentum the minority component contains a blocking region (breach) around the Fermi sphere in the weak-coupling limit, which engulfs more low-momentum modes as the coupling is increased, and eventually leads to a topological change in strong coupling, where the minority Fermi sphere contains either two occupied strips or an empty sphere. For non-orthogonal momenta, the blocking region is either reduced or extinct, i.e., no topological changes are observed.",
    "MGT": "The study of chiral quark matter has garnered significant attention due to its relevance in high-density quantum chromodynamics (QCD) and astrophysical phenomena such as neutron stars and heavy-ion collisions. This work investigates the phase diagram of chiral quark matter, emphasizing the emergence of Fulde-Ferrell (FF) pairing in regimes spanning weak to strong coupling. FF pairing, characterized by a spatially modulated condensate, arises as a solution to imbalanced systems where mismatched Fermi surfaces inhibit conventional pairing. Using a combination of analytical techniques and numerical simulations within the framework of Nambu–Jona-Lasinio (NJL) models extended to include vector interactions, we analyze the interplay between chiral symmetry breaking and superconducting phases. Our study reveals that FF pairing dominates in regions of intermediate coupling strength, where the competition between pairing and chiral condensation is most pronounced. At weak coupling, the system favors BCS-like pairing, while at strong coupling, the chiral condensate suppresses superconducting phases entirely. The phase diagram exhibits a rich structure, including regions of coexistence between chiral symmetry breaking and spatially modulated superconductivity. Temperature and chemical potential are identified as key control parameters governing transitions between these phases. The results are consistent with predictions from gauge theories and provide insight into the microscopic mechanisms driving inhomogeneous pairing in dense quark matter. These findings have implications for understanding the internal structure and dynamics of compact astrophysical objects, as well as for experimental explorations of QCD matter under extreme conditions. The study opens avenues for further exploration of exotic phases in strongly interacting matter and their astrophysical manifestations."
  },
  {
    "id": 109,
    "prompt": "Coulomb gas transitions in three-dimensional classical dimer models",
    "HWT": "Close-packed, classical dimer models on three-dimensional, bipartite lattices harbor a Coulomb phase with power-law correlations at infinite temperature. Here, we discuss the nature of the thermal phase transition out of this Coulomb phase for a variety of dimer models which energetically favor crystalline dimer states with columnar ordering. For a family of these models we find a direct thermal transition from the Coulomb phase to the dimer crystal. While some systems exhibit (strong) first-order transitions in correspondence with the Landau-Ginzburg-Wilson paradigm, we also find clear numerical evidence for continuous transitions. A second family of models undergoes two consecutive thermal transitions with an intermediate paramagnetic phase separating the Coulomb phase from the dimer crystal. We can describe all of these phase transitions in one unifying framework of candidate field theories with two complex Ginzburg-Landau fields coupled to a U(1) gauge field. We derive the symmetry-mandated Ginzburg-Landau actions in these field variables for the various dimer models and discuss implications for their respective phase transitions.",
    "MGT": "We investigate the phase transitions in three-dimensional classical dimer models through the framework of the Coulomb gas formalism. Dimer models, which describe arrangements of hard-core particles on lattice edges subject to local constraints, exhibit rich statistical mechanics due to their inherent geometric frustration. In three dimensions, the long-wavelength behavior of the system can be mapped to an emergent Coulomb phase, characterized by algebraic decays in correlation functions and the presence of effective gauge fields. We analyze the interplay between thermal fluctuations, lattice topology, and local constraints, which drive transitions between different phases. Using numerical simulations and analytical techniques, we identify critical points where the Coulomb phase breaks down, giving rise to symmetry-breaking or disordered states. These transitions are classified based on universality classes and are shown to depend sensitively on lattice geometry and anisotropy. Our results provide insights into the broader class of constrained systems, with implications for strongly correlated materials, artificial spin ice, and quantum dimer models. The study highlights the role of emergent gauge fields in driving novel critical phenomena in three-dimensional frustrated systems."
  },
  {
    "id": 110,
    "prompt": "Self-Force Calculations with Matched Expansions and Quasinormal Mode Sums",
    "HWT": "We present the first application of the Poisson-Wiseman-Anderson method of matched expansions, to compute the self-force acting on a point particle moving in a curved spacetime. The method uses two expansions for the Green function, valid in `quasilocal' and `distant past' regimes, which are matched within the normal neighbourhood. We perform our calculation in a static region of the spherically symmetric Nariai spacetime (dS_2 x S^2), on which scalar perturbations are governed by a radial equation with a P\\\"oschl-Teller potential. We combine (i) a very high order quasilocal expansion, and (ii) an expansion in quasinormal modes, to determine the Green function globally. We show it is singular everywhere on the null wavefront (even outside the normal neighbourhood), and apply asymptotic methods to determine its singular structure. We find the Green function undergoes a transition every time the null wavefront passes through a caustic: the singular part follows a repeating four-fold sequence $\\delta(\\sigma)$, $1/\\pi \\sigma$, $-\\delta(\\sigma)$, $-1/\\pi \\sigma$ etc., where $\\sigma$ is Synge's world function. The matched expansion method provides new insight into the non-local properties of the self-force; we find the contribution from the segment of the worldline lying outside the normal neighbourhood is significant. We compute the scalar self-force acting on a static particle, and validate against an alternative method. Finally, we discuss wave propagation on black hole spacetimes (where any expansion in quasinormal modes will be augmented by a branch cut integral) and predict that the Green function in Schwarzschild spacetime will inherit the four-fold singular structure found here.",
    "MGT": "The study of self-force effects in curved spacetime is a cornerstone of understanding the dynamics of small compact objects in general relativity, particularly in the context of extreme mass ratio inspirals (EMRIs). This paper presents a novel approach for calculating self-force corrections by combining matched asymptotic expansions with quasinormal mode (QNM) summation techniques. Matched asymptotic expansions allow for a detailed treatment of the near-zone behavior of the perturbing field, accurately resolving the singular structure near the particle while ensuring continuity with the far-zone asymptotics. Simultaneously, the quasinormal mode approach provides a natural framework for representing the radiative aspects of the field in the far-zone, leveraging the resonant modes of the black hole spacetime. \n\nThe proposed hybrid methodology resolves critical challenges in self-force computations by merging these complementary perspectives, ensuring both high precision near the particle and robust representation of wave propagation at large distances. We demonstrate the efficacy of this approach by applying it to scalar and gravitational perturbations in Schwarzschild spacetime, providing analytical and numerical results that confirm the consistency and accuracy of our framework. The summation over QNM contributions is shown to converge rapidly when combined with the near-zone matched expansion, highlighting the computational advantages of this technique.\n\nAdditionally, we explore the physical implications of self-force effects on orbital evolution, focusing on the interplay between conservative and dissipative components of the force. Our results underscore the importance of accurate self-force modeling for predicting gravitational waveforms from EMRIs, a key target for future space-based observatories such as LISA. The hybrid approach introduced here paves the way for extending self-force calculations to more complex scenarios, including spinning black holes and higher-dimensional spacetimes, offering a versatile tool for probing the intricate dynamics of compact object systems in relativity."
  },
  {
    "id": 111,
    "prompt": "Nuclear Structure in 146Gd",
    "HWT": "In this work the experimental study of the 144Sm(alpha, 2n) fusion-evaporation reaction is presented. The experiment was carried out at the IKP of the University of Cologne in order to identify double octupole states and two-particle configurations in the 146Gd nucleus. The target was surrounded by a compact array of nine individual Ge detectors and one EUROBALL CLUSTER detector. A total of 44 new states have been identified, as well as new gamma rays corresponding to 26 previously known levels. Among these levels, new candidates for the two-particle configuration states have been found as well as for the (3- x 2+) and (3- x 3-) two phonon multiplets. A very important results of this work is the unequivocal assignment of the 6- member of the two phonon octupole state in 146Gd by identifying the E3 branching to the one phonon 3- state. This result presents the first conclusive observation of a 6+ to 3- to 0+ double E3 cascade in the decay of a two-phonon octupole state.",
    "MGT": "The study of nuclear structure in isotopes of gadolinium provides vital insights into the behavior of atomic nuclei, particularly those far from stability. This research focuses on the detailed examination of the nuclear structure of the isotope ^146Gd. Utilizing advanced gamma-ray spectroscopy techniques and high-resolution detectors, we have identified various energy levels and transition pathways within the nucleus of ^146Gd. Our experimental setup employed a fusion-evaporation reaction using a ^116Sn target and a ^30Si beam, leading to the population of excited states in ^146Gd. Analysis of the resulting gamma-ray spectra allowed us to construct a precise level scheme, revealing new insights into the structural features of this isotope. Comparisons with theoretical models such as the shell model and collective model calculations indicate significant deviations, suggesting potential new patterns of nuclear deformation and shape coexistence. These findings contribute to the broader understanding of nuclear forces and the interaction mechanisms in medium-mass nuclei. Additionally, the results have implications for refining nuclear models and enhance predictive capabilities for isotopes near the closed neutron shell. Future work will explore the implications of these structural features on the stability and decay properties of ^146Gd."
  },
  {
    "id": 112,
    "prompt": "Incommensurate spin-density wave and magnetic lock-in transition in CaFe4As3",
    "HWT": "The magnetic structure for the newly discovered iron-arsenide compound \\CaFeAs has been studied by neutron powder diffraction. Long-range magnetic order is detected below 85K, with an incommensurate modulation described by the propagation vector k=(0, $\\delta$,0), $\\delta\\sim$ 0.39. Below $\\sim$ 25K, our measurements detect a first-order phase transition where $\\delta$ locks into the commensurate value 3/8. A model of the magnetic structure is proposed for both temperature regimes, based on Rietveld refinements of the powder data and symmetry considerations. The structures correspond to longitudinal spin-density-waves with magnetic moments directed along the \\textit{b}-axis. A Landau analysis captures the change in thermodynamic quantities observed at the two magnetic transitions, in particular the drop in resistivity at the lock-in transition.",
    "MGT": "The spin-density wave (SDW) state in low-dimensional magnetic systems often exhibits complex incommensurate structures, which are sensitive to subtle lattice and electronic interactions. In this study, we investigate the emergence of an incommensurate SDW and the associated magnetic lock-in transition in the quasi-one-dimensional compound CaFe4As3. Using a combination of neutron diffraction, magnetization measurements, and theoretical modeling, we reveal the presence of an incommensurate SDW below the Néel temperature, characterized by a modulation vector that varies with temperature. Upon further cooling, a magnetic lock-in transition occurs, where the SDW becomes commensurate with the lattice, driven by strong magnetoelastic coupling. This transition is accompanied by distinct anomalies in thermodynamic properties, highlighting the interplay between spin and lattice degrees of freedom. Our findings shed light on the mechanisms governing SDW formation and lock-in transitions, providing insights into the rich magnetic behavior of low-dimensional iron-based systems."
  },
  {
    "id": 113,
    "prompt": "The Order of Phase Transitions in Barrier Crossing",
    "HWT": "A spatially extended classical system with metastable states subject to weak spatiotemporal noise can exhibit a transition in its activation behavior when one or more external parameters are varied. Depending on the potential, the transition can be first or second-order, but there exists no systematic theory of the relation between the order of the transition and the shape of the potential barrier. In this paper, we address that question in detail for a general class of systems whose order parameter is describable by a classical field that can vary both in space and time, and whose zero-noise dynamics are governed by a smooth polynomial potential. We show that a quartic potential barrier can only have second-order transitions, confirming an earlier conjecture [1]. We then derive, through a combination of analytical and numerical arguments, both necessary conditions and sufficient conditions to have a first-order vs. a second-order transition in noise-induced activation behavior, for a large class of systems with smooth polynomial potentials of arbitrary order. We find in particular that the order of the transition is especially sensitive to the potential behavior near the top of the barrier.",
    "MGT": "In the study of barrier crossing phenomena, understanding the nature of phase transitions is crucial for advancing theoretical models and practical applications. This paper investigates the order of phase transitions occurring during barrier crossing processes, employing a combination of analytical techniques and computational simulations. By examining systems subjected to varying energy landscapes and external perturbations, we uncover the conditions under which first-order and second-order phase transitions manifest. Our findings reveal that the presence of metastable states and their stability play a significant role in determining the order of the transition. Furthermore, we identify critical parameters that govern the switch between different transition orders, providing insights into the underlying mechanisms. Through detailed analysis, we demonstrate that first-order transitions are characterized by abrupt changes in order parameters, while second-order transitions exhibit continuous transformations. The results highlight the importance of considering both thermodynamic and kinetic factors in predicting phase behavior. This research contributes to a deeper understanding of phase transitions in barrier crossing, with implications for fields such as chemical kinetics, material science, and biological systems. The insights gained from this study pave the way for designing optimized processes and materials by leveraging the controllable aspects of phase transition orders. Future work will extend these findings to more complex and dynamic systems."
  },
  {
    "id": 114,
    "prompt": "Implication of the observable spectral cutoff energy evolution in XTE J1550-564",
    "HWT": "The physical mechanisms responsible for production of the non-thermal emission in accreting black holes (BH) should be imprinted in the observational apperances of the power law tails in the X-ray spectra from these objects. Different spectral states exhibited by galactic BH binaries allow examination of the photon upscattering under different accretion regimes. We revisit the data collected by Rossi X-ray Timing Explorer (RXTE) from the BH X-ray binary XTE J1550-564 during two periods of X-ray activity in 1998 and 2000 focusing on the behavior of the high energy cutoff of the power law part of the spectrum. For the 1998 outburst the transition from the low-hard state to the intermediate state was accompanied by a gradual decrease in the cutoff energy which then showed an abrupt reversal to a clear increasing trend as the source evolved to the very high and high-soft states. The 2000 outburst showed only the decreasing part of this pattern. Notably, the photon indexes corresponding to the cutoff increase for the 1998 event are much higher than the index values reached during the 2000 rise transition. We attribute this difference in the cutoff energy behavior to the different partial contributions of the thermal and non-thermal (bulk motion) Comptonization in photon upscattering. Namely, during the 1998 event the higher accretion rate presumably provided more cooling to the Comptonizing media and thus reducing the effectiveness of the thermal upscattering process. Under these conditions the bulk motion takes a leading role in boosting the input soft photons. Monte Carlo simulations of the Comptonization in a bulk motion region near an accreting black hole by Laurent & Titarchuk 2010 strongly support this scenario.",
    "MGT": "The study of X-ray binaries, particularly those hosting black holes, provides significant insights into the accretion processes and relativistic jets. XTE J1550-564, a well-known black hole X-ray binary system, has been the subject of extensive research due to its variable nature and the rich variety of phenomena it exhibits. This paper focuses on the observable spectral cutoff energy evolution in XTE J1550-564, which holds key implications for understanding the physical conditions near the black hole. Using data obtained from multiple observations during different outburst phases, we analyze the spectral energy distribution, paying particular attention to the spectral cutoff energy and its evolution over time. Our findings indicate that the cutoff energy exhibits considerable variability, correlating with changes in the X-ray flux and spectral states of the system. These results suggest that the spectral cutoff is influenced by the geometry of the accretion disk and the configuration of the corona, as well as by the dynamics of the inner accretion flow. Furthermore, our analysis reveals that during the hard-to-soft state transitions, the cutoff energy decreases significantly, implying a cooling of the Comptonizing electrons. This transition is consistent with the formation of a more optically thick accretion disk. The study also explores the implications of these findings for the models of accretion flows and the conditions that lead to jet formation. By comparing the observed spectral characteristics with theoretical models, we aim to constrain the physical parameters of the system, such as the electron temperature and optical depth of the corona. Our results contribute to a deeper understanding of the complex interplay between accretion processes and the relativistic jets in black hole X-ray binaries, offering new perspectives on the fundamental physics governing these enigmatic systems."
  },
  {
    "id": 115,
    "prompt": "Time Step Expansions and the Invariant Manifold Approach to Lattice Boltzmann Models",
    "HWT": "The classical method for deriving the macroscopic dynamics of a lattice Boltzmann system is to use a combination of different approximations and expansions. Usually a Chapman-Enskog analysis is performed, either on the continuous Boltzmann system, or its discrete velocity counterpart. Separately a discrete time approximation is introduced to the discrete velocity Boltzmann system, to achieve a practically useful approximation to the continuous system, for use in computation. Thereafter, with some additional arguments, the dynamics of the Chapman-Enskog expansion are linked to the discrete time system to produce the dynamics of the completely discrete scheme. In this paper we put forward a different route to the macroscopic dynamics. We begin with the system discrete in both velocity space and time. We hypothesize that the alternating steps of advection and relaxation, common to all lattice Boltzmann schemes, give rise to a slow invariant manifold. We perform a time step expansion of the discrete time dynamics using the invariance of the manifold. Finally we calculate the dynamics arising from this system. By choosing the fully discrete scheme as a starting point we avoid mixing approximations and arrive at a general form of the microscopic dynamics up to the second order in the time step. We calculate the macroscopic dynamics of two commonly used lattice schemes up to the first order, and hence find the precise form of the deviation from the Navier-Stokes equations in the dissipative term, arising from the discretization of velocity space. Finally we perform a short wave perturbation on the dynamics of these example systems, to find the necessary conditions for their stability.",
    "MGT": "The lattice Boltzmann method (LBM) has emerged as an effective computational approach for simulating fluid dynamics, offering advantages in terms of simplicity and parallelizability. Despite its widespread application, there remains a need to enhance its computational efficiency and accuracy, particularly for complex flows. This study investigates the use of time step expansions and the invariant manifold approach as a means to refine LBM. The research focuses on the theoretical underpinnings of time step expansions, which are employed to extend the stability and accuracy of numerical simulations without compromising the inherent simplicity of the LBM framework. By integrating this with the invariant manifold approach, the study aims to systematically reduce the dimensionality of the problem, identifying key variables that govern the system's dynamics. The invariant manifold approach provides a rigorous mathematical framework for approximating the slow manifold of the system, thereby capturing the essential features of the fluid flow with reduced computational expense. We incorporate these methodologies into lattice Boltzmann models and conduct a series of numerical experiments to assess their impact on performance. The results demonstrate that the combined approach significantly enhances the stability and accuracy of LBM simulations, particularly in scenarios characterized by high Reynolds numbers and complex boundary conditions. This hybrid methodology also shows promise in reducing computational costs, making LBM more feasible for large-scale simulations. The findings suggest that the synergy between time step expansions and invariant manifold techniques could pave the way for more robust and efficient implementations of lattice Boltzmann models, potentially broadening their applicability in fluid dynamics research and industry. Future research directions include extending this approach to multi-phase flows and exploring its integration with other advanced numerical techniques."
  },
  {
    "id": 116,
    "prompt": "Azimuthal Anisotropy: Ridges, Recombination and Breaking of Quark Number Scaling",
    "HWT": "Azimuthal anisotropy is studied by taking into account the ridges created by semi-hard scattering, which is sensitive to the initial spatial configuration in non-central heavy-ion collisions. No rapid thermalization is required. Although hydrodynamics is not used in this study, the validity of hydrodynamical expansion is not excluded at later time after equilibration is achieved. Phenomenological properties of the bulk and ridge behaviors are used as inputs to determine the elliptic flow of pion and proton at low p_T. At intermediate p_T the recombination of shower partons with thermal partons becomes more important. The phi dependence arises from the variation of the in-medium path length of the hard parton that generates the shower. The p_T dependence of v_2 is therefore very different at intermediate p_T compared to that at low p_T. Quark number scaling of v_2 is shown to be only approximately valid at low p_T, but is broken at intermediate p_T, even though recombination is the mechanism of hadronization in all p_T regions considered.",
    "MGT": "Azimuthal anisotropy in high-energy nuclear collisions provides critical insights into the properties of the quark-gluon plasma (QGP), a state of matter believed to have existed shortly after the Big Bang. This study delves into the complex interplay between ridges, recombination, and the breaking of quark number scaling, each serving as a crucial aspect of the anisotropic flow observed in heavy-ion collisions. We investigate how initial geometric configurations and subsequent medium interactions give rise to ridge phenomena, characterized by long-range rapidity correlations seen in the transverse plane. Furthermore, the role of quark recombination processes is scrutinized, highlighting their contribution to the collective flow patterns and deviations from simple scaling laws based on quark number. Our analysis employs a combination of theoretical models and experimental data from the Large Hadron Collider (LHC) and the Relativistic Heavy Ion Collider (RHIC), offering a comprehensive understanding of the mechanisms underlying azimuthal anisotropy. The results suggest significant modifications in hadronization processes, challenging existing paradigms and pointing toward a more nuanced picture of QGP dynamics, with implications for the fundamental understanding of strong interactions in extreme conditions."
  },
  {
    "id": 117,
    "prompt": "Accurate structure factors from pseudopotential methods",
    "HWT": "Highly accurate experimental structure factors of silicon are available in the literature, and these provide the ideal test for any \\emph{ab initio} method for the construction of the all-electron charge density. In a recent paper [J. R. Trail and D. M. Bird, Phys. Rev. B {\\bf 60}, 7863 (1999)] a method has been developed for obtaining an accurate all-electron charge density from a first principles pseudopotential calculation by reconstructing the core region of an atom of choice. Here this method is applied to bulk silicon, and structure factors are derived and compared with experimental and Full-potential Linear Augmented Plane Wave results (FLAPW). We also compare with the result of assuming the core region is spherically symmetric, and with the result of constructing a charge density from the pseudo-valence density + frozen core electrons. Neither of these approximations provide accurate charge densities. The aspherical reconstruction is found to be as accurate as FLAPW results, and reproduces the residual error between the FLAPW and experimental results.",
    "MGT": "Accurate determination of structure factors is essential for understanding the electronic, optical, and structural properties of materials. Pseudopotential methods, which simplify the treatment of core electrons while preserving the accuracy of valence electron interactions, offer a computationally efficient approach to calculating structure factors. This study explores the application of pseudopotential techniques to achieve precise structure factor calculations for a wide range of crystalline materials. A systematic comparison is performed between pseudopotential-based results and experimental data, as well as fully ab initio all-electron methods, to validate the accuracy and reliability of the pseudopotential approach. Particular emphasis is placed on the role of pseudopotential transferability, the choice of exchange-correlation functional, and the impact of resolution in reciprocal space. The findings demonstrate that pseudopotential methods, when carefully parameterized, can reproduce experimental structure factors with high fidelity while significantly reducing computational cost. Moreover, this approach enables the investigation of complex materials systems where all-electron methods would be computationally prohibitive. These results highlight the potential of pseudopotential methods as a powerful tool for advancing material science, particularly in the study of electronic structure and lattice dynamics. Future directions for improving pseudopotential accuracy and expanding applicability are discussed."
  },
  {
    "id": 118,
    "prompt": "Examining the crossover from hadronic to partonic phase in QCD",
    "HWT": "It is argued that, due to the existence of two vacua -- perturbative and physical -- in QCD, the mechanism for the crossover from hadronic to partonic phase is hard to construct. The challenge is: how to realize the transition between the two vacua during the gradual crossover of the two phases. A possible solution of this problem is proposed and a mechanism for crossover, consistent with the principle of QCD, is constructed. The essence of this mechanism is the appearance and growing up of a kind of grape-shape perturbative vacuum inside the physical one. A dynamical percolation model based on a simple dynamics for the delocalization of partons is constructed to exhibit this mechanism. The crossover from hadronic matter to sQGP as well as the transition from sQGP to wQGP in the increasing of temperature is successfully described by using this model with a temperature dependent parameter.",
    "MGT": "The transition from the hadronic to the partonic phase represents a fundamental shift in the behavior of strongly interacting matter under extreme conditions, as described by Quantum Chromodynamics (QCD). This study investigates the crossover between these phases, focusing on the interplay between confinement, deconfinement, and chiral symmetry restoration. Utilizing lattice QCD simulations and effective field theories, we analyze thermodynamic observables, such as energy density and pressure, to identify signatures of the transition. Additionally, we explore the role of transport coefficients, such as shear viscosity, in characterizing the phase behavior near the crossover region. The results highlight the gradual nature of the transition, where hadronic degrees of freedom dissolve into a quasi-free partonic plasma. Comparisons with experimental data from heavy-ion collisions provide insights into the relevance of these findings to the quark-gluon plasma observed in laboratory settings. Our work underscores the importance of bridging theoretical models and experimental observations to deepen understanding of QCD phase transitions."
  },
  {
    "id": 119,
    "prompt": "Supersymmetric Leptogenesis with a Light Hidden Sector",
    "HWT": "Supersymmetric scenarios incorporating thermal leptogenesis as the origin of the observed matter-antimatter asymmetry generically predict abundances of the primordial elements which are in conflict with observations. In this paper we propose a simple way to circumvent this tension and accommodate naturally thermal leptogenesis and primordial nucleosynthesis. We postulate the existence of a light hidden sector, coupled very weakly to the Minimal Supersymmetric Standard Model, which opens up new decay channels for the next-to-lightest supersymmetric particle, thus diluting its abundance during nucleosynthesis. We present a general model-independent analysis of this mechanism as well as two concrete realizations, and describe the relevant cosmological and astrophysical bounds and implications for this dark matter scenario. Possible experimental signatures at colliders and in cosmic-ray observations are also discussed.",
    "MGT": "Supersymmetric leptogenesis provides a compelling framework for explaining the cosmic baryon asymmetry through the generation of a lepton asymmetry, later converted to baryons via sphaleron processes. In this work, we explore a novel extension involving a light hidden sector coupled to the Standard Model through supersymmetric interactions. The hidden sector introduces additional dynamical degrees of freedom, including light scalar and fermion fields, which can catalyze efficient leptogenesis even at lower temperatures. We analyze the interplay between supersymmetry-breaking effects, hidden sector dynamics, and out-of-equilibrium decays, demonstrating that a viable baryon asymmetry can emerge under realistic cosmological conditions. Furthermore, we assess experimental signatures, such as displaced vertex events and missing energy signals, that could reveal the presence of the hidden sector at collider experiments. This framework offers intriguing insights into baryogenesis and supersymmetric model building in beyond-the-Standard-Model physics."
  },
  {
    "id": 120,
    "prompt": "Switching between Hidden Markov Models using Fixed Share",
    "HWT": "In prediction with expert advice the goal is to design online prediction algorithms that achieve small regret (additional loss on the whole data) compared to a reference scheme. In the simplest such scheme one compares to the loss of the best expert in hindsight. A more ambitious goal is to split the data into segments and compare to the best expert on each segment. This is appropriate if the nature of the data changes between segments. The standard fixed-share algorithm is fast and achieves small regret compared to this scheme. Fixed share treats the experts as black boxes: there are no assumptions about how they generate their predictions. But if the experts are learning, the following question arises: should the experts learn from all data or only from data in their own segment? The original algorithm naturally addresses the first case. Here we consider the second option, which is more appropriate exactly when the nature of the data changes between segments. In general extending fixed share to this second case will slow it down by a factor of T on T outcomes. We show, however, that no such slowdown is necessary if the experts are hidden Markov models.",
    "MGT": "Hidden Markov Models (HMMs) are widely used for modeling sequential data across diverse domains, including speech recognition, bioinformatics, and financial forecasting. In practice, the performance of a single HMM may degrade when applied to heterogeneous data, necessitating methods for dynamically switching between multiple models. This paper explores the application of the Fixed Share algorithm, a powerful tool for online learning in non-stationary environments, to the problem of switching between HMMs. Fixed Share enables adaptive redistribution of model weights, allowing for seamless transitions between models based on their predictive accuracy over time. We propose an integrated framework that combines Fixed Share with traditional HMM inference techniques, enabling dynamic model selection while preserving the probabilistic foundations of HMMs. Through empirical evaluation on synthetic and real-world datasets, our approach demonstrates significant improvements in predictive accuracy compared to static model selection and naive blending methods. Additionally, we analyze the theoretical underpinnings of Fixed Share within the context of HMMs, highlighting its ability to handle abrupt changes in data distributions while minimizing regret. The results show that this method is particularly effective in environments where the underlying system dynamics are complex and evolve over time. This work provides a robust foundation for real-time model adaptation in sequential data applications, offering new opportunities for improved decision-making in dynamic settings."
  },
  {
    "id": 121,
    "prompt": "Massive gravity and structure formation",
    "HWT": "We study the growth of cosmological perturbations in the model of Lorentz-violating massive gravity. The Friedman equation in this model acquires an unconventional term due to the Lorentz-breaking condensates which has the equation of state w = -1 / (3 gamma) with gamma being a free parameter taking values outside of the range [0,1/3]. Apart from the standard contributions, the perturbations above the Friedmann background contain an extra piece which is proportional to an arbitrary function theta(x) of the space coordinates. This function appears as an integration constant and corresponds to a non-propagating scalar mode which may, however, become dynamical with the account of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1 the ``anomalous'' perturbations grow slower than the standard ones and thus the model is compatible with observations. Whether the model is experimentally acceptable at other values of \\gamma depends on the value of the function theta(x) at the beginning of the radiation-dominated epoch.",
    "MGT": "This study investigates the implications of massive gravity theories on cosmic structure formation, offering insights into the dynamics of large-scale structures in the universe. Massive gravity, an extension of general relativity, suggests that gravitons possess a nonzero mass, thereby modifying gravitational interactions over cosmic distances. We explore how these modifications influence the growth of density perturbations and the evolution of cosmic structures from the early universe to the present epoch. Utilizing analytical techniques and numerical simulations, we examine the impact of massive gravity on key cosmological observables, such as the cosmic microwave background radiation, galaxy clustering, and the distribution of dark matter. Our findings indicate that massive gravity models can lead to noticeable deviations from the predictions of standard cosmology, particularly affecting the rate of structure formation and the anisotropies in the cosmic microwave background. The results suggest that future astronomical surveys and high-precision cosmological data can potentially distinguish between massive gravity models and the standard Lambda Cold Dark Matter (ΛCDM) model, providing a pathway to testing the viability of these theories and their role in explaining the universe's accelerated expansion."
  },
  {
    "id": 122,
    "prompt": "From high-mass starless cores to high-mass protostellar objects",
    "HWT": "Aims: Our aim is to understand the evolutionary sequence of high-mass star formation from the earliest evolutionary stage of high-mass starless cores, via high-mass cores with embedded low- to intermediate-mass objects, to finally high-mass protostellar objects. Methods: Herschel far-infrared PACS and SPIRE observations are combined with existing data at longer and shorter wavelengths to characterize the spectral and physical evolution of massive star-forming regions. Results: The new Herschel images spectacularly show the evolution of the youngest and cold high-mass star-forming regions from mid-infrared shadows on the Wien-side of the spectral energy distribution (SED), via structures almost lost in the background emission around 100mum, to strong emission sources at the Rayleigh-Jeans tail. Fits of the SEDs for four exemplary regions covering evolutionary stages from high-mass starless cores to high-mass protostellar objects reveal that the youngest regions can be fitted by single-component black-bodies with temperatures on the order of 17K. More evolved regions show mid-infrared excess emission from an additional warmer component, which however barely contributes to the total luminosities for the youngest regions. Exceptionally low values of the ratio between bolometric and submm luminosity additionally support the youth of the infrared-dark sources. Conclusions: The Herschel observations reveal the spectral and physical properties of young high-mass star-forming regions in detail. The data clearly outline the evolutionary sequence in the images and SEDs. Future work on larger samples as well as incorporating full radiative transfer calculations will characterize the physical nature at the onset of massive star formation in even more depth.",
    "MGT": "High-mass star formation remains one of the most enigmatic processes in astrophysics, with significant gaps in our understanding of the transition from high-mass starless cores to high-mass protostellar objects. This evolutionary phase is critical for constraining the physical conditions and mechanisms that drive massive star formation, as well as for identifying the initial mass reservoir available for stellar growth. Using observations across multiple wavelengths, coupled with advanced numerical simulations, we investigate the physical properties, chemical evolution, and kinematics of high-mass starless cores as they evolve into protostellar objects. Our study reveals that high-mass starless cores are characterized by extreme densities, cold temperatures, and significant gravitational instability, which rapidly lead to collapse and the formation of accretion disks. Protostellar feedback mechanisms, including radiative heating, outflows, and turbulence, are shown to play a pivotal role in shaping the surrounding environment and regulating subsequent accretion rates. We further identify key spectral markers and molecular tracers that distinguish high-mass starless cores from their protostellar counterparts, providing valuable diagnostics for observational studies. The transition phase is marked by dynamic interactions between infalling material, emerging protostellar jets, and magnetic fields, which collectively influence the mass and angular momentum transfer processes. This research highlights the importance of high spatial and spectral resolution observations in disentangling the complexities of high-mass star formation. Our findings contribute to a more nuanced understanding of the initial conditions required for massive star birth and provide a foundation for future investigations into the formation and early evolution of high-mass stellar systems."
  },
  {
    "id": 123,
    "prompt": "Modeling Vacuum Arcs",
    "HWT": "We are developing a model of vacuum arcs. This model assumes that arcs develop as a result of mechanical failure of the surface due to Coulomb explosions, followed by ionization of fragments by field emission and the development of a small, dense plasma that interacts with the surface primarily through self sputtering and terminates as a unipolar arc capable of producing breakdown sites with high enhancement factors. We have attempted to produce a self consistent picture of triggering, arc evolution and surface damage. We are modeling these mechanisms using Molecular Dynamics (mechanical failure, Coulomb explosions, self sputtering), Particle-In-Cell (PIC) codes (plasma evolution), mesoscale surface thermodynamics (surface evolution), and finite element electrostatic modeling (field enhancements). We can present a variety of numerical results. We identify where our model differs from other descriptions of this phenomenon.",
    "MGT": "Vacuum arcs are critical phenomena in high-voltage systems, particle accelerators, and fusion devices, where they can disrupt operation and cause hardware degradation. Despite their importance, the underlying mechanisms governing vacuum arc formation, evolution, and extinction remain poorly understood due to their complex interplay of plasma physics, material science, and electromagnetic effects. This study develops a comprehensive modeling framework for vacuum arcs, integrating microscopic material properties, plasma generation, and field emission dynamics. Using multi-scale simulations, we capture the transition from initial electron emission to plasma sheath formation and arc stabilization. Results highlight the influence of material composition, surface roughness, and applied voltage on arc behavior, providing predictive insights into arc initiation thresholds and energy dissipation rates. Comparisons with experimental data validate the model's accuracy and offer a deeper understanding of arc-induced damage mechanisms. These findings contribute to improved design strategies for vacuum systems, minimizing arc occurrence and extending operational lifetimes in advanced technological applications."
  },
  {
    "id": 124,
    "prompt": "Comprehensive Characterization of InGaAs/InP Avalanche Photodiodes at 1550 nm with an Active Quenching ASIC",
    "HWT": "We present an active quenching application specific integrated circuit (ASIC), for use in conjunction with InGaAs/InP avalanche photodiodes (APDs), for 1550 nm single-photon detection. To evaluate its performance, we first compare its operation with that of standard quenching electronics. We then test 4 InGaAs/InP APDs using the ASIC, operating both in the free-running and gated modes, to study more general behavior. We investigate not only the standard parameters under different working conditions but also parameters such as charge persistence and quenching time. We also use the multiple trapping model to account for the afterpulsing behavior in the gated mode, and further propose a model to take account of the afterpulsing effects in the free-running mode. Our results clearly indicate that the performance of APDs with an on-chip quenching circuit significantly surpasses the conventional quenching electronics, and makes them suitable for practical applications, e.g., quantum cryptography.",
    "MGT": "In this study, we present a detailed characterization of InGaAs/InP avalanche photodiodes (APDs) optimized for operation at the telecom wavelength of 1550 nm, integrated with an active quenching application-specific integrated circuit (ASIC). The investigation focuses on key performance metrics, including dark count rate, photon detection efficiency, timing jitter, and afterpulsing probability, under varying bias voltages and temperature conditions. The active quenching ASIC enables precise control and rapid quenching of avalanche events, significantly improving the device's overall reliability and suitability for high-speed applications. Experimental results demonstrate excellent detection efficiency exceeding 30% at a low dark count rate, with timing jitter below 100 ps, highlighting the device’s potential for photon-starved quantum communication systems and LiDAR applications. Additionally, the study provides insights into the interplay between the APD structure and the ASIC in suppressing afterpulsing phenomena, ensuring stable long-term operation. These findings establish InGaAs/InP APDs with active quenching ASICs as promising candidates for next-generation single-photon detection systems."
  },
  {
    "id": 125,
    "prompt": "Coexistence between superconducting and spin density wave states in iron-based superconductors: Ginzburg-Landau analysis",
    "HWT": "We consider the interplay between superconducting (SC) and commensurate spin-density-wave (SDW) orders in iron-pnictides by analyzing a multiple order Ginzburg-Landau free energy. We are particularly interested in whether the doping-induced transition between the two states is first order, or the two pure phases are separated by an intermediate phase with coexisting SC and SDW orders. For perfect nesting, the two orders do not coexist, because SDW order, which comes first, gaps the full Fermi surface leaving no space for SC to develop. When nesting is not perfect due to either ellipticity of electron bands or doping-induced difference in chemical potentials for holes and electrons, SDW order still leaves modified Fermi surfaces for not too strong SDW magnetism and the SC order may develop. We show that the two orders coexist only when certain relations between ellipticity and doping are met. In particular, in a compensated metal, ellipticity alone is not sufficient for coexistence of the two orders.",
    "MGT": "The coexistence of superconductivity and spin density wave (SDW) states in iron-based superconductors remains a central topic in condensed matter physics, with implications for understanding unconventional superconductivity. In this work, we employ a Ginzburg-Landau formalism to investigate the interplay between these two competing orders. By constructing a phenomenological free energy that incorporates the superconducting and SDW order parameters, we analyze the conditions under which coexistence becomes energetically favorable. The mutual interaction terms between the orders are found to play a pivotal role in determining the stability of the coexistence phase, and we identify regimes where the competition leads to suppression or enhancement of one order by the other. Our analysis highlights the influence of microscopic parameters, such as coupling strength and anisotropy, on the phase diagram, offering insights into experimental observations in iron pnictides and chalcogenides. The results provide a framework for understanding the rich phase behavior in these materials and suggest possible avenues for tuning coexistence via external parameters such as pressure or doping."
  },
  {
    "id": 126,
    "prompt": "A Constructive Generalization of Nash Equilibrium for Better Payoffs and Stability",
    "HWT": "In a society of completely selfish individuals where everybody is only interested in maximizing his own payoff, does any equilibrium exist for the society? John Nash proved more than 50 years ago that an equilibrium always exists such that nobody would benefit from unilaterally changing his strategy. Nash Equilibrium is a central concept in game theory, which offers a mathematical foundation for social science and economy. However, it is important from both a theoretical and a practical point of view to understand game playing where individuals are less selfish. This paper offers a constructive generalization of Nash equilibrium to study n-person games where the selfishness of individuals can be defined at any level, including the extreme of complete selfishness. The generalization is constructive since it offers a protocol for individuals in a society to reach an equilibrium. Most importantly, this paper presents experimental results and theoretical investigation to show that the individuals in a society can reduce their selfishness level together to reach a new equilibrium where they can have better payoffs and the society is more stable at the same time. This study suggests that, for the benefit of everyone in a society (including the financial market), the pursuit of maximal payoff by each individual should be controlled at some level either by voluntary good citizenship or by imposed regulations.",
    "MGT": "The Nash equilibrium is a cornerstone of game theory, providing a framework for predicting strategic behavior in competitive and cooperative settings. However, its reliance on individual rationality and static optimality often results in outcomes that are suboptimal in terms of collective payoffs and stability. This paper introduces a constructive generalization of Nash equilibrium, termed the Cooperative Stability Equilibrium (CSE), designed to address these limitations. The CSE expands the standard Nash framework by incorporating cooperative dynamics and iterative optimization processes that account for mutual benefit and long-term stability. By redefining equilibrium conditions to prioritize collective payoff maximization alongside individual strategic consistency, the CSE offers a robust alternative for decision-making scenarios where traditional Nash equilibria fail to deliver satisfactory outcomes. Through formal analysis, the paper demonstrates that the CSE retains the foundational properties of Nash equilibrium, such as existence and rational strategy profiles, while achieving higher payoffs and enhanced stability across a diverse range of games. Numerical simulations and case studies illustrate the practical advantages of this approach, including its applications in economic negotiations, resource allocation, and multi-agent systems. The findings suggest that the CSE framework significantly broadens the scope of equilibrium analysis, creating pathways for more socially optimal and resilient decision-making. This constructive generalization reimagines equilibrium theory as a dynamic and cooperative construct, paving the way for further research into hybrid models of strategic interaction."
  },
  {
    "id": 127,
    "prompt": "High energy emission and polarisation limits for the INTEGRAL burst GRB 061122",
    "HWT": "(Abridged) GRB 061122 is one of the brightest GRBs detected within INTEGRAL's field of view to date. The two gamma-ray detectors on INTEGRAL were used to investigate the spectral characteristics of GRB 061122. A search for linear polarisation in the prompt emission was carried out using the SPI multiple event data in the energy range 100 keV-1 MeV. The prompt spectrum was best fit by a combination of a blackbody and a power--law model (the quasithermal model), with evidence for high energy emission continuing above 8 MeV. A pseudo-redshift value of pz = 0.95 +/- 0.18 was determined using the spectral fit parameters. The isotropic energy at this pseudo-redshift is 8.5 x 10^{52} erg. The jet opening angle was estimated to be smaller than 2.8 deg or larger than 11.9 deg from the X-ray lightcurve. An upper limit of 60% polarisation was determined for the prompt emission of GRB 061122, using the multiple event data. The high energy emission observed in the spectrum may be due to the reverse shock interacting with the GRB ejecta when it is decelerated by the circumburst medium. This behaviour has been observed in a small fraction of GRBs to date, but is expected to be more commonly observed by the Fermi Gamma-ray Space Telescope. The conditions for polarisation are met if the jet opening angle is less than 2.8 deg, but further constraints on the level of polarisation are not possible.",
    "MGT": "GRB 061122, a gamma-ray burst observed by the INTEGRAL spacecraft, provides critical insights into high-energy astrophysical phenomena and polarization characteristics of transient cosmic events. This study examines the emission properties and polarization constraints of GRB 061122, focusing on the burst's spectral and temporal evolution across the energy range covered by INTEGRAL's instruments. Utilizing data from the SPI and IBIS detectors, we perform detailed spectral modeling to characterize the burst's high-energy emission, yielding constraints on the peak energy, photon indices, and total fluence. The results reveal a typical Band-like spectrum, with evidence of significant spectral evolution during the burst's prompt emission phase. Additionally, polarimetric analysis of the gamma-ray data is conducted using the SPI instrument's Compton scattering capabilities to explore potential polarization signatures. While no statistically significant polarization signal is detected, upper limits on linear polarization are derived, contributing to ongoing efforts to understand the magnetic field structures and emission mechanisms in GRB jets. The results are consistent with theoretical models predicting synchrotron radiation as a dominant emission process, albeit with notable variability in jet composition and geometry. This work highlights the importance of multi-instrument observations for constraining high-energy processes in GRBs and underscores the utility of INTEGRAL in probing both spectral and polarimetric properties. By placing GRB 061122 within the broader context of the GRB population, we discuss implications for jet dynamics, particle acceleration, and magnetization levels. Future observations with advanced polarimetric sensitivity will be pivotal in refining our understanding of the polarization characteristics and their connection to GRB emission mechanisms."
  },
  {
    "id": 128,
    "prompt": "A critical layer model for turbulent pipe flow",
    "HWT": "A model-based description of the scaling and radial location of turbulent fluctuations in turbulent pipe flow is presented and used to illuminate the scaling behaviour of the very large scale motions. The model is derived by treating the nonlinearity in the perturbation equation (involving the Reynolds stress) as an unknown forcing, yielding a linear relationship between the velocity field response and this nonlinearity. We do not assume small perturbations. We examine propagating modes, permitting comparison of our results to experimental data, and identify the steady component of the velocity field that varies only in the wall-normal direction as the turbulent mean profile. The \"optimal\" forcing shape, that gives the largest velocity response, is assumed to lead to modes that will be dominant and hence observed in turbulent pipe flow. An investigation of the most amplified velocity response at a given wavenumber-frequency combination reveals critical layer-like behaviour reminiscent of the neutrally stable solutions of the Orr-Sommerfeld equation in linearly unstable flow. Two distinct regions in the flow where the influence of viscosity becomes important can be identified, namely a wall layer that scales with $R^{+1/2}$ and a critical layer, where the propagation velocity is equal to the local mean velocity, that scales with $R^{+2/3}$ in pipe flow. This framework appears to be consistent with several scaling results in wall turbulence and reveals a mechanism by which the effects of viscosity can extend well beyond the immediate vicinity of the wall.",
    "MGT": "This study presents the development of a critical layer model aimed at enhancing the understanding of turbulent pipe flow dynamics. Turbulent flow in circular pipes exhibits complex interactions between large-scale structures and small-scale turbulence, challenging existing modeling approaches. The proposed framework introduces the concept of a critical layer, defined as the region where the mean velocity gradient and turbulent energy production achieve dynamic balance. By integrating theoretical insights from hydrodynamic stability and turbulence theory, the model captures the interplay between energy transfer mechanisms across the wall-normal direction. A systematic analysis of direct numerical simulation (DNS) data is employed to validate the critical layer hypothesis, identifying key spatial regions within the flow where turbulent production and dissipation rates converge. \n\nThe model further emphasizes the role of coherent structures, such as streaks and vortices, in shaping the turbulent energy cascade. Parametric studies reveal the dependence of critical layer positioning on Reynolds number, supporting the scalability of the framework to high-Reynolds-number flows. Comparisons with established empirical and analytical models highlight the improved predictive capability of the critical layer approach, particularly in resolving near-wall turbulence and bulk flow properties. \n\nApplications of the model extend to engineering scenarios requiring precise flow control, such as pipeline transport and energy systems, where understanding turbulent behavior is paramount. The findings offer novel perspectives on the mechanisms governing turbulent pipe flow and pave the way for refined turbulence models in computational fluid dynamics (CFD). By bridging foundational theory with practical computational approaches, this study contributes to the broader effort to achieve robust and accurate predictions of complex fluid dynamics in industrial and natural systems."
  },
  {
    "id": 129,
    "prompt": "Importance of constraining the dense matter Equation of State in pulsar astrophysics",
    "HWT": "We study the dependence of the surface magnetic fields of radio pulsars on the choice of Equations of State, pulsar masses and the values of the angle between the magnetic axis and the spin axis of the pulsars within simple dipole model. We show that the values of the surface magnetic field can be even order of magnitude different from its canonical values. This difference will effect any magnetosphere related model to explain observational features of radio pulsars and magnetars. We find a significant difference of the value of the surface magnetic field from the commonly quoted value for the faster member of the double pulsar system, i.e. PSR J0737-3039A as here both the mass of the pulsar and the angle between the magnetic axis and the spin axis are known. Our study reveals the importance of constraining the dense matter Equations of State in pulsar astrophysics as well as hints an alternative way to constrain these by independent determination of the pulsar magnetic field.",
    "MGT": "The dense matter Equation of State (EoS) plays a pivotal role in understanding the fundamental properties of neutron stars and their astrophysical behavior. Pulsars, highly magnetized rotating neutron stars, serve as cosmic laboratories for probing dense matter physics under extreme conditions. Constraining the EoS is vital for linking pulsar observations, such as mass, radius, and spin frequency measurements, with theoretical models of nuclear and particle physics. Accurate constraints enable precise predictions of neutron star structure, maximum mass limits, and phenomena like gravitational wave emission from mergers. Recent advancements in multi-messenger astrophysics, including X-ray and radio timing observations, alongside gravitational wave detections, have provided unprecedented opportunities to refine the EoS. However, challenges persist due to uncertainties in nuclear interactions at supra-nuclear densities and the complex interplay of exotic states such as hyperons, quark matter, or condensates. This article underscores the importance of constraining the dense matter EoS, highlighting its implications for pulsar astrophysics, neutron star evolution, and broader questions in fundamental physics, including the nature of matter at the highest densities encountered in the universe."
  },
  {
    "id": 130,
    "prompt": "Noise and nonlinearities in high-throughput data",
    "HWT": "High-throughput data analyses are becoming common in biology, communications, economics and sociology. The vast amounts of data are usually represented in the form of matrices and can be considered as knowledge networks. Spectra-based approaches have proved useful in extracting hidden information within such networks and for estimating missing data, but these methods are based essentially on linear assumptions. The physical models of matching, when applicable, often suggest non-linear mechanisms, that may sometimes be identified as noise. The use of non-linear models in data analysis, however, may require the introduction of many parameters, which lowers the statistical weight of the model. According to the quality of data, a simpler linear analysis may be more convenient than more complex approaches. In this paper, we show how a simple non-parametric Bayesian model may be used to explore the role of non-linearities and noise in synthetic and experimental data sets.",
    "MGT": "In the era of big data, high-throughput technologies have become indispensable across various scientific disciplines, offering unprecedented insights into complex systems. However, the rapid expansion of data volume has introduced significant challenges in terms of noise and nonlinearities, which can obscure true biological or physical signals. This paper investigates the impact of these factors on data analysis and interpretation. We explore various sources of noise, including technical, biological, and environmental, and their implications for data quality. Additionally, we examine how nonlinearities can arise in high-throughput data due to system-level interactions and measurement limitations, complicating downstream analyses. Through a combination of theoretical modeling and empirical case studies, we assess the effectiveness of current methodologies in mitigating these issues. Our findings suggest that while advanced statistical and computational techniques can partially address noise and nonlinearities, there is a critical need for more robust, adaptable models. Ultimately, this study highlights the necessity for interdisciplinary approaches to enhance the reliability and accuracy of insights drawn from high-throughput datasets."
  },
  {
    "id": 131,
    "prompt": "Dilatons in Hidden Local Symmetry for Hadrons in Dense Matter",
    "HWT": "With the explicit breaking of scale invariance by the trace anomaly of QCD rephrased in terms of spontaneous breaking, low-energy strong interaction dynamics of dense (and also hot) matter can be effectively captured by -- in addition to the Nambu-Goldstone bosons and the vector mesons -- two dilaton fields, the \"soft\" ($\\chi_s$) field that is locked to chiral symmetry and the \"hard\" ($\\chi_h$) field which remains unaffected by chiral symmetry. The interplay of the soft and hard dilatons plays a subtle role in how chiral symmetry is manifested in hot and/or dense matter. The scale anomaly in which the soft component intervenes vanishes at the chiral transition in a way analogous to the restoration of scale symmetry in the Freund-Nambu model, while that of the hard component remains broken throughout the QCD sector. Most remarkable of all is its role in the chiral anomaly sector through a \"homogeneous Wess-Zumino (hWZ) term\" of the form $\\omega_\\mu B^\\mu$ on the structure of a single baryon as well as dense baryonic matter. It figures crucially in predicting a \"Little Bag\" for the nucleon and a \"quarkyonic phase\" in the form of a half-skyrmion matter at high density. We show how the vanishing of the vector-meson mass at the vector manifestation fixed point in hidden local symmetry theory can be related to the property of the \"matter field\" in the Freund-Nambu model that leaves scale symmetry invariant. The emerging structure of dense hadronic matter in the model so constructed suggests what could be amiss in describing dense matter in holographic dual QCD at its large $N_c$ and 't Hooft limit.",
    "MGT": "In this study, we explore the role of dilatons within the framework of hidden local symmetry (HLS) to investigate the behavior of hadronic matter under conditions of high density. Dilatons, as scalar fields associated with the spontaneous breaking of scale invariance, provide a crucial link between chiral symmetry restoration and the modification of hadronic properties in dense environments. By incorporating dilatons into the HLS formalism, we aim to extend its applicability to regimes where density-dependent effects become significant, such as in compact astrophysical objects or heavy-ion collision experiments. The interplay between dilaton dynamics and vector meson interactions is examined, revealing significant implications for the scaling behaviors of hadronic masses and coupling constants in dense matter. \n\nOur analysis highlights how dilaton condensates evolve with density, influencing the effective restoration of chiral symmetry and the emergence of novel phases of matter. We also investigate the impact of dilaton fields on the vector meson dominance mechanism and the in-medium modifications of mesonic and baryonic properties. Through effective field theory techniques, we derive density-dependent relations that connect dilaton dynamics to observable quantities, such as the equation of state and spectral functions of hadrons in dense matter. These results are compared with empirical constraints from astrophysical observations and experimental data.\n\nWe find that the inclusion of dilatons within the HLS framework not only provides a unified description of scale and chiral symmetries but also enhances predictive power in modeling dense hadronic systems. This approach offers a promising avenue for understanding fundamental aspects of QCD in extreme conditions, including the transition to deconfined quark matter. The implications of this work extend to both theoretical developments in nuclear physics and practical applications in interpreting astrophysical phenomena, such as neutron star interiors and heavy-ion collisions at high energies."
  },
  {
    "id": 132,
    "prompt": "Surface magnetic fields on two accreting T Tauri stars: CV Cha and CR Cha",
    "HWT": "We have produced brightness and magnetic field maps of the surfaces of CV Cha and CR Cha: two actively accreting G and K-type T Tauri stars in the Chamaeleon I star-forming cloud with ages of 3-5 Myr. Our magnetic field maps show evidence for strong, complex multi-polar fields similar to those obtained for young rapidly rotating main sequence stars. Brightness maps indicate the presence of dark polar caps and low latitude spots -- these brightness maps are very similar to those obtained for other pre-main sequence and rapidly rotating main sequence stars. Only two other classical T Tauri stars have been studied using similar techniques so far: V2129 Oph and BP Tau. CV Cha and CR Cha show magnetic field patterns that are significantly more complex than those recovered for BP Tau, a fully convective T Tauri star. We discuss possible reasons for this difference and suggest that the complexity of the stellar magnetic field is related to the convection zone; with more complex fields being found in T Tauri stars with radiative cores (V2129 Oph, CV Cha and CR Cha). However, it is clearly necessary to conduct magnetic field studies of T Tauri star systems, exploring a wide range of stellar parameters in order to establish how they affect magnetic field generation, and thus how these magnetic fields are likely to affect the evolution of T Tauri star systems as they approach the main sequence.",
    "MGT": "We present a detailed study of the surface magnetic fields on two accreting T Tauri stars, CV Cha and CR Cha, based on high-resolution spectropolarimetric observations combined with advanced magnetic field reconstruction techniques. T Tauri stars, as young pre-main sequence objects, are crucial for understanding stellar evolution processes, particularly in the presence of strong magnetic fields that regulate accretion dynamics and stellar winds. Using Zeeman-Doppler imaging and magnetically sensitive absorption lines, we map the large-scale magnetic topologies of CV Cha and CR Cha, revealing complex field structures with significant contributions from both dipolar and multipolar components. The field strengths on CV Cha and CR Cha are found to range between several hundred gauss to over a kilogauss, with notable differences in field orientation and configuration. These variations suggest a link between magnetic field geometry and accretion activity, which we explore through simultaneous photometric and spectroscopic monitoring of accretion tracers such as Hα emission. The interplay between magnetic field and accretion funnels is also investigated, highlighting the role of magnetospheric interactions in shaping circumstellar disk evolution. Comparative analysis with other T Tauri stars indicates that the magnetic properties of CV Cha and CR Cha are consistent with their masses and rotation rates, while exhibiting unique features that may relate to their early evolutionary states. This study underscores the importance of magnetic field characterization in understanding the magnetohydrodynamic processes governing star-disk systems and provides insights into the diverse magnetic environments of young stellar objects."
  },
  {
    "id": 133,
    "prompt": "Positive and negative streamers in ambient air: modeling evolution and velocities",
    "HWT": "We simulate short positive and negative streamers in air at standard temperature and pressure. They evolve in homogeneous electric fields or emerge from needle electrodes with voltages of 10 to 20 kV. The streamer velocity at given streamer length depends only weakly on the initial ionization seed, except in the case of negative streamers in homogeneous fields. We characterize the streamers by length, head radius, head charge and field enhancement. We show that the velocity of positive streamers is mainly determined by their radius and in quantitative agreement with recent experimental results both for radius and velocity. The velocity of negative streamers is dominated by electron drift in the enhanced field; in the low local fields of the present simulations, it is little influenced by photo-ionization. Though negative streamer fronts always move at least with the electron drift velocity in the local field, this drift motion broadens the streamer head, decreases the field enhancement and ultimately leads to slower propagation or even extinction of the negative streamer.",
    "MGT": "This study presents a comprehensive modeling approach to understand the evolution and velocities of positive and negative streamers in ambient air. Streamers are pivotal in various atmospheric and industrial processes, yet their dynamic behaviors remain inadequately understood. Utilizing advanced computational models, we simulate the intricate physical and chemical interactions governing streamer propagation. Our models incorporate the effects of electric fields, ambient air composition, and initial ionization conditions to accurately depict streamer dynamics. Results reveal distinct differences in the propagation velocities and branching tendencies between positive and negative streamers, largely influenced by local electric field enhancement and electron attachment rates. Positive streamers exhibit faster propagation due to enhanced photoionization and reduced electron attachment, while negative streamers show increased branching influenced by higher electron affinity in air molecules. The study underscores the significance of initial conditions and external parameters in dictating streamer behavior. These findings contribute valuable insights into optimizing applications such as lightning protection, pollution control, and plasma-assisted combustion. Future work will focus on experimental validation and exploring the implications of these dynamics under varying atmospheric conditions."
  },
  {
    "id": 134,
    "prompt": "Extinction risk and structure of a food web model",
    "HWT": "We investigate in detail the model of a trophic web proposed by Amaral and Meyer [Phys. Rev. Lett. 82, 652 (1999)]. We focused on small-size systems that are relevant for real biological food webs and for which the fluctuations are playing an important role. We show, using Monte Carlo simulations, that such webs can be non-viable, leading to extinction of all species in small and/or weakly coupled systems. Estimations of the extinction times and survival chances are also given. We show that before the extinction the fraction of highly-connected species (\"omnivores\") is increasing. Viable food webs exhibit a pyramidal structure, where the density of occupied niches is higher at lower trophic levels, and moreover the occupations of adjacent levels are closely correlated. We also demonstrate that the distribution of the lengths of food chains has an exponential character and changes weakly with the parameters of the model. On the contrary, the distribution of avalanche sizes of the extinct species depends strongly on the connectedness of the web. For rather loosely connected systems we recover the power-law type of behavior with the same exponent as found in earlier studies, while for densely-connected webs the distribution is not of a power-law type.",
    "MGT": "The study of food web models is crucial for understanding the dynamics of ecosystems and the factors influencing species survival. This research explores the intricate relationship between food web structure and extinction risk. By constructing a theoretical model, we simulate various ecological scenarios to examine how changes in food web architecture impact species persistence. Our model incorporates key ecological parameters such as trophic levels, connectivity, and energy transfer efficiency.\n\nWe employ a combination of analytical and computational techniques to assess extinction risks within different food web configurations. The findings reveal that highly connected and complex food webs exhibit increased resilience against species loss, primarily due to their ability to redistribute energy and compensate for species declines. Conversely, simplified food webs with lower connectivity are more susceptible to cascading extinctions, as the loss of a single species can significantly disrupt energy flow and trophic interactions.\n\nFurthermore, the study highlights the critical role of keystone species in maintaining food web stability. The removal or decline of these species leads to disproportionate effects on overall web structure and function, thereby elevating extinction risk. Our results underscore the importance of preserving biodiversity and maintaining a balanced food web structure to mitigate extinction risks.\n\nThis research contributes to the growing body of literature on ecological resilience and provides valuable insights for conservation strategies aimed at preserving ecosystem integrity in the face of environmental change."
  },
  {
    "id": 135,
    "prompt": "Dumb-bell swimmers",
    "HWT": "We investigate the way in which oscillating dumb-bells, a simple microscopic model of apolar swimmers, move at low Reynold's number. In accordance with Purcell's Scallop Theorem a single dumb-bell cannot swim because its stroke is reciprocal in time. However the motion of two or more dumb-bells, with mutual phase differences, is not time reversal invariant, and hence swimming is possible. We use analytical and numerical solutions of the Stokes equations to calculate the hydrodynamic interaction between two dumb-bell swimmers and to discuss their relative motion. The cooperative effect of interactions between swimmers is explored by considering first regular, and then random arrays of dumb-bells. We find that a square array acts as a micropump. The long time behaviour of suspensions of dumb-bells is investigated and compared to that of model polar swimmers.",
    "MGT": "Dumb-bell swimmers, a class of minimalistic artificial microswimmers, offer a simplified yet insightful model for studying self-propelled motion in low Reynolds number environments. Comprising two spheres connected by a rigid rod and subjected to periodic non-reciprocal actuation, these systems exemplify key principles of microscale hydrodynamics. In this work, we investigate the dynamics of dumb-bell swimmers using both theoretical analysis and computational simulations, addressing their propulsion mechanisms, efficiency, and interactions with surrounding fluid and obstacles. We explore how various geometrical and actuation parameters influence swimming performance, focusing on the transition between regimes of directed motion and chaotic trajectories. The study highlights the potential applications of dumb-bell swimmers in targeted delivery, environmental sensing, and microscale transport. By providing a foundational understanding of these systems, this work contributes to the broader field of artificial microswimmers and opens avenues for the design of optimized miniature robotic platforms."
  },
  {
    "id": 136,
    "prompt": "Indirect detection of gravitino dark matter including its three-body decays",
    "HWT": "It was recently pointed out that in supersymmetric scenarios with gravitino dark matter and bilinear R-parity violation, gravitinos with masses below Mw typically decay with a sizable branching ratio into the 3-body final states W^*+lepton and Z^*+neutrino. In this paper we study the indirect detection signatures of gravitino dark matter including such final states. First, we obtain the gamma ray spectrum from gravitino decays, which features a monochromatic contribution from the decay into photon+neutrino and a continuum contribution from the three-body decays. After studying its dependence on supersymmetric parameters, we compute the expected gamma ray fluxes and derive new constraints, from recent FERMI data, on the R-parity breaking parameter and on the gravitino lifetime. Indirect detection via antimatter searches, a new possibility brought about by the three-body final states, is also analyzed. For models compatible with the gamma ray observations, the positron signal is found to be negligible whereas the antiproton one can be significant.",
    "MGT": "Gravitino dark matter, a well-motivated candidate within supersymmetric theories, offers intriguing possibilities for indirect detection through its decay channels. This study explores the potential for indirect detection of gravitino dark matter, focusing on its three-body decay processes which have significant implications for cosmic ray and gamma-ray observations. By examining the decay products resulting from gravitino interactions, we refine the theoretical framework to encompass the complexities of these multi-body decays. Our analysis leverages state-of-the-art computational models to simulate the decay spectra and the resulting observable signals, offering new insights into the parameter space of supersymmetry breaking. We discuss the prospects of detecting these signals with upcoming and current astrophysical observatories, such as the Fermi Large Area Telescope and the Cherenkov Telescope Array, highlighting the sensitivity required to discern gravitino signatures amidst astrophysical backgrounds. This investigation not only enhances our understanding of gravitino dark matter properties but also provides a pathway for future experimental strategies, potentially guiding the design of next-generation detectors aimed at unveiling the elusive nature of dark matter in the universe."
  },
  {
    "id": 137,
    "prompt": "Impure Thoughts on Inelastic Dark Matter",
    "HWT": "The inelastic dark matter scenario was proposed to reconcile the DAMA annual modulation with null results from other experiments. In this scenario, WIMPs scatter into an excited state, split from the ground state by an energy delta comparable to the available kinetic energy of a Galactic WIMP. We note that for large splittings delta, the dominant scattering at DAMA can occur off of thallium nuclei, with A~205, which are present as a dopant at the 10^-3 level in NaI(Tl) crystals. For a WIMP mass m~100GeV and delta~200keV, we find a region in delta-m-parameter space which is consistent with all experiments. These parameters in particular can be probed in experiments with thallium in their targets, such as KIMS, but are inaccessible to lighter target experiments. Depending on the tail of the WIMP velocity distribution, a highly modulated signal may or may not appear at CRESST-II.",
    "MGT": "In recent years, the study of inelastic dark matter (IDM) has gained prominence as a compelling extension of the standard dark matter paradigm. This paper explores the theoretical and phenomenological implications of IDM, particularly focusing on the 'impurities' or deviations from its idealized models. We investigate the influence of these impurities on the cosmic evolution and detectability of dark matter. By employing a range of computational models and simulations, we demonstrate how inelastic interactions could lead to distinct signatures that can be observed through current and upcoming astrophysical surveys. Our analysis reveals that even minor impurities in the inelastic scattering processes can significantly affect the thermal relic density and the velocity distribution of dark matter particles. Additionally, we discuss the potential for IDM to address discrepancies in direct detection experiments and its compatibility with observed cosmic microwave background anisotropies. This study underscores the necessity of considering non-ideal characteristics in IDM models to enhance our understanding of dark matter's role in the universe."
  },
  {
    "id": 138,
    "prompt": "Opportunistic Scheduling and Beamforming for MIMO-OFDMA Downlink Systems with Reduced Feedback",
    "HWT": "Opportunistic scheduling and beamforming schemes with reduced feedback are proposed for MIMO-OFDMA downlink systems. Unlike the conventional beamforming schemes in which beamforming is implemented solely by the base station (BS) in a per-subcarrier fashion, the proposed schemes take advantages of a novel channel decomposition technique to perform beamforming jointly by the BS and the mobile terminal (MT). The resulting beamforming schemes allow the BS to employ only {\\em one} beamforming matrix (BFM) to form beams for {\\em all} subcarriers while each MT completes the beamforming task for each subcarrier locally. Consequently, for a MIMO-OFDMA system with $Q$ subcarriers, the proposed opportunistic scheduling and beamforming schemes require only one BFM index and $Q$ supportable throughputs to be returned from each MT to the BS, in contrast to $Q$ BFM indices and $Q$ supportable throughputs required by the conventional schemes. The advantage of the proposed schemes becomes more evident when a further feedback reduction is achieved by grouping adjacent subcarriers into exclusive clusters and returning only cluster information from each MT. Theoretical analysis and computer simulation confirm the effectiveness of the proposed reduced-feedback schemes.",
    "MGT": "Efficient resource allocation in multi-user MIMO-OFDMA downlink systems remains a significant challenge in wireless communication, especially under constraints of limited channel state information (CSI) feedback. This paper investigates an opportunistic scheduling and beamforming framework that minimizes feedback overhead while maintaining high spectral efficiency and fairness among users. The proposed scheme leverages statistical CSI and limited instantaneous feedback to select users and allocate resources dynamically, ensuring optimal exploitation of multi-user diversity and spatial degrees of freedom. A novel reduced-feedback mechanism is introduced, wherein users periodically submit quantized CSI metrics based on a predefined threshold, significantly decreasing signaling overhead without compromising system performance. The paper also presents an adaptive beamforming strategy that aligns transmission beams with the strongest channel eigenmodes, thereby maximizing throughput gains while mitigating inter-user interference. The performance of the proposed scheduling algorithm is analyzed through extensive simulations in realistic wireless environments, comparing it against conventional full-feedback methods. Results demonstrate that the reduced-feedback scheme achieves comparable spectral efficiency and fairness metrics while reducing feedback by up to 70%, making it highly suitable for modern broadband systems. The findings highlight that opportunistic scheduling and beamforming with reduced feedback provide a scalable solution for next-generation MIMO-OFDMA networks, addressing critical challenges in feedback constraints and computational complexity."
  },
  {
    "id": 139,
    "prompt": "Normal galaxies in the XMM-Newton fields. X-rays as a star formation indicator",
    "HWT": "Context: We use the first XMM serendipitous source catalogue (1XMM) to compile a sample of normal X-ray galaxies Aims: We seek to expand the database of X-ray selected normal galaxies at intermediate redshifts and examine the relation between X-ray emission and star formation for late-type systems Methods: The candidates are selected based on their X-ray (soft spectra), X-ray to optical [log(fx/fo)<-2] and optical (extended sources) properties. 44 candidates are found and 35 are spectroscopically observed with the Australian National University's 2.3m telescope to examine their nature. Results: Of the 35 sources observed, 2 are AGN, 11 emission line galaxies, 12 absorption line galaxies, 6 have featureless spectra while 4 are associated with Galactic stars. We combine our emission line sample with earlier works forming the most comprehensive X-ray selected galaxy sample for the study of the X-ray luminosity to the Halpha luminosity - a well-calibrated star-formation indicator - relation. Conclusions: We find that the X-ray luminosity strongly correlates with the Halpha luminosity, suggesting that the X-rays efficiently trace the star-formation.",
    "MGT": "This study explores the potential of utilizing X-ray emission as an indicator of star formation in normal galaxies, using data collected from XMM-Newton fields. Traditionally, star formation rates (SFRs) have been deduced using multi-wavelength data, including ultraviolet, optical, and infrared observations. However, recent advancements suggest that X-ray emissions, primarily originating from high-mass X-ray binaries (HMXBs) and supernova remnants, can offer an alternative method for assessing star-forming activities. Our research analyzes a sample of normal galaxies observed with XMM-Newton, focusing on their X-ray luminosities and correlating these with established SFR indicators. We also account for contributions from low-mass X-ray binaries and active galactic nuclei to isolate the X-ray emissions directly related to star formation processes. Our findings indicate a robust correlation between X-ray luminosity and SFR, suggesting that X-ray data can serve as a reliable proxy for star formation, particularly in environments where other wavelengths are obscured by dust. This correlation holds significant implications for studying distant galaxies where traditional indicators are challenging to obtain. By integrating X-ray data, our approach offers a more comprehensive understanding of star formation across diverse galactic environments, enhancing our ability to investigate the evolutionary history of galaxies across cosmic time."
  },
  {
    "id": 140,
    "prompt": "Effect of chemical substitution and pressure on YbRh2Si2",
    "HWT": "We carried out electrical resistivity experiments on (Yb, La)Rh2Si2 and on Yb(Rh, Ir)2Si2 under pressure and in magnetic fields. YbRh2Si2 exhibits a weak antiferromagnetic transition at atmospheric pressure with a N\\'eel temperature of only T_N = 70 mK. By applying a small magnetic field T_N can be continuously suppressed to T=0 at B_c = 60 mT (B_|_c) driving the system to a quantum critical point (QCP). On applying external pressure the magnetic phase is stabilized and T_N(p) is increasing as usually observed in Yb-based heavy-fermion metals. Substituting Yb by La or Rh by Ir allows to create a negative chemical pressure, La (Ir) being smaller than Yb (Rh), and eventually to drive YbRh2Si2 to a pressure controlled QCP. In this paper we compare the effect of external hydrostatic pressure and chemical substitution on the ground-state properties of YbRh2Si2.",
    "MGT": "The heavy fermion compound YbRh₂Si₂ has garnered significant attention due to its proximity to quantum criticality and unconventional electronic behavior. This study investigates the impact of chemical substitution and external pressure on the physical properties of YbRh₂Si₂, focusing on its magnetic, electronic, and structural characteristics. Substitution of Rh with transition metals and Si with Ge systematically tunes the electronic structure and modifies the hybridization between localized 4f electrons of Yb and conduction electrons, shifting the quantum critical point. Concurrently, the application of hydrostatic pressure suppresses magnetic ordering and induces a non-trivial evolution of the Fermi surface. Both methods reveal the interplay between Kondo screening and Ruderman-Kittel-Kasuya-Yosida (RKKY) interactions, which govern the material's complex phase diagram. Experimental techniques, including resistivity, magnetization, and specific heat measurements, are complemented by theoretical calculations to elucidate the microscopic mechanisms underlying these phenomena. The findings provide deeper insights into quantum criticality in heavy fermion systems and establish pathways for tailoring emergent electronic properties via external tuning parameters."
  },
  {
    "id": 141,
    "prompt": "Radiation-Hydrodynamics of Hot Jupiter Atmospheres",
    "HWT": "Radiative transfer in planetary atmospheres is usually treated in the static limit, i.e., neglecting atmospheric motions. We argue that hot Jupiter atmospheres, with possibly fast (sonic) wind speeds, may require a more strongly coupled treatment, formally in the regime of radiation-hydrodynamics. To lowest order in v/c, relativistic Doppler shifts distort line profiles along optical paths with finite wind velocity gradients. This leads to flow-dependent deviations in the effective emission and absorption properties of the atmospheric medium. Evaluating the overall impact of these distortions on the radiative structure of a dynamic atmosphere is non-trivial. We present transmissivity and systematic equivalent width excess calculations which suggest possibly important consequences for radiation transport in hot Jupiter atmospheres. If winds are fast and bulk Doppler shifts are indeed important for the global radiative balance, accurate modeling and reliable data interpretation for hot Jupiter atmospheres may prove challenging: it would involve anisotropic and dynamic radiative transfer in a coupled radiation-hydrodynamical flow. On the bright side, it would also imply that the emergent properties of hot Jupiter atmospheres are more direct tracers of their atmospheric flows than is the case for Solar System planets. Radiation-hydrodynamics may also influence radiative transfer in other classes of hot exoplanetary atmospheres with fast winds.",
    "MGT": "The atmospheres of hot Jupiters, gas giant exoplanets orbiting close to their host stars, present a unique laboratory for studying the interplay between radiative processes and hydrodynamic flows. These environments are characterized by extreme temperatures, intense stellar irradiation, and complex atmospheric dynamics, which together drive a range of phenomena such as thermal redistribution, atmospheric circulation, and potential mass loss. In this study, we develop a comprehensive radiation-hydrodynamics framework to model the coupled effects of stellar radiation and fluid dynamics in these atmospheres. Using state-of-the-art simulations, we explore how key factors, including stellar flux, planetary rotation, and atmospheric composition, influence temperature gradients, wind patterns, and energy transport. We find that the radiative heating on the day side leads to supersonic winds that redistribute energy to the cooler night side, creating steep thermal contrasts. Additionally, strong vertical winds and hydrodynamic escape are observed in some cases, suggesting potential atmospheric erosion over time. Our models reveal the importance of non-equilibrium chemistry and opacity variations in shaping the radiative cooling rates and flow structures. These results provide insights into the evolutionary pathways of hot Jupiters and their observable signatures, such as thermal phase curves and spectral features. This work highlights the necessity of coupling radiative transfer and hydrodynamics for accurately characterizing the diverse and dynamic atmospheres of close-in gas giants."
  },
  {
    "id": 142,
    "prompt": "Gemini GMOS spectroscopy of HeII nebulae in M33",
    "HWT": "We have carried out a narrow-band survey of the Local Group galaxy, M33, in the HeII4686 emission line, to identify HeII nebulae in this galaxy. With spectroscopic follow-up observations, we confirm three of seven candidate objects, including identification of two new HeII nebulae, BCLMP651, HBW673. We also obtain spectra of associated ionizing stars for all the HII regions, identifying two new WN stars. We demonstrate that the ionizing source for the known HeII nebula, MA 1, is consistent with being the early-type WN star MC8 (M33-WR14), by carrying out a combined stellar and nebular analysis of MC8 and MA1. We were unable to identify the helium ionizing sources for HBW 673 and BCLMP 651, which do not appear to be Wolf-Rayet stars. According to the [OIII]5007/Hbeta vs [NII]6584/Halpha diagnostic diagram, excitation mechanisms apart from hot stellar continuum are needed to account for the nebular emission in HBW 673, which appears to have no stellar source at all.",
    "MGT": "We present an analysis of Gemini GMOS spectroscopic observations of HeII nebulae in the nearby spiral galaxy M33. These nebulae, identified by their prominent HeII λ4686 emission, are rare astrophysical environments that provide critical insights into the properties of massive stars, ionizing sources, and feedback processes in galaxies. Our study focuses on a sample of HeII-bright regions, selected from previous imaging surveys, to investigate their physical conditions, ionization mechanisms, and stellar content. High-resolution spectroscopy with the GMOS instrument enables precise measurements of nebular line ratios, electron densities, and temperatures, as well as the kinematics of the ionized gas. Through a combination of photoionization modeling and diagnostic line analysis, we identify potential sources of the hard ionizing radiation required to produce HeII emission, including Wolf-Rayet stars, stripped stellar remnants, and high-mass X-ray binaries. Furthermore, we explore spatial variations in the nebular properties, revealing evidence for localized stellar feedback and shocks. These observations offer new constraints on the formation and evolution of HeII nebulae, as well as their role in shaping the interstellar medium of M33. Our findings contribute to a broader understanding of massive star populations and ionization processes in star-forming galaxies."
  },
  {
    "id": 143,
    "prompt": "Magnetic Field Properties in High Mass Star Formation from Large to Small Scales - A Statistical Analysis from Polarization Data",
    "HWT": "Polarization data from high mass star formation regions (W51 e2/e8, Orion BN/KL) are used to derive statistical properties of the plane of sky projected magnetic field. Structure function and auto-correlation function are calculated for observations with various resolutions from the BIMA and SMA interferometers, covering a range in physical scales from $\\sim 70$~mpc to $\\sim 2.1$~mpc. Results for the magnetic field turbulent dispersion, its turbulent to mean field strength ratio and the large-scale polarization angle correlation length are presented as a function of the physical scale at the star formation sites. Power law scaling relations emerge for some of these physical quantities. The turbulent to mean field strength ratio is found to be close to constant over the sampled observing range, with a hint of a decrease toward smaller scales, indicating that the role of magnetic field and turbulence is evolving with physical scale. A statistical method is proposed to separate large and small scale correlations from an initial ensemble of polarization segments. This also leads to a definition of a turbulent polarization angle correlation length.",
    "MGT": "This study explores the intricate properties of magnetic fields in high mass star formation regions, employing a comprehensive statistical analysis of polarization data across varying scales. High mass stars significantly influence their surroundings, and understanding the magnetism involved in their formation is crucial for astrophysical models. Our research integrates data from large-scale surveys, such as those conducted by the Planck satellite, with higher resolution observations from ground-based telescopes. By analyzing polarized light emitted from dust grains aligned with magnetic fields, we identify patterns and correlations that reveal the structure and strength of magnetic fields from parsec to sub-parsec scales. Statistical methods, including principal component analysis and hierarchical clustering, are deployed to discern trends and dependencies within the datasets. The findings highlight the role of magnetic fields in regulating accretion processes and shaping the morphology of star-forming regions. Moreover, this analysis provides insights into the transition from diffuse interstellar clouds to dense cores where star formation occurs. The results underscore the importance of multi-scale analyses in understanding the complexities of high mass star formation and suggest avenues for future investigations to refine theoretical models and simulations of magnetohydrodynamic processes in astrophysical environments."
  },
  {
    "id": 144,
    "prompt": "Star cluster kinematics with AAOmega",
    "HWT": "The high-resolution setup of the AAOmega spectrograph on the Anglo-Australian Telescope makes it a beautiful radial velocity machine, with which one can measure velocities of up to 350-360 stars per exposure to +/-1--2 km/s in a 2-degree field of view. Here we present three case studies of star cluster kinematics, each based on data obtained on three nights in February 2008. The specific aims included: (i) cluster membership determination for NGC 2451A and B, two nearby open clusters in the same line-of-sight; (ii) a study of possible membership of the planetary nebula NGC 2438 in the open cluster M46; and (iii) the radial velocity dispersion of M4 and NGC 6144, a pair of two globular clusters near Antares. The results which came out of only three nights of AAT time illustrate very nicely the potential of the instrument and, for example, how quickly one can resolve decades of contradiction in less than two hours of net observing time.",
    "MGT": "This study explores the kinematic properties of star clusters using data obtained from the AAOmega spectrograph. AAOmega, a multi-object fiber-fed spectrograph on the Anglo-Australian Telescope, provides high-resolution spectra essential for examining the dynamics within star clusters. By analyzing radial velocities and proper motions, we aim to construct a comprehensive model of star cluster kinematics. Our sample includes several open and globular clusters, offering a diverse range of ages, metallicities, and stellar populations. We employ advanced data reduction techniques and statistical methods to extract precise kinematic information from the spectral data. The results reveal intricate internal motions and potential substructures within clusters, contributing to our understanding of their formation and evolution. Furthermore, we investigate the influence of external forces, such as tidal interactions with the Milky Way, on cluster dynamics. Our findings enhance the current models of stellar dynamics and provide insights into the gravitational interactions shaping star clusters. This research underscores the utility of AAOmega in advancing the field of astrophysics through detailed kinematic studies of celestial objects."
  },
  {
    "id": 145,
    "prompt": "The Dependence of Type Ia Supernova Luminosities on their Host Galaxies",
    "HWT": "(Abridged) Precision cosmology with Type Ia supernovae (SNe Ia) makes use of the fact that SN Ia luminosities depend on their light-curve shapes and colours. Using Supernova Legacy Survey (SNLS) and other data, we show that there is an additional dependence on the global characteristics of their host galaxies: events of the same light-curve shape and colour are, on average, 0.08mag (~4.0sigma) brighter in massive host galaxies (presumably metal-rich) and galaxies with low specific star-formation rates (sSFR). SNe Ia in galaxies with a low sSFR also have a smaller slope (\"beta\") between their luminosities and colours with ~2.7sigma significance, and a smaller scatter on SN Ia Hubble diagrams (at 95% confidence), though the significance of these effects is dependent on the reddest SNe. SN Ia colours are similar between low-mass and high-mass hosts, leading us to interpret their luminosity differences as an intrinsic property of the SNe and not of some external factor such as dust. If the host stellar mass is interpreted as a metallicity indicator, the luminosity trends are in qualitative agreement with theoretical predictions. We show that the average stellar mass, and therefore the average metallicity, of our SN Ia host galaxies decreases with redshift. The SN Ia luminosity differences consequently introduce a systematic error in cosmological analyses, comparable to the current statistical uncertainties on parameters such as w. We show that the use of two SN Ia absolute magnitudes, one for events in high-mass (metal-rich) galaxies, and one for events in low-mass (metal-poor) galaxies, adequately corrects for the differences. Cosmological fits incorporating these terms give a significant reduction in chi^2 (3.8-4.5sigma). We conclude that future SN Ia cosmological analyses should use a correction of this (or similar) form to control demographic shifts in the galaxy population.",
    "MGT": "Type Ia supernovae (SNe Ia) are critical tools in modern astrophysics, serving as standardizable candles for measuring cosmic distances and probing the accelerated expansion of the universe. However, increasing evidence suggests that their luminosities are not entirely independent of the properties of their host galaxies, potentially introducing systematic uncertainties in cosmological studies. This paper investigates the dependence of SNe Ia luminosities on host galaxy characteristics, including stellar mass, star formation rate, and metallicity, using a comprehensive dataset of observed supernovae and host galaxy properties. Our analysis reveals statistically significant correlations between SNe Ia luminosities and host galaxy stellar mass, with supernovae in more massive galaxies exhibiting higher luminosity corrections after standardization. Furthermore, we find evidence that supernovae in galaxies with lower star formation rates and higher metallicities tend to have less scatter in their luminosities, suggesting an intrinsic dependence on the underlying stellar population and chemical composition. \n\nTo quantify these correlations, we apply hierarchical Bayesian models that account for both statistical and systematic uncertainties while incorporating host galaxy parameters into the standardization process. The results suggest that incorporating host galaxy information can improve the precision of distance estimates, reducing the Hubble residual scatter by approximately 10%. However, we caution that uncorrected correlations could bias cosmological parameters, particularly the determination of the dark energy equation of state parameter, \\( w \\), by up to 3% in extreme cases. We compare our findings with predictions from stellar evolution and explosion models, which suggest that variations in progenitor age, metallicity, and accretion history could drive the observed trends. These results emphasize the importance of accounting for host galaxy properties in SNe Ia cosmology and highlight the need for further investigations into the physical mechanisms underlying these dependencies. Future surveys with high-resolution imaging and spectroscopic follow-up will be essential to disentangle the complex interplay between supernova progenitors and their environments, ultimately improving the reliability of SNe Ia as cosmological probes."
  },
  {
    "id": 146,
    "prompt": "Radiative emission of solar features in the Ca II K line: comparison of measurements and models",
    "HWT": "We study the radiative emission of various types of solar features, such as quiet Sun, enhanced network, plage, and bright plage regions, identified on filtergrams taken in the Ca II K line. We analysed fulldisk images obtained with the PSPT, by using three interference filters that sample the Ca II K line with different bandpasses. We studied the dependence of the radiative emission of disk features on the filter bandpass. We also performed a NLTE spectral synthesis of the Ca II K line integrated over the bandpass of PSPT filters. The synthesis was carried out by utilizing both the PRD and CRD with the most recent set of semi empirical atmosphere models in the literature and some earlier atmosphere models. We measured the CLV of intensity values for various solar features identified on PSPT images and compared the results obtained with those derived from the synthesis. We find that CRD calculations derived using the most recent quiet Sun model, on average, reproduce the measured values of the quiet Sun regions slightly more accurately than PRD computations with the same model. This may reflect that the utilized atmospheric model was computed assuming CRD. Calculations with PRD on earlier quiet Sun model atmospheres reproduce measured quantities with a similar accuracy as to that achieved here by applying CRD to the recent model. We also find that the median contrast values measured for most of the identified bright features, disk positions, and filter widths are, on average, a factor 1.9 lower than those derived from PRD simulations performed using the recent bright feature models. The discrepancy between measured and modeled values decreases by 12% after taking into account straylight effects on PSPT images. PRD computations on either the most recent or the earlier atmosphere models of bright features reproduce measurements from plage and bright plage regions with a similar accuracy.",
    "MGT": "The Ca II K line is a prominent spectral feature in solar observations, offering critical insights into the chromospheric activity and magnetic structuring of the Sun. This study investigates the radiative emission of solar features—such as sunspots, plages, and quiet Sun regions—in the Ca II K line by comparing high-resolution observational measurements with results from state-of-the-art radiative transfer models. Observational data were sourced from ground-based telescopes and spaceborne spectrometers, providing a comprehensive dataset spanning multiple solar cycles. Synthetic Ca II K profiles were generated using advanced models incorporating non-local thermodynamic equilibrium (non-LTE) effects, realistic solar atmospheres, and magnetic field configurations. The comparison reveals systematic discrepancies between measured and modeled emissions, particularly in regions of heightened magnetic activity. While the models accurately reproduce the general shape and intensity of the line core for quiet Sun regions, the emission profiles of active solar phenomena such as plages and sunspots exhibit deviations in both core brightness and wing asymmetries. These differences are attributed to limitations in the treatment of chromospheric heating mechanisms and magnetic field interactions within the modeling framework. Additionally, the temporal evolution of Ca II K emission during solar flares highlights the complex interplay between dynamic energy release processes and radiative cooling. The findings underscore the importance of refining chromospheric models to account for spatial and temporal variations in solar activity. By quantifying the relationship between magnetic field strength, chromospheric temperature, and Ca II K line emission, this work enhances our understanding of solar variability and its broader implications for stellar atmospheres. Future efforts are recommended to improve observational coverage, particularly in ultraviolet regimes, and to integrate advanced magnetohydrodynamic simulations for better predictive capabilities. The study concludes that while current models capture essential features of solar chromospheric emission, further advancements are necessary to bridge the gap between theoretical predictions and observational reality, ensuring robust interpretations of solar and stellar magnetism."
  },
  {
    "id": 147,
    "prompt": "Possible evidence for a common radial structure in nearby AGN tori",
    "HWT": "We present a quantitative and relatively model-independent way to assess the radial structure of nearby AGN tori. These putative tori have been studied with long-baseline infrared (IR) interferometry, but the spatial scales probed are different for different objects. They are at various distances and also have different physical sizes which apparently scale with the luminosity of the central engine. Here we look at interferometric visibilities as a function of spatial scales normalized by the size of the inner torus radius R_in. This approximately eliminates luminosity and distance dependence and, thus, provides a way to uniformly view the visibilities observed for various objects and at different wavelengths. We can construct a composite visibility curve over a large range of spatial scales if different tori share a common radial structure. The currently available observations do suggest model-independently a common radial surface brightness distribution in the mid-IR that is roughly of a power-law form r^-2 as a function of radius r, and extends to ~100 times R_in. Taking into account the temperature decrease toward outer radii with a simple torus model, this corresponds to the radial surface density distribution of dusty material directly illuminated by the central engine roughly in the range between r^0 and r^-1. This should be tested with further data.",
    "MGT": "Active galactic nuclei (AGN) are among the most luminous objects in the universe, powered by accretion onto supermassive black holes. A defining feature of AGN is the presence of dusty tori, which obscure the central regions and produce strong infrared emission. While the geometry and composition of AGN tori remain actively debated, recent observations suggest a commonality in their radial structure across a variety of nearby AGN. In this study, we analyze high-resolution infrared and spectral data from a sample of nearby AGN to investigate the radial distribution of dust in their tori. The results reveal striking similarities in the dust temperature gradients and sublimation radii, independent of the AGN luminosity or host galaxy type. These findings are consistent with a universal torus structure governed by radiation pressure and dust sublimation physics, rather than external environmental factors. Furthermore, comparisons between hydrodynamic simulations and observed data suggest that the radial dust distribution may be shaped by feedback mechanisms linked to the AGN accretion process. This evidence for a common radial structure has implications for unifying theoretical models of AGN and understanding the role of tori in regulating the growth of supermassive black holes. Future work will focus on expanding the sample size and integrating multi-wavelength observations to further refine our understanding of AGN torus dynamics and their broader cosmological significance."
  },
  {
    "id": 148,
    "prompt": "Testing Newtonian gravity with distant globular clusters: NGC1851 and NGC1904",
    "HWT": "Globular clusters are useful to test the validity of Newtonian dynamics in the low acceleration regime typical of galaxies, without the complications of non-baryonic dark matter. Specifically, in absence of disturbing effects, e.g. tidal heating, their velocity dispersion is expected to vanish at large radii. If such behaviour is not observed, and in particular if, as observed in elliptical galaxies, the dispersion is found constant at large radii below a certain threshold acceleration, this might indicate a break down of Newtonian dynamics. To minimise the effects of tidal heating in this paper we study the velocity dispersion profile of two distant globular clusters, NGC 1851 and NGC 1904. The velocity dispersion profile is derived from accurate radial velocities measurements, obtained at the ESO 8m VLT telescope. Reliable data for 184 and 146 bona fide cluster star members, respectively for NGC 1851 and NGC 1904, were obtained. These data allow to trace the velocity dispersion profile up to ~2r0, where r0 is the radius at which the cluster internal acceleration of gravity is a0 = 10e-8 cm/s/s. It is found that in both clusters the velocity dispersion becomes constant beyond ~r0. These new results are fully in agreement with those found for other five globular clusters previously investigated as part of this project. Taken all together, these 7 clusters support the claim that the velocity dispersion is constant beyond r0, irrespectively of the specific physical properties of the clusters: mass, size, dynamical history, and distance from the Milky Way. The strong similarly with the constant velocity dispersion observed in elliptical galaxies beyond r0 is suggestive of a common origin for this phenomenon in the two class of objects, and might indicate a breakdown of Newtonian dynamics below a0.",
    "MGT": "Globular clusters serve as valuable laboratories for examining the fundamental laws of gravity in diverse astrophysical contexts. In this study, we investigate the dynamics of NGC1851 and NGC1904, two distant globular clusters located in the outer halo of the Milky Way, to test the validity of Newtonian gravity in regions of low baryonic density and weak gravitational fields. We utilize high-precision stellar kinematic data derived from spectroscopic measurements and proper motions obtained through the Gaia mission, focusing on the velocity dispersion profiles and mass-to-light ratios of these clusters. By modeling the internal dynamics of NGC1851 and NGC1904 under the assumption of Newtonian gravity, we compare the predicted profiles with observational data to assess potential deviations.  \n\nOur analysis incorporates a range of dynamical modeling techniques, including Jeans modeling and direct N-body simulations, to account for the effects of anisotropy, tidal truncation, and mass segregation within the clusters. We also consider alternative gravitational theories, such as Modified Newtonian Dynamics (MOND), to explore whether non-Newtonian effects might better describe the observed kinematic behavior. Results indicate that Newtonian gravity generally reproduces the velocity dispersion profiles of NGC1851 and NGC1904 within observational uncertainties, although subtle discrepancies are observed in the outskirts of both clusters. These deviations could reflect tidal interactions with the Milky Way, unresolved stellar populations, or non-Newtonian effects in regions of low acceleration.\n\nFurthermore, we discuss the implications of these findings for dark matter distribution in the Galactic halo and the broader applicability of Newtonian gravity in extragalactic systems. While our results support Newtonian dynamics in the regime probed by these clusters, they highlight the need for further observational and theoretical studies to refine constraints on gravity in weak-field conditions. This work demonstrates the utility of globular clusters as astrophysical testbeds for probing fundamental physics and advancing our understanding of the underlying nature of gravity."
  },
  {
    "id": 149,
    "prompt": "Jets and environment of microquasars",
    "HWT": "Two relativistic X-ray jets have been detected with the Chandra X-ray observatory from the black hole X-ray transient XTE J1550-564. We report a full analysis of the evolution of the two jets with a gamma-ray burst external shock model. A plausible scenario suggests a cavity outside the central source and the jets first travelled with constant velocity and then are slowed down by the interactions between the jets and the interstellar medium (ISM). The best fitted radius of the cavity is $\\sim$0.36 pc on the eastern side and $\\sim$0.46 pc on the western side, and the densities also show asymmetry, of $\\sim$0.015 cm$^{-3}$ on the east to $\\sim$0.21 cm$^{-3}$ on the west. A large scale low density region is also found in another microquasar system, H 1743-322. These results are consistent with previous suggestions that the environment of microquasars should be rather vacuous, compared to the normal Galactic environment. A generic scenario for microquasar jets is proposed, classifying the observed jets into three main categories, with different jet morphologies (and sizes) corresponding to different scales of vacuous environments surrounding them.",
    "MGT": "Microquasars, stellar-mass analogs of quasars, are characterized by their compact objects—usually black holes or neutron stars—accreting matter from a companion star. These systems produce relativistic jets that interact dynamically with their surrounding environment, offering valuable insights into high-energy astrophysical processes. This study explores the complex relationship between microquasar jets and their environments, examining how varying physical parameters such as jet power, composition, and velocity influence local interstellar medium (ISM) properties. Observational data from radio, X-ray, and gamma-ray emissions reveal that microquasar jets can induce shock waves, compress ISM material, and trigger localized star formation, while also producing extended structures such as lobes and bubbles detectable at multiple wavelengths. Additionally, simulations suggest that jet-environment interactions are highly sensitive to factors like ISM density gradients and magnetic field orientations, which can affect jet propagation and energy dissipation. Microquasars serve as laboratories for studying relativistic outflows and particle acceleration mechanisms, providing analogs to larger-scale extragalactic phenomena such as active galactic nuclei. By analyzing jet-induced feedback processes, this research enhances our understanding of how microquasars regulate their environments, contributing to broader discussions on galactic evolution and energy transport. Future advancements in observational techniques and numerical modeling promise to refine our understanding of these dynamic systems, revealing new connections between jets, compact objects, and their cosmic surroundings."
  },
  {
    "id": 150,
    "prompt": "Radio and mid-infrared identification of BLAST source counterparts in the Chandra Deep Field South",
    "HWT": "We have identified radio and/or mid-infrared counterparts to 198 out of 350 sources detected at >=5 sigma over ~ 9 square degrees centered on the Chandra Deep Field South (CDFS) by the Balloon-borne Large Aperture Submillimeter Telescope (BLAST) at 250, 350 and 500 um. We have matched 114 of these counterparts to optical sources with previously derived photometric redshifts and fitted SEDs to the BLAST fluxes and fluxes at 70 and 160 um acquired with the Spitzer Space Telescope. In this way, we have constrained dust temperatures, total far-infrared/sub-millimeter luminosities and star formation rates for each source. Our findings show that on average, the BLAST sources lie at significantly lower redshifts and have significantly lower rest-frame dust temperatures compared to submm sources detected in surveys conducted at 850 um. We demonstrate that an apparent increase in dust temperature with redshift in our sample arises as a result of selection effects. Finally, we provide the full multi-wavelength catalog of >= 5 sigma BLAST sources contained within the complete ~ 9 square degree survey area.",
    "MGT": "We present a study aimed at identifying radio and mid-infrared counterparts to submillimeter sources detected by the Balloon-borne Large Aperture Submillimeter Telescope (BLAST) in the Chandra Deep Field South (CDFS). Submillimeter observations trace dusty, star-forming galaxies at high redshifts, but their precise identification remains challenging due to the low resolution of submillimeter maps. We use deep radio imaging at 1.4 GHz and Spitzer mid-infrared data at 3.6–24 μm to refine source positions and establish robust associations. Employing positional matching techniques, supplemented by spectral energy distribution fitting, we identify counterparts for a significant fraction of the BLAST sources, revealing their physical properties and redshift distribution. Our results confirm that many BLAST sources are associated with luminous infrared galaxies, dominated by intense star formation activity. Moreover, we find evidence of overlap between BLAST sources and active galactic nuclei (AGN), suggesting a complex interplay between star formation and AGN activity in these systems. This study highlights the importance of multi-wavelength approaches in resolving submillimeter source counterparts and provides new insights into the population of high-redshift, dusty galaxies in the CDFS. Future observations with higher resolution will further refine these associations and enhance our understanding of galaxy evolution."
  },
  {
    "id": 151,
    "prompt": "Noncommutativity in space-time extended by Liouville field",
    "HWT": "The world-sheet quantum conformal invariance can be realized in the presence of the conformal factor $F$, by inclusion of Liouville term. In the background with linear dilaton field, $\\Phi(x)=\\Phi_0+a_\\mu x^\\mu$, the field $F$ becomes a new noncommutative variable. Therefore, it is natural to extend space-time with a new coordinate, $F$, in order to unify expressions for noncommutativity parameter $\\Theta^{ij}$ of the space-time coordinates $x^i$, with the part $\\Theta^i$ connecting noncommutativity between coordinates $x^i$ and $F$. In this way we solve the problems of Dp-brane noncommutativity in a more elegant way. The technical advantage uses the fact that in the extended space-time the action with dilaton field can be rewritten in dilaton free form. We use canonical method and extend its application to the derivation of boundary conditions. From requirement that Hamiltonian, as the time translation generator, has well defined derivatives in the coordinates and momenta, we obtain boundary conditions directly in the canonical form.",
    "MGT": "In this study, we investigate the implications of noncommutativity in space-time extended by the inclusion of a Liouville field. Noncommutative geometry, a framework that modifies the classical notions of space-time by introducing noncommuting coordinates, has proven to be a powerful tool in addressing inconsistencies at the intersection of quantum mechanics and general relativity. By incorporating a Liouville field, traditionally associated with two-dimensional conformal field theories, we explore the dynamics of a noncommutative space-time extension and its impact on physical observables. Our approach employs a deformation quantization technique to encode noncommutative structures, while the Liouville field is treated as a dynamical degree of freedom coupling to the geometry. We derive modified field equations that reveal how the interplay between noncommutativity and the Liouville field alters the curvature and symmetries of the extended space-time. Furthermore, we analyze the resulting energy-momentum tensor and find novel contributions that could have implications for understanding early-universe cosmology and black hole singularities. The results suggest that the coupling of noncommutative geometry with the Liouville field leads to a richer structure of space-time, potentially providing insights into the quantum nature of gravity. Future work could explore phenomenological consequences and connections with string theory frameworks."
  },
  {
    "id": 152,
    "prompt": "Concavity for nuclear binding energies, thermodynamical functions and density functionals",
    "HWT": "Sequences of experimental ground-state energies for both odd and even $A$ are mapped onto concave patterns cured from convexities due to pairing and/or shell effects. The same patterns, completed by a list of excitation energies, give numerical estimates of the grand potential $\\Omega(\\beta, \\mu)$ for a mixture of nuclei at low or moderate temperatures $T=\\beta^{-1}$ and at many chemical potentials $\\mu. $ The average nucleon number $<{\\bf A} >(\\beta, \\mu)$ then becomes a continuous variable, allowing extrapolations towards nuclear masses closer to drip lines. We study the possible concavity of several thermodynamical functions, such as the free energy and the average energy, as functions of $<{\\bf A} >. $ Concavity, which always occur for the free energy and is usually present for the average energy, allows easy interpolations and extrapolations providing upper and lower bounds, respectively, to binding energies. Such bounds define an error bar for the prediction of binding energies. Finally we show how concavity and universality are related in the theory of the nuclear density functional.",
    "MGT": "The study of concavity properties plays a significant role in understanding the behavior of nuclear binding energies, thermodynamic functions, and density functionals, all of which are fundamental to the domains of nuclear physics, statistical mechanics, and quantum chemistry. This work explores the mathematical and physical implications of concavity in these contexts, focusing on its predictive and constraining power for systems governed by complex interactions. For nuclear binding energies, concavity provides insights into the stability and energy distributions of nuclei, offering a framework to refine theoretical models and improve consistency with experimental data. In thermodynamics, concavity properties of free energy and entropy functions are essential for the derivation of equilibrium conditions, phase transitions, and material response under external perturbations. Similarly, in density functional theory, concavity constraints influence the design and performance of exchange-correlation functionals, directly impacting the accuracy of quantum mechanical simulations for many-electron systems. By establishing a unified approach to concavity analysis across these diverse areas, we demonstrate how it serves as a powerful tool to uncover universal principles, reduce computational complexities, and enhance predictive capabilities. This interdisciplinary investigation highlights the deep connections between mathematical structures and physical phenomena, paving the way for more robust theories and applications in nuclear science and quantum systems modeling."
  },
  {
    "id": 153,
    "prompt": "Quantum corrections to solitons and BPS saturation",
    "HWT": "We review our work of the past decade on one-loop quantum corrections to the mass M and central charge Z of solitons in supersymmetric field theories: the kink, the vortex, and the monopoles (focussing on the kink and the monopoles here). In each case a new feature was needed to obtain BPS saturation: a new anomaly-like contribution to Z for the kink and the N=2 monopole, the effect of classical winding of the quantum vortex contributing to Z, surface terms contributing to M of the N=4 monopole and to Z of the N=2 and N=4 monopoles, and composite operator renormalization for the currents of the \"finite\" N=4 model. We use dimensional regularization, modified to preserve susy and be applicable to solitons, and suitable renormalization conditions. In the mode expansion of bosonic and fermionic quantum fields, zero modes appear then as massless nonzero modes.",
    "MGT": "Quantum corrections to solitons and their impact on BPS saturation are explored within the framework of quantum field theory and supersymmetric models. Solitons, as localized, stable solutions to nonlinear equations, play a significant role in understanding non-perturbative phenomena. In supersymmetric theories, solitons often achieve Bogomol'nyi-Prasad-Sommerfield (BPS) saturation, where their mass equals the topological charge, ensuring stability and preserving a fraction of supersymmetry. This work investigates the effects of quantum corrections on BPS states, focusing on perturbative and non-perturbative contributions. Utilizing techniques such as effective action analysis and supersymmetric regularization, we demonstrate how quantum fluctuations modify soliton mass and dynamics while preserving or breaking BPS saturation conditions. Particular attention is given to the interplay between quantum anomalies, renormalization effects, and the underlying topological structure. Results reveal that quantum corrections can induce deviations from exact BPS saturation but often maintain near-saturation due to supersymmetric constraints. These findings offer deeper insights into soliton dynamics and the robustness of BPS states in quantum regimes."
  },
  {
    "id": 154,
    "prompt": "Generation-by-Generation Dissection of the Response Function in Long Memory Epidemic Processes",
    "HWT": "In a number of natural and social systems, the response to an exogenous shock relaxes back to the average level according to a long-memory kernel $\\sim 1/t^{1+\\theta}$ with $0 \\leq \\theta <1$. In the presence of an epidemic-like process of triggered shocks developing in a cascade of generations at or close to criticality, this \"bare\" kernel is renormalized into an even slower decaying response function $\\sim 1/t^{1-\\theta}$. Surprisingly, this means that the shorter the memory of the bare kernel (the larger $1+\\theta$), the longer the memory of the response function (the smaller $1-\\theta$). Here, we present a detailed investigation of this paradoxical behavior based on a generation-by-generation decomposition of the total response function, the use of Laplace transforms and of \"anomalous\" scaling arguments. The paradox is explained by the fact that the number of triggered generations grows anomalously with time at $\\sim t^\\theta$ so that the contributions of active generations up to time $t$ more than compensate the shorter memory associated with a larger exponent $\\theta$. This anomalous scaling results fundamentally from the property that the expected waiting time is infinite for $0 \\leq \\theta \\leq 1$. The techniques developed here are also applied to the case $\\theta >1$ and we find in this case that the total renormalized response is a {\\bf constant} for $t < 1/(1-n)$ followed by a cross-over to $\\sim 1/t^{1+\\theta}$ for $t \\gg 1/(1-n)$.",
    "MGT": "In this study, we investigate the intricate dynamics of epidemic processes characterized by long memory, focusing on the response function's evolution across successive generations. Epidemic models traditionally assume Markovian dynamics, where the future state of the system depends solely on its current state. However, real-world epidemics often exhibit long memory properties, where past states influence future dynamics over extended periods. This research aims to dissect and understand these processes by employing a generation-by-generation analysis to trace the response function's development.\n\nWe utilize a combination of theoretical modeling and computational simulations to explore how long memory effects alter the trajectory of epidemic outbreaks. By decomposing the epidemic process into generational segments, we can examine the persistence of memory effects over time and their impact on the response function, which reflects the system's sensitivity to initial conditions and external interventions. Our approach allows us to capture the nuanced behavior of epidemics that cannot be adequately described by traditional short-memory models.\n\nThe findings reveal that long memory significantly modulates the response function, resulting in delayed peak infection rates and prolonged epidemic duration. Additionally, our analysis demonstrates how interventions, such as vaccination and social distancing, interact with memory effects, potentially leading to non-intuitive outcomes. For instance, the timing and intensity of interventions can have amplified or diminished effects depending on the generational stage of the epidemic.\n\nThis generation-by-generation dissection enhances our understanding of the memory-dependent mechanisms governing epidemic processes. It provides critical insights for designing more effective public health strategies, particularly in managing diseases with long incubation periods or those influenced by prolonged social behaviors. Our results underscore the importance of incorporating long memory considerations into epidemiological models to better predict and control future outbreaks."
  },
  {
    "id": 155,
    "prompt": "Diffusivity bounds for 1D Brownian polymers",
    "HWT": "We study the asymptotic behavior of a self-interacting one-dimensional Brownian polymer first introduced by Durrett and Rogers [Probab. Theory Related Fields 92 (1992) 337--349]. The polymer describes a stochastic process with a drift which is a certain average of its local time. We show that a smeared out version of the local time function as viewed from the actual position of the process is a Markov process in a suitably chosen function space, and that this process has a Gaussian stationary measure. As a first consequence, this enables us to partially prove a conjecture about the law of large numbers for the end-to-end displacement of the polymer formulated in Durrett and Rogers [Probab. Theory Related Fields 92 (1992) 337--349]. Next we give upper and lower bounds for the variance of the process under the stationary measure, in terms of the qualitative infrared behavior of the interaction function. In particular, we show that in the locally self-repelling case (when the process is essentially pushed by the negative gradient of its own local time) the process is super-diffusive.",
    "MGT": "In this study, we investigate the diffusivity properties of one-dimensional (1D) Brownian polymers, a system characterized by the interplay of random motion and polymeric constraints. Brownian polymers, often modeled as chains of particles undergoing stochastic Brownian motion, serve as a fundamental model in understanding polymer dynamics in confined geometries. Our focus is on establishing theoretical bounds for the diffusivity of these polymers, a crucial parameter influencing their transport properties. Through a combination of analytical techniques and numerical simulations, we derive upper and lower bounds for the diffusivity coefficient, considering various polymer lengths and interaction potentials. We extend existing theories of single-particle Brownian motion to account for the collective behavior of polymeric chains, introducing corrections that capture the influence of chain connectivity and entanglement effects. Our results demonstrate that the diffusivity of 1D Brownian polymers is markedly reduced compared to free Brownian particles, with the reduction factor strongly dependent on the polymer length and the nature of the interaction potential. These findings have significant implications for understanding the diffusion-driven processes in biological systems and synthetic materials, where polymeric structures are prevalent. This work lays the groundwork for further explorations into higher-dimensional systems and more complex interaction scenarios, contributing to the broader field of polymer physics."
  },
  {
    "id": 156,
    "prompt": "$H^1$ and dyadic $H^1$",
    "HWT": "In this paper we give a simple proof of the fact that the average over all dyadic lattices of the dyadic $H^1$-norm of a function gives an equivalent $H^1$-norm. The proof we present works for both one-parameter and multi-parameter Hardy spaces. The results of such type are known. The first result (for one-parameter Hardy spces) belongs to Burgess Davis (1980). Also, by duality, such results are equivalent to the \"BMO from dyadic BMO\" statements proved by Garnett-Jones(1982} for one parameter case, and by Pipher-Ward (2008) for two-parameter case. While the paper generalizes these results to the multi-parameter setting, this is not its main goal. The purpose of the paper is to present an approach leading to a simple proof, which works in both one-parameter and multi-parameter cases. The main idea of treating square function as a Calderon--Zygmind operator is a commonplace in harmonic analysis; the main observation, on which the paper is based, is that one can treat the random dyadic square function this way. After that, all is proved by using the standard and well-known results about Calderon--Zygmind operators in the Hilbert-space-valued setting. As an added bonus, we get a simple proof of the (equivalent by duality) inclusion $\\text{BMO}\\subset \\text{BMO}_d$, $H^1_d \\subset H^1$ in the multi-parameter case. Note, that unlike the one-parameter case, the inclusions in the general situation are far from trivial.",
    "MGT": "This paper explores the intricate relationships between the classical Hardy space $H^1$ and its dyadic counterpart, $H^1_{\\text{dyadic}}$, within the context of harmonic analysis. The Hardy space $H^1$, central to the study of singular integrals and boundary value problems, is characterized by the control of its maximal function and atomic decomposition. On the other hand, $H^1_{\\text{dyadic}}$ is defined within the framework of dyadic systems, offering a discretized approach to the study of function spaces and operators. Despite their apparent differences, $H^1$ and $H^1_{\\text{dyadic}}$ exhibit striking parallels, particularly in their atomic decompositions and duality relationships with respective BMO spaces. \n\nWe present a detailed examination of the structural differences and similarities between the two spaces. Through the use of atomic representations, we establish criteria under which functions in $H^1_{\\text{dyadic}}$ can be extended to $H^1$, and vice versa, highlighting essential differences arising from the discretization inherent in the dyadic setting. Additionally, we investigate the behavior of singular integral operators on these spaces, emphasizing their boundedness properties and demonstrating how such operators interact with the underlying dyadic and continuous structures.\n\nOur findings reveal that while the dyadic Hardy space provides a simplified and computationally accessible model, it retains much of the richness of the classical space. However, subtle distinctions emerge, particularly in the handling of boundary phenomena and global structure. These results contribute to the understanding of the interplay between discrete and continuous models in harmonic analysis and offer insights into the broader applicability of dyadic techniques in solving problems traditionally approached via classical methods. Ultimately, this study underscores the utility of $H^1_{\\text{dyadic}}$ as both a practical tool and a theoretical bridge to the classical Hardy space $H^1$."
  },
  {
    "id": 157,
    "prompt": "Constraints on the Cosmological Constant due to Scale Invariance",
    "HWT": "We consider the standard model with local scale invariance. The theory shows exact scale invariance of dimensionally regulated action. We show that massless gauge fields, which may be abelian or non-abelian, lead to vanishing contribution to the cosmological constant in this theory. This result follows in the quantum theory, to all orders in the gauge couplings. However we have not considered contributions higher orders in the gravitational coupling. Similarly we also find that massless fermion fields yield null contribution to the cosmological constant. The effective cosmological constant in this theory is non-zero due to the phenomenon of cosmological symmetry breaking, which also gives masses to all the massive fields, besides generating the Planck mass. We find a simple relationship between the curvature scalar and the vacuum value of the Higgs field in the limit when we ignore all other contributions to the energy density besides the vacuum energy.",
    "MGT": "Scale invariance has long been recognized as a fundamental symmetry in theoretical physics, offering insights into the nature of fundamental interactions and the structure of spacetime. In this study, we explore the implications of scale invariance for the cosmological constant, Λ, a key parameter governing the accelerated expansion of the universe. By examining scale-invariant models and their compatibility with observational data, we identify constraints on Λ that arise from preserving this symmetry at cosmological scales. The analysis incorporates both theoretical considerations, such as the role of spontaneous symmetry breaking and quantum corrections, and empirical evidence from the cosmic microwave background, large-scale structure, and supernova luminosity distances. Our findings suggest that scale invariance imposes stringent limits on the magnitude of Λ, potentially addressing fine-tuning problems and providing a pathway toward a deeper understanding of dark energy. These results highlight the interplay between fundamental symmetries and cosmological phenomena, paving the way for further investigations into the nature of the universe's accelerated expansion."
  },
  {
    "id": 158,
    "prompt": "Total Variation, Adaptive Total Variation and Nonconvex Smoothly Clipped Absolute Deviation Penalty for Denoising Blocky Images",
    "HWT": "The total variation-based image denoising model has been generalized and extended in numerous ways, improving its performance in different contexts. We propose a new penalty function motivated by the recent progress in the statistical literature on high-dimensional variable selection. Using a particular instantiation of the majorization-minimization algorithm, the optimization problem can be efficiently solved and the computational procedure realized is similar to the spatially adaptive total variation model. Our two-pixel image model shows theoretically that the new penalty function solves the bias problem inherent in the total variation model. The superior performance of the new penalty is demonstrated through several experiments. Our investigation is limited to \"blocky\" images which have small total variation.",
    "MGT": "This study investigates the efficacy of three regularization techniques—total variation (TV), adaptive total variation (ATV), and the nonconvex smoothly clipped absolute deviation (SCAD) penalty—for denoising blocky images. Blocky images, characterized by sharp edges and uniform regions, often pose challenges for traditional denoising methods that can oversmooth edges or fail to preserve structural details. TV and ATV are widely used edge-preserving approaches, while SCAD introduces a nonconvex penalty to balance edge preservation and noise suppression. We analyze their mathematical properties, computational efficiency, and denoising performance across synthetic and real-world blocky images. Results demonstrate that ATV effectively adapts to varying noise levels, while SCAD achieves superior edge preservation without sacrificing smoothness in homogeneous regions. These findings highlight the potential of hybrid approaches for blocky image restoration tasks."
  },
  {
    "id": 159,
    "prompt": "Graphical Probabilistic Routing Model for OBS Networks with Realistic Traffic Scenario",
    "HWT": "Burst contention is a well-known challenging problem in Optical Burst Switching (OBS) networks. Contention resolution approaches are always reactive and attempt to minimize the BLR based on local information available at the core node. On the other hand, a proactive approach that avoids burst losses before they occur is desirable. To reduce the probability of burst contention, a more robust routing algorithm than the shortest path is needed. This paper proposes a new routing mechanism for JET-based OBS networks, called Graphical Probabilistic Routing Model (GPRM) that selects less utilized links, on a hop-by-hop basis by using a bayesian network. We assume no wavelength conversion and no buffering to be available at the core nodes of the OBS network. We simulate the proposed approach under dynamic load to demonstrate that it reduces the Burst Loss Ratio (BLR) compared to static approaches by using Network Simulator 2 (ns-2) on NSFnet network topology and with realistic traffic matrix. Simulation results clearly show that the proposed approach outperforms static approaches in terms of BLR.",
    "MGT": "Optical Burst Switching (OBS) networks have emerged as a promising solution to handle high-speed data transmission in modern optical communication systems. Efficient routing within such networks is crucial to manage burst loss and optimize resource utilization, especially under realistic traffic scenarios characterized by dynamic and unpredictable demands. In this study, we propose a Graphical Probabilistic Routing Model (GPRM) tailored for OBS networks. The model leverages probabilistic graph theory to dynamically adapt routing decisions based on the statistical properties of network traffic and resource availability. By integrating historical traffic patterns and real-time network conditions, the GPRM facilitates informed routing choices that reduce contention and enhance throughput. Simulation results reveal that the proposed model outperforms conventional deterministic routing approaches in scenarios with varying traffic loads, achieving lower burst loss rates and improved end-to-end delay. Additionally, the adaptability of the GPRM makes it robust against traffic fluctuations, ensuring stable performance under both peak and off-peak conditions. This work underscores the importance of probabilistic frameworks in addressing the challenges of realistic OBS traffic management, paving the way for more intelligent and efficient optical network operations in future high-demand environments."
  },
  {
    "id": 160,
    "prompt": "Technicolor and Lattice Gauge Theory",
    "HWT": "Technicolor and other theories of dynamical electroweak symmetry breaking invoke chiral symmetry breaking triggered by strong gauge-dynamics, analogous to that found in QCD, to explain the observed W, Z, and fermion masses. In this talk we describe why a realistic theory of dynamical electroweak symmetry breaking must, relative to QCD, produce an enhanced fermion condensate. We quantify the degree to which the technicolor condensate must be enhanced in order to yield the observed quark masses, and still be consistent with phenomenological constraints on flavor-changing neutral-currents. Lattice studies of technicolor and related theories provide the only way to demonstrate that such enhancements are possible and, hopefully, to discover viable candidate models. We comment briefly on the current status of non-perturbative investigations of dynamical electroweak symmetry breaking, and provide a \"wish-list\" of phenomenologically-relevant properties that are important to calculate in these theories",
    "MGT": "Technicolor and lattice gauge theory are pivotal frameworks in advancing our understanding of strong interactions and symmetry breaking in particle physics. This article explores the interplay between technicolor models and lattice gauge theory, offering insights into the mechanisms underlying mass generation. Technicolor theories propose an alternative to the Higgs mechanism, suggesting that mass arises from new strong dynamics rather than elementary scalar fields. Lattice gauge theory, a non-perturbative computational tool, allows for the rigorous investigation of these dynamics by discretizing spacetime into a lattice framework. We discuss recent advancements in lattice simulations that provide evidence for technicolor scenarios, highlighting the role of lattice gauge theory in modeling complex interactions and predicting phenomenological outcomes. Our findings underscore the importance of lattice methods in testing the viability of technicolor models and exploring novel phases of gauge theories. This study contributes to the broader quest to unify the Standard Model with new physics, potentially guiding future experimental searches."
  },
  {
    "id": 161,
    "prompt": "Characteristics of Anemone Active Regions Appearing in Coronal Holes Observed with {\\it Yohkoh} Soft X-ray Telescope",
    "HWT": "Coronal structure of active regions appearing in coronal holes is studied by using the data obtained with the Soft X-Ray Telescope (SXT) aboard {\\it Yohkoh} from 1991 November to 1993 March. The following characteristics are found; Many of active regions appearing in coronal holes show a structure that looks like a ``sea-anemone''. Such active regions are called {\\it anemone ARs}. About one-forth of all active regions that were observed with SXT from their births showed the anemone structure. For almost all the anemone ARs, the order of magnetic polarities is consistent with the Hale-Nicholson's polarity law. These anemone ARs also showed more or less east-west asymmetry in X-ray intensity distribution, such that the following (eastern) part of the ARs is brighter than its preceding (western) part. This, as well as the anemone shape itself, is consistent with the magnetic polarity distribution around the anemone ARs. These observations also suggest that an active region appearing in coronal holes has simpler (less sheared) and more preceding-spot-dominant magnetic structure than those appearing in other regions.",
    "MGT": "This study investigates the unique characteristics of anemone active regions that emerge within coronal holes, utilizing observational data from the {\\it Yohkoh} Soft X-ray Telescope. Anemone active regions, recognized for their distinct radial configurations resembling sea anemones, are frequently observed during solar minimum phases. Our analysis focuses on the spatial distribution, magnetic field topology, and the emission properties of these regions in soft X-rays. The data reveal that anemone active regions in coronal holes exhibit lower plasma temperatures and densities compared to those outside coronal holes, suggesting a distinct heating mechanism. Additionally, magnetic field measurements indicate complex, multipolar structures that may facilitate reconnection processes, contributing to the dynamic evolution of the coronal environment. The study highlights the role of anemone active regions as potential sources of solar wind streams due to their open magnetic field configurations. Furthermore, the temporal evolution of these regions indicates a correlation with increased solar wind velocities and geomagnetic activity. This research enhances our understanding of the solar corona's structure and dynamics, emphasizing the importance of anemone active regions in influencing solar-terrestrial interactions. Future studies are recommended to explore the implications of these findings for space weather forecasting and solar cycle prediction models."
  },
  {
    "id": 162,
    "prompt": "The Nearby and Extremely Metal-Poor Galaxy CGCG 269-049",
    "HWT": "We present Hubble Space Telescope (HST) and Spitzer Space Telescope images and photometry of the extremely metal-poor (Z = 0.03 Z_sol) blue dwarf galaxy CGCG 269-049. The HST images reveal a large population of red giant and asymptotic giant branch stars, ruling out the possibility that the galaxy has recently formed. From the magnitude of the tip of the red giant branch, we measure a distance to CGCG 269-049 of only 4.9 +/- 0.4 Mpc. The spectral energy distribution of the galaxy between ~3.6 - 70 microns is also best fitted by emission from predominantly ~10 Gyr old stars, with a component of thermal dust emission having a temperature of 52 +/- 10 K. The HST and Spitzer photometry indicate that more than 60% of CGCG 269-049's stellar mass consists of stars ~10 Gyr old, similar to other local blue dwarf galaxies. Our HST H-alpha image shows no evidence of a supernova-driven outflow that could be removing metals from the galaxy, nor do we find evidence that such outflows occurred in the past. Taken together with CGCG 269-049's large ratio of neutral hydrogen mass to stellar mass (~10), these results are consistent with recent simulations in which the metal deficiency of local dwarf galaxies results mainly from inefficient star formation, rather than youth or the escape of supernova ejecta.",
    "MGT": "CGCG 269-049 is an intriguing subject of study due to its proximity and its extremely low metallicity, offering a unique laboratory for understanding early galaxy formation and evolution. This article presents a comprehensive analysis of CGCG 269-049, utilizing a suite of observations from multi-band imaging and spectroscopic data. The study aims to characterize the structural properties, stellar population, and chemical composition of the galaxy. Our observations reveal that CGCG 269-049 exhibits a simple morphology typically associated with dwarf galaxies, with a prominent blue color indicative of active star formation. Spectroscopic analysis confirms its extremely low metallicity, placing it among the most metal-poor galaxies known. This low metallicity provides essential insights into primordial star formation processes and the initial mass function in environments similar to the early universe. Through modeling of the spectral energy distribution, we estimate the galaxy's star formation rate and infer the presence of young stellar populations. CGCG 269-049's proximity allows for detailed study of its interstellar medium, which is characterized by low dust content and high gas-to-dust ratio. These findings contribute to our understanding of the conditions under which early galaxy formation occurred and how such environments have evolved over cosmic time. This research underscores the importance of nearby metal-poor galaxies as analogs to the high-redshift universe and highlights the potential for future studies using next-generation telescopes to further unravel the mysteries of galaxy formation in the early universe."
  },
  {
    "id": 163,
    "prompt": "Spin-Dynamics of the antiferromagnetic S=1/2-Chain at finite magnetic Fields and intermediate Temperatures",
    "HWT": "We present a study of the dynamic structure factor of the antiferromagnetic spin-1/2 Heisenberg chain at finite temperatures and finite magnetic fields. Using Quantum-Monte-Carlo based on the stochastic series expansion and Maximum-Entropy methods we evaluate the longitudinal and the transverse dynamic structure factor from vanishing magnetic fields up to and above the threshold $B_c$ for ferromagnetic saturation, as well as for high and for intermediate temperatures. We study the field-induced redistribution of spectral weight contrasting longitudinal versus transverse excitations. At finite fields below saturation incommensurate low-energy modes are found consistent with zero temperature Bethe-Ansatz. The crossover between the field induced ferromagnet above $B_c$ and the Luttinger liquid below $B_c$ is analyzed in terms of the transverse spin-dynamics. Evaluating sum-rules we assess the quality of the analytic continuation and demonstrate excellent consistency of the Maximum-Entropy results.",
    "MGT": "The study investigates the spin dynamics of antiferromagnetic S=1/2 chains subjected to finite magnetic fields and intermediate temperatures, aiming to elucidate their complex magnetic behavior. Utilizing advanced analytical techniques and numerical simulations, we explore the intricate interplay between thermal fluctuations and magnetic field-induced effects on the spin excitation spectrum. The analysis reveals that at intermediate temperatures, thermal agitation significantly influences the spin correlations, leading to characteristic modifications in the dynamical structure factor. Furthermore, finite magnetic fields induce notable shifts and splittings in the magnon dispersion, highlighting the competition between Zeeman energy and antiferromagnetic interactions. Detailed examination of these phenomena provides insights into the crossover behavior between quantum and classical regimes, presenting implications for the understanding of low-dimensional magnetic systems. Our findings contribute to the broader comprehension of spin-chain dynamics, potentially informing experimental pursuits in magnetic materials and fostering advancements in quantum technologies."
  },
  {
    "id": 164,
    "prompt": "Millisecond microwave spikes: statistical study and application for plasma diagnostics",
    "HWT": "We analyze a dense cluster of solar radio spikes registered at ~ 4.5 -- 6 GHz by the Purple Mountain Observatory spectrometer (Nanjing, China) operating in the 4.5 -- 7.5 GHz range with the 5 ms temporal resolution. To handle with the data from the spectrometer we developed a new technique utilizing a nonlinear multi-Gaussian spectral fit based on chi-squared criteria to extract individual spikes from the originally recorded spectra. Applying this method to the experimental raw data we eventually identified about 3000 spikes for this event, which allows for a detailed statistical analysis. Various statistical characteristics of the spikes have been evaluated, including intensity distributions, spectral bandwidth distributions, and distribution of the spike mean frequencies. The most striking finding of this analysis is distributions of the spike bandwidth, which are remarkably asymmetric. To reveal the underlaying microphysics we explore the local trap model with the renormalized theory of spectral profile of the electron cyclotron maser (ECM) emission peak in a source with random magnetic irregularities. The distribution of the solar spikes relative bandwidth calculated within the local trap model represents an excellent fit to the experimental data. Accordingly, the developed technique may offer a new tool of studying very low levels of the magnetic turbulence in the spike sources, when the ECM mechanism of the spike cluster is confirmed.",
    "MGT": "In the pursuit of advancing plasma diagnostics, the study of millisecond microwave spikes presents a novel approach to understanding plasma behaviors in various environments. This research focuses on the statistical analysis of microwave spikes occurring in the millisecond range, aiming to uncover their underlying mechanisms and potential applications. Utilizing a comprehensive dataset gathered from state-of-the-art plasma experiments, we conducted a thorough statistical evaluation to characterize the temporal and spectral properties of these microwave spikes. The findings reveal distinct patterns and correlations between spike occurrences and plasma parameters, suggesting the presence of specific interaction processes within the plasma medium. A significant aspect of this study is the identification of key statistical metrics that can be employed as diagnostic tools, enhancing the accuracy and efficiency of plasma monitoring systems. Moreover, we explore the feasibility of integrating these metrics into real-time diagnostic frameworks, offering improved resolution and sensitivity for detecting plasma instabilities. The application of millisecond microwave spikes in diagnostics demonstrates promising potential for advancing plasma research, particularly in fusion reactors, astrophysical studies, and industrial plasma applications. By elucidating the statistical characteristics of these spikes, we provide a foundation for further exploration into their role in plasma dynamics and interactions. This study not only contributes to the fundamental understanding of microwave-plasma interactions but also opens new avenues for practical diagnostic solutions, paving the way for more sophisticated and reliable plasma monitoring techniques in scientific and industrial settings."
  },
  {
    "id": 165,
    "prompt": "Antibunching correlations in a strongly coupled exciton - photonic crystal cavity system: Role of off-resonant coupling to multiple excitons",
    "HWT": "We employ a master equation approach to study the second-order quantum autocorrelation functions for up to two independent quantum dot excitons, coupled to an off-resonant cavity in a photonic crystal - single quantum dot system. For a single coupled off-resonant exciton, we observe novel oscillatory behaviour in the early-time dynamics of the cavity autocorrelation function, which leads to decreased antibunching relative to the exciton mode. With a second coupled exciton in the system, we find that the magnitude and the lifetime of these oscillations greatly increases, since the cavity is then able to exchange photons with multiple excitonic resonances. We unambiguously show that this spoils the antibunching characteristics of the cavity quasi-mode, while the autocorrelation of the first exciton is unaffected. We also examine the effects of detector time resolution and make a direct connection to a series of recent experiments.",
    "MGT": "In this study, we explore antibunching correlations within a strongly coupled exciton-photonic crystal cavity system, emphasizing the impact of off-resonant coupling to multiple excitons. Utilizing advanced quantum optical techniques, we analyze the system's emission characteristics to reveal how off-resonant interactions influence photon statistics and lead to antibunching phenomena. Our theoretical framework incorporates multi-exciton dynamics, providing insights into the interplay between resonant and off-resonant coupling mechanisms. The results highlight deviations from conventional single-exciton models, demonstrating how multiple excitons contribute to modulating the photon emission process. The findings underscore the significance of off-resonant coupling in designing quantum light sources, offering pathways to enhance non-classical light generation in photonic devices. Through experimental validation, we confirm the theoretical predictions, establishing a comprehensive understanding of photon-exciton interactions in complex cavity environments. This work paves the way for optimizing quantum photonic systems and advancing applications in quantum computing and communication technologies."
  },
  {
    "id": 166,
    "prompt": "Black hole mass and variability in quasars",
    "HWT": "We report on a study that finds a positive correlation between black hole mass and variability amplitude in quasars. Roughly 100 quasars at z<0.75 were selected by matching objects from the QUEST1 Variability Survey with broad-lined objects from the Sloan Digital Sky Survey. Black hole masses were estimated with the virial method using the broad Hbeta line, and variability was characterized from the QUEST1 light curves. The correlation between black hole mass and variability amplitude is significant at the 99% level or better and does not appear to be caused by obvious selection effects inherent to flux-limited samples. It is most evident for rest frame time lags of the order a few months up to the QUEST1 maximum temporal resolution of about 2 years. The correlation between black hole mass and variability amplitude means that the more massive black holes have larger percentage flux variations. Over 2-3 orders of magnitude in black hole mass, the amplitude increases by approximately 0.2 mag. A likely explanation for the correlation is that the more massive black holes are starving and produce larger flux variations because they do not have a steady inflow of gaseous fuel. Assuming that the variability arises from changes in the accretion rate Li & Cao [8] show that flux variations similar to those observed are expected as a consequence of the more massive black holes having cooler accretion disks.",
    "MGT": "Quasars, among the most luminous and distant objects in the universe, are powered by accreting supermassive black holes. The mass of these black holes is a fundamental parameter influencing the quasar's properties and variability. This study investigates the relationship between black hole mass and the optical variability observed in quasars. Utilizing a comprehensive dataset from various astronomical surveys, including the Sloan Digital Sky Survey (SDSS) and the Pan-STARRS1, we measure and analyze the variability characteristics of a large sample of quasars with well-determined black hole masses. Employing advanced statistical methods, we explore how black hole mass correlates with variability amplitude and timescale. Our analysis reveals a significant dependency of variability on the black hole mass, suggesting that more massive black holes tend to exhibit less frequent but more intense variability events. These findings provide insights into the accretion processes and the dynamic environment surrounding supermassive black holes. The study also assesses the influence of other factors, such as accretion rate and quasar luminosity, and how they interplay with black hole mass to affect variability. By understanding the mass-variability relationship, this research offers key implications for theoretical models of quasar dynamics and evolution. Furthermore, it contributes to the broader understanding of the role of supermassive black holes in galaxy formation and the cosmic history of the universe. Our results underscore the importance of precise mass measurements in unraveling the complex nature of quasar variability and pave the way for future observational campaigns targeting these enigmatic celestial phenomena."
  },
  {
    "id": 167,
    "prompt": "Determinant Quantum Monte Carlo Study of the Orbitally Selective Mott Transition",
    "HWT": "We study the conductivity, density of states, and magnetic correlations of a two dimensional, two band fermion Hubbard model using determinant Quantum Monte Carlo (DQMC) simulations. We show that an orbitally selective Mott transition (OSMT) occurs in which the more weakly interacting band can be metallic despite complete localization of the strongly interacting band. The DQMC method allows us to test the validity of the use of a momentum independent self-energy which has been a central approximation in previous OSMT studies. In addition, we show that long range antiferromagnetic order (LRAFO) is established in the insulating phase, similar to the single band, square lattice Hubbard Hamiltonian. Because the critical interaction strengths for the onset of insulating behavior are much less than the bandwidth of the itinerant orbital, we suggest that the development of LRAFO plays a key role in the transitions.",
    "MGT": "In this study, we employ the determinant quantum Monte Carlo (DQMC) method to investigate the orbitally selective Mott transition (OSMT) in multi-orbital systems. The OSMT is characterized by the selective localization of electrons in specific orbitals while others remain itinerant, which plays a crucial role in strongly correlated electron systems. Utilizing DQMC allows for unbiased simulations of interacting electrons within a realistic lattice model, capturing the interplay between electronic correlations and orbital degrees of freedom. Our results provide insights into the conditions under which OSMT occurs, focusing on the role of intra- and inter-orbital interactions and crystal field splitting. We identify critical parameters that favor the transition and examine the emergent electronic properties across the transition. Furthermore, we discuss the implications of our findings for understanding the electronic behavior in materials exhibiting OSMT, such as iron-based superconductors and transition metal oxides. This study advances the understanding of correlated electron phenomena and highlights DQMC as a powerful tool for exploring complex quantum phase transitions."
  },
  {
    "id": 168,
    "prompt": "Storage of Quantum Coherences as Phase Labeled Local Polarization in Solid State NMR",
    "HWT": "Nuclear spins are promising candidates for quantum information processing because their good isolation from the environment precludes the rapid loss of quantum coherence. Many strategies have been developed to further extend their decoherence times. Some of them make use of decoupling techniques based on the Carr-Purcell and Carr-Purcell-Meiboom-Gill pulse sequences. In many cases, when applied to inhomogeneous samples, they yield a magnetization decay much slower than the Hahn echo. However, we have proved that these decays cannot be associated with longer decoherence times as coherences remain frozen. They result from coherences recovered after their storage as local polarization and thus they can be used as memories. We show here how this freezing of the coherent state, which can subsequently be recovered after times longer than the natural decoherence time of the system, can be generated in a controlled way with the use of field gradients. A similar behaviour of homogeneous samples in inhomogeneous fields are demonstrated. It is emphasized that the effects of inhomogeneities in solid state NMR, independently of their origin, should not be disregarded as they play a crucial role in multipulse sequences.",
    "MGT": "In the realm of quantum information processing, the ability to efficiently store and retrieve quantum coherences is paramount. This study presents a novel approach for the storage of quantum coherences using phase-labeled local polarization techniques within solid-state Nuclear Magnetic Resonance (NMR) frameworks. By leveraging the inherent properties of solid-state environments, we exploit the robust and long-lived nature of local polarization states to achieve reliable coherence storage. Our experimental setup utilizes advanced phase labeling schemes to encode quantum information, ensuring high fidelity and resilience against decoherence effects. The results demonstrate that this method not only preserves quantum coherence over extended periods but also facilitates the retrieval of stored information with minimal loss, offering significant improvements over traditional coherence storage techniques. Comprehensive analysis of the polarization dynamics reveals insights into the interaction mechanisms and coherence transfer efficiencies, underscoring the potential for scalable quantum information storage solutions. This approach paves the way for integrating quantum coherence storage within solid-state systems, highlighting its applicability in quantum computing and information technologies. Future work will focus on optimizing phase labeling protocols and exploring the integration with other quantum systems, further enhancing the capabilities and applications of solid-state NMR in quantum information science."
  },
  {
    "id": 169,
    "prompt": "Heat Transfer in Underground Rail Tunnels",
    "HWT": "The transfer of heat between the air and surrounding soil in underground tunnels ins investigated, as part of the analysis of environmental conditions in underground rail systems. Using standard turbulent modelling assumptions, flow profiles are obtained in both open tunnels and in the annulus between a tunnel wall and a moving train, from which the heat transfer coefficient between the air and tunnel wall is computed. The radial conduction of heat through the surrounding soil resulting from changes in the temperature of air in the tunnel are determined. An impulse change and an oscillating tunnel air temperature are considered separately. The correlations between fluctuations in heat transfer coefficient and air temperature are found to increase the mean soil temperature. Finally, a model for the coupled evolution of the air and surrounding soil temperature along a tunnel of finite length is given.",
    "MGT": "This study investigates the complex mechanisms of heat transfer in underground rail tunnels, focusing on the dynamic interactions between thermal conduction, convection, and radiation. With urban infrastructure expanding rapidly, understanding the thermal environment of subterranean transit systems is crucial for optimizing energy efficiency and passenger comfort. Utilizing advanced computational fluid dynamics (CFD) simulations alongside empirical data acquired from strategic monitoring stations within metro networks, the research identifies key factors influencing thermal behavior, including train velocity, tunnel geometry, and ambient air conditions. Results demonstrate significant variability in temperature profiles along different sections of the tunnels, offering insights into localized heat management strategies. Additionally, the study explores the implications of thermal accumulation on tunnel systems' structural integrity and operational reliability. By providing a comprehensive analysis of heat transfer phenomena, this work contributes to developing innovative cooling systems and enhancing sustainable practices in underground transportation infrastructure, thereby supporting the future growth of urban transit networks."
  },
  {
    "id": 170,
    "prompt": "On the fate of vacuum bubbles on matter backgrounds",
    "HWT": "In this letter we discuss cosmological first order phase transitions with de Sitter bubbles nucleating on (inhomogeneous) matter backgrounds. The de Sitter bubble can be a toy model for an inflationary phase of universes like our own. Using the thin wall approximation and the Israel junction method we trace the classical evolution of the formed bubbles within a compound model. We first address homogeneous ambient space (FRW model) and already find that bubbles nucleated in a dust dominated background cannot expand. For an inhomogeneous dust background (LTB model) we describe cases with at least initially expanding bubbles. Yet, an ensuing passage of the bubble wall through ambient curvature inhomogeneities remains unnoticed for observers inside the bubble. Notable effects also for interior observers are found in the case of a rapid background phase transition in a FRW model.",
    "MGT": "In this research, we investigate the dynamics of vacuum bubbles in the presence of matter backgrounds, an area of significant interest in theoretical physics due to implications for cosmology and quantum field theory. We focus on the evolution and stability of vacuum bubbles when they interact with surrounding matter, employing a combination of analytical and numerical methods. Our analysis reveals that the fate of these bubbles is intricately tied to the density and configuration of the ambient matter. We identify several key factors governing bubble expansion, contraction, or potential stabilization, including energy density contrasts and the nature of the matter field interactions. The study contributes to a broader understanding of phase transitions in the early universe and the role of vacuum decay in cosmological scenarios. Additionally, implications for potential observational signatures in astrophysical phenomena are considered. Our findings open new avenues for exploring fundamental questions about the fabric of spacetime and its evolution under varying conditions."
  },
  {
    "id": 171,
    "prompt": "Steady periodic gravity waves with surface tension",
    "HWT": "In this paper we consider two-dimensional, stratified, steady water waves propagating over an impermeable flat bed and with a free surface. The motion is assumed to be driven by capillarity (that is, surface tension) on the surface and a gravitational force acting on the body of the fluid. We prove the existence of global continua of classical solutions that are periodic and traveling. This is accomplished by first constructing a 1-parameter family of laminar flow solutions, $\\mathcal{T}$, then applying bifurcation theory methods to obtain local curves of small amplitude solutions branching from $\\mathcal{T}$ at an eigenvalue of the linearized problem. Each solution curve is then continued globally by means of a degree theoretic theorem in the spirit of Rabinowitz. Finally, we complement the degree theoretic picture by proving an alternate global bifurcation theorem via the analytic continuation method of Dancer.",
    "MGT": "This study investigates the dynamics of steady periodic gravity waves on fluid surfaces with the inclusion of surface tension effects. Traditionally, gravity waves have been analyzed under the assumption of negligible surface tension, leading to simplified models that may overlook significant phenomena. By incorporating surface tension, this research revisits the classical gravity wave theory to provide a comprehensive understanding of wave behavior across a broader spectrum of conditions. Using advanced mathematical techniques, the study derives new solutions that elucidate the interplay between gravitational forces and surface tension in wave formation and propagation. The results reveal that surface tension notably influences wave amplitude, frequency, and stability, leading to the emergence of wave patterns previously unaccounted for. Furthermore, the analysis highlights the conditions under which surface tension becomes a dominant factor in wave dynamics. These findings have implications for various fields, including oceanography and material science, where accurate wave modeling is crucial. The study concludes by suggesting potential applications and further areas of exploration in the context of fluid dynamics."
  },
  {
    "id": 172,
    "prompt": "Massive runaway stars in the Large Magellanic Cloud",
    "HWT": "The origin of massive field stars in the Large Magellanic Cloud (LMC) has long been an enigma. The recent measurements of large offsets (~100 km/s) between the heliocentric radial velocities of some very massive (O2-type) field stars and the systemic LMC velocity provides a possible explanation of this enigma and suggests that the field stars are runaway stars ejected from their birth places at the very beginning of their parent cluster's dynamical evolution. A straightforward way to prove this explanation is to measure the proper motions of the field stars and to show that they are moving away from one of the nearby star clusters or OB associations. This approach however is complicated by the large distance to the LMC, which makes accurate proper motion measurements difficult. We use an alternative approach for solving the problem, based on the search for bow shocks produced by runaway stars. The geometry of detected bow shocks would allow us to infer the direction of stellar motion and thereby to determine their possible parent clusters. In this paper we present the results of a search for bow shocks around six massive field stars which were suggested in the literature as candidate runaway stars. Using archival (Spitzer Space Telescope) data, we found a bow shock associated with one of our program stars, the O2 V((f*)) star BI 237, which is the first-ever detection of bow shocks in the LMC. Orientation of the bow shock suggests that BI 237 was ejected from the OB association LH 82 (located at ~120 pc in projection from the star). A by-product of our search is the detection of bow shocks generated by four OB stars in the field of the LMC and an arc-like structure attached to the candidate luminous blue variable R81 (HD 269128). The geometry of two of these bow shocks is consistent with the possibility that their associated stars were ejected from the 30 Doradus star forming complex.",
    "MGT": "This study investigates the phenomenon of massive runaway stars within the Large Magellanic Cloud (LMC), a satellite galaxy of the Milky Way. Runaway stars, characterized by their high velocities and isolated positions, are crucial for understanding stellar dynamics and the complex gravitational interactions within galaxies. The LMC, with its unique proximity and rich stellar composition, presents an ideal environment for examining such astrophysical occurrences. Utilizing data from recent surveys and observations, including high-resolution spectroscopy and astrometric measurements, this research identifies and analyzes a sample of massive runaway stars in the LMC. \n\nThe study focuses on determining the origins and the mechanisms that contribute to the runaway nature of these stars. Two primary scenarios are considered: ejection through dynamical interactions in dense star clusters and supernova explosions in binary systems. By analyzing the trajectories and velocities of these stars, we aim to reconstruct their potential paths and the forces influencing their current states. We employ advanced computational models to simulate these scenarios, comparing theoretical predictions with observed data to validate our hypotheses.\n\nOur findings reveal a significant number of massive runaway stars, suggesting a combination of dynamical ejections and binary supernova events as contributing factors. The data indicate that many of these stars originated from dense star-forming regions within the LMC, undergoing rapid acceleration due to gravitational interactions with other massive bodies. Additionally, evidence of supernova remnants in proximity to some runaway stars supports the binary disruption model, highlighting the role of stellar evolution in this phenomenon.\n\nThis research contributes to the broader understanding of stellar evolution and galaxy dynamics by elucidating the processes that lead to the formation of runaway stars. The insights gained from this study not only enhance our knowledge of the LMC's stellar population but also provide a comparative basis for studying similar phenomena in other galaxies. Future investigations will focus on expanding the sample size and incorporating multi-wavelength observations to gain a more comprehensive understanding of the physical properties and life cycles of these intriguing stellar objects. Through such efforts, we aim to refine the models of stellar dynamics and improve predictions regarding the behavior and fate of massive stars in galaxy environments."
  },
  {
    "id": 173,
    "prompt": "Abundance stratification in Type Ia Supernovae - II: The rapidly declining, spectroscopically normal SN 2004eo",
    "HWT": "The variation of properties of Type Ia supernovae, the thermonuclear explosions of Chandrasekhar-mass carbon-oxygen white dwarfs, is caused by different nucleosynthetic outcomes of these explosions, which can be traced from the distribution of abundances in the ejecta. The composition stratification of the spectroscopically normal but rapidly declining SN2004eo is studied performing spectrum synthesis of a time-series of spectra obtained before and after maximum, and of one nebular spectrum obtained about eight months later. Early-time spectra indicate that the outer ejecta are dominated by oxygen and silicon, and contain other intermediate-mass elements (IME), implying that the outer part of the star was subject only to partial burning. In the inner part, nuclear statistical equilibrium (NSE) material dominates, but the production of 56Ni was limited to ~0.43 \\pm 0.05 Msun. An innermost zone containing ~0.25 Msun of stable Fe-group material is also present. The relatively small amount of NSE material synthesised by SN2004eo explains both the dimness and the rapidly evolving light curve of this SN.",
    "MGT": "This study delves into the abundance stratification in Type Ia supernovae, with a focus on the rapidly declining yet spectroscopically normal SN 2004eo. Through detailed spectral analysis, we aim to unravel the intricacies behind its chemical composition and the implications for its progenitor systems. Utilizing a robust dataset, including time-series optical spectra and photometry, we employ advanced radiative transfer models to dissect the layers of ejecta from the explosion. Our findings reveal a marked stratification in the distribution of elements such as silicon, calcium, and iron, with significant variation across different velocity regimes. The observations suggest that SN 2004eo underwent a relatively efficient nuclear burning process, resulting in distinct abundance patterns. This stratification provides insights into the explosion mechanics and energy release, contributing to our understanding of Type Ia supernovae as standard candles for cosmology. Moreover, the study highlights the importance of spectroscopic diversity in these events, challenging existing models and underscoring the need for refined theoretical frameworks. Ultimately, this work advances the comprehension of Type Ia supernovae, enhancing their role in probing the universe's expansion history."
  },
  {
    "id": 174,
    "prompt": "The Computational Power of Symmetric Hamiltonians",
    "HWT": "The presence of symmetries, be they discrete or continuous, in a physical system typically leads to a reduction in the problem to be solved. Here we report that neither translational invariance nor rotational invariance reduce the computational complexity of simulating Hamiltonian dynamics; the problem is still BQP complete, and is believed to be hard on a classical computer. This is achieved by designing a system to implement a Universal Quantum Interface, a device which enables control of an entire computation through the control of a fixed number of spins, and using it as a building-block to entirely remove the need for control, except in the system initialisation. Finally, it is shown that cooling such Hamiltonians to their ground states in the presence of random magnetic fields solves a QMA-complete problem.",
    "MGT": "This study explores the computational capabilities inherent in symmetric Hamiltonians, a critical component in quantum computing and physics. Symmetric Hamiltonians, which exhibit invariance under certain transformations, are pivotal in modeling quantum systems. We investigate their role in enhancing computational processes, focusing on how symmetry can be exploited to optimize algorithmic efficiency and computational accuracy. By analyzing various symmetry classes and their corresponding Hamiltonians, we identify patterns and structures that facilitate problem-solving in quantum algorithms. Our research demonstrates that symmetric Hamiltonians can provide a significant computational advantage by reducing complexity and resource requirements. Furthermore, we explore potential applications in quantum simulations and error correction, underscoring their relevance in advancing quantum technologies. This paper contributes to a deeper understanding of how symmetry in Hamiltonian systems can be harnessed to improve computational performance, offering insights into future developments in quantum computing and related fields."
  },
  {
    "id": 175,
    "prompt": "The Variation of the Galaxy Luminosity Function with Group Properties",
    "HWT": "We explore the shape of the galaxy luminosity function (LF) in groups of different mass by creating composite LFs over large numbers of groups. Following previous work using total group luminosity as the mass indicator, here we split our groups by multiplicity and by estimated virial (group halo) mass, and consider red (passive) and blue (star forming) galaxies separately. In addition we utilise two different group catalogues (2PIGG and Yang et al. ) in order to ascertain the impact of the specific grouping algorithm and further investigate the environmental effects via variations in the LF with position in groups. Our main results are that LFs show a steepening faint end for early type galaxies as a function of group mass/ multiplicity, with a much suppressed trend (evident only in high mass groups) for late type galaxies. Variations between LFs as a function of group mass are robust irrespective of which grouping catalogue is used, and broadly speaking what method for determining group `mass' is used. We find in particular that there is a significant deficit of low-mass passive galaxies in low multiplicity groups, as seen in high redshift clusters. Further to this, the variation in the LF appears to only occur in the central regions of systems, and in fact seems to be most strongly dependent on the position in the group relative to the virial radius. Finally, distance-rank magnitude relations were considered. Only the Yang groups demonstrated any evidence of a correlation between a galaxy's position relative to the brightest group member and its luminosity. 2PIGG possessed no such gradient, the conclusion being the FOF algorithm suppresses the signal for weak luminosity--position trends and the Yang grouping algorithm naturally enhances it.",
    "MGT": "The study of galaxy luminosity functions is crucial in understanding the distribution of galaxy brightness and its dependence on various environmental factors. This research investigates how the galaxy luminosity function varies with group properties, providing insights into the complex interplay between galaxy formation and evolution processes within different cosmic environments. Utilizing data from the Sloan Digital Sky Survey (SDSS), we examine a comprehensive sample of galaxy groups, characterized by a range of properties including group mass, size, density, and dynamical state. Our analysis employs advanced statistical methods to assess the influence of these properties on the luminosity function, offering a nuanced view of how galaxies of different brightness levels are distributed within groups.\n\nThe results reveal significant variation in the luminosity function across different group environments. High-mass groups tend to host brighter galaxies, skewing the luminosity function towards higher luminosities, while low-mass groups exhibit a greater proportion of faint galaxies. Additionally, group size emerges as a critical factor, with larger groups showing a broader luminosity function range compared to smaller ones. Group density also plays a pivotal role, where denser groups display a higher concentration of luminous galaxies, suggesting enhanced star formation activity or merging processes. Furthermore, dynamically relaxed groups differ from those in a state of dynamical disturbance, with the former exhibiting a smoother luminosity distribution indicative of more stable evolutionary processes.\n\nThese findings underscore the importance of group properties in shaping galaxy luminosity functions, highlighting the necessity to consider environmental influences in models of galaxy evolution. The study provides a framework for future investigations into the role of cosmic structures in dictating galaxy characteristics and offers potential pathways for exploring how interactions within groups drive the diversity observed in galaxy populations. Our research contributes to a deeper understanding of the universe's structure, emphasizing the intricate relationship between galaxies and their host environments."
  },
  {
    "id": 176,
    "prompt": "Local unitary transformation, long-range quantum entanglement, wave function renormalization, and topological order",
    "HWT": "Two gapped quantum ground states in the same phase are connected by an adiabatic evolution which gives rise to a local unitary transformation that maps between the states. On the other hand, gapped ground states remain within the same phase under local unitary transformations. Therefore, local unitary transformations define an equivalence relation and the equivalence classes are the universality classes that define the different phases for gapped quantum systems. Since local unitary transformations can remove local entanglement, the above equivalence/universality classes correspond to pattern of long range entanglement, which is the essence of topological order. The local unitary transformation also allows us to define a wave function renormalization scheme, under which a wave function can flow to a simpler one within the same equivalence/universality class. Using such a setup, we find conditions on the possible fixed-point wave functions where the local unitary transformations have \\emph{finite} dimensions. The solutions of the conditions allow us to classify this type of topological orders, which generalize the string-net classification of topological orders. We also describe an algorithm of wave function renormalization induced by local unitary transformations. The algorithm allows us to calculate the flow of tensor-product wave functions which are not at the fixed points. This will allow us to calculate topological orders as well as symmetry breaking orders in a generic tensor-product state.",
    "MGT": "In recent years, significant progress has been made in understanding the intricate relationship between local unitary transformations, long-range quantum entanglement, wave function renormalization, and topological order in quantum systems. This paper delves into these interconnected concepts to explore their implications for quantum computation and condensed matter physics. Local unitary transformations serve as pivotal tools in maintaining the quantum coherence essential for entangled states, facilitating the manipulation and preservation of quantum information across extended distances. By examining the role of local unitary operations, we elucidate how they influence the robustness of long-range entanglement, a fundamental aspect underpinning topological quantum computation. The study further investigates wave function renormalization, a technique employed to simplify complex quantum systems while retaining critical physical properties. Through this framework, we examine how renormalization affects the stability and classification of topological phases. Our analysis reveals that wave function renormalization can lead to emergent phenomena that are indicative of new forms of topological order, challenging conventional paradigms. By integrating these concepts, we propose a unified theoretical framework that enhances our understanding of quantum systems with topological characteristics. This framework holds promise for designing more effective quantum algorithms and materials with novel properties. Ultimately, the insights gained from this study have profound implications for advancing the frontier of quantum technologies, offering a pathway to harnessing the power of quantum mechanics in practical applications. This paper paves the way for future research into the fundamental aspects of quantum entanglement and topological structures, fostering innovation in quantum science and engineering."
  },
  {
    "id": 177,
    "prompt": "Two Models for Noisy Feedback in MIMO Channels",
    "HWT": "Two distinct models of feedback, suited for FDD (Frequency Division Duplex) and TDD (Frequency Division Duplex) systems respectively, have been widely studied in the literature. In this paper, we compare these two models of feedback in terms of the diversity multiplexing tradeoff for varying amount of channel state information at the terminals. We find that, when all imperfections are accounted for, the maximum achievable diversity order in FDD systems matches the diversity order in TDD systems. TDD systems achieve better diversity order at higher multiplexing gains. In FDD systems, the maximum diversity order can be achieved with just a single bit of feedback. Additional bits of feedback (perfect or imperfect) do not affect the diversity order if the receiver does not know the channel state information.",
    "MGT": "This paper explores two distinct models for understanding and mitigating the effects of noisy feedback in Multiple Input Multiple Output (MIMO) communication channels. MIMO systems, pivotal for enhancing data transmission rates, often grapple with feedback imperfections that can degrade performance. The first model investigates the impact of noise on feedback loops within the context of channel state information (CSI) acquisition. It employs advanced mathematical tools to quantify noise effects and proposes algorithms for noise reduction. The second model examines the role of feedback error in adaptive transmission strategies, offering insights into optimizing power allocation and beamforming techniques. Both models are rigorously tested through simulations, demonstrating their efficacy in improving reliability and throughput in MIMO systems. By providing a comprehensive analysis of noisy feedback, this study contributes to the development of robust communication systems capable of maintaining high performance in challenging environments."
  },
  {
    "id": 178,
    "prompt": "On the Stability of Elliptical Vortices in Accretion Discs",
    "HWT": "(Abriged) The existence of large-scale and long-lived 2D vortices in accretion discs has been debated for more than a decade. They appear spontaneously in several 2D disc simulations and they are known to accelerate planetesimal formation through a dust trapping process. However, the issue of the stability of these structures to the imposition of 3D disturbances is still not fully understood, and it casts doubts on their long term survival. Aim: We present new results on the 3D stability of elliptical vortices embedded in accretion discs, based on a linear analysis and several non-linear simulations. Methods: We derive the linearised equations governing the 3D perturbations in the core of an elliptical vortex, and we show that they can be reduced to a Floquet problem. We solve this problem numerically in the astrophysical regime and we present several analytical limits for which the mechanism responsible for the instability can be explained. Finally, we compare the results of the linear analysis to some high resolution simulations. Results: We show that most anticyclonic vortices are unstable due to a resonance between the turnover time and the local epicyclic oscillation period. In addition, we demonstrate that a strong vertical stratification does not create any additional stable domain of aspect ratio, but it significantly reduces growth rates for relatively weak (and therefore elongated) vortices. Conclusions: Elliptical vortices are always unstable, whatever the horizontal or vertical aspect-ratio is. The instability can however be weak and is often found at small scales, making it difficult to detect in low-order finite-difference simulations.",
    "MGT": "The study of elliptical vortices within accretion discs is crucial for understanding the dynamics of astrophysical systems, particularly in the context of angular momentum transport and the formation of large-scale structures. This paper investigates the stability of elliptical vortices in accretion discs, providing a comprehensive analysis grounded in fluid dynamics and astrophysical principles. Using advanced numerical simulations and analytical techniques, we explore the behavior of vortices under various conditions, including variations in the disc's density profile, temperature gradients, and external perturbations. Our findings reveal that the stability of elliptical vortices is significantly influenced by the disc's physical parameters, with certain configurations promoting stability while others lead to rapid vortex decay. We establish a stability criterion based on the aspect ratio and circulation of the vortex, offering insights into the conditions under which vortices can persist over extended periods. Furthermore, the interaction between elliptical vortices and the disc's magnetic fields is examined, highlighting the role of magnetic tension in stabilizing these structures. The implications of our results extend to the broader understanding of accretion discs, suggesting that stable elliptical vortices may contribute to localized enhancements in angular momentum transport, potentially impacting the accretion process itself. This study underscores the importance of considering vortex dynamics in models of accretion discs and encourages further investigation into the interplay between vortical structures and disc evolution. Our research not only advances the theoretical framework for studying elliptical vortices in astrophysical discs but also provides a foundation for future observational efforts aimed at detecting these phenomena in various celestial bodies."
  },
  {
    "id": 179,
    "prompt": "Astrophysics with the AMS-02 experiment",
    "HWT": "The Alpha Magnetic Spectrometer (AMS), whose final version AMS-02 is to be installed on the International Space Station (ISS) for at least 3 years, is a detector designed to measure charged cosmic ray spectra with energies up to the TeV region and with high energy photon detection capability up to a few hundred GeV, using state-of-the-art particle identification techniques. Following the successful flight of the detector prototype (AMS-01) aboard the space shuttle, AMS-02 is expected to provide a significant improvement on the current knowledge of the elemental and isotopic composition of hadronic cosmic rays due to its long exposure time (minimum of 3 years) and large acceptance (0.5 m^2 sr) which will enable it to collect a total statistics of more than 10^10 nuclei. Detector capabilities for charge, velocity and mass identification, estimated from ion beam tests and detailed Monte Carlo simulations, are presented. Relevant issues in cosmic ray astrophysics addressed by AMS-02, including the test of cosmic ray propagation models, galactic confinement times and the influence of solar cycles on the local cosmic ray flux, are briefly discussed.",
    "MGT": "The Alpha Magnetic Spectrometer (AMS-02) experiment, mounted on the International Space Station, represents a significant advancement in the study of cosmic ray physics and astrophysics. Since its deployment in 2011, AMS-02 has provided an unprecedented volume of high-precision measurements of cosmic ray particles, including protons, helium, and heavier nuclei, as well as electrons and positrons. This paper explores the implications of AMS-02 data for astrophysics, particularly in understanding the origin and propagation mechanisms of cosmic rays. The AMS-02's ability to detect rare components, such as antimatter particles, offers insights into the potential existence of dark matter and the nature of matter-antimatter asymmetry. Furthermore, the comprehensive dataset allows for refined models of cosmic ray propagation through the interstellar medium, aiding in the resolution of long-standing astrophysical puzzles, such as the observed excess of positrons. Through detailed analysis, this study discusses the transformative impact of AMS-02 measurements on our comprehension of high-energy astrophysical phenomena and the broader implications for particle physics. The findings underscore the necessity of continued space-based experiments to unravel the complexities of the universe and highlight AMS-02's pivotal role in bridging the gap between theoretical predictions and empirical observations in the field of astrophysics."
  },
  {
    "id": 180,
    "prompt": "Supercurrent and multiple singlet-doublet phase transitions of a quantum dot Josephson junction inside an Aharonov-Bohm ring",
    "HWT": "We study a quantum dot Josephson junction inside an Aharonov-Bohm environment. The geometry is modeled by an Anderson impurity coupled to two directly-linked BCS leads. We illustrate that the well-established picture of the low-energy physics being governed by an interplay of two distinct (singlet and doublet) phases is still valid for this interferometric setup. The phase boundary depends, however, non-monotonically on the coupling strength between the superconductors, causing the system to exhibit re-entrance behavior and multiple phase transitions. We compute the zero-temperature Josephson current and demonstrate that it can become negative in the singlet phase by virtue of the Coulomb interaction U. As a starting point, the limit of large superconducting energy gaps \\Delta=\\infty is solved analytically. In order to tackle arbitrary \\Delta<\\infty and U>0, we employ a truncated functional renormalization group scheme which was previously demonstrated to give quantitatively reliable results for the quantum dot Josephson problem.",
    "MGT": "This study explores the intriguing phenomena of supercurrent and singlet-doublet phase transitions in a quantum dot Josephson junction embedded within an Aharonov-Bohm ring. By employing advanced theoretical models, we examine the interplay between quantum coherence and electron correlation in this complex system. Our analysis reveals a rich phase diagram characterized by multiple singlet-doublet transitions, driven by variations in the Aharonov-Bohm phase and gate voltages. We demonstrate how these transitions significantly influence the supercurrent, offering new insights into the controllable manipulation of quantum states. The study highlights the role of the Aharonov-Bohm effect in modulating the supercurrent through interference patterns, providing a mechanism to tune the Josephson coupling. Furthermore, we discuss the implications for quantum computing applications, where precise control of supercurrent and quantum states is paramount. Our findings offer a pathway to harnessing quantum dot Josephson junctions within mesoscopic rings for advanced quantum technologies, presenting a promising avenue for future experimental exploration and technological innovation."
  },
  {
    "id": 181,
    "prompt": "Tests of analytical hadronisation models using event shape moments in {\\epem} annihilation",
    "HWT": "Predictions of analytical models for hadronisation, namely the dispersive model, the shape function and the single dressed gluon approximation, are compared with moments of hadronic event shape distributions measured in \\epem annihilation at centre-of-mass energies between 14 and 209 GeV. In contrast to Monte Carlo models for hadronisation, analytical models require to adjust only two universal parameters, the strong coupling and a second quantity parametrising nonperturbative corrections. The extracted values of as are consistent with the world average and competitive with previous measurements. The variance of event shape distributions is compared with predictions given by some of these models. Limitations of the models, probably due to unknown higher order corrections, are demonstrated and discussed.",
    "MGT": "This study examines the efficacy of analytical hadronisation models through the analysis of event shape moments in electron-positron ({\\epem}) annihilation processes. Utilizing data from high-energy physics experiments, we scrutinize various models that predict the transformation of quarks and gluons into hadrons. The event shape moments serve as critical observables, offering insights into the dynamics of the hadronisation process. By comparing theoretical predictions with experimental findings, we assess the strengths and limitations of existing models. Our results show that while some models accurately describe certain aspects of the hadronisation, discrepancies remain, suggesting the need for refined approaches. This work contributes to a deeper understanding of hadronisation mechanisms and provides guidance for future model development, ultimately enhancing the precision of theoretical predictions in particle physics."
  },
  {
    "id": 182,
    "prompt": "Using a priori knowledge to construct copulas",
    "HWT": "Our purpose is to model the dependence between two random variables, taking into account a priori knowledge on these variables. For example, in many applications (oceanography, finance.. . ), there exists an order relation between the two variables; when one takes high values, the other cannot take low values, but the contrary is possible. The dependence for the high values of the two variables is, therefore, not symmetric. However a minimal dependence also exists: low values of one variable are associated with low values of the other variable. The dependence can also be extreme for the maxima or the minima of the two variables. In this paper, we construct step by step asymmetric copulas with asymptotic minimal dependence, and with or without asymptotic maximal dependence, using mixture variables to get at first asymmetric dependence and then minimal dependence. We fit these models to a real dataset of sea states and compare them using Likelihood Ratio Tests when they are nested, and BIC- criterion (Bayesian Information criterion) otherwise.",
    "MGT": "Copulas are powerful statistical tools for modeling complex dependencies between random variables, and their construction often relies on empirical data or parametric assumptions. This article explores a novel approach to constructing copulas using a priori knowledge, extending beyond traditional methods to enhance flexibility and applicability in diverse fields such as finance, insurance, and environmental science. By integrating domain-specific insights and theoretical considerations into the copula construction process, we aim to achieve more accurate and representative models of dependency structures. The proposed framework leverages both qualitative and quantitative a priori information, enabling the incorporation of expert judgments, historical data patterns, and theoretical constraints. This approach not only enhances the precision of dependency modeling but also facilitates the inclusion of non-standard relationships often observed in real-world phenomena. Through a series of simulations and case studies, we demonstrate the effectiveness of our methodology in capturing complex interdependencies that conventional copula models may overlook. Our findings suggest that employing a priori knowledge in copula construction can significantly improve model performance, offering a robust alternative for researchers and practitioners seeking to understand and predict multivariate relationships in various applications."
  },
  {
    "id": 183,
    "prompt": "Wave and ray analysis of a type of cloak exhibiting magnified and shifted scattering effect",
    "HWT": "Ray-tracing exercise and full-wave analysis were performed to validate the performance of a new type of cloak composed of isotropic metamaterials. It is shown that objects inside the folded region of this cloak appear invisible to the incoming light from a ray tracing exercise, but exhibit magnified and shifted scattering under a plane wave illumination from a full wave analysis. Gaussian beams are introduced to resolve this interesting paradox resulted from these two methods. We show that at the time-harmonic state, small energy can be diffracted into the folded region and contribute to the resonant state even when the Gaussian beam is steered away from the cloak with an object inside. A scattering pattern identical to that scattered from the image of the object will be formed, which agrees well with the phenomenon in the plane wave incidence case.",
    "MGT": "This study explores a unique category of cloaks that demonstrate magnified and shifted scattering effects, using wave and ray analysis techniques. Traditional cloaking devices aim to render objects invisible by guiding electromagnetic waves around them, minimizing scattering. In contrast, the cloaks examined here intentionally alter the scattering properties, thereby amplifying and displacing the scattered waves. Through computational simulations and theoretical modeling, we investigate the principles underlying this novel approach to cloaking. The analysis reveals that strategic manipulation of the cloak's material parameters can lead to enhanced visibility of the cloaked object in specific directions, offering potential applications in areas such as radar technology and optical sensing. Our findings contribute to the understanding of non-standard cloaking effects and open avenues for the development of advanced materials with tailored electromagnetic responses. This research lays the groundwork for future experiments aimed at harnessing these unique scattering properties for practical technological advancements."
  },
  {
    "id": 184,
    "prompt": "Position Dependent Mass Schroedinger Equation and Isospectral Potentials : Intertwining Operator approach",
    "HWT": "Here we have studied first and second-order intertwining approach to generate isospectral partner potentials of position-dependent (effective) mass Schroedinger equation. The second-order intertwiner is constructed directly by taking it as second order linear differential operator with position depndent coefficients and the system of equations arising from the intertwining relationship is solved for the coefficients by taking an ansatz. A complete scheme for obtaining general solution is obtained which is valid for any arbitrary potential and mass function. The proposed technique allows us to generate isospectral potentials with the following spectral modifications: (i) to add new bound state(s), (ii) to remove bound state(s) and (iii) to leave the spectrum unaffected. To explain our findings with the help of an illustration, we have used point canonical transformation (PCT) to obtain the general solution of the position dependent mass Schrodinger equation corresponding to a potential and mass function. It is shown that our results are consistent with the formulation of type A N-fold supersymmetry [14,18] for the particular case N = 1 and N = 2 respectively.",
    "MGT": "The study of quantum systems with position-dependent mass (PDM) has garnered significant interest due to its applications in diverse fields such as condensed matter physics, nuclear physics, and semiconductor theory. This paper explores the position-dependent mass Schrödinger equation and its isospectral potentials through the lens of the intertwining operator approach. By employing this method, we develop a systematic framework for generating isospectral potentials associated with a given PDM Hamiltonian. The intertwining operator technique allows for the construction of non-trivial transformation operators that relate different Hamiltonians sharing the same energy spectrum, thereby uncovering novel potential landscapes. We demonstrate the effectiveness of this approach by obtaining explicit expressions for a class of PDM systems and their corresponding isospectral partners. Furthermore, we delve into the mathematical properties and symmetries of these operators, revealing insights into the underlying algebraic structure of PDM quantum mechanics. Our findings highlight the versatility of the intertwining operator approach in addressing the complexities inherent in PDM systems, offering a robust tool for theoretical investigations and potential applications in designing quantum devices with tailored spectral properties. This work lays the groundwork for further exploration into the rich tapestry of quantum mechanics with position-dependent mass and its myriad implications."
  },
  {
    "id": 185,
    "prompt": "PQCD Formulations with Heavy Quark Masses and Global Analysis",
    "HWT": "We critically review heavy quark mass effects in DIS and their impact on global analyses. We lay out all elements of a properly defined general mass variable flavor number scheme (GM VFNS) that are shared by all modern formulations of the problem. We then explain the freedom in choosing specific implementations and spell out, in particular, the current formulations of the CTEQ and MSTW groups. We clarify the approximations in the still widely-used zero mass variable flavor scheme (ZM VFNS), mention the inherent flaws in its conventional implementation, and consider the possibility of mending some of these flaws. We discuss practical issues concerning the use of parton distributions in various physical applications, in view of the different schemes. And we comment on the possible presence of intrinsic heavy flavors.",
    "MGT": "This study delves into the perturbative Quantum Chromodynamics (PQCD) framework, incorporating heavy quark masses to enhance the precision of theoretical predictions. By integrating state-of-the-art techniques, we systematically address the complexities associated with heavy quarks in PQCD calculations. A global analysis is conducted, leveraging experimental data from high-energy physics experiments to validate the robustness of our formulations. Our approach not only refines the understanding of heavy quark dynamics but also contributes to the broader quest for precision in QCD analyses. The results demonstrate improved consistency with experimental observations, highlighting the importance of heavy quark mass effects in PQCD. This research paves the way for more accurate modeling of processes involving heavy quarks, offering insights into the interplay between theory and experiment. Our findings underscore the significance of incorporating heavy quark masses in PQCD, with potential implications for future explorations in particle physics."
  },
  {
    "id": 186,
    "prompt": "Minimum feature size preserving decompositions",
    "HWT": "The minimum feature size of a crossing-free straight line drawing is the minimum distance between a vertex and a non-incident edge. This quantity measures the resolution needed to display a figure or the tool size needed to mill the figure. The spread is the ratio of the diameter to the minimum feature size. While many algorithms (particularly in meshing) depend on the spread of the input, none explicitly consider finding a mesh whose spread is similar to the input. When a polygon is partitioned into smaller regions, such as triangles or quadrangles, the degradation is the ratio of original to final spread (the final spread is always greater). Here we present an algorithm to quadrangulate a simple n-gon, while achieving constant degradation. Note that although all faces have a quadrangular shape, the number of edges bounding each face may be larger. This method uses Theta(n) Steiner points and produces Theta(n) quadrangles. In fact to obtain constant degradation, Omega(n) Steiner points are required by any algorithm. We also show that, for some polygons, a constant factor cannot be achieved by any triangulation, even with an unbounded number of Steiner points. The specific lower bounds depend on whether Steiner vertices are used or not.",
    "MGT": "In computational geometry, the preservation of minimum feature sizes during decomposition processes is critical for applications ranging from computer graphics to engineering simulations. This paper introduces a novel approach to minimum feature size preserving decompositions, addressing the challenges of maintaining geometric integrity while optimizing for computational efficiency. The proposed method utilizes advanced algorithms to ensure that decomposed structures retain the smallest significant features, which are often lost in traditional decomposition techniques. By implementing a combination of hierarchical partitioning and adaptive refinement strategies, our approach guarantees that all critical geometric features are preserved, thus enhancing the fidelity of the decomposed models. The efficacy of the method is demonstrated through a series of experiments involving complex geometric shapes, where traditional methods often fail to maintain minimum feature sizes. Our results show significant improvements in preserving geometric detail and reducing computational overhead, offering practical implications for fields such as finite element analysis and computer-aided design. Furthermore, the paper explores the theoretical underpinnings of the algorithm, providing insights into its robustness and adaptability to various geometric configurations. The findings highlight the potential for this approach to be integrated into existing geometrical processing frameworks, offering a pathway to more accurate and efficient simulations. Overall, this work represents a significant advancement in the field of computational geometry, with implications for both academic research and industry applications."
  },
  {
    "id": 187,
    "prompt": "Mapping the Geography of Science: Distribution Patterns and Networks of Relations among Cities and Institutes",
    "HWT": "Using Google Earth, Google Maps and/or network visualization programs such as Pajek, one can overlay the network of relations among addresses in scientific publications on the geographic map. We discuss the pros en cons of the various options, and provide software (freeware) for bridging existing gaps between the Science Citation Indices and Scopus, on the one side, and these various visualization tools, on the other. At the level of city names, the global map can be drawn reliably on the basis of the available address information. At the level of the names of organizations and institutes, there are problems of unification both in the ISI-databases and Scopus. Pajek enables us to combine the visualization with statistical analysis, whereas the Google Maps and its derivates provide superior tools at the Internet.",
    "MGT": "This study examines the geographical distribution and network connections of scientific research across global cities and institutions. Utilizing a comprehensive dataset of scientific publications, we analyze the spatial patterns of research output and collaboration. Our findings reveal significant clustering of scientific activity in major urban centers, with cities like New York, London, and Tokyo emerging as prominent hubs. We identify key institutional networks that contribute to knowledge production and dissemination, highlighting the roles of universities, research institutes, and collaborative partnerships in shaping scientific landscapes. Employing network analysis, we uncover intricate inter-city and inter-institutional connections, illustrating the global interdependencies within the scientific community. The analysis underscores the importance of geographic and institutional factors in influencing research productivity and collaboration. By mapping these patterns, the study provides insights into the dynamics of scientific innovation and offers a framework for policy-makers to enhance regional research capacities and international cooperation."
  },
  {
    "id": 188,
    "prompt": "The ALICE TPC, a large 3-dimensional tracking device with fast readout for ultra-high multiplicity events",
    "HWT": "The design, construction, and commissioning of the ALICE Time-Projection Chamber (TPC) is described. It is the main device for pattern recognition, tracking, and identification of charged particles in the ALICE experiment at the CERN LHC. The TPC is cylindrical in shape with a volume close to 90 m^3 and is operated in a 0.5 T solenoidal magnetic field parallel to its axis. In this paper we describe in detail the design considerations for this detector for operation in the extreme multiplicity environment of central Pb--Pb collisions at LHC energy. The implementation of the resulting requirements into hardware (field cage, read-out chambers, electronics), infrastructure (gas and cooling system, laser-calibration system), and software led to many technical innovations which are described along with a presentation of all the major components of the detector, as currently realized. We also report on the performance achieved after completion of the first round of stand-alone calibration runs and demonstrate results close to those specified in the TPC Technical Design Report.",
    "MGT": "The Time Projection Chamber (TPC) designed for the ALICE experiment at CERN is a pioneering advancement in particle physics, specifically tailored to handle ultra-high multiplicity events such as those observed in heavy-ion collisions. This paper discusses the innovative features of the ALICE TPC, accentuating its role as a large-scale, three-dimensional tracking device with rapid readout capabilities. The TPC's dimensions and configuration allow for precise spatial resolution, essential for reconstructing complex event topologies in environments with unprecedented particle densities. We delve into the technical specifications, including its operational principles based on electron drift and amplification, as well as the cutting-edge electronics that facilitate swift data acquisition, crucial for real-time analysis and interpretation. This device demonstrates significant improvements over previous models, offering enhanced sensitivity and accuracy in tracking charged particles. Detailed performance evaluations highlight its efficiency in coping with the challenges posed by high multiplicity scenarios. The article further explores its integration within the ALICE experiment, underscoring its contribution to advancing our understanding of quantum chromodynamics and the properties of the quark-gluon plasma. The ALICE TPC stands as a cornerstone in experimental particle physics, setting a benchmark for future developments in high-energy physics instrumentation."
  },
  {
    "id": 189,
    "prompt": "The UV-optical colours of brightest cluster galaxies in optically and X-ray selected clusters",
    "HWT": "Many brightest cluster galaxies (BCGs) at the centers of X-ray selected clusters exhibit clear evidence for recent star formation. However, studies of BCGs in optically-selected clusters show that star formation is not enhanced when compared to control samples of non-BCGs of similar stellar mass. Here we analyze a sample of 113 BCGs in low redshift (z<0.1), optically-selected clusters, a matched control sample of non-BCGs, and a smaller sample of BCGs in X-ray selected clusters. We convolve the SDSS images of the BCGs to match the resolution of the GALEX data and we measure UV-optical colours in their inner and outer regions. We find that optically-selected BCGs exhibit smaller scatter in optical colours and redder inner NUV-r colours than the control galaxies, indicating that they are a homogenous population with very little ongoing star formation. The BCGs in the X-ray selected cluster sample span a similar range in optical colours, but have bluer NUV-r colours. Among X-ray selected BCGs, those located in clusters with central cooling times of less than 1 Gyr are significantly bluer than those located in clusters where the central gas cooling times are long. Our main conclusion is that the location of a galaxy at the centre of its halo is not sufficient to determine whether or not it is currently forming stars. One must also have information about the thermodynamic state of the gas in the core of the halo.",
    "MGT": "Brightest cluster galaxies (BCGs) are pivotal in understanding the evolution of galaxies and galaxy clusters, given their massive size and central location in clusters. This study explores the UV-optical colors of BCGs in clusters selected through optical and X-ray methods, aiming to elucidate the impact of different selection processes on BCG characteristics. Our analysis uses a comprehensive dataset, incorporating BCGs from both optically selected and X-ray selected clusters, enabling a comparative investigation into their UV-optical color profiles. Utilizing high-quality photometric data, we assess the color distributions to identify potential differences linked to the selection method. The results reveal that BCGs in optically selected clusters exhibit distinct UV-optical color trends compared to those in X-ray selected clusters, suggesting variations in star formation history or other evolutionary processes. The UV-optical color differences could be indicative of varying environmental influences within the cluster's central regions, potentially driven by the differing dynamics and gas content associated with the selection method. Moreover, our findings suggest that optical selection might favor clusters with more actively star-forming BCGs, while X-ray selection may correlate with more quiescent BCGs. These insights contribute to a deeper understanding of the role of BCGs in the broader context of cluster evolution and highlight the importance of selection criteria in astrophysical research. Future work could expand this analysis by incorporating spectroscopic data and simulations to further disentangle the underlying mechanisms influencing BCG color diversity and their implications for the evolutionary pathways of galaxy clusters."
  },
  {
    "id": 190,
    "prompt": "Shells, jets, and internal working surfaces in the molecular outflow from IRAS 04166+2706",
    "HWT": "Context: IRAS 04166+2706 in Taurus is one of the most nearby young stellar objects whose molecular outflow contains a highly collimated fast component. Methods: We have observed the IRAS 04166+2706 outflow with the IRAM Plateau de Bure interferometer in CO(J=2-1) and SiO(J=2-1) achieving angular resolutions between 2'' and 4''. To improve the quality of the CO(2-1) images, we have added single dish data to the interferometer visibilities. Results: The outflow consists of two distinct components. At velocities <10 km/s, the gas forms two opposed, approximately conical shells that have the YSO at their vertex. These shells coincide with the walls of evacuated cavities and seem to result from the acceleration of the ambient gas by a wide-angle wind. At velocities >30 km/s, the gas forms two opposed jets that travel along the center of the cavities and whose emission is dominated by a symmetric collection of at least 7 pairs of peaks. The velocity field of this component presents a sawtooth pattern with the gas in the tail of each peak moving faster than the gas in the head. This pattern, together with a systematic widening of the peaks with distance to the central source, is consistent with the emission arising from internal working surfaces traveling along the jet and resulting from variations in the velocity field of ejection. We interpret this component as the true protostellar wind, and we find its composition consistent with a chemical model of such type of wind. Conclusions: Our results support outflow wind models that have simultaneously wide-angle and narrow components, and suggest that the EHV peaks seen in a number of outflows consist of internally-shocked wind material.",
    "MGT": "The study of molecular outflows from young stellar objects provides crucial insights into the processes governing star formation and early stellar evolution. IRAS 04166+2706, a low-mass protostar located in the Taurus molecular cloud, exhibits a particularly intriguing outflow characterized by complex structures, including shells, jets, and internal working surfaces. This paper presents a comprehensive analysis of these features, utilizing high-resolution millimeter-wave observations to unravel the dynamics and morphology of the outflow.\n\nOur observations reveal that the molecular outflow from IRAS 04166+2706 is predominantly composed of well-collimated jets emanating from the central protostar. These jets are punctuated by a series of internal working surfaces, where shocks and interactions between faster and slower moving ejected material are evident. Such internal working surfaces are identified by abrupt changes in velocity and enhanced emission regions, indicative of shock heating and subsequent molecular excitation.\n\nSurrounding the jets, we identify large, expansive shells of molecular gas, which we hypothesize to be the result of entrainment processes and bow shock interactions with the ambient medium. The shell structures exhibit a layered morphology, suggesting episodic ejection events and highlighting the variability of the outflow over time scales of a few years.\n\nThrough detailed kinematic analysis, we trace the evolution of the outflow features, estimating the mass ejection rates and energetics associated with the protostellar activity. Our findings support a model where periodic accretion bursts onto the protostar drive the observed variability in outflow properties. Additionally, we explore the implications of these dynamic structures for the surrounding molecular cloud environment, considering the potential for feedback processes that may influence future star formation in the vicinity.\n\nIn summary, the molecular outflow from IRAS 04166+2706 presents a rich tapestry of physical phenomena, serving as an exemplary case for studying the interplay between protostellar jets, shocks, and molecular cloud interactions. This research enhances our understanding of the mechanisms shaping young stellar objects and their immediate environments."
  },
  {
    "id": 191,
    "prompt": "Parameter Degeneracy in Flavor-Dependent Reconstruction of Supernova Neutrino Fluxes",
    "HWT": "We reexamine the possibility of reconstructing the initial fluxes of supernova neutrinos emitted in a future core-collapse galactic supernova explosion and detected in a Megaton-sized water Cherenkov detector. A novel key element in our method is the inclusion, in addition to the total and the average energies of each neutrino species, of a \"pinching\" parameter characterizing the width of the distribution as a fit parameter. We uncover in this case a continuous degeneracy in the reconstructed parameters of supernova neutrino fluxes at the neutrinosphere. We analyze in detail the features of this degeneracy and show how it occurs irrespective of the parametrization used for the distribution function. Given that this degeneracy is real we briefly comment on possible steps towards resolving it, which necessarily requires going beyond the setting presented here.",
    "MGT": "This study investigates parameter degeneracy in the flavor-dependent reconstruction of neutrino fluxes from core-collapse supernovae. Neutrinos play a pivotal role in supernova dynamics, and their detailed study offers insights into fundamental physics. However, accurately reconstructing neutrino fluxes is challenged by degeneracies in parameter space, which can obscure flavor transformation signatures and impact the precision of neutrino oscillation measurements. Using advanced statistical techniques and numerical simulations, we explore how these degeneracies arise and propose methods to mitigate their effects. Our analysis highlights the importance of incorporating flavor-dependent information to break degeneracies and improve reconstruction fidelity. We demonstrate that enhanced detector technologies and refined modeling can significantly reduce uncertainties, offering more reliable data for theoretical interpretations. These findings underscore the critical need for interdisciplinary approaches to address complex challenges in neutrino astrophysics, ultimately paving the way for more precise constraints on supernova neutrino properties."
  },
  {
    "id": 192,
    "prompt": "One-dimensional quantum cellular automata over finite, unbounded configurations",
    "HWT": "One-dimensional quantum cellular automata (QCA) consist in a line of identical, finite dimensional quantum systems. These evolve in discrete time steps according to a local, shift-invariant unitary evolution. By local we mean that no instantaneous long-range communication can occur. In order to define these over a Hilbert space we must restrict to a base of finite, yet unbounded configurations. We show that QCA always admit a two-layered block representation, and hence the inverse QCA is again a QCA. This is a striking result since the property does not hold for classical one-dimensional cellular automata as defined over such finite configurations. As an example we discuss a bijective cellular automata which becomes non-local as a QCA, in a rare case of reversible computation which does not admit a straightforward quantization. We argue that a whole class of bijective cellular automata should no longer be considered to be reversible in a physical sense. Note that the same two-layered block representation result applies also over infinite configurations, as was previously shown for one-dimensional systems in the more elaborate formalism of operators algebras [9]. Here the proof is made simpler and self-contained, moreover we discuss a counterexample QCA in higher dimensions.",
    "MGT": "In this study, we explore the theoretical framework and computational capabilities of one-dimensional quantum cellular automata (QCA) operating over finite, unbounded configurations. This research aims to bridge the understanding of classical cellular automata with their quantum counterparts, emphasizing the distinctive properties intrinsic to quantum mechanics that offer novel computational paradigms. We begin by defining a QCA model that incorporates quantum states into each cell, allowing for superposition and entanglement across the cellular array. The focus is placed on examining the evolution rules that govern the state transitions in these quantum systems, and how such rules can be systematically constructed to ensure unitary evolution, crucial for preserving quantum coherence. The study delves into the implications of boundary conditions in finite systems and the challenges they pose for maintaining computational universality. Through rigorous analysis, we demonstrate that certain configurations exhibit enhanced computational power, surpassing classical limits due to the quantum interference effects. Moreover, we investigate the scalability of these automata and their potential applications in simulating quantum systems and solving complex computational problems. Our findings contribute significantly to the field of quantum computing and open avenues for further research into the practical implementation of QCA in quantum information processing and cryptography, highlighting the transformative potential of quantum technologies in theoretical and applied domains."
  },
  {
    "id": 193,
    "prompt": "Detection of a Thermal Spectral Component in the Prompt Emission of GRB 100724B",
    "HWT": "Observations of GRB 100724B with the Fermi Gamma-Ray Burst Monitor (GBM) find that the spectrum is dominated by the typical Band functional form, which is usually taken to represent a non-thermal emission component, but also includes a statistically highly significant thermal spectral contribution. The simultaneous observation of the thermal and non-thermal components allows us to confidently identify the two emission components. The fact that these seem to vary independently favors the idea that the thermal component is of photospheric origin while the dominant non-thermal emission occurs at larger radii. Our results imply either a very high efficiency for the non-thermal process, or a very small size of the region at the base of the flow, both quite challenging for the standard fireball model. These problems are resolved if the jet is initially highly magnetized and has a substantial Poynting flux.",
    "MGT": "The prompt emission of gamma-ray bursts (GRBs) is typically characterized by complex spectral features that challenge existing theoretical models. In this study, we investigate the spectral properties of GRB 100724B using data obtained from the Fermi Gamma-ray Space Telescope. Our analysis reveals the presence of a distinct thermal spectral component coexisting with the non-thermal emission traditionally attributed to synchrotron radiation. By employing time-resolved spectral analysis, we demonstrate that the thermal component dominates the early phase of the burst, gradually decreasing in prominence as the event progresses. This finding suggests a potential link between the thermal emission and the central engine's activity, providing insights into the physical processes at play during the initial stages of GRB emission. Our results imply that future models of GRB prompt emissions should incorporate both thermal and non-thermal components to accurately capture the complexities observed. This study advances our understanding of GRB emission mechanisms and highlights the necessity for multi-component spectral analysis in GRB research."
  },
  {
    "id": 194,
    "prompt": "Emittance Measurement in MICE",
    "HWT": "Muon ionization cooling provides the only practical solution to prepare high-brilliance beams necessary for a neutrino factory or muon collider. The Muon Ionization Cooling Experiment (MICE), under development at the Rutherford Appleton Laboratory, is installing the first set of particle detectors ever built to measure to 0.1% the emittance of a 200 MeV/c or so muon beam in and out of a cooling cell, and thus measure the cooling cell's performance. Two identical \"emittometers\" (a precise scintillating-fiber tracker in solenoidal magnetic field and a 50 ps time-of-flight station) measure the six phase-space coordinates of each muon. Another TOF plane and two Cherenkov counters assure the purity of the incoming muon beam. A downstream electron/muon calorimeter eliminates contamination from decay electrons.",
    "MGT": "The Muon Ionization Cooling Experiment (MICE) aims to demonstrate the principle of ionization cooling, crucial for reducing the phase space volume of muon beams in future accelerators. This study focuses on emittance measurement techniques employed in MICE to evaluate the cooling performance. Utilizing state-of-the-art detectors, including scintillating fiber trackers and time-of-flight systems, precise measurements of muon beam emittance were achieved under various conditions. The experiment provides insights into the behavior of muon beams through ionization cooling channels, contributing significantly to the validation of theoretical models. The data gathered offer a comprehensive analysis of emittance reduction, highlighting the correlation between cooling components and their efficiency. This work underscores the importance of accurate emittance measurement in optimizing cooling processes, paving the way for advancements in muon accelerator designs and enhancing the feasibility of future high-energy physics experiments."
  },
  {
    "id": 195,
    "prompt": "U(1)-Symmetry breaking and violation of axial symmetry in TlCuCl3 and other insulating spin systems",
    "HWT": "We describe the Bose-Einstein condensate of magnetic bosonic quasiparticles in insulating spin systems using a phenomenological standard functional method for T = 0. We show that results that are already known from advanced computational techniques immediately follow. The inclusion of a perturbative anisotropy term that violates the axial symmetry allows us to remarkably well explain a number of experimental features of the dimerized spin-1/2 system TlCuCl3. Based on an energetic argument we predict a general intrinsic instability of an axially symmetric magnetic condensate towards a violation of this symmetry, which leads to the spontaneous formation of an anisotropy gap in the energy spectrum above the critical field. We, therefore, expect that a true Goldstone mode in insulating spin systems, i.e., a strictly linear energy-dispersion relation down to arbitrarily small excitations energies, cannot be observed in any real material.",
    "MGT": "This study investigates the phenomena of U(1)-symmetry breaking and axial symmetry violation in TlCuCl3 and other insulating spin systems. Utilizing advanced spectroscopic techniques and theoretical modeling, we explore the mechanisms driving these symmetry anomalies in quantum magnetic materials. Our findings demonstrate that U(1)-symmetry breaking in TlCuCl3 is closely linked to the emergence of a Bose-Einstein condensation of magnons, precipitating a distinct phase transition. Additionally, we reveal that axial symmetry violations are influenced by lattice distortions and spin-orbit interactions, impacting the magnetic excitation spectrum and ground state properties. Comparative analysis across various insulating spin compounds highlights the role of symmetry breaking in modulating magnetic behavior and suggests potential pathways for engineered quantum states. This research not only advances understanding of complex spin dynamics but also offers insights into the design of novel materials with tailored magnetic properties, paving the way for future developments in quantum computing and magnetic technology."
  },
  {
    "id": 196,
    "prompt": "Identification of the Lithium Depletion Boundary and Age of the Southern Open Cluster Blanco 1",
    "HWT": "We present results from a spectroscopic study of the very low mass members of the Southern open cluster Blanco 1 using the Gemini-N telescope. We obtained intermediate resolution (R~4400) GMOS spectra for 15 cluster candidate members with I~14-20 mag, and employed a series of membership criteria - proximity to the cluster's sequence in an I/I-Ks color-magnitude diagram (CMD), kinematics agreeing with the cluster systemic motion, magnetic activity as a youth indicator - to classify 10 of these objects as probable cluster members. For these objects, we searched for the presence of the Li I 6708 A feature to identify the lithium depletion boundary (LDB) in Blanco 1. The I/I-Ks CMD shows a clear mass segregation in the Li distribution along the cluster sequence; namely, all higher mass stars are found to be Li-poor, while lower mass stars are found to be Li-rich. The division between Li-poor and Li-rich (i.e., the LDB) in Blanco 1 is found at I=$18.78 \\pm 0.24$ and I-Ks=$3.05 \\pm 0.10$. Using current pre-main-sequence evolutionary models we determine an LDB age of $132 \\pm 24$ Myr. Comparing our derived LDB age to upper-main-sequence isochrone ages for Blanco 1, as well as for other open clusters with identified LDBs, we find good chronometric consistency when using stellar evolution models that incorporate a moderate degree of convective core overshoot.",
    "MGT": "We present a comprehensive study aimed at identifying the lithium depletion boundary (LDB) and determining the age of the southern open cluster Blanco 1. Blanco 1 is a nearby, young cluster that provides an excellent laboratory for studying stellar evolution and lithium depletion processes. Our analysis is based on high-resolution spectroscopic observations obtained using the European Southern Observatory's Very Large Telescope (VLT) and supplemented by photometric data from the Gaia mission. We have identified the LDB by detecting the sharp transition in lithium abundance among the cluster's low-mass stars. The presence of lithium in these stars serves as a critical diagnostic of their evolutionary status, allowing us to pinpoint the age of the cluster with precision. By comparing the observed lithium depletion patterns to theoretical models, we estimate the age of Blanco 1 to be approximately 132 ± 15 million years, consistent with previous estimates derived from main-sequence turn-off fitting and gyrochronology methods. Our findings also suggest that Blanco 1 exhibits a slightly higher than average metallicity, which may influence the derived age and lithium depletion process. This study underscores the importance of lithium as an age indicator for young stellar populations and contributes to a more nuanced understanding of the evolutionary dynamics within open clusters. Our results have implications for refining models of stellar evolution and for the calibration of lithium depletion as an age-dating method. Future work will involve expanding the spectroscopic survey to include additional members of Blanco 1 and other clusters to further elucidate the role of metallicity and other factors in lithium depletion."
  },
  {
    "id": 197,
    "prompt": "Solar Gamma Rays Powered by Secluded Dark Matter",
    "HWT": "Secluded dark matter models, in which WIMPs annihilate first into metastable mediators, can present novel indirect detection signatures in the form of gamma rays and fluxes of charged particles arriving from directions correlated with the centers of large astrophysical bodies within the solar system, such as the Sun and larger planets. This naturally occurs if the mean free path of the mediator is in excess of the solar (or planetary) radius. We show that existing constraints from water Cerenkov detectors already provide a novel probe of the parameter space of these models, complementary to other sources, with significant scope for future improvement from high angular resolution gamma-ray telescopes such as Fermi-LAT. Fluxes of charged particles produced in mediator decays are also capable of contributing a significant solar system component to the spectrum of energetic electrons and positrons, a possibility which can be tested with the directional and timing information of PAMELA and Fermi.",
    "MGT": "This study explores the intriguing possibility that secluded dark matter is a significant driver of solar gamma-ray emissions. Recent observations have detected an unexpected excess of gamma rays emanating from the Sun, prompting a reevaluation of conventional astrophysical models. We propose a novel mechanism in which secluded dark matter particles interact within the solar environment, leading to gamma-ray production. Through detailed theoretical analysis and computational simulations, we investigate scenarios where dark matter particles, isolated from ordinary matter via a hidden sector, undergo annihilation or decay processes. These interactions release energetic gamma rays, which could account for the anomalous solar observations. Our model considers various secluded dark matter candidates and their corresponding interaction strengths, providing predictions that align with observed gamma-ray spectra. Additionally, we discuss the potential implications for dark matter detection and the broader understanding of solar physics. The findings offer a compelling avenue for future research, highlighting the intersection of particle physics and solar astrophysics, and potentially unveiling new aspects of the dark matter paradigm."
  },
  {
    "id": 198,
    "prompt": "P values, confidence intervals, or confidence levels for hypotheses?",
    "HWT": "Null hypothesis significance tests and p values are widely used despite very strong arguments against their use in many contexts. Confidence intervals are often recommended as an alternative, but these do not achieve the objective of assessing the credibility of a hypothesis, and the distinction between confidence and probability is an unnecessary confusion. This paper proposes a more straightforward (probabilistic) definition of confidence, and suggests how the idea can be applied to whatever hypotheses are of interest to researchers. The relative merits of the different approaches are discussed using a series of illustrative examples: usually confidence based approaches seem more transparent and useful, but there are some contexts in which p values may be appropriate. I also suggest some methods for converting results from one format to another. (The attractiveness of the idea of confidence is demonstrated by the widespread persistence of the completely incorrect idea that p=5% is equivalent to 95% confidence in the alternative hypothesis. In this paper I show how p values can be used to derive meaningful confidence statements, and the assumptions underlying the derivation. ) Key words: Confidence interval, Confidence level, Hypothesis testing, Null hypothesis significance tests, P value, User friendliness.",
    "MGT": "Recent advancements in statistical analysis have sparked considerable debate regarding the optimal methodologies for hypothesis testing, particularly focusing on the use of p values, confidence intervals, and confidence levels. This paper aims to critically evaluate the efficacy and appropriateness of these three statistical tools in the context of hypothesis testing. P values, traditionally employed to determine the significance of results, provide a probability measure but have been criticized for their potential to mislead and for not conveying the magnitude of an effect. Confidence intervals offer a range within which the true parameter is expected to lie, thus providing a more comprehensive understanding of the data's reliability and precision. Confidence levels, often associated with Bayesian approaches, reflect the degree of certainty regarding the hypothesis, offering a probabilistic framework that can incorporate prior knowledge. Through comparative analysis, we explore the strengths and limitations of each method, emphasizing their practical applications and implications in various research scenarios. The paper also discusses the common misconceptions surrounding these approaches and underscores the importance of context and transparency in selecting the appropriate tool. We propose guidelines for researchers to enhance the robustness of statistical inference and advocate for a more nuanced application of these methodologies to foster reliable and meaningful scientific conclusions."
  },
  {
    "id": 199,
    "prompt": "A Non-Cooperative Method for Path Loss Estimation in Femtocell Networks",
    "HWT": "A macrocell superposed by indoor deployed femtocells forms a geography-overlapped and spectrum-shared two tier network, which can efficiently improve coverage and enhance system capacity. It is important for reducing inter-tier co-channel interference that any femtocell user (FU) can select suitable access channel according to the path losses between itself and the macrocell users (MUs). Path loss should be estimated non-cooperatively since information exchange is difficult between macrocell and femtocells. In this paper, a novel method is proposed for FU to estimate the path loss between itself and any MU independently. According to the adaptive modulation and coding (AMC) mode information broadcasted by the macrocell base station (BS), FU first estimates the path loss between BS and a MU by using Maximum a Posteriori (MAP) method. The probability distribution function (PDF) and statistics of the transmission power of the MU is then derived. According to the sequence of received powers from the MU, FU estimates the path loss between itself and the MU by using minimum mean square error (MMSE) method. Simulation results show that the proposed method can efficiently estimate the path loss between any FU and any MU in all kinds of conditions.",
    "MGT": "In the burgeoning field of wireless communications, femtocell networks have emerged as a pivotal solution to improve indoor coverage and capacity. However, the deployment of femtocells introduces complex challenges, particularly in the accurate estimation of path loss, which is crucial for efficient network planning and management. This study presents a novel non-cooperative method for path loss estimation in femtocell networks, focusing on minimizing dependencies on external data sources and enhancing real-time adaptability. Unlike traditional cooperative approaches that rely heavily on centralized data acquisition and processing, our method utilizes distributed algorithms that leverage local measurements and self-organizing principles. The proposed method employs advanced signal processing techniques to analyze the radio environment autonomously, enabling femtocells to independently estimate path loss with minimal overhead. Through extensive simulations and real-world experiments, we demonstrate the effectiveness of our approach in various indoor scenarios, highlighting its robustness and scalability. The results indicate that our non-cooperative method achieves comparable accuracy to cooperative techniques, while significantly reducing latency and resource consumption. This work not only advances the understanding of path loss dynamics in femtocell networks but also provides a practical framework for enhancing the self-sufficiency and operational efficiency of future wireless systems. The implications of this research extend to the optimization of network configurations and the facilitation of seamless connectivity in dense urban environments."
  }
]