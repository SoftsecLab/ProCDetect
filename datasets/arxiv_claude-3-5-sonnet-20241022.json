[
  {
    "id": 0,
    "prompt": "Properties of high-degree oscillation modes of the Sun observed with Hinode/SOT",
    "HWT": "Aims. With the Solar Optical Telescope on Hinode, we investigate the basic properties of high-degree solar oscillations observed at two levels in the solar atmosphere, in the G-band (formed in the photosphere) and in the Ca II H line (chromospheric emission). Methods. We analyzed the data by calculating the individual power spectra as well as the cross-spectral properties, i.e., coherence and phase shift. The observational properties are compared with a simple theoretical model, which includes the effects of correlated noise. Results. The results reveal significant frequency shifts between the Ca II H and G-band spectra, in particular above the acoustic cut-off frequency for pseudo-modes. The cross-spectrum phase shows peaks associated with the acoustic oscillation (p-mode) lines, and begins to increase with frequency around the acoustic cut-off. However, we find no phase shift for the (surface gravity wave) f-mode. The observed properties for the p-modes are qualitatively reproduced in a simple model with a correlated background if the correlated noise level in the Ca II H data is higher than in the G-band data. These results suggest that multi-wavelength observations of solar oscillations, in combination with the traditional intensity-velocity observations, may help to determine the level of the correlated background noise and to determine the type of wave excitation sources on the Sun.",
    "MGT": "We present a comprehensive analysis of high-degree oscillation modes in the solar photosphere using high-resolution observations from the Solar Optical Telescope (SOT) aboard the Hinode spacecraft. Our investigation focuses on p-modes with spherical harmonic degrees l > 1000, which correspond to spatial scales smaller than 2 Mm on the solar surface. Using Doppler velocity measurements obtained through spectroscopic observations of the Fe I 630.15 nm line, we analyzed a continuous 72-hour time series to achieve sufficient frequency resolution for mode identification.\n\nThe power spectra reveal clear signatures of high-degree modes extending beyond l = 3000, with lifetimes ranging from 2 to 8 minutes. We observe systematic variations in mode amplitude and frequency as functions of degree, with higher-degree modes showing progressively shorter lifetimes and reduced amplitudes. The frequency spacing between adjacent radial orders remains consistent with theoretical predictions from standard solar models, confirming the reliability of our mode identification.\n\nSpatial analysis reveals that high-degree modes exhibit strong sensitivity to local magnetic field concentrations, with significant power suppression observed in regions of enhanced magnetic flux density exceeding 500 G. This magnetic suppression effect becomes increasingly pronounced for modes with l > 2000, suggesting fundamental interactions between acoustic waves and magnetic field structures at granular scales.\n\nOur results provide new constraints on near-surface convection processes and magnetic field topology. The observed properties of these high-degree modes offer insights into energy transport mechanisms in the solar photosphere and contribute to improved understanding of solar oscillation physics at unprecedented spatial resolution."
  },
  {
    "id": 1,
    "prompt": "Bifurcation and Secondary Bifurcation of Heavy Periodic Hydroelastic Travelling Waves",
    "HWT": "The paper deals with a problem of interaction between hydrodynamics and mechanics of nonlinear elastic bodies. The existence question for two-dimensional symmetric steady waves travelling on the surface of a deep ocean beneath a heavy elastic membrane is analyzed as a problem in bifurcation theory. The behaviour of the two-dimensional cross-section of the membrane is modelled as a thin (unshearable), heavy, hyperelastic Cosserat rod, following Antman's elasticity theory, and the fluid beneath is supposed to be in steady 2D irrotational motion under gravity. Assuming that gravity and the density of the undeformed membrane are prescribed, the free parameters of the problem are the speed of the wave and drift velocity of the membrane. The analysis relies upon a conformal formulation of the hydro-elastic problem developed in previous papers; the basic tool for the study of the bifurcation picture is the implicit function theorem, under some non-resonance assumptions. The most interesting part of the final result is the existence of a symmetry-breaking 'third sheet' of solutions, which bifurcates from primary sheets, and is a hydro-elastic analogue of the phenomenon known as 'Wilton ripples' in the surface tension case.",
    "MGT": "This study investigates the complex dynamics of heavy periodic hydroelastic travelling waves, focusing on primary and secondary bifurcation phenomena. Through rigorous mathematical analysis and numerical simulations, we examine the behavior of elastic sheets interacting with fluid flow under gravitational effects. Our research reveals previously undocumented bifurcation patterns emerging from the coupling between elastic deformation and hydrodynamic forces. Using a combination of spectral methods and bifurcation theory, we demonstrate the existence of multiple solution branches and their interconnections. The primary bifurcation manifests as a transition from simple periodic waves to more complex waveforms, while secondary bifurcations lead to the emergence of new solution families with distinct spatial and temporal characteristics. We identify critical parameters governing these transitions and establish stability criteria for the various wave modes. Our findings indicate that the system exhibits rich dynamical behavior, including period-doubling cascades and symmetry-breaking bifurcations. The results provide fundamental insights into the nature of fluid-structure interactions in hydroelastic systems and have significant implications for applications in marine engineering, flexible wave energy converters, and ice sheet dynamics. This work extends the current understanding of nonlinear wave phenomena and establishes a theoretical framework for predicting and controlling wave behavior in hydroelastic systems."
  },
  {
    "id": 2,
    "prompt": "Structure of the coadjoint orbits of Lie groups",
    "HWT": "We study the geometrical structure of the coadjoint orbits of an arbitrary complex or real Lie algebra ${\\mathfrak g}$ containing some ideal ${\\mathfrak n}$. It is shown that any coadjoint orbit in ${\\mathfrak g}^*$ is a bundle with the affine subspace of ${\\mathfrak g}^*$ as its fibre. This fibre is an isotropic submanifold of the orbit and is defined only by the coadjoint representations of the Lie algebras ${\\mathfrak g}$ and ${\\mathfrak n}$ on the dual space ${\\mathfrak n}^*$. The use of this fact and an application of methods of symplectic geometry give a new insight into the structure of coadjoint orbits and allow us to generalize results derived earlier in the case when ${\\mathfrak g}$ is a split extension using the Abelian ideal ${\\mathfrak n}$ (a semidirect product). As applications, a new proof of the formula for the index of Lie algebra and a necessary condition of integrality of a coadjoint orbit are obtained.",
    "MGT": "We investigate the geometric and algebraic structure of coadjoint orbits for various classes of Lie groups, providing both classification results and explicit parametrizations. The coadjoint action of a Lie group G on the dual space g* of its Lie algebra naturally partitions g* into orbits, each carrying a canonical symplectic structure arising from the Kirillov-Kostant-Souriau theorem. We establish criteria for determining orbit dimensions and develop systematic methods for computing stabilizer subgroups and their corresponding orbit types.\n\nOur main results include a complete classification of coadjoint orbits for compact semisimple Lie groups and detailed analysis of the nilpotent and solvable cases. For semisimple groups, we demonstrate that orbits correspond bijectively to Weyl group orbits in the dual Cartan subalgebra, with each orbit being a homogeneous symplectic manifold. In the nilpotent setting, we prove that generic orbits achieve maximal dimension and exhibit polynomial parametrizations.\n\nFurthermore, we examine the relationship between coadjoint orbits and representation theory, showing how orbit structure reflects the decomposition of induced representations. Applications to geometric quantization and moment map theory are discussed, with particular attention to the role of coadjoint orbits as phase spaces in classical mechanics. Our methods combine techniques from differential geometry, algebraic topology, and harmonic analysis, providing new computational tools for explicit orbit determination in specific examples."
  },
  {
    "id": 3,
    "prompt": "A manifold of possible physics-laws in a universe where the planck constant and speed of light parameters vary",
    "HWT": "I assume a universe whereby the speed of light and the planck constant are not constants but instead parameters that vary locally in time-and space. When describing motion, I am able to derive a modified path integral description at the quantum level, which offers a natural extension of quantum mechanics. At the microscopic level, this path integral intuitively describes a physics with many quantum realities thus leading to a novel concept of manifold of physics, which can be looked at as a novel action principle. This paradigm reflects the notion that the observed laws of physics on any given scale are determined by the underlying distribution of the fundamental parameters (i. e Quantum Mechanics is just one point on this manifold), thus leading to many possible physical-law based behaviors. By choosing a Gaussian distribution of the parameters, a quadratic action term appears in the path-integral, which in turns leads to a complex classical action (and by continuation a new description for inertia) at the classical level. In the accompanying manuscript the classical doublet equation of motion is applied to the Newtonian gravitation field, and a MOND-like, dark-energy-like, and pioneer-anomaly-like solutions are derived.",
    "MGT": "In this theoretical exploration, we investigate the implications of a universe where fundamental physical constants, specifically the Planck constant (ħ) and the speed of light (c), are treated as variable parameters rather than fixed values. Through rigorous mathematical modeling and computational simulations, we demonstrate the existence of a continuous manifold of possible physics-laws that emerge from these varying constants. Our analysis reveals that this manifold exhibits remarkable topological properties, including multiple connected components corresponding to distinct physical regimes. We show that certain regions of this manifold support stable particle configurations and wave-like phenomena analogous to those observed in our universe, while other regions predict entirely novel physical behaviors. The study employs differential geometry and numerical methods to map the boundaries between these regions and characterize the transitions between different physical paradigms. Particularly noteworthy is our discovery of invariant quantities that persist across the entire manifold, suggesting deeper underlying principles independent of specific constant values. These findings contribute to our understanding of the role of fundamental constants in physics and raise intriguing questions about the uniqueness of our observed physical laws. The research also has implications for multiverse theories and the anthropic principle, suggesting that viable physics might exist under a broader range of conditions than previously thought."
  },
  {
    "id": 4,
    "prompt": "Stochasticity in N-body Simulations of Disc Galaxies",
    "HWT": "We demonstrate that the chaotic nature of N-body systems can lead to macroscopic variations in the evolution of collisionless simulations containing rotationally supported discs. The unavoidable stochasticity that afflicts all simulations generally causes mild differences between the evolution of similar models but, in order to illustrate that this is not always true, we present a case that shows extreme bimodal divergence. The divergent behaviour occurs in two different types of code and is independent of all numerical parameters. We identify and give explicit illustrations of several sources of stochasticity, and also show that macroscopic variations in the evolution can originate from differences at the round-off error level. We obtain somewhat more consistent results from simulations in which the halo is set up with great care compared with those started from more approximate equilibria, but we have been unable to eliminate diverging behaviour entirely because the main sources of stochasticity are intrinsic to the disc. We show that the divergence is only temporary and that halo friction is merely delayed, for a substantial time in some cases. We argue that the delays are unlikely to arise in real galaxies, and that our results do not affect dynamical friction constraints on halo density. Stochastic variations in the evolution are inevitable in all simulations of disc-halo systems, irrespective of how they were created, although their effect is generally far less extreme than we find here. The possibility of divergent behaviour complicates comparison of results from different workers.",
    "MGT": "We investigate the role of stochasticity in N-body simulations of disc galaxies, examining how finite particle number effects influence long-term galactic evolution and structure formation. Using a suite of high-resolution simulations with particle numbers ranging from 10^5 to 10^7, we systematically analyze the impact of discrete sampling on key dynamical processes including spiral arm formation, bar instabilities, and vertical heating mechanisms.\n\nOur simulations employ identical initial conditions across different particle realizations to isolate stochastic effects from deterministic evolution. We find that shot noise introduces significant variability in the timing and morphology of spiral structures, with lower-resolution simulations exhibiting enhanced stochastic heating rates that artificially accelerate disc thickening by factors of 2-3 compared to higher-resolution counterparts. Bar formation timescales show substantial scatter, varying by up to 2 Gyr in otherwise identical systems, while final bar strengths demonstrate strong correlation with local particle density fluctuations in the central regions.\n\nWe develop a theoretical framework linking the amplitude of stochastic fluctuations to the local relaxation time and particle number density, successfully predicting the observed heating rates across our simulation suite. Our results demonstrate that achieving convergent disc evolution requires particle numbers exceeding 10^6 within the disc component, with vertical velocity dispersions serving as particularly sensitive diagnostics of numerical stochasticity.\n\nThese findings have important implications for interpreting N-body simulations of galaxy formation and evolution, particularly for studies of disc survival in cosmological contexts and the secular evolution of galactic structures. We provide practical guidelines for simulation design and highlight the necessity of resolution studies in numerical galaxy formation investigations."
  },
  {
    "id": 5,
    "prompt": "Cox rings, semigroups and automorphisms of affine algebraic varieties",
    "HWT": "We study the Cox realization of an affine variety, i.e., a canonical representation of a normal affine variety with finitely generated divisor class group as a quotient of a factorially graded affine variety by an action of the Neron-Severi quasitorus. The realization is described explicitly for the quotient space of a linear action of a finite group. A universal property of this realization is proved, and some results on the divisor theory of an abstract semigroup emerging in this context are given. We show that each automorphism of an affine variety can be lifted to an automorphism of the Cox ring normalizing the grading. It follows that the automorphism group of a non-degenerate affine toric variety of dimension $\\geq 2$ has infinite dimension. We obtain a wild automorphism of the three-dimensional quadratic cone that rises to Anick's automorphism of the polynomial algebra in four variables.",
    "MGT": "We investigate the relationship between Cox rings, associated semigroups, and the automorphism groups of affine algebraic varieties over algebraically closed fields. For a normal affine variety X with finitely generated divisor class group, we establish a correspondence between certain elements of the Cox ring and rational maps that extend to automorphisms of X. Our main result shows that the structure of the effective cone in the divisor class group directly influences the dimension of the automorphism group. We prove that when the Cox ring admits a natural grading by the divisor class group, the associated semigroup of effective divisor classes determines key properties of Aut(X). Specifically, we demonstrate that varieties with Cox rings having finite-dimensional homogeneous components possess automorphism groups of bounded dimension, while those with infinitely generated components may admit infinite-dimensional automorphism groups. Applications include new characterizations of varieties with large automorphism groups and explicit computations for certain toric and quasi-toric varieties. Our methods combine techniques from algebraic geometry, commutative algebra, and the theory of algebraic groups to provide both theoretical insights and computational tools."
  },
  {
    "id": 6,
    "prompt": "The North American and Pelican Nebulae I. IRAC Observations",
    "HWT": "We present a 9 deg^2 map of the North American and Pelican Nebulae regions obtained in all four IRAC channels with the Spitzer Space Telescope. The resulting photometry is merged with that at JHKs from 2MASS and a more spatially limited $BVI$ survey from previous ground-based work. We use a mixture of color- color diagrams to select a minimally contaminated set of more than 1600 objects that we claim are young stellar objects (YSOs) associated with the star forming region. Because our selection technique uses IR excess as a requirement, our sample is strongly biased against inclusion of Class III YSOs. The distribution of IRAC spectral slopes for our YSOs indicates that most of these objects are Class II, with a peak towards steeper spectral slopes but a substantial contribution from a tail of flat spectrum and Class I type objects. By studying the small fraction of the sample that is optically visible, we infer a typical age of a few Myr for the low mass population. The young stars are clustered, with about a third of them located in eight clusters that are located within or near the LDN 935 dark cloud. Half of the YSOs are located in regions with surface densities higher than 1000 YSOs / deg^2. The Class I objects are more clustered than the Class II stars.",
    "MGT": "We present mid-infrared observations of the North American Nebula (NGC 7000) and Pelican Nebula (IC 5070) obtained with the Infrared Array Camera (IRAC) aboard the Spitzer Space Telescope. These observations cover approximately 9 square degrees at 3.6, 4.5, 5.8, and 8.0 μm, providing unprecedented sensitivity and spatial resolution for studying the stellar populations and dust properties in this nearby star-forming complex located at a distance of ~600 pc. The IRAC data reveal extensive diffuse emission from polycyclic aromatic hydrocarbons (PAHs) and hot dust, clearly delineating the photodissociation regions associated with the central ionizing sources. We identify over 1,800 point sources across the surveyed region, including numerous young stellar objects (YSOs) and embedded protostars previously undetected in optical surveys. Color-magnitude and color-color diagrams constructed from the IRAC photometry allow us to classify stellar populations and identify candidate YSOs based on their infrared excess emission. The spatial distribution of these sources reveals several distinct clustering patterns, suggesting multiple episodes of star formation within the complex. Particularly noteworthy is the discovery of a new embedded cluster in the southern region of the Pelican Nebula, containing approximately 50 candidate YSOs. The mid-infrared morphology shows significant structural complexity, with prominent dark lanes and bright-rimmed clouds indicative of triggered star formation. These observations provide the foundation for detailed studies of the star formation history and evolution of this important nearby star-forming region."
  },
  {
    "id": 7,
    "prompt": "Nonlinear current-voltage behavior and electrically driven phase transition in charge frustrated LuFe2O4",
    "HWT": "Electric transport measurements of the charge frustrated LuFe2O4, in which the charge ordering (CO) and electronic ferroelectricity are found, reveal strong nonlinear electric conduction upon application of electrical field in both single crystalline and polycrystalline samples. The threshold electric fields (Et) in single crystalline LuFe2O4 are estimated respectively to be about 60V/cm and 10V/cm with E parallel and perpendicular to the c-axis direction. Experimental measurements also demonstrate that the I-V nonlinearity increases quickly with lowering temperature. Furthermore, our in-situ TEM investigations evidently reveal that the nonlinear I-V behavior is intrinsically in correlation with a current driven charge ordering insulator-metal transition, and the applied electrical field triggers a visible CO collapse recognizable as the fading of satellite spots of the CO modulations.",
    "MGT": "# Nonlinear current-voltage behavior and electrically driven phase transition in charge frustrated LuFe2O4\n\nWe report on the unusual electronic transport properties of charge frustrated LuFe2O4. Temperature-dependent current-voltage measurements reveal strongly nonlinear behavior below the charge ordering temperature (TCO ≈ 320 K), with a dramatic increase in conductivity above a threshold electric field. This nonlinearity is analyzed within the framework of collective charge transport in a system with strong electron correlations. High-resolution x-ray diffraction and dielectric spectroscopy demonstrate that application of an electric field induces a structural phase transition, accompanied by partial melting of the charge ordered state. The electric field effectively reduces the energy barrier between competing charge configurations, allowing the system to access metastable states. Our findings suggest that LuFe2O4 represents a model system for studying electrically tunable phase transitions in frustrated electronic materials, with potential applications in neuromorphic computing and resistive switching devices. The observed phenomena are attributed to the delicate balance between charge ordering, geometric frustration, and electron-lattice coupling in this multiferroic oxide."
  },
  {
    "id": 8,
    "prompt": "Non-cooperative games for spreading code optimization, power control and receiver design in wireless data networks",
    "HWT": "This paper focuses on the issue of energy efficiency in wireless data networks through a game theoretic approach. The case considered is that in which each user is allowed to vary its transmit power, spreading code, and uplink receiver in order to maximize its own utility, which is here defined as the ratio of data throughput to transmit power. In particular, the case in which linear multiuser detectors are employed at the receiver is treated first, and, then, the more challenging case in which non-linear decision feedback multiuser receivers are adopted is addressed. It is shown that, for both receivers, the problem at hand of utility maximization can be regarded as a non-cooperative game, and it is proved that a unique Nash equilibrium point exists. Simulation results show that significant performance gains can be obtained through both non-linear processing and spreading code optimization; in particular, for systems with a number of users not larger than the processing gain, remarkable gains come from spreading code optimization, while, for overloaded systems, the largest gainscome from the use of non-linear processing. In every case, however, the non-cooperative games proposed here are shown to outperform competing alternatives.",
    "MGT": "This paper investigates non-cooperative game theory applications for joint optimization of spreading code design, power control, and receiver configuration in wireless data networks. We formulate the multi-user interference scenario as a strategic game where each user independently optimizes their transmission parameters to maximize individual utility while competing for shared spectral resources. The proposed framework addresses three critical network optimization problems simultaneously: spreading sequence selection for code-division multiple access systems, transmit power allocation under interference constraints, and adaptive receiver filter design for enhanced signal detection.\n\nWe develop a comprehensive game-theoretic model where players represent network users with conflicting objectives, and strategies encompass the joint selection of spreading codes, power levels, and receiver parameters. The utility functions incorporate signal-to-interference-plus-noise ratio maximization, power consumption minimization, and throughput optimization. We prove the existence of Nash equilibria for the multi-dimensional strategy space and propose distributed algorithms for equilibrium computation that require only local channel state information.\n\nSimulation results demonstrate that the non-cooperative approach achieves near-optimal performance compared to centralized solutions while maintaining practical implementation feasibility. The proposed algorithms converge to stable operating points that balance individual user performance with overall network efficiency. Performance analysis reveals significant improvements in spectral efficiency, energy consumption, and interference mitigation compared to conventional orthogonal resource allocation schemes. The framework provides valuable insights for autonomous network optimization in next-generation wireless systems."
  },
  {
    "id": 9,
    "prompt": "Galactic Small Scale Structure Revealed by the GALFA-HI Survey",
    "HWT": "The Galactic Arecibo L-band Feed Array HI (GALFA-HI) survey is mapping the entire Arecibo sky at 21-cm, over a velocity range of -700 to +700 km/s (LSR), at a velocity resolution of 0.18 km/s and an angular resolution of 3.5 arcmin. The unprecedented resolution and sensitivity of the GALFA-HI survey have resulted in the detection of many isolated, very compact HI clouds at low Galactic velocities which are distinctly separated from the HI disk emission. In the limited area of ~4600 deg$^2$ searched so far, we have detected 96 such compact clouds. The detected clouds are cold with kinetic temperature less than 300 K. Moreover, they are quite compact and faint, with median values of 5 arcmin in angular size, 0.75 K in peak brightness temperature, and $5\\times10^{18}$ cm$^{-2}$ in HI column density. From the modeling of spatial and velocity distributions of the whole compact cloud population, we find that the bulk of clouds are related to the Galactic disk, and are within a few kpc distance. We present properties of the compact clouds sample and discuss various possible scenarios for the origin of this clouds population and its role in the Galactic interstellar medium studies.",
    "MGT": "We present new insights into the small-scale structure of the Milky Way's neutral hydrogen distribution using data from the Galactic Arecibo L-Band Feed Array HI (GALFA-HI) survey. This comprehensive survey provides unprecedented angular resolution and sensitivity for studying the complex morphology of the interstellar medium across significant portions of the Galactic plane and high-latitude regions. Our analysis reveals intricate filamentary structures, velocity coherent features, and previously unresolved cold neutral medium components that extend across multiple spatial scales from parsec to kiloparsec dimensions. \n\nThe enhanced resolution capabilities of GALFA-HI enable detailed characterization of the turbulent cascade in the neutral hydrogen gas, revealing power-law scaling relationships consistent with Kolmogorov turbulence theory across spatial scales ranging from the survey resolution limit to the largest coherent structures. We identify numerous previously unknown cold HI clouds and intermediate-velocity features that provide new constraints on models of Galactic fountain flows and accretion processes. The survey data also reveal significant substructure within established HI complexes, including velocity gradients and temperature variations that suggest ongoing dynamical evolution driven by stellar feedback and gravitational instabilities.\n\nThese observations demonstrate the critical importance of high-resolution HI surveys for understanding the multiphase nature of the interstellar medium and its role in regulating star formation processes. The detailed morphological and kinematic information provided by GALFA-HI represents a substantial advance in our ability to probe the small-scale physics governing the structure and evolution of neutral hydrogen in the Galaxy, with implications for understanding similar processes in external galaxies."
  },
  {
    "id": 10,
    "prompt": "Spin Bose-Metal phase in a spin-1/2 model with ring exchange on a two-leg triangular strip",
    "HWT": "Recent experiments on triangular lattice organic Mott insulators have found evidence for a 2D spin liquid in proximity to the metal-insulator transition. A Gutzwiller wavefunction study of the triangular lattice Heisenberg model with appropriate four-spin ring exchanges has found that the projected spinon Fermi sea state has a low variational energy. This wavefunction, together with a slave particle gauge theory, suggests that such spin liquid possesses spin correlations that are singular along surfaces in momentum space (\"Bose surfaces\"). Signatures of this state, which we refer to as a \"Spin Bose-Metal\" (SBM), are expected to be manifest in quasi-1D ladder systems: The discrete transverse momenta cut through the 2D Bose surface leading to a distinct pattern of 1D gapless modes. Here we search for a quasi-1D descendant of the triangular lattice SBM state by exploring the Heisenberg plus ring model on a two-leg strip (zigzag chain). Using DMRG, variational wavefunctions, and a Bosonization analysis, we map out the full phase diagram. Without ring exchange the model is equivalent to the J_1 - J_2 Heisenberg chain, and we find the expected Bethe-chain and dimerized phases. Remarkably, moderate ring exchange reveals a new gapless phase over a large swath of the phase diagram. Spin and dimer correlations possess particular singular wavevectors and allow us to identify this phase as the hoped for quasi-1D descendant SBM state. We derive a low energy theory and find three gapless modes and one Luttinger parameter controlling all power laws. Potential instabilities out of the zigzag SBM give rise to other interesting phases such as a period-3 VBS or a period-4 Chirality order, which we discover in the DMRG; we also find an interesting SBM state with partial ferromagnetism.",
    "MGT": "We investigate the ground state properties of a spin-1/2 Heisenberg model with ring exchange interactions on a two-leg triangular strip geometry. The model incorporates both nearest-neighbor antiferromagnetic Heisenberg exchange and four-spin ring exchange terms, which compete to produce a rich phase diagram with novel quantum phases. Using density matrix renormalization group calculations and exact diagonalization techniques, we map out the complete ground state phase diagram as a function of the ring exchange coupling strength.\n\nOur results reveal the existence of a remarkable Spin Bose-Metal phase, characterized by gapless spin excitations and algebraically decaying spin correlations with continuously varying critical exponents. This phase emerges in the intermediate coupling regime where the ring exchange term is sufficiently strong to suppress conventional magnetic ordering but not strong enough to drive the system into a fully gapped phase. The Spin Bose-Metal exhibits power-law decay of both longitudinal and transverse spin correlations, with correlation functions that follow universal scaling forms characteristic of a Tomonaga-Luttinger liquid description for spin degrees of freedom.\n\nWe analyze the nature of this exotic phase through detailed studies of the entanglement spectrum, central charge measurements, and finite-size scaling analysis. The entanglement entropy grows logarithmically with subsystem size, confirming the critical nature of the ground state, while the extracted central charge c = 1 is consistent with a single gapless mode. The dynamic structure factor reveals a continuum of low-energy excitations with linear dispersion, further supporting the Tomonaga-Luttinger liquid picture.\n\nAdditionally, we identify the quantum phase transitions separating the Spin Bose-Metal from adjacent phases, including a transition to a valence bond solid phase at strong ring exchange coupling and crossovers to magnetically ordered phases at weak coupling. The critical exponents governing these transitions are determined through finite-size scaling analysis. Our findings demonstrate that ring exchange interactions can stabilize exotic quantum spin liquid phases even in quasi-one-dimensional geometries, providing new insights into the role of multi-spin interactions in frustrated quantum magnets and their potential realization in ultracold atomic systems and quantum spin simulators."
  },
  {
    "id": 11,
    "prompt": "Assisted Common Information with Applications to Secure Two-Party Computation",
    "HWT": "Secure multi-party computation is a central problem in modern cryptography. An important sub-class of this are problems of the following form: Alice and Bob desire to produce sample(s) of a pair of jointly distributed random variables. Each party must learn nothing more about the other party's output than what its own output reveals. To aid in this, they have available a set up - correlated random variables whose distribution is different from the desired distribution - as well as unlimited noiseless communication. In this paper we present an upperbound on how efficiently a given set up can be used to produce samples from a desired distribution. The key tool we develop is a generalization of the concept of common information of two dependent random variables [Gacs-Korner, 1973]. Our generalization - a three-dimensional region - remedies some of the limitations of the original definition which captured only a limited form of dependence. It also includes as a special case Wyner's common information [Wyner, 1975]. To derive the cryptographic bounds, we rely on a monotonicity property of this region: the region of the \"views\" of Alice and Bob engaged in any protocol can only monotonically expand and not shrink. Thus, by comparing the regions for the target random variables and the given random variables, we obtain our upperbound.",
    "MGT": "We introduce the concept of assisted common information, a novel information-theoretic primitive that extends classical common information by incorporating assistance from an external helper. In this framework, two parties Alice and Bob seek to generate a shared secret using their correlated sources X and Y, respectively, with the aid of a helper Charlie who has access to correlated side information Z. We establish fundamental limits for assisted common information by deriving tight upper and lower bounds on the minimum communication rates required from both the parties and the helper to achieve maximal shared randomness.\n\nOur main theoretical contribution demonstrates that assisted common information can strictly exceed classical common information under certain correlation structures, quantifying the precise conditions under which helper assistance provides information-theoretic advantages. We develop an optimization framework based on convex programming to compute assisted common information rates for discrete memoryless sources and prove convergence guarantees for our proposed algorithms.\n\nThe practical significance of our results is demonstrated through applications to secure two-party computation protocols. We show how assisted common information enables the construction of more efficient secret sharing schemes and secure multiparty computation protocols with reduced communication complexity. Specifically, our protocols achieve logarithmic improvement in communication rounds compared to existing approaches while maintaining information-theoretic security guarantees.\n\nExperimental evaluation on both synthetic and real-world datasets validates our theoretical predictions and demonstrates computational efficiency of our algorithms. Our framework opens new directions for leveraging side information in distributed cryptographic protocols, with potential applications extending to blockchain consensus mechanisms, federated learning, and privacy-preserving data analytics where external assistance can enhance security without compromising privacy."
  },
  {
    "id": 12,
    "prompt": "Quantum fluctuations in the transverse Ising spin glass model: A field theory of random quantum spin systems",
    "HWT": "We develop a mean-field theory for random quantum spin systems using the spin coherent state path integral representation. After the model is reduced to the mean field one-body Hamiltonian, the integral is analyzed with the aid of several methods such as the semiclassical method and the gauge transformation. As an application we consider the Sherrington-Kirkpatrick model in a transverse field. Using the Landau expansion and its improved versions, we give a detailed analysis of the imaginary-time dependence of the order parameters. Integrating out the quantum part of the order parameters, we obtain the effective renormalized free energy written in terms of the classically defined order parameters. Our method allows us to obtain the spin glass-paramagnetic phase transition point $\\Gamma/J\\sim 1.62$ at T=0.",
    "MGT": "# Quantum fluctuations in the transverse Ising spin glass model: A field theory of random quantum spin systems\n\nWe investigate the interplay between quantum fluctuations and disorder in the transverse Ising spin glass model using field-theoretical methods. Our approach maps the quantum spin system onto a (d+1)-dimensional classical model with effective long-range interactions in the imaginary time direction. We derive the replica field theory for this system and analyze the phase diagram through renormalization group techniques. Our results reveal that quantum fluctuations significantly modify the critical behavior compared to the classical spin glass, leading to a quantum phase transition with distinct universal exponents. We find that the quantum critical point exhibits an emergent dynamical scaling with z≈2, and the spin glass susceptibility follows a modified Curie-Weiss law at low temperatures. These findings provide insight into the fundamental nature of quantum glassy phases and may explain recent experimental observations in disordered quantum magnets and superconducting circuits where quantum effects dominate at low temperatures."
  },
  {
    "id": 13,
    "prompt": "The Kadomtsev-Petviashvili II Equation on the Half-Plane",
    "HWT": "The KPII equation is an integrable nonlinear PDE in 2+1 dimensions (two spatial and one temporal), which arises in several physical circumstances, including fluid mechanics where it describes waves in shallow water. It provides a multidimensional generalisation of the renowned KdV equation. In this work, we employ a novel approach recently introduced by one of the authors in connection with the Davey-Stewartson equation \\cite{FDS2009}, in order to analyse the initial-boundary value problem for the KPII equation formulated on the half-plane. The analysis makes crucial use of the so-called d-bar formalism, as well as of the so-called global relation. A novel feature of boundary as opposed to initial-value problems in 2+1 is that the d-bar formalism now involves a function in the complex plane which is discontinuous across the real axis.",
    "MGT": "This study investigates the initial-boundary value problem for the Kadomtsev-Petviashvili II (KP-II) equation on the half-plane. We establish well-posedness in anisotropic Sobolev spaces by developing a novel approach combining the Fokas method with modern harmonic analysis techniques. Our analysis reveals that the solution exhibits unique behavior at the boundary, characterized by dispersive effects distinct from those observed in the full-plane case. We prove the existence and uniqueness of solutions for initial data in H^s(R+×R) with s>3/2, subject to appropriate boundary conditions. Furthermore, we demonstrate that these solutions depend continuously on the initial data. The paper also addresses the persistence of regularity and provides explicit decay estimates for the solutions. Our results extend the current understanding of the KP-II equation and have potential applications in plasma physics and fluid dynamics, particularly in scenarios involving physical boundaries."
  },
  {
    "id": 14,
    "prompt": "Two-loop renormalization of scalar and pseudoscalar fermion bilinears on the lattice",
    "HWT": "We compute the two-loop renormalization functions, in the RI $^\\prime$ scheme, of local bilinear quark operators $\\bar{\\psi}\\Gamma\\psi$, where $\\Gamma$ denotes the Scalar and Pseudoscalar Dirac matrices, in the lattice formulation of QCD. We consider both the flavor non-singlet and singlet operators; the latter, in the scalar case, leads directly to the two-loop fermion mass renormalization, $Z_m$. As a prerequisite for the above, we also compute the quark field renormalization, $Z_{\\psi}$, up to two loops. We use the clover action for fermions and the Wilson action for gluons. Our results are given as a polynomial in $c_{SW}$, in terms of both the renormalized and bare coupling constant, in the renormalized Feynman gauge. We also confirm the 1-loop renormalization functions, for generic gauge. Finally, we present our results in the $\\bar{MS}$ scheme, for easier comparison with calculations in the continuum. The corresponding results, for fermions in an arbitrary representation, are included in an Appendix.",
    "MGT": "We present a comprehensive two-loop renormalization analysis of scalar and pseudoscalar fermion bilinear operators in lattice quantum chromodynamics. Using Wilson fermions with the standard plaquette gauge action, we calculate the renormalization constants for these operators through next-to-leading order in perturbation theory. Our computation employs dimensional regularization in the continuum limit and addresses the mixing between scalar and pseudoscalar operators that arises due to the explicit chiral symmetry breaking inherent in Wilson fermions.\n\nThe renormalization procedure is carried out in the modified minimal subtraction scheme, and we provide explicit expressions for the finite parts of the renormalization constants. We examine the scale dependence of these constants and verify that the anomalous dimensions reproduce the known continuum results. Particular attention is paid to the treatment of operator mixing, which requires careful consideration of the renormalization matrix structure.\n\nOur results are essential for precision calculations of hadronic matrix elements involving scalar and pseudoscalar currents, including studies of quark masses, sigma terms, and form factors. The two-loop accuracy achieved here significantly reduces the systematic uncertainties associated with perturbative matching between lattice and continuum schemes. We present numerical results for the renormalization constants as functions of the coupling constant and discuss their implications for phenomenological applications in lattice QCD calculations."
  },
  {
    "id": 15,
    "prompt": "The stubborn problem is stubborn no more (a polynomial algorithm for 3-compatible colouring and the stubborn list partition problem)",
    "HWT": "One of the driving problems in the CSP area is the Dichotomy Conjecture, formulated in 1993 by Feder and Vardi [STOC'93], stating that for any fixed relational structure G the Constraint Satisfaction Problem CSP(G) is either NP--complete or polynomial time solvable. A large amount of research has gone into checking various specific cases of this conjecture. One such variant which attracted a lot of attention in the recent years is the LIST MATRIX PARTITION problem. In 2004 Cameron et al. [SODA'04] classified almost all LIST MATRIX PARTITION variants for matrices of size at most four. The only case which resisted the classification became known as the STUBBORN PROBLEM. In this paper we show a result which enables us to finish the classification - thus solving a problem which resisted attacks for the last six years. Our approach is based on a combinatorial problem known to be at least as hard as the STUBBORN PROBLEM - the 3-COMPATIBLE COLOURING problem. In this problem we are given a complete graph with each edge assigned one of 3 possible colours and we want to assign one of those 3 colours to each vertex in such a way that no edge has the same colour as both of its endpoints. The tractability of the 3-COMPATIBLE COLOURING problem has been open for several years and the best known algorithm prior to this paper is due to Feder et al. [SODA'05] - a quasipolynomial algorithm with a n^O(log n / log log n) time complexity. In this paper we present a polynomial-time algorithm for the 3-COMPATIBLE COLOURING problem and consequently we prove a dichotomy for the k-COMPATIBLE COLOURING problem.",
    "MGT": "We present a polynomial-time algorithm for the 3-compatible colouring problem and its generalization, the stubborn list partition problem, resolving a longstanding open question in computational complexity theory. The 3-compatible colouring problem asks whether the vertices of a given graph can be properly coloured using three colours such that each colour class induces a subgraph with maximum degree at most one. This problem has been notorious for its resistance to both polynomial-time algorithms and NP-hardness proofs, earning it the designation as a \"stubborn\" problem in graph theory literature.\n\nOur main contribution is a novel algorithmic approach that combines structural graph decomposition with dynamic programming techniques. We introduce the concept of \"compatibility certificates\" that capture the essential constraints imposed by the degree-one requirement on colour classes. By systematically analyzing the interaction between these certificates and the underlying graph structure, we develop a recursive procedure that explores all feasible colour assignments in polynomial time.\n\nThe algorithm operates by first identifying a bounded-width tree decomposition of the input graph that respects certain compatibility properties. We prove that such decompositions always exist and can be computed efficiently. The dynamic programming phase then processes this decomposition bottom-up, maintaining compact representations of partial solutions at each node. A key insight is that the number of distinct compatibility states remains polynomial due to structural constraints inherent in 3-compatible colourings.\n\nWe extend our results to the more general stubborn list partition problem, where vertices must be partitioned into prescribed lists of colour classes, each satisfying specific degree constraints. Our algorithm generalizes naturally to this setting, maintaining polynomial complexity under reasonable assumptions on the constraint structure.\n\nThe time complexity of our algorithm is O(n^7) for the 3-compatible colouring problem and O(n^k+4) for the k-list stubborn partition problem, where n is the number of vertices. We also provide improved bounds for special graph classes including planar graphs and graphs of bounded treewidth, achieving O(n^4) and O(n^2) complexities respectively."
  },
  {
    "id": 16,
    "prompt": "SAM Lectures on Extremal Black Holes in d=4 Extended Supergravity",
    "HWT": "We report on recent results in the study of extremal black hole attractors in N=2, d=4 ungauged Maxwell-Einstein supergravities. For homogeneous symmetric scalar manifolds, the three general classes of attractor solutions with non-vanishing Bekenstein-Hawking entropy are discussed. They correspond to three (inequivalent) classes of orbits of the charge vector, which sits in the relevant symplectic representation R_{V} of the U-duality group. Other than the 1/2-BPS one, there are two other distinct non-BPS classes of charge orbits, one of which has vanishing central charge. The complete classification of the U-duality orbits, as well as of the moduli spaces of non-BPS attractors (spanned by the scalars which are not stabilized at the black hole event horizon), is also reviewed. Finally, we consider the analogous classification for N>2-extended, d=4 ungauged supergravities, in which also the 1/N-BPS attractors yield a related moduli space.",
    "MGT": "# SAM Lectures on Extremal Black Holes in d=4 Extended Supergravity\n\nThis article presents a comprehensive analysis of extremal black hole solutions in four-dimensional extended supergravity theories. We develop a systematic framework for classifying these solutions based on their symmetry properties and near-horizon geometries. Our approach reveals the deep connection between the attractor mechanism and the entropy of extremal black holes, demonstrating how scalar fields flow to fixed values at the horizon regardless of their asymptotic values. We explicitly construct multi-centered black hole configurations and analyze their stability conditions. The BPS and non-BPS branches of solutions are carefully distinguished, with particular attention to the role of duality symmetries in generating new solutions. The relationship between the black hole potential and the central charge is elucidated, providing insight into the quantum structure of these spacetimes. Our results establish a precise correspondence between extremal black hole entropy and the topological properties of the underlying moduli space, with implications for microscopic entropy counting in string theory realizations of these supergravity models."
  },
  {
    "id": 17,
    "prompt": "Enhancing extraordinary transmission of light through a metallic nano slit with a nano cavity antenna",
    "HWT": "The extraordinary transmission of light through a nano slit in a metal film is enhanced by introducing a nano cavity antenna formed by a nearby metallic nano-strip over the slit opening. For a fixed wavelength, the width of the metallic nano-strip should be chosen to make the horizontal metal-insulator-metal waveguide of finite length resonant as a Fabry-Perot cavity. When such a cavity antenna is used to enhance the transmission through a non-resonant nano slit, the slit should be opened at a position with maximal magnetic field in the horizontal resonant cavity. It is shown that an optimized cavity antenna can enhance greatly the transmission of light through a non-resonant nano slit (by about 20 times) or a resonant nano slit (by 124%). The transmission spectrum of the nano slit can also be tuned by adjusting the width of the metallic nano-strip. Such a transmission enhancement with a nano cavity antenna is studied for the first time and the physical mechanism is explained.",
    "MGT": "This study investigates the enhancement of extraordinary optical transmission through metallic nano slits by incorporating nano cavity antennas. We demonstrate that strategically positioned nano cavities can significantly amplify light transmission beyond the conventional diffraction limit through subwavelength apertures. Using finite-difference time-domain simulations and experimental validation, we show that the nano cavity antenna creates localized surface plasmon resonances that couple efficiently with incident electromagnetic radiation. The cavity geometry and positioning relative to the slit are optimized to achieve maximum field enhancement and transmission efficiency. Our results reveal that the nano cavity antenna increases transmission by up to 340% compared to bare nano slits, with the enhancement mechanism attributed to improved impedance matching and resonant field amplification. The spectral response exhibits sharp transmission peaks that can be tuned by adjusting cavity dimensions and materials. Experimental measurements using focused ion beam fabricated structures confirm theoretical predictions, showing excellent agreement between simulated and measured transmission spectra. This approach offers promising applications in optical filtering, sensing, and light harvesting devices where efficient light coupling through subwavelength features is critical."
  },
  {
    "id": 18,
    "prompt": "A universal exponential factor in the dimensional crossover from graphene to graphite",
    "HWT": "A universal exponential factor, $\\gamma_{c}=\\pi/2$, is disclosed for the dimensional crossover of few-layer graphene (FLG) from two-dimensional graphene to three-dimensional graphite. $\\gamma_{c}$ is found by analyzing available experimental data on different properties of FLG with varying thickness. A theoretical study on the phonon spectrum of the vertical acoustic mode in FLG is carried out to further check this exponential factor $\\gamma_{c}$. Interestingly, the same exponential factor appears in the dimensional crossover of the phonon mode. It turns out that the exponential factor $\\gamma_{c}$ is related to the homogeneous Helmholtz-like molal equation in the mass transfer with a first order chemical reaction. The finding should provide valuable information for experimentalists and theorists in the future investigation on thickness dependent properties of FLG.",
    "MGT": "We present a comprehensive theoretical and experimental investigation of the dimensional crossover phenomenon in carbon-based materials, specifically examining the transition from two-dimensional graphene to three-dimensional graphite. Through systematic analysis of electronic band structure evolution, we identify a universal exponential scaling factor that governs the dimensional crossover behavior across varying layer thicknesses. Our density functional theory calculations reveal that the interlayer coupling strength exhibits exponential dependence on the number of graphene layers, characterized by a decay constant of 0.287 ± 0.012 nm⁻¹. Experimental validation using angle-resolved photoemission spectroscopy on mechanically exfoliated samples confirms this theoretical prediction, demonstrating excellent agreement within 3% deviation. The universal exponential factor emerges from the competition between intralayer π-orbital interactions and interlayer van der Waals coupling, providing fundamental insight into the electronic structure evolution of layered materials. These findings establish a predictive framework for understanding dimensional crossover phenomena in other two-dimensional materials and their bulk counterparts, with implications for electronic device applications and materials design strategies."
  },
  {
    "id": 19,
    "prompt": "Shrinkage regression for multivariate inference with missing data, and an application to portfolio balancing",
    "HWT": "Portfolio balancing requires estimates of covariance between asset returns. Returns data have histories which greatly vary in length, since assets begin public trading at different times. This can lead to a huge amount of missing data--too much for the conventional imputation-based approach. Fortunately, a well-known factorization of the MVN likelihood under the prevailing historical missingness pattern leads to a simple algorithm of OLS regressions that is much more reliable. When there are more assets than returns, however, OLS becomes unstable. Gramacy, et al. (2008), showed how classical shrinkage regression may be used instead, thus extending the state of the art to much bigger asset collections, with further accuracy and interpretation advantages. In this paper, we detail a fully Bayesian hierarchical formulation that extends the framework further by allowing for heavy-tailed errors, relaxing the historical missingness assumption, and accounting for estimation risk. We illustrate how this approach compares favorably to the classical one using synthetic data and an investment exercise with real returns. An accompanying R package is on CRAN.",
    "MGT": "# Shrinkage regression for multivariate inference with missing data, and an application to portfolio balancing\n\nWe propose a novel shrinkage regression approach for multivariate inference in the presence of missing data, with specific application to portfolio optimization. Missing data presents significant challenges in financial modeling, particularly when constructing optimal portfolios requiring complete covariance matrices. Our method integrates a shrinkage estimator with multiple imputation techniques to address both high dimensionality and missingness patterns in financial time series. We develop theoretical guarantees for the consistency of our estimator under a broad class of missing data mechanisms, including Missing Completely at Random (MCAR) and Missing at Random (MAR) scenarios. Empirical evaluations using both simulated data and real-world financial datasets demonstrate that our approach outperforms traditional methods in terms of portfolio performance metrics, including Sharpe ratio and maximum drawdown. The shrinkage parameter is adaptively tuned to balance bias-variance tradeoffs, resulting in more stable portfolio weights even when missing data rates exceed 30%. Our framework provides practitioners with a robust tool for portfolio balancing that maintains efficiency without requiring complete market data, addressing a critical gap in existing methodologies for investment management under uncertainty."
  },
  {
    "id": 20,
    "prompt": "Galaxy Satellites and the Weak Equivalence Principle",
    "HWT": "Numerical simulations of the effect of a long-range scalar interaction (LRSI) acting only on nonbaryonic dark matter, with strength comparable to gravity, show patterns of disruption of satellites that can agree with what is seen in the Milky Way. This includes the symmetric Sagittarius stellar stream. The exception presented here to the Kesden and Kamionkowski demonstration that an LRSI tends to produce distinctly asymmetric streams follows if the LRSI is strong enough to separate the stars from the dark matter before tidal disruption of the stellar component, and if stars dominate the mass in the luminous part of the satellite. It requires that the Sgr galaxy now contains little dark matter, which may be consistent with the Sgr stellar velocity dispersion, for in the simulation the dispersion at pericenter exceeds virial. We present other examples of simulations in which a strong LRSI produces satellites with large mass-to-light ratio, as in Draco, or free streams of stars, which might be compared to \"orphan\" streams.",
    "MGT": "We investigate the implications of satellite galaxy dynamics for testing the weak equivalence principle (WEP) in the context of modified gravity theories. Using high-precision astrometric data from Gaia DR3, we analyze the orbital motions of 15 Milky Way satellite galaxies with well-constrained proper motions and distances. Our analysis focuses on detecting potential violations of the WEP through differential accelerations that would manifest as anomalous orbital behaviors inconsistent with standard Newtonian dynamics and general relativity. We employ a Bayesian framework to constrain the Eötvös parameter η, which quantifies WEP violations, by comparing observed satellite trajectories with theoretical predictions under various modified gravity scenarios including f(R) theories and scalar-tensor models. Our results yield η < 2.3 × 10⁻⁴ at 95% confidence, representing a factor of three improvement over previous constraints from satellite dynamics. Notably, we find no statistically significant deviations from WEP expectations in the satellite population studied. The Leo I galaxy shows marginal tension with standard predictions, warranting further investigation. These findings strengthen confidence in the universality of gravitational physics across galactic scales while establishing satellite galaxy dynamics as a powerful probe for fundamental physics beyond the Standard Model."
  },
  {
    "id": 21,
    "prompt": "Thermal and magnetic properties of a low-temperature antiferromagnet Ce$_4$Pt$_{12}$Sn$_{25}$",
    "HWT": "We report specific heat ($C$) and magnetization ($M$) of single crystalline Ce$_4$Pt$_{12}$Sn$_{25}$ at temperature down to $\\sim$50mK and in fields up to 3T. $C/T$ exhibits a sharp anomaly at 180mK, with a large $\\Delta C/T\\sim$30J/molK$^2$-Ce, which, together with the corresponding cusp-like magnetization anomaly, indicates an antiferromagnetic (AFM) ground state with a N\\'eel temperature $T_N$=180mK. Numerical calculations based on a Heisenberg model reproduce both zero-field $C$ and $M$ data, thus placing Ce$_4$Pt$_{12}$Sn$_{25}$ in the weak exchange coupling $J<J_c$ limit of the Doniach diagram, with a very small Kondo scale $T_K\\ll T_N$. Magnetic field suppresses the AFM state at $H^*\\approx$0.7T, much more effectively than expected from the Heisenberg model, indicating additional effects possibly due to frustration or residual Kondo screening.",
    "MGT": "The thermal and magnetic properties of the intermetallic compound Ce$_4$Pt$_{12}$Sn$_{25}$ have been investigated through comprehensive measurements of specific heat, magnetic susceptibility, and magnetization across a wide temperature range. X-ray diffraction confirms the formation of a single-phase cubic structure with space group Im-3m. Magnetic susceptibility measurements reveal Curie-Weiss behavior above 50 K with an effective magnetic moment of 2.54 μ$_B$ per Ce atom, consistent with Ce$^{3+}$ configuration. The Weiss temperature θ$_W$ = -12.3 K indicates predominantly antiferromagnetic interactions. Below T$_N$ = 4.2 K, the compound undergoes a transition to an antiferromagnetically ordered state, evidenced by a sharp peak in the specific heat and a deviation from Curie-Weiss behavior in the susceptibility. The magnetic entropy reaches 0.85R ln(2) at the transition, suggesting partial quenching of the Ce$^{3+}$ magnetic moments. Magnetization isotherms at 2 K show linear field dependence up to 9 T with no indication of metamagnetic transitions. The specific heat below T$_N$ follows C$_m$ ∝ T$^{1.5}$ dependence, characteristic of three-dimensional antiferromagnetic magnons. The electronic contribution γ = 127 mJ/mol-Ce·K$^2$ indicates moderate heavy-fermion behavior. These results establish Ce$_4$Pt$_{12}$Sn$_{25}$ as a well-ordered low-temperature antiferromagnet with localized Ce$^{3+}$ moments and weak Kondo interactions."
  },
  {
    "id": 22,
    "prompt": "Profiles of emission lines generated by rings orbiting braneworld Kerr black holes",
    "HWT": "In the framework of the braneworld models, rotating black holes can be described by the Kerr metric with a tidal charge representing the influence of the non-local gravitational (tidal) effects of the bulk space Weyl tensor onto the black hole spacetime. We study the influence of the tidal charge onto profiled spectral lines generated by radiating tori orbiting in vicinity of a rotating black hole. We show that with lowering the negative tidal charge of the black hole, the profiled line becomes to be flatter and wider keeping their standard character with flux stronger at the blue edge of the profiled line. The extension of the line grows with radius falling and inclination angle growing. With growing inclination angle a small hump appears in the profiled lines due to the strong lensing effect of photons coming from regions behind the black hole. For positive tidal charge ($b>0$) and high inclination angles two small humps appear in the profiled lines close to the red and blue edge of the lines due to the strong lensing effect. We can conclude that for all values of $b$, the strongest effect on the profiled lines shape (extension) is caused by the changes of the inclination angle.",
    "MGT": "We investigate the spectroscopic signatures of emission lines produced by thin rings of radiating matter in circular orbits around rotating black holes within the braneworld scenario. The braneworld model modifies Einstein's general relativity through the inclusion of extra spatial dimensions, leading to corrections in the black hole metric that depend on the tidal charge parameter and affect the spacetime geometry in the vicinity of the event horizon. We employ ray-tracing techniques to compute the observed emission line profiles as seen by distant observers, accounting for gravitational redshift, Doppler effects, and light bending in the modified Kerr geometry.\n\nOur analysis reveals that braneworld corrections introduce distinctive features in the emission line profiles compared to standard general relativity predictions. The additional tidal charge parameter significantly influences the location of the innermost stable circular orbit, which directly affects the maximum gravitational redshift observable in the emission lines. We find that negative tidal charges enhance the gravitational effects, producing more pronounced redshifted wings in the line profiles, while positive tidal charges tend to reduce these effects.\n\nThe computed line profiles exhibit characteristic asymmetric shapes with enhanced blue and redshifted components that carry unique signatures of the braneworld modifications. These spectroscopic features provide potential observational tests for distinguishing braneworld black holes from their general relativistic counterparts. Our results suggest that high-resolution X-ray spectroscopy of accretion flows around supermassive black holes could serve as a probe for extra-dimensional physics and braneworld cosmological models."
  },
  {
    "id": 23,
    "prompt": "Eta Carinae and Nebulae Around Massive Stars: Similarities to Planetary Nebulae?",
    "HWT": "I discuss some observational properties of aspherical nebulae around massive stars, and conclusions inferred for how they may have formed. Whether or not these ideas are applicable to the shaping of planetary nebulae is uncertain, but the observed similarities between some PNe and bipolar nebulae around massive stars is compelling. In the well-observed case of Eta Carinae, several lines of observational evidence point to a scenario where the shape of its bipolar nebula resulted from an intrinsically bipolar explosive ejection event rather than an interacting winds scenario occurring after ejection from teh star. A similar conclusion has been inferred for some planetary nebulae. I also briefly mention bipolar nebulae around some other massive stars, such as the progenitor of SN 1987A and related blue supergiants.",
    "MGT": "We present a comparative analysis of the nebular structures surrounding Eta Carinae and other massive stars, examining their morphological and physical similarities to classical planetary nebulae. High-resolution imaging and spectroscopic observations reveal that circumstellar nebulae around luminous blue variables and Wolf-Rayet stars exhibit bipolar morphologies, dense equatorial structures, and complex knot formations remarkably similar to those found in planetary nebulae around low-mass stars. Our analysis of the Homunculus nebula surrounding Eta Carinae demonstrates comparable expansion velocities, density distributions, and ionization patterns to well-studied planetary nebulae. We propose that common physical mechanisms, including stellar wind interactions, magnetic field configurations, and binary evolution processes, may govern nebular shaping across different stellar mass ranges. These findings suggest that the formation of aspherical circumstellar nebulae represents a universal phenomenon in stellar evolution, challenging traditional distinctions between massive star and planetary nebula formation paradigms and providing new insights into late-stage stellar mass loss processes."
  },
  {
    "id": 24,
    "prompt": "Sum-Capacity and the Unique Separability of the Parallel Gaussian MAC-Z-BC Network",
    "HWT": "It is known that the capacity of parallel (e.g., multi-carrier) Gaussian point-to-point, multiple access and broadcast channels can be achieved by separate encoding for each subchannel (carrier) subject to a power allocation across carriers. Recent results have shown that parallel interference channels are not separable, i.e., joint coding is needed to achieve capacity in general. This work studies the separability, from a sum-capacity perspective, of single hop Gaussian interference networks with independent messages and arbitrary number of transmitters and receivers. The main result is that the only network that is always (for all values of channel coefficients) separable from a sum-capacity perspective is the MAC-Z-BC network, i.e., a network where a MAC component and a BC component are linked by a Z component. The sum capacity of this network is explicitly characterized.",
    "MGT": "This paper investigates the sum-capacity and unique separability properties of the parallel Gaussian multiple access channel with interference and broadcast capabilities (MAC-Z-BC) network. We establish the sum-capacity region for this network topology under Gaussian noise assumptions and derive closed-form expressions for the achievable rate regions. The analysis reveals that the parallel structure introduces fundamental trade-offs between interference management and cooperative transmission strategies. We prove that the network exhibits unique separability properties, meaning that the optimal transmission scheme can be decomposed into independent parallel channel solutions without loss of optimality. Our results demonstrate that the sum-capacity is achieved through a specific power allocation strategy that balances the competing demands of multiple access, interference mitigation, and broadcast transmission. The theoretical framework is validated through numerical simulations, showing significant capacity gains compared to conventional interference treatment methods. These findings provide important insights for designing efficient transmission protocols in next-generation wireless networks with complex topologies involving simultaneous multiple access and broadcast operations."
  },
  {
    "id": 25,
    "prompt": "Advances in Data Combination, Analysis and Collection for System Reliability Assessment",
    "HWT": "The systems that statisticians are asked to assess, such as nuclear weapons, infrastructure networks, supercomputer codes and munitions, have become increasingly complex. It is often costly to conduct full system tests. As such, we present a review of methodology that has been proposed for addressing system reliability with limited full system testing. The first approaches presented in this paper are concerned with the combination of multiple sources of information to assess the reliability of a single component. The second general set of methodology addresses the combination of multiple levels of data to determine system reliability. We then present developments for complex systems beyond traditional series/parallel representations through the use of Bayesian networks and flowgraph models. We also include methodological contributions to resource allocation considerations for system relability assessment. We illustrate each method with applications primarily encountered at Los Alamos National Laboratory.",
    "MGT": "I need to write an academic abstract for the title \"Advances in Data Combination, Analysis and Collection for System Reliability Assessment\" that is about 154 words. This should be a technical abstract that covers:\n\n1. The context/problem\n2. The approach/methods\n3. Key findings/contributions\n4. Implications/applications\n\nThe topic is about system reliability assessment, focusing on three key areas:\n- Data combination\n- Data analysis \n- Data collection\n\nI should make this sound like a legitimate academic abstract with proper technical language and structure.\n\nLet me draft this:\n\nSystem reliability assessment has become increasingly critical in modern engineering applications, yet traditional approaches face significant challenges in handling heterogeneous data sources and complex failure mechanisms. This research presents novel methodologies for enhancing data combination, analysis, and collection strategies to improve reliability assessment accuracy and efficiency. We develop an integrated framework that leverages machine learning algorithms for intelligent data fusion, enabling seamless combination of historical failure data, real-time sensor measurements, and expert knowledge. Advanced statistical techniques including Bayesian networks and Monte Carlo simulation are employed for comprehensive analysis of uncertainty propagation and failure dependencies. A new adaptive data collection protocol is introduced that optimizes sensor placement and sampling frequencies based on system criticality and failure probability distributions. Experimental validation across multiple industrial systems demonstrates significant improvements in prediction accuracy, with error rates reduced by up to 35% compared to conventional methods. The proposed approach enables more informed maintenance decisions, reduces unexpected failures, and enhances overall system availability. These advances have substantial implications for safety-critical applications in aerospace, nuclear, and transportation industries where reliable assessment is paramount.\n\nLet me count the words... that's about 185 words, which is too long. I need to trim it down to around 154 words.\n\nLet me revise:\n\nSystem reliability assessment faces growing challenges in handling heterogeneous data sources and complex failure mechanisms across modern engineering systems. This research presents novel methodologies for enhancing data combination, analysis, and collection strategies to improve assessment accuracy and efficiency. We develop an integrated framework leveraging machine learning algorithms for intelligent data fusion, enabling seamless combination of historical failure data, real-time sensor measurements, and expert knowledge. System reliability assessment faces growing challenges in handling heterogeneous data sources and complex failure mechanisms across modern engineering systems. This research presents novel methodologies for enhancing data combination, analysis, and collection strategies to improve assessment accuracy and efficiency. We develop an integrated framework leveraging machine learning algorithms for intelligent data fusion, enabling seamless combination of historical failure data, real-time sensor measurements, and expert knowledge. Advanced statistical techniques including Bayesian networks and Monte Carlo simulation are employed for comprehensive uncertainty propagation analysis. A new adaptive data collection protocol optimizes sensor placement and sampling frequencies based on system criticality and failure probability distributions. Experimental validation across multiple industrial systems demonstrates significant improvements in prediction accuracy, with error rates reduced by up to 35% compared to conventional methods. The proposed approach enables more informed maintenance decisions, reduces unexpected failures, and enhances overall system availability. These advances have substantial implications for safety-critical applications in aerospace, nuclear, and transportation industries where reliable assessment is essential for operational safety."
  },
  {
    "id": 26,
    "prompt": "A celestial gamma-ray foreground due to the albedo of small solar system bodies and a remote probe of the interstellar cosmic ray spectrum",
    "HWT": "We calculate the gamma-ray albedo flux from cosmic-ray (CR) interactions with the solid rock and ice in Main Belt asteroids (MBAs), Jovian and Neptunian Trojan asteroids, and Kuiper Belt objects (KBOs) using the Moon as a template. We show that the gamma-ray albedo for the Main Belt, Trojans, and Kuiper Belt strongly depends on the small-body size distribution of each system. Based on an analysis of the Energetic Gamma Ray Experiment Telescope (EGRET) data we infer that the diffuse emission from the MBAs, Trojans, and KBOs has an integrated flux of less than ~6x10^{-6} cm^{-2} s^{-1} (100-500 MeV), which corresponds to ~12 times the Lunar albedo, and may be detectable by the forthcoming Gamma Ray Large Area Space Telescope (GLAST). If detected by GLAST, it can provide unique direct information about the number of small bodies in each system that is difficult to assess by any other method. Additionally, the KBO albedo flux can be used to probe the spectrum of CR nuclei at close-to-interstellar conditions. The orbits of MBAs, Trojans, and KBOs are distributed near the ecliptic, which passes through the Galactic center and high Galactic latitudes. Therefore, the asteroid gamma-ray albedo has to be taken into account when analyzing weak gamma-ray sources close to the ecliptic, especially near the Galactic center and for signals at high Galactic latitudes, such as the extragalactic gamma-ray emission. The asteroid albedo spectrum also exhibits a 511 keV line due to secondary positrons annihilating in the rock. This may be an important and previously unrecognized celestial foreground for the INTErnational Gamma-Ray Astrophysics Laboratory (INTEGRAL) observations of the Galactic 511 keV line emission including the direction of the Galactic center.",
    "MGT": "The inner solar system harbors numerous small bodies including asteroids, comets, and meteoroids that continuously interact with the ambient interstellar cosmic ray flux. When high-energy cosmic ray protons and heavier nuclei collide with these objects, they produce secondary particles including neutral pions that decay into gamma rays, creating an isotropic celestial foreground emission. This study presents the first comprehensive calculation of the gamma-ray albedo contribution from small solar system bodies to the diffuse gamma-ray background observed by space-based telescopes.\n\nWe develop a Monte Carlo framework to model cosmic ray interactions with a realistic size and spatial distribution of small bodies derived from observational surveys and dynamical simulations. The calculation incorporates the energy-dependent cosmic ray spectrum, nuclear interaction cross-sections, and pion production yields across the relevant energy range from 100 MeV to 100 GeV. We account for the gravitational focusing effect of the Sun on the interstellar cosmic ray flux and include contributions from main-belt asteroids, near-Earth objects, Jupiter Trojans, and the zodiacal dust complex.\n\nOur results demonstrate that small solar system bodies produce a measurable gamma-ray flux of approximately 2.3 × 10^-7 cm^-2 s^-1 sr^-1 above 100 MeV, representing roughly 0.8% of the total diffuse gamma-ray background measured by Fermi-LAT. The spectral shape of this emission directly traces the interstellar cosmic ray proton spectrum, providing a novel probe of cosmic ray propagation in the local interstellar medium uncontaminated by solar modulation effects.\n\nThis celestial foreground has important implications for precision measurements of extragalactic gamma-ray backgrounds and searches for dark matter annihilation signatures. The energy dependence and angular distribution of the small-body albedo emission exhibit distinctive characteristics that enable its identification and subtraction from observational data. Furthermore, future improvements in small-body population models and cosmic ray measurements will enhance the precision of this foreground correction, potentially revealing subtle spectral features in the pristine interstellar cosmic ray spectrum that remain hidden by solar modulation in direct measurements."
  },
  {
    "id": 27,
    "prompt": "Cosmological MHD simulation of a cooling flow cluster",
    "HWT": "Various observations of magnetic fields in the Intra-Cluster Medium (ICM), most of the time restricted to cluster cores, point towards field strength of the order of a few microG (synchrotron radiation from radio relics and radio halos, inverse Compton radiation in X-rays and Faraday rotation measure of polarised background sources). Both the origin and the spatial structure of galaxy clusters magnetic fields are still under debate. In particular, the radial profile of the magnetic field, from the core of clusters to their outskirts, is of great importance for cosmic rays propagation within the Cosmic Web. In this letter, we highlight the importance of cooling processes in amplifying the magnetic field in the core of galaxy clusters up to one order of magnitude above the typical amplification obtained for a pure adiabatic evolution. We have performed a \"zoom'' cosmological simulation of a 3 keV cluster, including dark matter and gas dynamics, atomic cooling, UV heating and star formation using the newly developed MHD solver in the AMR code RAMSES. Magnetic field amplification proceeds mainly through gravitational contraction. Shearing motions due to turbulence provide additional amplification in the outskirts of the cluster, while magnetic reconnection during mergers causes magnetic field dissipation in the core. Cooling processes have a strong impact on the magnetic field structure in the cluster. First, due to the sharp rise of the gas density in the centre, gravitational amplification is significantly amplified, when compared to the non--radiative run. Second, due to cooling processes, shearing motions are much stronger in the core than in the adiabatic case, leading to additional field amplification and no significant magnetic reconnection.",
    "MGT": "# Cosmological MHD Simulation of a Cooling Flow Cluster\n\nWe present results from a high-resolution cosmological magnetohydrodynamical (MHD) simulation of a massive galaxy cluster exhibiting strong cooling flow characteristics. The simulation employs an adaptive mesh refinement technique with a peak spatial resolution of 0.5 kpc in the cluster core, allowing us to resolve the complex interplay between cooling processes, magnetic fields, and turbulence. Starting from cosmological initial conditions, we follow the formation and evolution of a 8.5 × 10^14 M_⊙ cluster from redshift z = 120 to z = 0, incorporating radiative cooling, star formation, supernova feedback, and magnetic field amplification. \n\nOur results demonstrate that magnetic fields play a crucial role in regulating the cooling flow phenomenon. The simulated cluster develops a magnetic field structure with strengths reaching 10-20 μG in the central regions, consistent with Faraday rotation measurements. We find that magnetic tension suppresses gas mixing and turbulent dissipation, allowing thermal instabilities to develop more efficiently compared to purely hydrodynamical simulations. This leads to the formation of multiphase gas with temperatures ranging from 10^4 to 10^7 K organized in filamentary structures within the inner 100 kpc.\n\nThe simulation reproduces key observational features of cooling flow clusters, including a central temperature drop, enhanced metallicity, and the presence of Hα filaments aligned with the magnetic field lines. We observe that magnetic draping around rising AGN bubbles increases their stability and lifetime, enhancing their ability to distribute energy throughout the intracluster medium. Additionally, our results indicate that magnetic pressure support becomes significant in the cluster core, contributing up to 30% of the total pressure and altering the traditional hydrostatic equilibrium assumption used in mass estimates.\n\nThis work highlights the importance of including properly resolved magnetic fields in cosmological simulations of galaxy clusters and provides new insights into the complex thermodynamics of cooling flows and their connection to feedback processes."
  },
  {
    "id": 28,
    "prompt": "Probing the dusty environment of the Seyfert 1 nucleus in NGC 3783 with MIDI/VLTI interferometry",
    "HWT": "We present mid-IR spectro-interferometry of the Seyfert type 1 nucleus of NGC 3783. The dusty circumnuclear environment is spatially resolved and the wavelength dependence of the compact emission is discussed. The observations were carried out with the MIDI instrument at the Very Large Telescope Interferometer in the N-band. Spectra and visibilities were derived with a spectral resolution of 30 in the wavelength range from 8 to 13 micron. For the interpretation we developed a simple dusty disk model with small and variable covering factor. At baselines of 65 and 69 m, visibilities in the range of 0.4 to 0.7 were measured. The N-band spectra show a monotonic increase of the measured flux with wavelength with no apparent silicate feature around 10 micron. We find that the mid-IR emission from the nucleus can be reproduced by an extended dust disk or torus with a small covering factor of the radiating dust clouds. Our mid-IR observations of NGC 3783 are consistent with a clumpy circumnuclear dust environment. The interpretation in terms of a dusty torus with low covering factor supports a clumpy version of the unified scheme for AGN. The inferred sizes and luminosities are in good agreement with dust reverberation sizes and bolometric luminosities from optical and X-ray observations.",
    "MGT": "We present the first mid-infrared interferometric observations of the Seyfert 1 galaxy NGC 3783 using the MIDI instrument at the Very Large Telescope Interferometer. Our observations, conducted with baseline lengths ranging from 47 to 130 meters, probe the nuclear dusty environment on scales of approximately 1-10 parsecs. The visibility measurements reveal a partially resolved source with correlated flux densities decreasing from 0.8 to 0.3 as baseline length increases, indicating the presence of extended mid-infrared emission around the active galactic nucleus.\n\nWe detect significant dust emission at 10.7 μm with a total flux density of 2.1 ± 0.2 Jy, consistent with previous single-dish observations. The interferometric data constrain the characteristic size of the mid-infrared emitting region to approximately 3.2 ± 0.8 parsecs, assuming a Gaussian brightness distribution. This size is larger than expected from simple reprocessing models of the accretion disk but consistent with clumpy torus models that include radiative transfer effects.\n\nTemperature analysis of the dust emission suggests a radial temperature gradient from ~300 K at the inner edge to ~150 K at larger radii, supporting the presence of a stratified dusty structure. The position angle of the resolved emission is aligned within 15° of the radio jet axis, suggesting a possible connection between the dusty torus geometry and the large-scale outflow direction. These results provide new constraints on the physical properties and spatial distribution of circumnuclear dust in active galactic nuclei."
  },
  {
    "id": 29,
    "prompt": "On a reduction procedure for Horn inequalities in finite von Neumann algebras",
    "HWT": "We consider the analogues of the Horn inequalities in finite von Neumann algebras, which concern the possible spectral distributions of sums $a+b$ of self--adjoint elements $a$ and $b$ in a finite von Neumann algebra. It is an open question whether all of these Horn inequalities must hold in all finite von Neumann algebras, and this is related to Connes' embedding problem. For each choice of integers $1\\le r\\le n$, there is a set $T^n_r$ of Horn triples, and the Horn inequalities are in one-to-one correspondence with $\\cup_{1\\le r\\le n}T^n_r$. We consider a property P$_n$, analogous to one introduced by Therianos and Thompson in the case of matrices, amounting to the existence of projections having certain properties relative to arbitrary flags, which guarantees that a given Horn inequality holds in all finite von Neumann algebras. It is an open question whether all Horn triples in $T^n_r$ have property P$_n$. Certain triples in $T^n_r$ can be reduced to triples in $T^{n-1}_r$ by an operation we call {\\em TT--reduction}. We show that property P$_n$ holds for the original triple if property P$_{n-1}$ holds for the reduced one. We then characterize the TT--irreducible Horn triples in $T^n_3$, for arbitrary $n$, and for those LR--minimal ones (namely, those having Littlewood--Richardson coefficient equal to 1), we perform a construction of projections with respect to flags in arbitrary von Neumann algebras in order to prove property P$_n$ for them. This shows that all LR--minimal triples in $\\cup_{n\\ge3}T^n_3$ have property P$_n$, and so that the corresponding Horn inequalities hold in all finite von Neumann algebras.",
    "MGT": "We present a systematic reduction procedure for analyzing Horn inequalities in the context of finite von Neumann algebras, extending classical results from matrix theory to the more general noncommutative setting. Horn inequalities, which characterize the possible eigenvalues of sums and products of Hermitian matrices, have found profound applications in representation theory, combinatorics, and quantum information theory. Our work addresses the fundamental question of how these inequalities generalize when the underlying algebraic structure is a finite von Neumann algebra rather than the algebra of complex matrices.\n\nThe reduction procedure we develop exploits the tracial structure inherent in finite von Neumann algebras, utilizing the unique normalized faithful trace to establish a correspondence between spectral properties in the von Neumann algebra setting and those in finite-dimensional matrix algebras. We demonstrate that under appropriate conditions, Horn inequalities in finite von Neumann algebras can be systematically reduced to finite collections of classical Horn inequalities through a process we term \"tracial approximation.\"\n\nOur main theorem establishes that for self-adjoint elements in a finite von Neumann algebra, the validity of generalized Horn inequalities can be determined by examining their restrictions to an increasing sequence of finite-dimensional subalgebras that approximate the original algebra in the ultraweak topology. This reduction preserves the essential spectral relationships while making the inequalities computationally tractable.\n\nThe procedure involves three key steps: first, we construct a canonical embedding of the spectral data into a sequence of matrix algebras; second, we establish convergence criteria for the associated eigenvalue distributions; and third, we prove that the limiting behavior of classical Horn inequalities in these approximating sequences determines the validity of the original inequality in the von Neumann algebra.\n\nWe provide explicit algorithms for implementing this reduction and demonstrate their effectiveness through several illustrative examples, including applications to quantum channel capacities and free probability theory. The results also yield new insights into the structure of the cone of feasible spectral data in noncommutative settings, with implications for optimization problems in quantum information processing and the theory of operator algebras."
  },
  {
    "id": 30,
    "prompt": "Thermonuclear Reflect AB-Reactor",
    "HWT": "The author offers a new kind of thermonuclear reflect reactor. The remarkable feature of this new reactor is a three net AB reflector, which confines the high temperature plasma. The plasma loses part of its energy when it contacts with the net but this loss can be compensated by an additional permanent plasma heating. When the plasma is rarefied (has a small density), the heat flow to the AB reflector is not large and the temperature in the triple reflector net is lower than 2000 - 3000 K. This offered AB-reactor has significantly less power then the currently contemplated power reactors with magnetic or inertial confinement (hundreds-thousands of kW, not millions of kW). But it is enough for many vehicles and ships and particularly valuable for tunnelers, subs and space apparatus, where air to burn chemical fuel is at a premium or simply not available. The author has made a number of innovations in this reactor, researched its theory, developed methods of computation, made a sample computation of typical project. The main point of preference for the offered reactor is its likely cheapness as a power source. Key words: Micro-thermonuclear reactor, Multi-reflex AB-thermonuclear reactor, Self-magnetic AB-thermonuclear reactor, aerospace thermonuclear engine.",
    "MGT": "This study presents a comprehensive analysis of the Thermonuclear Reflect AB-Reactor, a novel fusion reactor design incorporating advanced magnetic confinement and neutron reflection technologies. The AB-Reactor utilizes a dual-chamber configuration with asymmetric magnetic field geometries to optimize plasma stability and energy extraction efficiency. Through computational fluid dynamics modeling and magnetohydrodynamic simulations, we demonstrate significant improvements in plasma confinement time and fusion reaction rates compared to conventional tokamak designs.\n\nThe reactor's innovative reflection system employs beryllium-tungsten composite walls with engineered microstructures that enhance neutron thermalization while minimizing material degradation. Experimental validation using a scaled prototype revealed a 34% increase in neutron flux utilization and a corresponding 28% improvement in tritium breeding ratio. The asymmetric field configuration reduces plasma turbulence by 42% while maintaining stable operation across a broader range of beta values.\n\nPerformance analysis indicates the AB-Reactor achieves a Q-factor of 15.7 under optimal conditions, representing a substantial advancement toward commercial viability. The design addresses critical challenges in fusion energy including tritium self-sufficiency, materials compatibility, and thermal management. Preliminary economic modeling suggests a 23% reduction in levelized cost of electricity compared to existing fusion concepts.\n\nThese findings demonstrate the AB-Reactor's potential as a transformative technology for sustainable fusion power generation. Future research will focus on scaling optimization, materials longevity testing, and integration with advanced plasma control systems to further enhance reactor performance and commercial feasibility."
  },
  {
    "id": 31,
    "prompt": "Vacuum static compactified wormholes in eight-dimensional Lovelock theory",
    "HWT": "In this paper new exact solutions in eight dimensional Lovelock theory will be presented. These solutions are vacuum static wormhole, black hole and generalized Bertotti-Robinson space-times with nontrivial torsion. All the solutions have a cross product structure of the type $M_{5}\\times \\Sigma_{3} $ where $M_{5}$ is a five dimensional manifold and $\\Sigma_{3}$ a compact constant curvature manifold. The wormhole is the first example of a smooth vacuum static Lovelock wormhole which is neither Chern-Simons nor Born-Infeld. It will be also discussed how the presence of torsion affects the \"navigableness\" of the wormhole for scalar and spinning particles. It will be shown that the wormhole with torsion may act as \"geometrical filter\": a very large torsion may \"increase the traversability\" for scalars while acting as a \"polarizator\" on spinning particles. This may have interesting phenomenological consequences.",
    "MGT": "We investigate vacuum static solutions in eight-dimensional Lovelock gravity theory that admit wormhole geometries with compactified extra dimensions. The field equations are solved analytically for a specific ansatz describing spherically symmetric spacetimes with two asymptotically flat regions connected by a throat. We demonstrate that stable traversable wormholes can exist without exotic matter when higher-order curvature terms in the Lovelock Lagrangian provide the necessary gravitational dynamics. The compactification mechanism involves rolling up four spatial dimensions into a compact manifold while preserving the wormhole structure in the remaining four-dimensional effective spacetime. Our solutions exhibit interesting topological properties, including non-trivial first and second Chern classes associated with the compactified dimensions. The throat radius and compactification scale are shown to be related through the Lovelock coupling constants, suggesting a fundamental connection between extra-dimensional physics and wormhole geometry. Stability analysis reveals that these configurations are classically stable against radial perturbations for a specific range of parameters. These results provide new insights into the relationship between higher-dimensional gravity theories and exotic spacetime geometries."
  },
  {
    "id": 32,
    "prompt": "Arithmetic of N=8 Black Holes",
    "HWT": "The microscopic formula for the degeneracies of 1/8 BPS black holes in type II string theory compactified on a six dimensional torus can be expressed as a sum of several terms. One of the terms is a function of the Cremmer-Julia invariant and gives the leading contribution to the entropy in the large charge limit. The other terms, which give exponentially subleading contribution, depend not only on the Cremmer-Julia invariant, but also on the arithmetic properties of the charges, and in fact exist only when the charges satisfy special arithmetic properties. We identify the origin of these terms in the macroscopic formula for the black hole entropy, based on quantum entropy function, as the contribution from non-trivial saddle point(s) in the path integral of string theory over the near horizon geometry. These saddle points exist only when the charge vectors satisfy the arithmetic properties required for the corresponding term in the microscopic formula to exist. Furthermore the leading contribution from these saddle points in the large charge limit agrees with the leading asymptotic behaviour of the corresponding term in the degeneracy formula.",
    "MGT": "We investigate the arithmetic properties of extremal black holes in N=8 supergravity, focusing on the discrete symmetries and number-theoretic structures underlying their entropy formulas. The duality group E₇₍₇₎(ℤ) acts on the charge lattice of these black holes, generating an infinite family of solutions related by arithmetic transformations. We demonstrate that the Bekenstein-Hawking entropy can be expressed in terms of modular forms and L-functions associated with exceptional Jordan algebras. Our analysis reveals deep connections between black hole microstates and the arithmetic of cubic norm forms over the integers. We establish that certain extremal black holes correspond to rational points on algebraic varieties defined over number fields, with their multiplicities governed by class numbers of quadratic forms. The asymptotic growth of black hole degeneracies follows from analytic properties of associated Dirichlet series, providing a bridge between quantum gravity and analytic number theory. We compute explicit examples where the entropy involves values of Dedekind zeta functions at integer points, suggesting a fundamental role for arithmetic geometry in understanding black hole thermodynamics. These results indicate that the microscopic structure of N=8 black holes encodes rich arithmetic information, opening new avenues for exploring quantum gravity through number-theoretic methods and establishing concrete connections between string theory and arithmetic algebraic geometry."
  },
  {
    "id": 33,
    "prompt": "Magnetic moments of $^{33}$Mg in time-odd relativistic mean field approach",
    "HWT": "The configuration-fixed deformation constrained relativistic mean field approach with time-odd component has been applied to investigate the ground-state properties of $^{33}$Mg with effective interaction PK1. The ground state of $^{33}$Mg has been found to be prolate deformed, $\\beta_2=0.23$, with the odd neutron in $1/2[330]$ orbital and the energy -251.85 MeV which is close to the data -252.06 MeV. The magnetic moment $- 0.9134 \\mu_\\mathrm{N}$ is obtained with the effective electromagnetic current which well reproduces the data $- 0.7456 \\mu_\\mathrm{N}$ self-consistently without introducing any parameter. The energy splittings of time reversal conjugate states, the neutron current, the energy contribution from the nuclear magnetic potential, and the effect of core polarization are discussed in detail.",
    "MGT": "The magnetic moments of the neutron-rich nucleus $^{33}$Mg have been investigated within the framework of the time-odd relativistic mean field (RMF) theory. The calculations employ the NL3 and DD-ME2 parameter sets to describe the nuclear many-body system, incorporating time-odd components in the mean field that arise from the unpaired nucleon's angular momentum coupling. The ground state configuration of $^{33}$Mg is determined through self-consistent RMF calculations, revealing a $2p_{3/2}$ neutron configuration for the unpaired nucleon. The computed magnetic moment shows significant sensitivity to the choice of effective interaction and the treatment of pairing correlations. Our results indicate that the time-odd terms contribute substantially to the magnetic moment, with corrections of approximately 15-20% compared to the Schmidt values. The calculated magnetic moment of $\\mu = -0.742$ nuclear magnetons using NL3 shows reasonable agreement with available experimental data, while DD-ME2 yields $\\mu = -0.688$ nuclear magnetons. These findings demonstrate the importance of relativistic effects and time-odd contributions in accurately describing magnetic properties of exotic nuclei far from stability."
  },
  {
    "id": 34,
    "prompt": "Counting p'-characters in finite reductive groups",
    "HWT": "This article is concerned with the relative McKay conjecture for finite reductive groups. Let G be a connected reductive group defined over the finite field F_q of characteristic p>0 with corresponding Frobenius map F. We prove that if the F-coinvariants of the component group of the center of G has prime order and if p is a good prime for G, then the relative McKay conjecture holds for G at the prime p. In particular, this conjecture is true for G^F in defining characteristic for G a simple and simply-connected group of type B_n, C_n, E_6 and E_7. Our main tools are the theory of Gelfand-Graev characters for connected reductive groups with disconnected center developed by Digne-Lehrer-Michel and the theory of cuspidal Levi subgroups. We also explicitly compute the number of semisimple classes of G^F for any simple algebraic group G.",
    "MGT": "We investigate the enumeration of p'-characters in finite reductive groups, where p' denotes the set of prime numbers distinct from the defining characteristic p. Our main result establishes an explicit formula for counting irreducible characters of p'-degree in classical groups over finite fields. Using techniques from the representation theory of finite groups of Lie type, we develop a systematic approach that relates the character degrees to the structure of maximal tori and Weyl groups. The counting formula involves combinatorial invariants associated with the root system and demonstrates surprising connections to number-theoretic properties of the underlying field. We prove that the number of p'-characters grows polynomially with the rank of the group, with the degree of growth determined by the type of the root system. Our methods extend previous work on character degree patterns and provide new insights into the distribution of character degrees in finite reductive groups. Applications to the McKay conjecture and related problems in modular representation theory are discussed."
  },
  {
    "id": 35,
    "prompt": "Semiclassical dynamics of quasi-one-dimensional, attractive Bose-Einstein condensates",
    "HWT": "The strongly interacting regime for attractive Bose-Einstein condensates (BECs) tightly confined in an extended cylindrical trap is studied. For appropriately prepared, non-collapsing BECs, the ensuing dynamics are found to be governed by the one-dimensional focusing Nonlinear Schr\\\"odinger equation (NLS) in the semiclassical (small dispersion) regime. In spite of the modulational instability of this regime, some mathematically rigorous results on the strong asymptotics of the semiclassical limiting solutions were obtained recently. Using these results, \"implosion-like\" and \"explosion-like\" events are predicted whereby an initial hump focuses into a sharp spike which then expands into rapid oscillations. Seemingly related behavior has been observed in three-dimensional experiments and models, where a BEC with a sufficient number of atoms undergoes collapse. The dynamical regimes studied here, however, are not predicted to undergo collapse. Instead, distinct, ordered structures, appearing after the \"implosion\", yield interesting new observables that may be experimentally accessible.",
    "MGT": "We investigate the semiclassical dynamics of quasi-one-dimensional Bose-Einstein condensates with attractive interparticle interactions using the nonlinear Schrödinger equation framework. Our analysis focuses on the formation and evolution of bright soliton states in elongated harmonic traps, where the transverse confinement effectively reduces the system dimensionality. Through numerical simulations of the Gross-Pitaevskii equation, we examine the stability conditions for solitonic solutions and their response to external perturbations. We find that the interplay between attractive nonlinearity and harmonic confinement leads to a rich dynamical behavior, including breathing oscillations and the emergence of metastable bound states. The semiclassical approximation provides excellent agreement with full quantum calculations for moderate particle numbers, while deviations become apparent in the few-particle regime where quantum fluctuations dominate. We characterize the parameter regimes where collapse instabilities occur and demonstrate that careful tuning of the scattering length can stabilize otherwise unstable configurations. Our results have implications for experimental realizations of attractive condensates in highly anisotropic traps and provide insights into the fundamental limits of semiclassical descriptions in low-dimensional quantum many-body systems."
  },
  {
    "id": 36,
    "prompt": "How to prevent type-flaw attacks on security protocols under algebraic properties",
    "HWT": "Type-flaw attacks upon security protocols wherein agents are led to misinterpret message types have been reported frequently in the literature. Preventing them is crucial for protocol security and verification. Heather et al. proved that tagging every message field with it's type prevents all type-flaw attacks under a free message algebra and perfect encryption system. In this paper, we prove that type-flaw attacks can be prevented with the same technique even under the ACUN algebraic properties of XOR which is commonly used in \"real-world\" protocols such as SSL 3.0. Our proof method is general and can be easily extended to other monoidal operators that possess properties such as Inverse and Idempotence as well. We also discuss how tagging could be used to prevent type-flaw attacks under other properties such as associativity of pairing, commutative encryption, prefix property and homomorphic encryption.",
    "MGT": "Type-flaw attacks exploit weaknesses in security protocol implementations where messages intended for one protocol step are maliciously redirected to another step, often bypassing authentication mechanisms. This paper addresses the prevention of such attacks in cryptographic protocols that operate under algebraic properties, where mathematical structures like groups, rings, or fields govern cryptographic operations. We propose a comprehensive framework for detecting and mitigating type-flaw vulnerabilities by introducing explicit type annotations and algebraic invariant checking during protocol verification. Our approach combines formal methods with algebraic reasoning to ensure message integrity across protocol steps. We demonstrate the effectiveness of our method through case studies on key exchange protocols and authentication schemes that utilize elliptic curve cryptography and modular arithmetic. The framework successfully identifies previously unknown type-flaw vulnerabilities in existing protocols while maintaining computational efficiency. Our results show that incorporating algebraic properties into type-flaw analysis significantly enhances protocol security without compromising performance, providing a practical solution for protocol designers seeking to prevent these subtle but dangerous attacks."
  },
  {
    "id": 37,
    "prompt": "A dynamical classification of the range of pair interactions",
    "HWT": "We formalize a classification of pair interactions based on the convergence properties of the {\\it forces} acting on particles as a function of system size. We do so by considering the behavior of the probability distribution function (PDF) P(F) of the force field F in a particle distribution in the limit that the size of the system is taken to infinity at constant particle density, i.e., in the \"usual\" thermodynamic limit. For a pair interaction potential V(r) with V(r) \\rightarrow \\infty) \\sim 1/r^a defining a {\\it bounded} pair force, we show that P(F) converges continuously to a well-defined and rapidly decreasing PDF if and only if the {\\it pair force} is absolutely integrable, i.e., for a > d-1, where d is the spatial dimension. We refer to this case as {\\it dynamically short-range}, because the dominant contribution to the force on a typical particle in this limit arises from particles in a finite neighborhood around it. For the {\\it dynamically long-range} case, i.e., a \\leq d-1, on the other hand, the dominant contribution to the force comes from the mean field due to the bulk, which becomes undefined in this limit. We discuss also how, for a \\leq d-1 (and notably, for the case of gravity, a=d-2) P(F) may, in some cases, be defined in a weaker sense. This involves a regularization of the force summation which is generalization of the procedure employed to define gravitational forces in an infinite static homogeneous universe. We explain that the relevant classification in this context is, however, that which divides pair forces with a > d-2 (or a < d-2), for which the PDF of the {\\it difference in forces} is defined (or not defined) in the infinite system limit, without any regularization. In the former case dynamics can, as for the (marginal) case of gravity, be defined consistently in an infinite uniform system.",
    "MGT": "In this comprehensive study, we present a novel theoretical framework for classifying the range of pair interactions in dynamical systems, addressing a fundamental gap in our understanding of particle behavior across different spatial and temporal scales. Our research establishes a rigorous mathematical foundation for categorizing interaction ranges based on their decay properties and characteristic length scales. Through careful analysis of both short-range and long-range interactions, we develop a unified classification scheme that encompasses everything from near-field effects to far-field asymptotic behaviors. The framework introduces a dimensionless parameter η that characterizes the effective range of interaction relative to the system size, allowing for systematic comparison across different physical systems. We demonstrate that interaction potentials can be classified into distinct universality classes, each exhibiting unique scaling properties and dynamical behaviors. Our analysis reveals three primary categories: ultra-short-range interactions (η < 1), intermediate-range interactions (1 ≤ η ≤ 2), and long-range interactions (η > 2), with several important subcategories within each class. Using numerical simulations and analytical methods, we validate this classification scheme across a wide range of physical systems, including molecular dynamics, colloidal suspensions, and gravitational systems. The results show remarkable universality in the dynamical behavior within each class, despite differences in the underlying physical mechanisms. Furthermore, we identify critical transition points between different ranges, characterized by distinct signatures in the system's collective behavior and correlation functions. This classification framework provides new insights into phase transitions, pattern formation, and collective phenomena in many-body systems. Our findings have significant implications for fields ranging from condensed matter physics to astrophysics, offering a powerful tool for predicting system behavior based on the fundamental properties of pair interactions. The work concludes by suggesting potential applications in the design of materials with tailored interaction ranges and the development of more efficient numerical simulation techniques for many-body systems."
  },
  {
    "id": 38,
    "prompt": "Heavy water around the L1448-mm protostar",
    "HWT": "Context: L1448-mm is the prototype of a low-mass Class 0 protostar driving a high-velocity jet. Given its bright H2O spectra observed with ISO, L1448-mm is an ideal laboratory to observe heavy water (HDO) emission. Aims: Our aim is to image the HDO emission in the protostar surroundings, the possible occurrence of HDO emission also investigating off L1448-mm, towards the molecular outflow. Methods: We carried out observations of L1448-mm in the HDO(1_10-1_11) line at 80.6 GHz, an excellent tracer of HDO column density, with the IRAM Plateau de Bure Interferometer. Results: We image for the first time HDO emission around L1448-mm. The HDO structure reveals a main clump at velocities close to the ambient one towards the the continuum peak that is caused by the dust heated by the protostar. In addition, the HDO map shows tentative weaker emission at about 2000 AU from the protostar towards the south, which is possibly associated with the walls of the outflow cavity opened by the protostellar wind. Conclusions: Using an LVG code, modelling the density and temperature profile of the hot-corino, and adopting a gas temperature of 100 K and a density of 1.5 10^8 cm^-3, we derive a beam diluted HDO column density of about 7 10^13 cm^-2, corresponding to a HDO abundance of about 4 10^-7. In addition, the present map supports the scenario where HDO can be efficiently produced in shocked regions and not uniquely in hot corinos heated by the newly born star.",
    "MGT": "We present high-resolution observations of deuterated water (HDO and D2O) emission around the Class 0 protostar L1448-mm using the Atacama Large Millimeter/submillimeter Array (ALMA). Our observations reveal compact emission of HDO (J=3₂,₁-4₁,₃) and D2O (J=1₁,₁-0₀,₀) lines within the inner 100 AU of the protostellar envelope. The spatial distribution of the deuterated water species shows a clear enhancement toward the central protostar, suggesting active water chemistry in the warm inner regions. Analysis of the line profiles indicates velocities consistent with both infall and rotation, providing evidence for a rotating disk-like structure. We derive HDO/H2O and D2O/HDO abundance ratios of (2.1 ± 0.3) × 10⁻³ and (1.7 ± 0.4) × 10⁻², respectively, which are significantly higher than the local interstellar D/H ratio. These elevated deuteration fractions suggest that the observed water molecules were primarily formed during the cold prestellar phase and have been preserved through the collapse process. Temperature estimates derived from the line intensity ratios indicate values of 100-150 K in the emitting region, consistent with theoretical predictions for water sublimation from dust grains. Our results provide important constraints on the chemical evolution of water during the earliest stages of star formation and offer insights into the mechanism by which water is transported from prestellar cores to protoplanetary disks. These findings have significant implications for understanding the origin of water in forming planetary systems and ultimately the delivery of water to terrestrial planets."
  },
  {
    "id": 39,
    "prompt": "Towards truly simultaneous PIXE and RBS analysis of layered objects in cultural heritage",
    "HWT": "For a long time, RBS and PIXE techniques have been used in the field of cultural heritage. Although the complementarity of both techniques has long been acknowledged, its full potential has not been yet developed due to the lack of general purpose software tools for analysing the data from both techniques in a coherent way. In this work we provide an example of how the recent addition of PIXE to the set of techniques supported by the DataFurnace code can significantly change this situation. We present a case in which a non homogeneous sample (an oxidized metal from a photographic plate -heliography- made by Niepce in 1827) is analysed using RBS and PIXE in a straightforward and powerful way that can only be performed with a code that treats both techniques simultaneously as a part of one single and coherent analysis. The optimization capabilities of DataFurnace, allowed us to obtain the composition profiles for these samples in a very simple way.",
    "MGT": "This study presents a novel approach for simultaneous Particle-Induced X-ray Emission (PIXE) and Rutherford Backscattering Spectrometry (RBS) analysis of stratified cultural heritage materials. Traditional sequential analysis methods suffer from beam damage accumulation and spatial registration challenges when examining delicate archaeological and artistic objects. Our methodology employs a dual-detector configuration with optimized beam parameters to enable truly concurrent data acquisition from identical sample volumes. The experimental setup utilizes a 2.5 MeV proton beam with specialized collimation systems and synchronized detection electronics. Validation studies on reference materials and authentic samples including medieval manuscript illuminations and ancient ceramic glazes demonstrate significantly improved analytical precision while reducing total analysis time by 60%. Depth profiling capabilities allow characterization of layered structures with sub-micrometer resolution, revealing previously undetectable interfacial compositions. The technique successfully identified trace elements in paint binders and ceramic matrices while simultaneously determining layer thicknesses and elemental depth distributions. This advancement addresses critical limitations in non-destructive analysis of irreplaceable cultural artifacts, offering enhanced sensitivity for provenance studies and conservation decision-making. The methodology's applicability extends to various heritage materials including metals, ceramics, paintings, and manuscripts."
  },
  {
    "id": 40,
    "prompt": "Dynamics of the entanglement between two oscillators in the same environment",
    "HWT": "We provide a complete characterization of the evolution of entanglement between two oscillators coupled to a common environment. For initial Gaussian states we identify three phases with different qualitative long time behavior: There is a phase where entanglement undergoes a sudden death (SD). Another phase (SDR) is characterized by an infinite sequence of events of sudden death and revival of entanglement. In the third phase (NSD) there is no sudden death of entanglement, which persist for long time. The phase diagram is described and analytic expressions for the boundary between phases are obtained. Numerical simulations show the accuracy of the analytic expressions. These results are applicable to a large variety of non--Markovian environments. The case of non--resonant oscillators is also numerically investigated.",
    "MGT": "We investigate the temporal evolution of quantum entanglement between two identical harmonic oscillators coupled to a common bosonic environment at zero temperature. Using the input-output formalism and master equation approach, we analyze how environmental coupling strength and oscillator separation affect entanglement dynamics. Our results demonstrate that initially separable oscillators can develop significant entanglement through their shared environment, with maximum entanglement achieved at intermediate coupling strengths. The entanglement exhibits oscillatory behavior with a characteristic frequency determined by the system-environment interaction parameters. For strong coupling regimes, we observe entanglement sudden death followed by revival phenomena. The common environment acts as an entangling mediator, creating correlations that persist even when direct oscillator interactions are absent. These findings have implications for quantum information processing in open systems and provide insights into environment-induced quantum correlations in coupled oscillator networks. Our theoretical predictions are validated through numerical simulations across various parameter regimes."
  },
  {
    "id": 41,
    "prompt": "Lie's Reduction Method and Differential Galois Theory in the Complex Analytic Context",
    "HWT": "This paper is dedicated to the differential Galois theory in the complex analytic context for Lie-Vessiot systems. Those are the natural generaliza- tion of linear systems, and the more general class of differential equations adimitting superposition laws, as recently stated in [5]. A Lie-Vessiot sys- tem is automatically translated into a equation in a Lie group that we call automorphic system. Reciprocally an automorphic system induces a hierarchy of Lie-Vessiot systems. In this work we study the global analytic aspects of a classical method of reduction of differential equations, due to S. Lie. We propose an differential Galois theory for automorphic systems, and explore the relationship between integrability in terms of Galois the- ory and the Lie's reduction method. Finally we explore the algebra of Lie symmetries of a general automorphic system.",
    "MGT": "We investigate the interplay between Lie's reduction method and differential Galois theory for linear differential equations in the complex analytic setting. By extending classical reduction techniques to meromorphic coefficient systems, we establish new connections between the solvability structure of differential equations and their associated Galois groups. Our main result demonstrates that Lie's reduction preserves essential properties of the differential Galois group while potentially simplifying the monodromy representation. We prove that for a reducible linear system, the differential Galois group of the reduced system is isomorphic to a quotient of the original Galois group, with the kernel determined by the reduction's invariant subspace structure. Furthermore, we show that certain classes of equations admitting Lie reductions possess Picard-Vessiot extensions with finite-dimensional solution spaces over smaller coefficient fields. These findings provide new computational approaches for analyzing the solvability of complex analytic differential systems and offer insights into the geometric structure of their solution manifolds. Applications to special functions and integrable systems are discussed."
  },
  {
    "id": 42,
    "prompt": "Generating technique for $U(1)^3 5D$ supergravity",
    "HWT": "We develop generating technique for solutions of $U(1)^3 5D$ supergravity via dimensional reduction to three dimensions. This theory, which recently attracted attention in connection with black rings, can be viewed as consistent truncation of the $T^6$ compactification of the eleven-dimensional supergravity. Its further reduction to three dimensions accompanied by dualisation of the vector fields leads to 3D gravity coupled sigma model on the homogeneous space $SO(4,4)/SO(4)\\times SO(4)$ or $SO(4,4)/SO(2,2)\\times SO(2,2)$ depending on the signature of the three-space. We construct a $8\\times 8$ matrix representation of these cosets in terms of lower-dimensional blocks. Using it we express solution generating transformations in terms of the potentials and identify those preserving asymptotic conditions relevant to black holes and black rings. As an application, we derive the doubly rotating black hole solution with three independent charges. A suitable contraction of the above cosets is used to construct a new representation of the coset $G_{2(2)}/(SL(2, R)\\times SL(2, R))$ relevant for minimal five-dimensional supergravity.",
    "MGT": "# Generating technique for $U(1)^3 5D$ supergravity\n\nThis paper presents a novel generating technique for constructing exact solutions to five-dimensional supergravity with three $U(1)$ gauge fields. By extending the solution-generating methods previously developed for minimal supergravity, we demonstrate how to systematically derive new charged rotating black hole solutions in $U(1)^3$ theory from known seed solutions. Our approach exploits the $SO(4,4)$ hidden symmetry structure of the dimensionally reduced theory, allowing for the application of specific $SO(4,4)$ transformations that preserve the asymptotic flatness while introducing or modifying electromagnetic charges. We explicitly construct the transformation matrix and provide the precise mapping between the seed and target solution parameters. As a demonstration of the technique's utility, we generate a family of non-extremal black hole solutions characterized by mass, two independent angular momenta, and three independent electric charges. These solutions include, as special cases, several previously known configurations, including the BMPV black hole and its non-extremal extensions. We analyze the physical properties of these solutions, including their horizon structure, thermodynamics, and BPS limits. This generating technique significantly simplifies the discovery of new solutions in $U(1)^3$ supergravity and provides valuable insights into the solution space of higher-dimensional charged rotating black holes relevant to string theory."
  },
  {
    "id": 43,
    "prompt": "Detailed Spectral Analysis of the Type Ib Supernova 1999dn. Paper I: Hydrogen-free Models",
    "HWT": "We present spectral fits to five epochs of the typical Type Ib supernova 1999dn using the generalized, non-LTE, stellar atmospheres code PHOENIX. Our goal is threefold: to determine basic physical properties of the supernova ejecta, such as velocity, temperature, and density gradients; to reproduce He I absorption lines by invoking non-thermal excitation; and, to investigate possible spectral signatures of hydrogen, especially a feature around 6200 Angstrom, which has been attributed to high velocity $H_\\alpha$. Our models assume an atmosphere with uniform composition devoid of any hydrogen. Our model spectra fit the observed spectra well, successfully reproducing most of the features, including the prominent He I absorptions. The most plausible alternative to $H_\\alpha$ as the source of the 6200 Angstrom feature is a blend of Fe II and Si II lines, which can be made stronger to fit the observed feature better by increasing the metallicity of the ejecta. High-metallicity models fit well at early epochs, but not as well as solar-metallicity models after maximum light. While this blend of metal lines is a reasonable explanation of the source of the 6200 Angstrom feature, it is still important to investigate hydrogen as the source; therefore, a second paper will present models that include a thin shell of hydrogen around the main composition structure.",
    "MGT": "We present a comprehensive spectral analysis of the Type Ib supernova SN 1999dn from 7 to 376 days after maximum light, utilizing observations obtained with multiple ground-based telescopes. This work represents the first paper in a series examining the detailed spectroscopic evolution of this well-observed stripped-envelope supernova. Our analysis employs hydrogen-free synthetic spectra generated using the SYNOW spectral synthesis code, systematically investigating the ionization states and velocity structures of the ejecta throughout the photospheric and early nebular phases. We identify spectral lines of helium, oxygen, magnesium, silicon, sulfur, calcium, and iron group elements, with particular attention to the evolution of He I absorption features that characterize Type Ib supernovae. The photospheric velocity, derived from Fe II λ5169 absorption, decreases from approximately 12,000 km/s at day 7 to 6,000 km/s by day 40, consistent with homologous expansion. Oxygen lines become increasingly prominent in the nebular phase, with [O I] λλ6300,6364 emerging as the dominant feature by day 376. The helium abundance derived from spectral modeling suggests a helium shell mass of 0.8-1.2 solar masses, typical for Type Ib supernovae originating from Wolf-Rayet progenitors. Temperature evolution indicates rapid cooling from 8,000 K to 4,500 K during the first month post-maximum. These hydrogen-free models successfully reproduce the observed spectral evolution, providing constraints on the explosion energetics, ejecta mass, and progenitor characteristics. Subsequent papers will explore hydrogen-bearing models and detailed abundance determinations through more sophisticated radiative transfer calculations."
  },
  {
    "id": 44,
    "prompt": "Evidence for Evolution Among Primordial Disks in the 5 Myr Old Upper Scorpius OB Association",
    "HWT": "Moderate-resolution, near-infrared spectra between 0.8 and 5.2 microns were obtained for 12 late-type (K0-M3) disk-bearing members of the ~5 Myr old Upper Scorpius OB association using SpeX on the NASA Infrared Telescope Facility. For most sources, continuum excess emission first becomes apparent between ~2.2 and 4.5 microns and is consistent with that produced by single-temperature blackbodies having characteristic temperatures ranging from ~500 to 1300 K. The near-infrared spectra for 5 of 12 Upper Scorpius sources exhibit Pa-gamma, Pa-beta and Br-gamma emission, indicators of disk accretion. Using a correlation between Pa-beta and Br-gamma emission line luminosity and accretion luminosity, mass accretion rates (Mdot) are derived for these sources that range from Mdot = 3.5 X 10^{-10} to 1.5 X 10^{-8} MSun per yr. Merging the SpeX observations with Spitzer Space Telescope mid-infrared (5.4-37.0 micron) spectroscopy and 24 and 70 micron broadband photometry, the observed spectral energy distributions are compared with those predicted by two-dimensional, radiative transfer accretion disk models. Of the 9 Upper Scorpius sources examined in this analysis, 3 exhibit spectral energy distributions that are most consistent with models having inner disk radii that substantially exceed their respective dust sublimation radii. The remaining Upper Scorpius members possess spectral energy distributions that either show significant dispersion among predicted inner disk radii or are best described by models having inner disk rims coincident with the dust sublimation radius.",
    "MGT": "# Evidence for Evolution Among Primordial Disks in the 5 Myr Old Upper Scorpius OB Association\n\nWe present a comprehensive study of primordial disks in the Upper Scorpius OB Association, the nearest region with substantial star formation activity at an age (~5 Myr) when most primordial disks have already dissipated. Using multi-wavelength photometry from Spitzer, WISE, and ground-based observatories, we analyzed the spectral energy distributions of 484 members to characterize their disk properties. Our results reveal a disk fraction of 16±2% for K/M-type stars, significantly lower than the ~80% observed in 1 Myr old regions, providing strong evidence for substantial disk evolution. Notably, we find a marked deficit of primordial disks with strong near-infrared excesses compared to younger regions, indicating significant clearing of the inner disk regions. The distribution of infrared spectral slopes suggests a continuous range of evolutionary states rather than distinct disk categories, with many systems showing signs of inside-out clearing consistent with disk photoevaporation models. We also observe a statistically significant correlation between disk properties and stellar mass, with higher-mass stars exhibiting more advanced disk evolution. Comparison with the younger Taurus region reveals that Upper Scorpius disks have, on average, weaker infrared excesses at all wavelengths, suggesting both dust settling and global disk depletion processes are active. Our findings provide important constraints on disk evolution timescales, indicating that the transition from primordial to debris disk systems occurs primarily between 3-10 Myr, with significant inner disk clearing preceding complete disk dissipation. These results have important implications for understanding the timescales available for planet formation in circumstellar disks."
  },
  {
    "id": 45,
    "prompt": "VLT and GTC observations of SDSS J0123+00: a type 2 quasar triggered in a galaxy encounter?",
    "HWT": "We present long-slit spectroscopy, continuum and [OIII]5007 imaging data obtained with the Very Large Telescope and the Gran Telescopio Canarias of the type 2 quasar SDSS J0123+00 at z=0.399. The quasar lies in a complex, gas-rich environment. It appears to be physically connected by a tidal bridge to another galaxy at a projected distance of ~100 kpc, which suggests this is an interacting system. Ionized gas is detected to a distance of at least ~133 kpc from the nucleus. The nebula has a total extension of ~180 kpc. This is one of the largest ionized nebulae ever detected associated with an active galaxy. Based on the environmental properties, we propose that the origin of the nebula is tidal debris from a galactic encounter, which could as well be the triggering mechanism of the nuclear activity. SDSS J0123+00 demonstrates that giant, luminous ionized nebulae can exist associated with type 2 quasars of low radio luminosities, contrary to expectations based on type 1 quasar studies.",
    "MGT": "We present new spectroscopic observations of SDSS J0123+00 obtained with the Very Large Telescope (VLT) and Gran Telescopio Canarias (GTC) to investigate the nature of this luminous type 2 quasar at z=0.399. Our high-resolution imaging reveals clear morphological disturbances consistent with a recent galaxy merger or close encounter, including tidal tails and asymmetric stellar distributions extending ~15 kpc from the nucleus. Long-slit spectroscopy shows prominent [OIII]λ5007 emission with complex kinematics, exhibiting velocity dispersions of σ~450 km/s and blue-shifted components indicative of outflowing gas. The narrow-line region extends over ~8 kpc, suggesting significant AGN photoionization. We measure a bolometric luminosity of L_bol~10^45.2 erg/s based on [OIII] luminosity scaling relations. Stellar population synthesis modeling indicates recent star formation activity within the past 100 Myr, coincident with the estimated merger timescale derived from morphological analysis. The spatial correlation between enhanced star formation regions and the extended emission-line gas suggests a causal relationship between the galaxy interaction and nuclear activity. Our results support theoretical models predicting that major mergers can simultaneously trigger both starburst activity and AGN fueling through gravitational torques that drive gas inflows to the galactic center, making SDSS J0123+00 an excellent laboratory for studying merger-induced quasar activation."
  },
  {
    "id": 46,
    "prompt": "Reasoning in Abella about Structural Operational Semantics Specifications",
    "HWT": "The approach to reasoning about structural operational semantics style specifications supported by the Abella system is discussed. This approach uses lambda tree syntax to treat object language binding and encodes binding related properties in generic judgments. Further, object language specifications are embedded directly into the reasoning framework through recursive definitions. The treatment of binding via generic judgments implicitly enforces distinctness and atomicity in the names used for bound variables. These properties must, however, be made explicit in reasoning tasks. This objective can be achieved by allowing recursive definitions to also specify generic properties of atomic predicates. The utility of these various logical features in the Abella system is demonstrated through actual reasoning tasks. Brief comparisons with a few other logic based approaches are also made.",
    "MGT": "We present a comprehensive study of formal reasoning techniques for structural operational semantics (SOS) specifications using the Abella theorem prover. Our approach leverages Abella's two-level logic system, which distinguishes between reasoning logic and specification logic, to enable natural and rigorous proofs about operational semantics. We demonstrate how Abella's nominal abstraction capabilities handle variable binding constructs effectively, avoiding common pitfalls associated with variable capture and substitution. Through detailed case studies involving lambda calculus variants and imperative language constructs, we show how meta-theoretic properties such as type preservation, progress, and confluence can be established systematically. Our methodology exploits Abella's inductive definitions and co-inductive reasoning to handle both finite and infinite computational traces. The results indicate that Abella provides an exceptionally well-suited environment for mechanized meta-theory of programming languages, offering both expressiveness and proof automation while maintaining mathematical rigor. This work contributes to the broader effort of mechanizing programming language theory and validates Abella's effectiveness for SOS reasoning."
  },
  {
    "id": 47,
    "prompt": "Post-launch performance of the Fermi Large Area Telescope",
    "HWT": "The Large Area Telescope (LAT) on-board the Fermi Gamma-ray Space Telescope started nominal operations on August 13, 2008, after about 60 days of instrument checkout and commissioning and is currently performing an all-sky gamma-ray survey from 30 MeV to above 300 GeV with unprecedented sensitivity and angular resolution. The LAT pre-launch response was tuned using Monte Carlo simulations and test beam data from a campaign necessarily limited in scope. This suggested a conservative approach in dealing with systematics that affect the reconstruction analysis of the first months of data taking. The first major update of the instrument performance based on flight data is now being completed. Not only are the LAT calibrations now based on flight data, but also the ground event reconstruction has been updated to accommodate on-orbit calibrations, and response was carefully verified using real data from celestial sources. In this contribution we describe the current best knowledge of the instrument, and our plans towards releasing public response functions to support data release in year 2.",
    "MGT": "The Fermi Large Area Telescope (LAT), launched in June 2008, has demonstrated exceptional performance capabilities that have revolutionized gamma-ray astronomy. Operating in the energy range from 20 MeV to over 300 GeV, the LAT has exceeded its design specifications across multiple performance metrics. The instrument's point spread function achieves better than 0.15° at 10 GeV, while maintaining an effective area exceeding 8000 cm² above 1 GeV. Dead time remains below 10% even during high-flux observations, ensuring efficient data collection. The LAT's all-sky scanning mode provides uniform exposure across the entire celestial sphere every three hours, enabling comprehensive monitoring of transient phenomena and systematic surveys of gamma-ray sources. Over its operational lifetime, the detector has maintained stable calibration with energy resolution better than 10% above 100 MeV. Background rejection capabilities have proven robust, with cosmic-ray suppression factors exceeding 10⁶. The telescope has detected over 5000 gamma-ray sources, including pulsars, blazars, and diffuse emission components. Long-term stability analyses confirm minimal degradation in detector performance, with all subsystems operating within nominal parameters. These achievements have established the Fermi LAT as the premier space-based gamma-ray observatory, providing unprecedented insights into high-energy astrophysical processes."
  },
  {
    "id": 48,
    "prompt": "The GASP-WEBT monitoring of 3C 454.3 during the 2008 optical-to-radio and gamma-ray outburst",
    "HWT": "Since 2001, the radio quasar 3C 454.3 has undergone a period of high optical activity, culminating in the brightest optical state ever observed, during the 2004-2005 outburst. The Whole Earth Blazar Telescope (WEBT) consortium has carried out several multifrequency campaigns to follow the source behaviour. The GLAST-AGILE Support Program (GASP) was born from the WEBT to provide long-term continuous optical-to-radio monitoring of a sample of gamma-loud blazars, during the operation of the AGILE and GLAST (now known as Fermi GST) gamma-ray satellites. The main aim is to shed light on the mechanisms producing the high-energy radiation, through correlation analysis with the low-energy emission. Thus, since 2008 the monitoring task on 3C 454.3 passed from the WEBT to the GASP, while both AGILE and Fermi detected strong gamma-ray emission from the source. We present the main results obtained by the GASP at optical, mm, and radio frequencies in the 2008-2009 season, and compare them with the WEBT results from previous years. An optical outburst was observed to peak in mid July 2008, when Fermi detected the brightest gamma-ray levels. A contemporaneous mm outburst maintained its brightness for a longer time, until the cm emission also reached the maximum levels. The behaviour compared in the three bands suggests that the variable relative brightness of the different-frequency outbursts may be due to the changing orientation of a curved inhomogeneous jet. The optical light curve is very well sampled during the entire season, which is also well covered by the various AGILE and Fermi observing periods. The relevant cross-correlation studies will be very important in constraining high-energy emission models.",
    "MGT": "We report on the multi-wavelength monitoring campaign of the flat-spectrum radio quasar 3C 454.3 conducted by the Whole Earth Blazar Telescope (WEBT) collaboration in conjunction with the Gamma-Ray Large Area Space Telescope (GLAST) Agile Science Program (GASP) during the extraordinary 2008 outburst. This blazar exhibited unprecedented activity across the electromagnetic spectrum, with optical brightness reaching V ≈ 12.0 mag, representing an increase of more than 5 magnitudes from its quiescent state. The coordinated observations spanned from radio to gamma-ray frequencies, providing comprehensive coverage of the source's spectral energy distribution during this exceptional flaring episode.\n\nThe optical light curves reveal a complex temporal structure with multiple sub-flares superimposed on the main outburst, suggesting a turbulent acceleration region within the relativistic jet. Polarimetric observations indicate significant variations in both the degree and angle of polarization, with peak polarization reaching approximately 20% during the brightest phases. The polarization angle rotations of up to 180° support models involving helical magnetic field structures or shock propagation through a curved jet geometry.\n\nRadio observations at multiple frequencies demonstrate spectral evolution consistent with synchrotron self-absorption in an expanding, relativistic shock. The radio flux density increased by factors of 3-5 across all observed frequencies, with peak emission occurring several weeks after the optical maximum, indicating standard synchrotron cooling processes.\n\nGamma-ray data from AGILE reveal correlated variability with the optical emission, suggesting co-spatial production regions for both components. The gamma-ray spectral analysis indicates inverse Compton scattering of synchrotron photons as the dominant emission mechanism, with external photon fields playing a secondary role.\n\nThese results provide crucial constraints on blazar emission models and demonstrate the importance of coordinated multi-wavelength campaigns for understanding the physical processes governing relativistic jet phenomena in active galactic nuclei."
  },
  {
    "id": 49,
    "prompt": "Right sneutrinos and the signals of a stable stop at the Large Hadron Collider",
    "HWT": "We investigate charged tracks signals of a supersymmetric scenario, where the lighter stop is the next-to-lightest supersymmetric particle (NLSP). It is found that such an NLSP is stable on the scale of the detector at the LHC if one has a right-chiral sneutrino as the lightest supersymmetric particle (LSP). After identifying some benchmark points in the parameter space of a supergravity scenario with non-universal scalar masses, we study a few specific classes of signals, namely, stop pair production and gluino pair production followed by each decaying into a stop and a top. It is shown that proper kinematic cuts remove the backgrounds in each case, and, while a few months' worth of data is sufficient to have copious events in the first case, one may require 300 $fb^{-1}$ for the other. One can also aspire to reconstruct the gluino mass, using the `visible' stable NLSP tracks.",
    "MGT": "I need to write an academic abstract for a particle physics paper about \"Right sneutrinos and the signals of a stable stop at the Large Hadron Collider\". This is clearly a theoretical particle physics paper dealing with supersymmetry (SUSY) phenomenology at the LHC.\n\nLet me break down the key concepts:\n- Right sneutrinos: These are supersymmetric partners of right-handed neutrinos\n- Stable stop: The stop is the supersymmetric partner of the top quark. If it's stable, it would be the lightest supersymmetric particle (LSP)\n- Large Hadron Collider (LHC): The particle accelerator where these signals would be observed\n\nThe abstract should cover:\n1. The theoretical framework/model being studied\n2. The specific scenario (stable stop, role of right sneutrinos)\n3. The phenomenological implications at the LHC\n4. Key findings or predictions\n5. Experimental signatures or detection strategies\n\nI need to write this in the style of a typical particle physics abstract, which tends to be technical and concise. The word count should be around 171 words.\n\nLet me draft this:\n\nWe investigate the phenomenology of supersymmetric models incorporating right-handed sneutrinos in scenarios where the lighter stop squark is the lightest supersymmetric particle and therefore stable. In such models, the right sneutrino can serve as the next-to-lightest supersymmetric particle, leading to distinctive cascade decay chains that significantly alter the experimental signatures at the Large Hadron Collider. We analyze the production and decay patterns of supersymmetric particles, focusing on the role of right sneutrinos in mediating decays to the stable stop. The presence of right sneutrinos modifies the missing energy spectrum and introduces additional leptons in the final state through their decays to Standard Model neutrinos and the stable stop. We perform a detailed analysis of the kinematic distributions and propose optimized search strategies for these scenarios. Our results demonstrate that the interplay between right sneutrinos and stable stops produces unique signatures that can be distinguished from conventional supersymmetric models and Standard Model backgrounds. We investigate the phenomenology of supersymmetric models incorporating right-handed sneutrinos in scenarios where the lighter stop squark is the lightest supersymmetric particle and therefore stable. In such models, the right sneutrino can serve as the next-to-lightest supersymmetric particle, leading to distinctive cascade decay chains that significantly alter experimental signatures at the Large Hadron Collider. We analyze the production and decay patterns of supersymmetric particles, focusing on the role of right sneutrinos in mediating decays to the stable stop. The presence of right sneutrinos modifies the missing energy spectrum and introduces additional leptons in final states through their decays to Standard Model neutrinos and the stable stop. We perform detailed analysis of kinematic distributions and propose optimized search strategies for these scenarios. Our results demonstrate that the interplay between right sneutrinos and stable stops produces unique signatures that can be distinguished from conventional supersymmetric models and Standard Model backgrounds. These findings provide important guidance for experimental searches and help establish discovery potential for such supersymmetric scenarios at current and future LHC runs."
  },
  {
    "id": 50,
    "prompt": "The Dynamics of Dense Cores in the Perseus Molecular Cloud II: The Relationship Between Dense Cores and the Cloud",
    "HWT": "We utilize the extensive datasets available for the Perseus molecular cloud to analyze the relationship between the kinematics of small-scale dense cores and the larger structures in which they are embedded. The kinematic measures presented here can be used in conjunction with those discussed in our previous work as strong observational constraints that numerical simulations (or analytic models) of star formation should match. We find that dense cores have small motions with respect to the 13CO gas, about one third of the 13CO velocity dispersion along the same line of sight. Within each extinction region, the core-to-core velocity dispersion is about half of the total (13CO) velocity dispersion seen in the region. Large-scale velocity gradients account for roughly half of the total velocity dispersion in each region, similar to what is predicted from large-scale turbulent modes following a power spectrum of P(k) ~ k^{-4}.",
    "MGT": "We present a comprehensive analysis of the spatial and kinematic relationships between dense cores and the large-scale structure of the Perseus molecular cloud using data from the James Clerk Maxwell Telescope SCUBA-2 continuum survey and molecular line observations. Our sample includes 452 starless cores identified across the cloud's three main regions: NGC 1333, IC 348, and B1. We examine correlations between core properties and their local environment, including column density, velocity dispersion, and proximity to stellar feedback. Dense cores show preferential alignment with filamentary structures, with 78% located within 0.1 pc of identified filaments. Core mass functions exhibit regional variations, with NGC 1333 producing more massive cores than IC 348 or B1. Kinematic analysis reveals that cores inherit approximately 60% of their velocity dispersion from the ambient cloud material, suggesting strong coupling between small-scale core dynamics and large-scale turbulent motions. Cores in high column density regions display enhanced stability against gravitational collapse, indicating that environmental pressure provides additional support. These findings demonstrate that dense core formation and evolution are intimately connected to the thermodynamic and kinematic properties of their parent molecular cloud, with implications for understanding the initial conditions of star formation."
  },
  {
    "id": 51,
    "prompt": "Towards a Maximal Mass Model",
    "HWT": "We investigate the possibility to construct a generalization of the Standard Model, which we call the Maximal Mass Model because it contains a limiting mass $M$ for its fundamental constituents. The parameter $M$ is considered as a new universal physical constant of Nature and therefore is called the fundamental mass. It is introduced in a purely geometrical way, like the velocity of light as a maximal velocity in the special relativity. If one chooses the Euclidean formulation of quantum field theory, the adequate realization of the limiting mass hypothesis is reduced to the choice of the de Sitter geometry as the geometry of the 4-momentum space. All fields, defined in de Sitter p-space in configurational space obey five dimensional Klein-Gordon type equation with fundamental mass $M$ as a mass parameter. The role of dynamical field variables is played by the Cauchy initial conditions given at $x_5 = 0$, guarantying the locality and gauge invariance principles. The corresponding to the geometrical requirements formulation of the theory of scalar, vector and spinor fields is considered in some detail. On a simple example it is demonstrated that the spontaneously symmetry breaking mechanism leads to renormalization of the fundamental mass $M$. A new geometrical concept of the chirality of the fermion fields is introduced. It would be responsible for new measurable effects at high energies $E \\geq M$. Interaction terms of a new type, due to the existence of the Higgs boson are revealed. The most intriguing prediction of the new approach is the possible existence of exotic fermions with no analogues in the SM, which may be candidate for dark matter constituents.",
    "MGT": "The user wants me to write an academic article abstract for a paper titled \"Towards a Maximal Mass Model\". The abstract should be about 301 words and should not include any headers, comments, or explanations - just the abstract text itself.\n\nGiven the title \"Towards a Maximal Mass Model\", this could be about several different academic fields:\n1. Physics/Cosmology - relating to maximum mass limits in stellar evolution, black holes, or particle physics\n2. Theoretical physics - maximum mass in field theories or gravitational systems\n3. Astrophysics - maximum mass of neutron stars, white dwarfs, or other compact objects\n4. Materials science - maximum mass loading in composite materials\n5. Engineering - maximum mass capacity models\n\nThe most likely interpretation seems to be in physics/astrophysics, possibly related to neutron stars, black holes, or some other massive astronomical objects. I'll write an abstract that focuses on theoretical physics/astrophysics, specifically around the concept of maximum mass limits in compact objects or gravitational systems.\n\nI need to structure this as a proper academic abstract with:\n- Background/motivation\n- Methods/approach\n- Key findings/results\n- Implications/conclusions\n\nLet me aim for exactly around 301 words.We present a comprehensive theoretical framework for determining absolute mass limits in gravitationally bound compact objects, addressing fundamental questions about the maximum achievable mass densities in the universe. Current models of neutron stars, quark stars, and exotic matter configurations suggest the existence of upper mass bounds, yet these limits remain poorly constrained due to uncertainties in the equation of state at supranuclear densities and the role of quantum chromodynamics in extreme environments.\n\nOur approach combines general relativistic hydrodynamics with advanced many-body quantum field theory to construct a maximal mass model that incorporates both known physics and plausible extensions beyond the Standard Model. We employ a systematic perturbative expansion around the Tolman-Oppenheimer-Volkoff limit, incorporating corrections from strange quark matter, kaon condensation, and hypothetical axion fields. The model accounts for rotation, magnetic field effects, and phase transitions that may occur at densities exceeding ten times nuclear saturation density.\n\nKey findings indicate that the absolute maximum mass for any stable compact object is approximately 3.2 solar masses, significantly higher than previous estimates of 2.0-2.5 solar masses. This upper bound emerges from fundamental constraints imposed by causality and the requirement that the speed of sound cannot exceed the speed of light. Our calculations reveal that exotic matter phases, particularly color superconducting quark matter, can sustain higher maximum masses than conventional neutron matter by up to 30%.\n\nThe model successfully reproduces observed masses of known pulsars while predicting the existence of a previously unidentified population of ultra-massive compact objects in the 2.8-3.2 solar mass range. These findings have profound implications for gravitational wave astronomy, suggesting that certain merger events may produce remnants that challenge current classification schemes. Furthermore, our results provide new constraints on the cosmic equation of state and offer testable predictions for next-generation observational facilities, potentially resolving long-standing discrepancies between theoretical predictions and astronomical observations of the most massive known compact objects."
  },
  {
    "id": 52,
    "prompt": "3-He in the Milky Way Interstellar Medium: Ionization Structure",
    "HWT": "The cosmic abundance of the 3-He isotope has important implications for many fields of astrophysics. We are using the 8.665 GHz hyperfine transition of 3-He+ to determine the 3-He/H abundance in Milky Way HII regions and planetary nebulae. This is one in a series of papers in which we discuss issues involved in deriving accurate 3-He/H abundance ratios from the available measurements. Here we describe the ionization correction we use to convert the 3-He+/H+ abundance, y3+, to the 3-He/H abundance, y3. In principle the nebular ionization structure can significantly influence the y3 derived for individual sources. We find that in general there is insufficient information available to make a detailed ionization correction. Here we make a simple correction and assess its validity. The correction is based on radio recombination line measurements of H+ and 4-He+, together with simple core-halo source models. We use these models to establish criteria that allow us to identify sources that can be accurately corrected for ionization and those that cannot. We argue that this effect cannot be very large for most of the sources in our observational sample. For a wide range of models of nebular ionization structure we find that the ionization correction factor varies from 1 to 1.8. Although large corrections are possible, there would have to be a conspiracy between the density and ionization structure for us to underestimate the ionization correction by a substantial amount.",
    "MGT": "We present a comprehensive analysis of the ionization structure of ³He in the Milky Way's interstellar medium using observational data from the Arecibo Observatory and Green Bank Telescope. Our study combines ³He⁺ hyperfine transition observations at 8.665 GHz with complementary H I and H II region surveys to constrain the spatial distribution and ionization state of helium-3 throughout the Galaxy. We find that the ³He⁺/³He ratio exhibits significant variation with galactocentric radius, ranging from 0.3 ± 0.1 in the inner Galaxy (R < 6 kpc) to 0.8 ± 0.2 in the outer disk (R > 10 kpc). This gradient correlates strongly with the observed H⁺/H ratio, suggesting that stellar UV radiation fields primarily control the helium-3 ionization balance in most regions. However, we identify several anomalous zones near supernova remnants and H II regions where the ³He⁺ fraction exceeds predictions from photoionization models by factors of 2-3. Monte Carlo radiative transfer simulations indicate that shock heating and charge exchange processes become dominant ionization mechanisms in these environments. Our results reveal that approximately 60% of interstellar helium-3 exists in ionized form within 500 pc of the Galactic plane, with the neutral fraction increasing toward higher latitudes. These findings have important implications for Big Bang nucleosynthesis constraints and stellar evolution models, as the ionization state affects both the observable ³He abundance and its incorporation into star-forming regions. We discuss the implications for galactic chemical evolution and propose future observational strategies to refine our understanding of light element processing in the interstellar medium."
  },
  {
    "id": 53,
    "prompt": "A Hybrid Mechanism Forming a 2:1 Librating-Circulating Resonant Configuration in the Planetary System",
    "HWT": "A diversity of resonance configurations may be formed under different migration of two giant planets. And the researchers show that the HD 128311 and HD 73526 planetary systems are involved in a 2:1 mean motion resonance but not in apsidal corotation, because one of the resonance argument circulates over the dynamical evolution. In this paper, we investigate potential mechanisms to form the 2:1 librating-circulating resonance configuration. In the late stage of planetary formation, scattering or colliding among planetesimals and planetary embryos can frequently occur. Hence, in our model, we consider a planetary configuration of two giants together with few terrestrial planets. We find that both colliding or scattering events at very early stage of dynamical evolution can influence the configurations trapped into resonance. A planet-planet scattering of a moderate terrestrial planet, or multiple scattering of smaller planets in a crowded planetary system can change the resonant configuration. In addition, collision or merging can alter the masses and location of the giant planets, which also play an important role in shaping the resonant configuration during the dynamical evolution. In this sense, the librating-circulating resonance configuration is more likely to form by a hybrid mechanism of scattering and collision.",
    "MGT": "We present a comprehensive analysis of a novel hybrid resonance mechanism that produces a stable 2:1 librating-circulating configuration in multi-planetary systems. Through extensive N-body simulations spanning 10^7 orbital periods, we demonstrate how gravitational perturbations between adjacent planets can establish a complex resonant state where one body exhibits librating motion while its companion maintains circulating behavior around the same mean motion resonance. Our numerical models incorporate realistic planetary masses ranging from super-Earth to Neptune-class objects, with initial semi-major axis ratios near the 2:1 commensurability. The hybrid mechanism emerges through a three-phase evolutionary process: initial capture into temporary resonance, followed by eccentricity damping that stabilizes the librating component, and subsequent secular perturbations that maintain the circulating motion of the outer body. We identify critical threshold values for planetary mass ratios (0.3 < m₁/m₂ < 2.1) and initial eccentricities (e < 0.08) that facilitate this configuration. The librating planet exhibits resonant angles oscillating with amplitudes of 15-45 degrees, while the circulating planet shows continuous angular advancement with periodic modulations. This mechanism provides a robust explanation for observed exoplanetary systems displaying apparent near-resonant architectures without strict period commensurability, offering new insights into planetary system evolution and migration processes in protoplanetary disks."
  },
  {
    "id": 54,
    "prompt": "Decidability properties for fragments of CHR",
    "HWT": "We study the decidability of termination for two CHR dialects which, similarly to the Datalog like languages, are defined by using a signature which does not allow function symbols (of arity >0). Both languages allow the use of the = built-in in the body of rules, thus are built on a host language that supports unification. However each imposes one further restriction. The first CHR dialect allows only range-restricted rules, that is, it does not allow the use of variables in the body or in the guard of a rule if they do not appear in the head. We show that the existence of an infinite computation is decidable for this dialect. The second dialect instead limits the number of atoms in the head of rules to one. We prove that in this case, the existence of a terminating computation is decidable. These results show that both dialects are strictly less expressive than Turing Machines. It is worth noting that the language (without function symbols) without these restrictions is as expressive as Turing Machines.",
    "MGT": "Constraint Handling Rules (CHR) is a declarative rule-based programming language primarily designed for constraint solving and reasoning applications. While CHR provides expressive power for implementing sophisticated constraint solvers, its full computational capabilities raise important theoretical questions regarding decidability of fundamental program properties. This paper investigates decidability properties for several syntactically restricted fragments of CHR, focusing on termination, confluence, and reachability problems.\n\nWe establish decidability results for three significant CHR fragments: range-restricted rules without function symbols, rules with bounded constraint store size, and acyclic dependency structures. For range-restricted CHR programs, we demonstrate that termination is decidable by reduction to Petri net reachability problems. The confluence property is shown to be decidable for the bounded constraint store fragment through finite state space analysis. Additionally, we prove that reachability becomes decidable for CHR programs with acyclic rule dependencies by constructing finite automata representations of constraint derivations.\n\nOur theoretical analysis employs techniques from formal language theory, Petri net analysis, and finite model theory. The decidability results provide foundations for developing automated verification tools for CHR programs and establish theoretical boundaries for practical constraint solver implementations. These findings contribute to the broader understanding of decidable fragments in logic programming languages."
  },
  {
    "id": 55,
    "prompt": "Temperature and fluence dependence of ultrafast phase separation dynamics in Pr0.6Ca0.4MnO3 thin films",
    "HWT": "Temperature and fluence dependence of the transient photoinduced reflectivity and the magnetooptical Kerr angle was measured in two Pr0.6Ca0.4MnO3 thin films subject to tensile and compressive substrate-induced strain. A photoinduced transient ferromagnetic metallic (TFM) phase is found to form below ~60K and ~40K in the substrate-strained and substrate-compressed film, respectively. From the hysteresis loops a difference in the TFM cluster sizes and amount of photomodulation is observed at low temperatures and low excitation fluences in the films with different strain. Surprisingly, the characteristic timescale for the TFM phase photomodulation is virtually strain independent. At high excitation fluences, the cluster sizes and amount of photomodulation are independent on the substrate-induced strain.",
    "MGT": "# Temperature and fluence dependence of ultrafast phase separation dynamics in Pr0.6Ca0.4MnO3 thin films\n\nWe investigate the ultrafast phase separation dynamics in Pr0.6Ca0.4MnO3 thin films as a function of temperature and laser fluence using time-resolved optical spectroscopy. Our measurements reveal that photoexcitation triggers a rapid transition from the charge-ordered insulating phase to a metastable metallic state within 1 picosecond. The recovery dynamics exhibit a strong temperature dependence, with a critical slowdown near the phase transition temperature (TCO ≈ 230 K). At low temperatures, we observe a threshold-like behavior with increasing fluence, suggesting a photoinduced first-order phase transition. The relaxation process follows a stretched exponential decay, indicating the presence of competing interactions and spatial inhomogeneities. Our results demonstrate that the phase separation in this manganite system can be dynamically controlled through temperature and optical excitation, providing insights into the fundamental mechanisms governing strongly correlated electron systems."
  },
  {
    "id": 56,
    "prompt": "Confinement of electrons in size modulated silicon nanowires",
    "HWT": "Based on first-principles calculations we showed that superlattices of periodically repeated junctions of hydrogen saturated silicon nanowire segments having different lengths and diameters form multiple quantum well structures. The band gap of the superlattice is modulated in real space as its diameter does and results in a band gap in momentum space which is different from constituent nanowires. Specific electronic states can be confined in either narrow or wide regions of superlattice. The type of the band lineup and hence the offsets of valence and conduction bands depend on the orientation of the superlattice as well as on the diameters of the constituent segments. Effects of the SiH vacancy and substitutional impurities on the electronic and magnetic properties have been investigated by carrying out spin-polarized calculations. Substitutional impurities with localized states near band edges can make modulation doping possible. Stability of the superlattice structure was examined by ab initio molecular dynamics calculations at high temperatures.",
    "MGT": "Silicon nanowires with periodic diameter modulations present unique opportunities for controlling electron transport through quantum confinement effects. This study examines the electronic properties of size-modulated silicon nanowires using density functional theory calculations and quantum transport simulations. We investigate how systematic variations in wire diameter create potential barriers and quantum wells that confine electrons in specific regions along the nanowire axis. Our results demonstrate that diameter modulations of 2-5 nm create significant confinement energies ranging from 50-200 meV, leading to discrete energy levels and enhanced quantum effects. The confinement strength correlates directly with the modulation amplitude and inversely with the average wire diameter. Transport measurements reveal pronounced conductance oscillations corresponding to resonant tunneling through confined states. Temperature-dependent studies show that confinement effects persist up to 77 K, indicating robust quantum behavior suitable for device applications. These findings establish size-modulated silicon nanowires as promising candidates for quantum electronic devices, offering precise control over electron localization through geometric engineering. The ability to tailor electronic properties through diameter modulation opens new pathways for next-generation nanoelectronic applications."
  },
  {
    "id": 57,
    "prompt": "Constraining the LRG Halo Occupation Distribution using Counts-in-Cylinders",
    "HWT": "The low number density of the Sloan Digital Sky Survey (SDSS) Luminous Red Galaxies (LRGs) suggests that LRGs occupying the same dark matter halo can be separated from pairs occupying distinct dark matter halos with high fidelity. We present a new technique, Counts-in-Cylinders (CiC), to constrain the parameters of the satellite contribution to the LRG Halo-Occupation Distribution (HOD). For a fiber collision-corrected SDSS spectroscopic LRG subsample at 0.16 < z < 0.36, we find the CiC multiplicity function is fit by a halo model where the average number of satellites in a halo of mass M is <Nsat(M)> = ((M - Mcut)/M1)^alpha with Mcut = 5.0 +1.5/-1.3 (+2.9/-2.6) X 10^13 Msun, M1 = 4.95 +0.37/-0.26 (+0.79/-0.53) X 10^14 Msun, and alpha = 1.035 +0.10/-0.17 (+0.24/-0.31) at the 68% and 95% confidence levels using a WMAP3 cosmology and z=0.2 halo catalog. Our method tightly constrains the fraction of LRGs that are satellite galaxies, 6.36 +0.38/-0.39, and the combination Mcut/10^{14} Msun + alpha = 1.53 +0.08/-0.09 at the 95% confidence level. We also find that mocks based on a halo catalog produced by a spherical overdensity (SO) finder reproduce both the measured CiC multiplicity function and the projected correlation function, while mocks based on a Friends-of-Friends (FoF) halo catalog has a deficit of close pairs at ~1 Mpc/h separations. Because the CiC method relies on higher order statistics of close pairs, it is robust to the choice of halo finder. In a companion paper we will apply this technique to optimize Finger-of-God (FOG) compression to eliminate the 1-halo contribution to the LRG power spectrum.",
    "MGT": "We present a novel approach to constrain the halo occupation distribution (HOD) of luminous red galaxies (LRGs) using the counts-in-cylinders (CiC) statistic, which measures the number density of galaxies within cylindrical volumes around target galaxies. Our method exploits the sensitivity of CiC measurements to both the central and satellite components of the HOD, providing complementary information to traditional two-point correlation function analyses. We apply this technique to a sample of 180,000 LRGs from the Sloan Digital Sky Survey Data Release 16, selected at redshift 0.15 < z < 0.35 with absolute r-band magnitudes Mr < -21.5.\n\nThe CiC statistic is computed for cylindrical apertures with radii ranging from 0.5 to 8.0 h⁻¹ Mpc and half-heights of 10-40 h⁻¹ Mpc, capturing galaxy correlations across multiple scales while minimizing redshift-space distortion effects. We model the expected CiC signal using a combination of N-body simulations and semi-analytic galaxy population models, incorporating realistic survey geometry and selection effects. Our HOD parameterization includes a modified Zheng et al. prescription with additional flexibility in the satellite occupation function to account for potential assembly bias effects.\n\nThrough Markov Chain Monte Carlo analysis, we constrain the minimum halo mass hosting central LRGs to be log₁₀(Mmin/h⁻¹M☉) = 13.02 ± 0.04, with a characteristic satellite occupation mass of log₁₀(M1/h⁻¹M☉) = 14.18 ± 0.08. The satellite fraction is measured to be fs = 0.12 ± 0.02, consistent with previous clustering analyses but with significantly improved precision. We find evidence for a steeper-than-unity slope in the satellite occupation function (α = 1.23 ± 0.06), suggesting enhanced satellite occupation in the most massive halos. Our results demonstrate that CiC statistics provide powerful constraints on HOD parameters, particularly for satellite populations, and offer a valuable complement to existing clustering methods for understanding galaxy-halo connections in large-scale structure surveys."
  },
  {
    "id": 58,
    "prompt": "Three-Dimensional Simulations of Mixing Instabilities in Supernova Explosions",
    "HWT": "We present the first three-dimensional (3D) simulations of the large-scale mixing that takes place in the shock-heated stellar layers ejected in the explosion of a 15.5 solar-mass blue supergiant star. The outgoing supernova shock is followed from its launch by neutrino heating until it breaks out from the stellar surface more than two hours after the core collapse. Violent convective overturn in the post-shock layer causes the explosion to start with significant asphericity, which triggers the growth of Rayleigh-Taylor (RT) instabilities at the composition interfaces of the exploding star. Deep inward mixing of hydrogen (H) is found as well as fast-moving, metal-rich clumps penetrating with high velocities far into the H-envelope of the star as observed, e.g., in the case of SN 1987A. Also individual clumps containing a sizeable fraction of the ejected iron-group elements (up to several 0.001 solar masses) are obtained in some models. The metal core of the progenitor is partially turned over with Ni-dominated fingers overtaking oxygen-rich bullets and both Ni and O moving well ahead of the material from the carbon layer. Comparing with corresponding 2D (axially symmetric) calculations, we determine the growth of the RT fingers to be faster, the deceleration of the dense metal-carrying clumps in the He and H layers to be reduced, the asymptotic clump velocities in the H-shell to be higher (up to ~4500 km/s for the considered progenitor and an explosion energy of 10^{51} ergs, instead of <2000 km/s in 2D), and the outward radial mixing of heavy elements and inward mixing of hydrogen to be more efficient in 3D than in 2D. We present a simple argument that explains these results as a consequence of the different action of drag forces on moving objects in the two geometries. (abridged)",
    "MGT": "Supernova explosions represent some of the most energetic events in the universe, playing crucial roles in stellar evolution, galactic chemical enrichment, and cosmic ray acceleration. During these explosive events, complex hydrodynamic instabilities develop at interfaces between compositionally distinct layers within the stellar interior, fundamentally altering the explosion dynamics and nucleosynthetic yields. Understanding these mixing processes is essential for accurate predictions of supernova light curves, spectral evolution, and heavy element production.\n\nWe present comprehensive three-dimensional hydrodynamic simulations investigating mixing instabilities in core-collapse supernova explosions, focusing on the development and evolution of Rayleigh-Taylor and Kelvin-Helmholtz instabilities at compositional interfaces. Our computational framework employs high-resolution adaptive mesh refinement techniques coupled with realistic equation of state treatments and detailed nuclear reaction networks. The simulations span from shock breakout through several hundred seconds of evolution, capturing the full development of instability-driven mixing processes.\n\nOur results demonstrate that three-dimensional effects significantly enhance mixing efficiency compared to previous two-dimensional studies. Rayleigh-Taylor instabilities at the He/H interface develop characteristic mushroom-shaped structures with growth rates exceeding linear predictions by factors of 2-3. The subsequent evolution exhibits complex multi-scale turbulent cascades, with energy injection occurring primarily at large scales corresponding to the pressure scale height. Kelvin-Helmholtz instabilities at velocity shear boundaries contribute additional mixing, particularly in regions where compositional gradients are steep.\n\nThe enhanced mixing dramatically affects nucleosynthetic yields, increasing the production of intermediate-mass elements by 40-60% while reducing the synthesis of iron-peak isotopes. Nickel-56 distribution becomes highly asymmetric, with significant quantities transported to outer ejecta layers, consistent with observations of early-time supernova light curves. The three-dimensional mixing also produces substantial polarization signatures in spectral line profiles, matching observed asymmetries in Type IIP supernovae.\n\nThese findings have important implications for supernova explosion models and their observational signatures. The enhanced mixing efficiency suggests that one-dimensional explosion models systematically underestimate the degree of compositional homogenization, leading to inaccurate predictions of nucleosynthetic yields and spectral evolution. Our results provide crucial benchmarks for future supernova simulations and offer new insights into the connection between explosion dynamics and observable properties."
  },
  {
    "id": 59,
    "prompt": "Bayesian orthogonal component analysis for sparse representation",
    "HWT": "This paper addresses the problem of identifying a lower dimensional space where observed data can be sparsely represented. This under-complete dictionary learning task can be formulated as a blind separation problem of sparse sources linearly mixed with an unknown orthogonal mixing matrix. This issue is formulated in a Bayesian framework. First, the unknown sparse sources are modeled as Bernoulli-Gaussian processes. To promote sparsity, a weighted mixture of an atom at zero and a Gaussian distribution is proposed as prior distribution for the unobserved sources. A non-informative prior distribution defined on an appropriate Stiefel manifold is elected for the mixing matrix. The Bayesian inference on the unknown parameters is conducted using a Markov chain Monte Carlo (MCMC) method. A partially collapsed Gibbs sampler is designed to generate samples asymptotically distributed according to the joint posterior distribution of the unknown model parameters and hyperparameters. These samples are then used to approximate the joint maximum a posteriori estimator of the sources and mixing matrix. Simulations conducted on synthetic data are reported to illustrate the performance of the method for recovering sparse representations. An application to sparse coding on under-complete dictionary is finally investigated.",
    "MGT": "I need to write an academic abstract for a paper titled \"Bayesian orthogonal component analysis for sparse representation\". This should be about 205 words and should follow the typical structure of an academic abstract:\n\n1. Brief introduction/motivation\n2. Problem statement\n3. Proposed method\n4. Key contributions/results\n5. Implications/applications\n\nThe topic involves:\n- Bayesian methods\n- Orthogonal component analysis (similar to PCA but with orthogonality constraints)\n- Sparse representation (finding sparse solutions to represent data)\n\nLet me craft an abstract that sounds technical and appropriate for this field, likely in machine learning/signal processing/statistics.This paper presents a novel Bayesian framework for orthogonal component analysis specifically designed to achieve sparse representation of high-dimensional data. Traditional principal component analysis and its variants often produce dense loadings that lack interpretability and fail to identify the most relevant features in complex datasets. To address these limitations, we develop a Bayesian orthogonal component analysis (BOCA) method that incorporates sparsity-inducing priors while maintaining orthogonality constraints among components.\n\nOur approach employs a hierarchical Bayesian model with spike-and-slab priors to automatically determine the sparsity pattern of component loadings. We derive an efficient variational inference algorithm that simultaneously estimates the sparse loadings and the number of significant components. The orthogonality constraint is enforced through a novel parameterization that ensures computational tractability while preserving the geometric properties essential for component analysis.\n\nExtensive experiments on synthetic and real-world datasets demonstrate that BOCA achieves superior sparse representation compared to existing methods, including sparse PCA and orthogonal matching pursuit. The method shows remarkable performance in feature selection, dimensionality reduction, and signal reconstruction tasks. Particularly noteworthy is its ability to identify interpretable components in genomic data analysis and image processing applications.\n\nThe proposed framework provides a principled approach to sparse orthogonal decomposition with quantified uncertainty, making it valuable for applications requiring both sparsity and orthogonality in component analysis."
  },
  {
    "id": 60,
    "prompt": "An analysis of the nucleon spectrum from lattice partially-quenched QCD",
    "HWT": "The chiral extrapolation of the nucleon mass, M_n, is investigated using data coming from 2-flavour partially-quenched lattice simulations. A large sample of lattice results from the CP-PACS Collaboration is analysed using the leading one-loop corrections, with explicit corrections for finite lattice spacing artifacts. The extrapolation is studied using finite range regularised chiral perturbation theory. The analysis also provides a quantitative estimate of the leading finite volume corrections. It is found that the discretisation, finite-volume and partial quenching effects can all be very well described in this framework, producing an extrapolated value of M_n in agreement with experiment. Furthermore, determinations of the low energy constants of the nucleon mass's chiral expansion are in agreement with previous methods, but with significantly reduced errors. This procedure is also compared with extrapolations based on polynomial forms, where the results are less encouraging.",
    "MGT": "I need to write an academic abstract for a physics paper about nucleon spectrum from lattice partially-quenched QCD. This is a technical topic in theoretical nuclear/particle physics. Let me break down what this would typically involve:\n\n1. Lattice QCD - computational approach to quantum chromodynamics using discretized spacetime\n2. Partially-quenched QCD - a theoretical framework where valence and sea quark masses can be different\n3. Nucleon spectrum - the energy levels/masses of nucleons (protons, neutrons) and related baryons\n\nA typical abstract should include:\n- Brief context/motivation\n- Methods used\n- Key results\n- Implications/conclusions\n\nI need to make this sound authentic and technical while staying around 154 words.We present a comprehensive study of the nucleon mass spectrum using lattice partially-quenched quantum chromodynamics (PQχQCD) simulations. Our calculations employ 2+1 flavor configurations with improved Wilson fermions on a 24³×48 lattice at β=1.95, corresponding to a lattice spacing of approximately 0.12 fm. We investigate the dependence of nucleon and Δ-baryon masses on both valence and sea quark masses, with particular emphasis on the chiral extrapolation to physical quark masses. The partially-quenched formalism allows systematic exploration of the quark mass dependence while maintaining computational efficiency. Our results demonstrate significant finite-volume effects and discretization artifacts that must be carefully controlled. We extract the nucleon-Δ mass splitting and compare with experimental values, finding agreement within statistical uncertainties after appropriate extrapolations. The calculated nucleon sigma term σπN = 45(8) MeV shows consistency with phenomenological determinations. These findings provide important constraints for effective field theory descriptions of low-energy QCD and contribute to our understanding of the non-perturbative structure of hadrons."
  },
  {
    "id": 61,
    "prompt": "Single-photon cooling at the limit of trap dynamics: Maxwell's Demon near maximum efficiency",
    "HWT": "We demonstrate a general and efficient informational cooling technique for atoms which is an experimental realization of a one-dimensional Maxwell's Demon. The technique transfers atoms from a magnetic trap into an optical trap via a single spontaneous Raman transition which is discriminatively driven near each atom's classical turning point. In this way, nearly all of the atomic ensemble's kinetic energy in one dimension is removed. We develop a simple analytical model to predict the efficiency of transfer between the traps and provide evidence that the performance is limited only by particle dynamics in the magnetic trap. Transfer efficiencies up to 2.2% are reported. We show that efficiency can be traded for phase-space compression, and we report compression up to a factor of 350. Our results represent a 15-fold improvement over our previous demonstration of the cooling technique.",
    "MGT": "We present a theoretical and experimental analysis of single-photon cooling in trapped ions operating at the fundamental limit imposed by trap dynamics. By implementing a Maxwell's demon protocol that selectively removes high-energy photons from the motional state, we achieve cooling rates that approach the maximum theoretical efficiency. Our scheme exploits the discrete nature of phonon excitations and employs real-time feedback control to conditionally extract energy from the system with near-unity probability. Experiments with a single $^{40}$Ca$^+$ ion in a Paul trap demonstrate ground-state cooling with 99.2% fidelity in 12 μs, representing a 50-fold improvement over Doppler cooling timescales. The protocol maintains coherence throughout the cooling process, enabling direct verification of quantum state preparation. Numerical simulations confirm that our approach saturates the fundamental bound set by the trap oscillation period, with the effective demon operating at 94% of Landauer's efficiency limit. These results establish single-photon cooling as a premier technique for rapid quantum state initialization and highlight the intimate connection between information processing and thermodynamics in quantum systems."
  },
  {
    "id": 62,
    "prompt": "Evidence for primordial mass segregation in globular clusters",
    "HWT": "We have studied the dissolution of initially mass segregated and unsegregated star clusters due to two-body relaxation in external tidal fields, using Aarseth's collisional N-body code NBODY4 on GRAPE6 special-purpose computers. When extrapolating results of initially not mass segregated models to globular clusters, we obtain a correlation between the time until destruction and the slope of the mass function, in the sense that globular clusters which are closer to dissolution are more strongly depleted in low-mass stars. This correlation fits observed mass functions of most globular clusters. The mass functions of several globular clusters are however more strongly depleted in low-mass stars than suggested by these models. Such strongly depleted mass functions can be explained if globular clusters started initially mass segregated. Primordial mass segregation also explains the correlation between the slope of the stellar mass function and the cluster concentration which was recently discovered by De Marchi et al. (2007). In this case, it is possible that all globular clusters started with a mass function similar to that seen in young open clusters in the present-day universe, at least for stars below m=0.8 Msun. This argues for a near universality of the mass function for different star formation environments and metallicities in the range -2 < [Fe/H] < 0. We finally describe a novel algorithm which can initialise stationary mass segregated clusters with arbitrary density profile and amount of mass segregation.",
    "MGT": "# Evidence for primordial mass segregation in globular clusters\n\nWe present comprehensive analysis of stellar mass distribution in a sample of Galactic globular clusters (GCs) using deep Hubble Space Telescope photometry combined with state-of-the-art dynamical models. Our study reveals compelling evidence for primordial mass segregation—the preferential formation of massive stars in cluster centers—challenging the long-standing assumption that mass segregation in GCs results solely from two-body relaxation processes. By constructing mass-dependent radial density profiles for 17 GCs spanning diverse dynamical ages (0.5-10 relaxation times), we identify significant central concentrations of high-mass stars in dynamically young clusters that cannot be explained by secular evolution alone. The observed segregation exceeds theoretical predictions from pure dynamical evolution by factors of 1.5-3 in clusters younger than 2 relaxation times. We quantify the primordial component using a newly developed parameter (ψ) that measures the deviation between observed and theoretically predicted mass segregation, finding that 14 of 17 clusters show ψ > 0.2, indicating substantial primordial contribution. Furthermore, we demonstrate correlations between the degree of primordial segregation and cluster formation environment parameters, including metallicity and galactocentric distance. These findings align with theoretical models of competitive gas accretion during cluster formation and have significant implications for understanding initial conditions of GC evolution, interpretations of GC mass functions, and dynamical modeling of these systems. Our results suggest that primordial mass segregation is a widespread phenomenon in GC formation, requiring fundamental revisions to current paradigms of cluster formation and early dynamical evolution."
  },
  {
    "id": 63,
    "prompt": "Synchronization and entrainment of coupled circadian oscillators",
    "HWT": "Circadian rhythms in mammals are controlled by the neurons located in the suprachiasmatic nucleus of the hypothalamus. In physiological conditions, the system of neurons is very efficiently entrained by the 24-hour light-dark cycle. Most of the studies carried out so far emphasize the crucial role of the periodicity imposed by the light dark cycle in neuronal synchronization. Nevertheless, heterogeneity as a natural and permanent ingredient of these cellular interactions is seemingly to play a major role in these biochemical processes. In this paper we use a model that considers the neurons of the suprachiasmatic nucleus as chemically-coupled modified Goodwin oscillators, and introduce non-negligible heterogeneity in the periods of all neurons in the form of quenched noise. The system response to the light-dark cycle periodicity is studied as a function of the interneuronal coupling strength, external forcing amplitude and neuronal heterogeneity. Our results indicate that the right amount of heterogeneity helps the extended system to respond globally in a more coherent way to the external forcing. Our proposed mechanism for neuronal synchronization under external periodic forcing is based on heterogeneity-induced oscillators death, damped oscillators being more entrainable by the external forcing than the self-oscillating neurons with different periods.",
    "MGT": "This study investigates the complex dynamics of coupled circadian oscillators and their synchronization patterns in biological systems. We present a comprehensive mathematical framework for analyzing the entrainment mechanisms between multiple oscillators, with particular focus on the phase relationships and coupling strengths that emerge under various environmental conditions. Using both experimental data from mammalian SCN neurons and computational modeling, we demonstrate that networks of circadian oscillators exhibit robust synchronization properties that depend critically on their coupling architecture and internal parameter distributions. Our results reveal a previously unidentified class of stable phase-locked states that arise from the interplay between intrinsic oscillator frequencies and network topology. We show that these states are resistant to moderate environmental perturbations while maintaining flexibility to adapt to significant zeitgeber changes. Through bifurcation analysis, we identify key parameter regimes where the system transitions between different synchronization modes, providing insight into the underlying mechanisms of circadian rhythm disorders. Additionally, we propose a novel metric for quantifying the degree of entrainment in complex oscillator networks. These findings advance our understanding of how biological timing systems achieve robust synchronization and suggest potential therapeutic approaches for circadian rhythm disruptions in medical conditions."
  },
  {
    "id": 64,
    "prompt": "Coherent Cherenkov radio pulses from hadronic showers up to EeV energies",
    "HWT": "The Cherenkov radio pulse emitted by hadronic showers in ice is calculated for showers of energies in the EeV range. This is obtained with three dimensional simulations of both shower development and the coherent radio pulse emitted as the excess charge develops in the shower. A Monte Carlo, ZHAireS, has been developed for this purpose combining the high energy hadronic interaction capabilities of AIRES, and the dense media propagation capabilities of TIERRAS, with the precise low energy tracking and specific algorithms developed to calculate the radio emission in ZHS. A thinning technique is implemented and optimized to allow the simulation of radio pulses induced by showers up to 10 EeV in ice. The code is validated comparing the results for electromagnetic and hadronic showers to those obtained with GEANT4 and ZHS codes. The contribution to the pulse of other shower particles in addition to electrons and positrons, mainly pions and muons, is found to be below 1%. The characteristics of hadronic showers and the corresponding Cherenkov frequency spectra are compared with those from purely electromagnetic showers. The dependence of the spectra on shower energy and high-energy hadronic model is addressed and parameterizations for the radio emission in hadronic showers in ice are given for practical applications.",
    "MGT": "We present a comprehensive study of coherent Cherenkov radio emission from hadronic showers at ultra-high energies, extending up to 10^18 eV (EeV). Using state-of-the-art Monte Carlo simulations incorporating detailed particle interaction models and electromagnetic field calculations, we investigate the characteristics of radio signals generated by extensive air showers initiated by hadrons. Our analysis reveals that the coherent Cherenkov emission maintains remarkable stability in its frequency spectrum and angular distribution across six orders of magnitude in primary energy. The simulations demonstrate that the radio pulse amplitude scales linearly with shower energy, while the characteristic Cherenkov angle remains nearly constant at approximately 1.1°. We observe that the frequency spectrum peaks in the microwave region (3-5 GHz) and exhibits a sharp cutoff at higher frequencies due to coherence effects. The lateral distribution of the radio signal shows a distinctive ring-like structure, with maximum field strengths occurring at distances of 50-100 meters from the shower axis, depending on the observation altitude. These findings have significant implications for the detection of ultra-high-energy cosmic rays and neutrinos, suggesting that radio detection techniques could provide a cost-effective method for observing extensive air showers at the highest energies. Our results also indicate potential applications in large-scale cosmic ray observatories and future neutrino detection experiments."
  },
  {
    "id": 65,
    "prompt": "Angular Momentum Transport in Protoplanetary and Black-Hole Accretion Disks: The Role of Parasitic Modes in the Saturation of MHD Turbulence",
    "HWT": "The magnetorotational instability (MRI) is considered a key process for driving efficient angular momentum transport in astrophysical disks. Understanding its non-linear saturation constitutes a fundamental problem in modern accretion disk theory. The large dynamical range in physical conditions in accretion disks makes it challenging to address this problem only with numerical simulations. We analyze the concept that (secondary) parasitic instabilities are responsible for the saturation of the MRI. Our approach enables us to explore dissipative regimes that are relevant to astrophysical and laboratory conditions that lie beyond the regime accessible to current numerical simulations. We calculate the spectrum and physical structure of parasitic modes that feed off the fastest, exact (primary) MRI mode when its amplitude is such that the fastest parasitic mode grows as fast as the MRI. We argue that this \"saturation\" amplitude provides an estimate of the magnetic field that can be generated by the MRI before the secondary instabilities suppress its growth significantly. Recent works suggest that the saturation amplitude of the MRI depends mainly on the magnetic Prandtl number. Our results suggest that, as long as viscous effects do not dominate the fluid dynamics, the saturation level of the MRI depends only on the Elsasser number $\\Lambda_\\eta$. We calculate the ratio between the stress and the magnetic energy density, $\\alpha_{\\rm sat}\\beta_{\\rm sat}$, associated with the primary MRI mode. We find that for $\\Lambda_\\eta >1$ Kelvin-Helmholtz modes are responsible for saturation and $\\alpha_{\\rm sat}\\beta_{\\rm sat} = 0.4$, while for $\\Lambda_\\eta < 1$ tearing modes prevail and $\\alpha_{\\rm sat}\\beta_{\\rm sat} \\simeq 0.5 \\, \\Lambda_\\eta$. Several features of MRI simulations in accretion disks surrounding young stars and compact objects can be interpreted in terms of our findings.",
    "MGT": "In this paper, we investigate the mechanisms of angular momentum transport in protoplanetary and black-hole accretion disks, with a particular focus on the role of parasitic instabilities in regulating magnetohydrodynamic (MHD) turbulence. The magnetorotational instability (MRI) is widely recognized as the primary driver of turbulence in these systems, but the physical processes governing its saturation remain incompletely understood. We present a comprehensive numerical study using high-resolution 3D MHD simulations that span a range of disk parameters relevant to both protoplanetary and black-hole accretion environments. Our simulations reveal that parasitic modes—secondary instabilities that feed on the MRI—play a crucial role in limiting the amplitude of the MRI and thus determining the efficiency of angular momentum transport. We demonstrate that these parasitic instabilities, primarily of Kelvin-Helmholtz and tearing-mode type, become increasingly important in regimes of low magnetic Prandtl number, which are characteristic of protoplanetary disks. In contrast, in the high magnetic Prandtl number environments typical of black-hole accretion disks, the parasitic modes are less effective at limiting MRI growth, resulting in more vigorous turbulence and enhanced angular momentum transport. We quantify the relationship between the saturation amplitude of the MRI and the growth rates of the dominant parasitic modes across different disk conditions, establishing a predictive framework for estimating accretion efficiencies. Additionally, we find that the vertical stratification of the disk significantly affects the development of these parasitic instabilities, introducing important modifications to existing theoretical models. Our results have significant implications for understanding accretion rates and disk evolution in diverse astrophysical systems, from planet formation to active galactic nuclei, and help resolve discrepancies between theoretical predictions and observational constraints on disk lifetimes and accretion luminosities."
  },
  {
    "id": 66,
    "prompt": "Rebuttal to \"Comment by V. M. Krasnov on 'Counterintuitive consequence of heating in strongly-driven intrinsic junctions of Bi2Sr2CaCu2O8+d Mesas' \"",
    "HWT": "In our article [1], we found that with increasing dissipation there is a clear, systematic shift and sharpening of the conductance peak along with the disappearance of the higher-bias dip/hump features (DHF), for a stack of intrinsic Josephson junctions (IJJs) of intercalated Bi2Sr2CaCu2O8+{\\delta} (Bi2212). Our work agrees with Zhu et al [2] on unintercalated, pristine Bi2212, as both studies show the same systematic changes with dissipation. The broader peaks found with reduced dissipation [1,2] are consistent with broad peaks in the density-of-states (DOS) found among scanning tunneling spectroscopy [3] (STS), mechanical contact tunneling [4] (MCT) and inferred from angle (momentum) resolved photoemission spectroscopy [5] (ARPES); results that could not be ignored. Thus, sharp peaks are extrinsic and cannot correspond to the superconducting DOS. We suggested that the commonality of the sharp peaks in our conductance data, which is demonstrably shown to be heating-dominated, and the peaks of previous intrinsic tunneling spectroscopy (ITS) data implies that these ITS reports might need reinterpretation.",
    "MGT": "We present a comprehensive rebuttal to the recent critique by V. M. Krasnov regarding our published findings on heating effects in strongly-driven intrinsic Josephson junctions of Bi2Sr2CaCu2O8+d mesa structures. Krasnov's comment fundamentally misinterprets our experimental methodology and theoretical framework, leading to erroneous conclusions about the temperature dependence of junction dynamics. Our original work demonstrated that under high-bias conditions, local heating in these layered superconductor systems produces counterintuitive effects on the current-voltage characteristics, specifically an apparent enhancement of the superconducting gap rather than its expected suppression. Krasnov incorrectly assumes uniform temperature distribution across the mesa structure and fails to account for the highly anisotropic thermal conductivity inherent to the layered cuprate architecture. His critique overlooks critical aspects of our finite-element thermal modeling, which explicitly incorporates the temperature-dependent thermal boundary resistance between individual CuO2 layers. Furthermore, Krasnov's alternative interpretation based on conventional Joule heating mechanisms cannot explain the observed bias-dependent evolution of quasiparticle tunneling features in our differential conductance measurements. We provide additional experimental evidence, including temperature-dependent spectroscopic data and complementary numerical simulations, that conclusively support our original interpretation. The heating-induced gap enhancement phenomenon represents a genuine manifestation of the complex interplay between thermal effects and intrinsic junction physics in strongly-correlated layered superconductors, with significant implications for understanding high-temperature superconductivity mechanisms."
  },
  {
    "id": 67,
    "prompt": "Temperature dependent sound velocity in hydrodynamic equations for relativistic heavy-ion collisions",
    "HWT": "We analyze the effects of different forms of the sound-velocity function cs(T) on the hydrodynamic evolution of matter formed in the central region of relativistic heavy-ion collisions. At high temperatures (above the critical temperature Tc) the sound velocity is calculated from the recent lattice simulations of QCD, while in the low temperature region it is obtained from the hadron gas model. In the intermediate region we use different interpolations characterized by the values of the sound velocity at the local maximum (at T = 0.4 Tc) and local minimum (at T = Tc). In all considered cases the temperature dependent sound velocity functions yield the entropy density, which is consistent with the lattice QCD simulations at high temperature. Our calculations show that the presence of a distinct minimum of the sound velocity leads to a very long (about 20 fm/c) evolution time of the system, which is not compatible with the recent estimates based on the HBT interferometry. Hence, we conclude that the hydrodynamic description is favored in the case where the cross-over phase transition renders the smooth sound velocity function with a possible shallow minimum at Tc.",
    "MGT": "We investigate the temperature dependence of sound velocity in the context of relativistic hydrodynamic equations applied to heavy-ion collision systems. The sound velocity, a fundamental thermodynamic quantity characterizing the medium's response to pressure fluctuations, plays a crucial role in determining the collective flow patterns and energy transport mechanisms in the quark-gluon plasma formed during ultra-relativistic nuclear collisions. Using lattice QCD calculations and phenomenological equations of state, we analyze how the sound velocity varies across the phase transition region from hadronic matter to deconfined quark matter. Our results demonstrate that the sound velocity exhibits a pronounced minimum near the pseudocritical temperature, consistent with the expected softening of the equation of state during the crossover transition. We incorporate these temperature-dependent sound velocity profiles into (2+1)-dimensional viscous hydrodynamic simulations of Au+Au collisions at RHIC and Pb+Pb collisions at LHC energies. The calculations reveal that the temperature dependence significantly affects the evolution of the fireball, particularly influencing the radial and elliptic flow coefficients. Comparison with experimental data shows improved agreement when realistic temperature-dependent sound velocities are employed, suggesting that accurate modeling of this thermodynamic property is essential for precision studies of the QCD phase diagram through heavy-ion collision observables."
  },
  {
    "id": 68,
    "prompt": "Energy spectra of cosmic-ray nuclei at high energies",
    "HWT": "We present new measurements of the energy spectra of cosmic-ray (CR) nuclei from the second flight of the balloon-borne experiment Cosmic Ray Energetics And Mass (CREAM). The instrument included different particle detectors to provide redundant charge identification and measure the energy of CRs up to several hundred TeV. The measured individual energy spectra of C, O, Ne, Mg, Si, and Fe are presented up to $\\sim 10^{14}$ eV. The spectral shape looks nearly the same for these primary elements and it can be fitted to an $E^{-2.66 \\pm 0.04}$ power law in energy. Moreover, a new measurement of the absolute intensity of nitrogen in the 100-800 GeV/$n$ energy range with smaller errors than previous observations, clearly indicates a hardening of the spectrum at high energy. The relative abundance of N/O at the top of the atmosphere is measured to be $0.080 \\pm 0.025 $(stat. )$ \\pm 0.025 $(sys. ) at $\\sim $800 GeV/$n$, in good agreement with a recent result from the first CREAM flight.",
    "MGT": "We present measurements of the energy spectra of cosmic-ray nuclei from protons to iron at energies between 10^14 and 10^17 eV using data collected over seven years of operation. The analysis is based on extensive air shower observations recorded by a hybrid detector system combining surface particle detectors and fluorescence telescopes. Individual nuclear species are identified through a comprehensive reconstruction algorithm that utilizes the correlation between shower maximum depth and the logarithmic mass of the primary particle.\n\nThe measured spectra exhibit a systematic hardening with increasing nuclear charge, consistent with rigidity-dependent acceleration mechanisms. All nuclear components show a gradual steepening around 3×10^15 eV, suggesting a common spectral feature across different species. The proton spectrum displays a spectral index of γ = 2.68 ± 0.02 below the ankle region, while heavier nuclei show progressively harder indices. Iron nuclei demonstrate the hardest spectrum with γ = 2.45 ± 0.05 in the same energy range.\n\nComparison with theoretical models indicates that the observed spectral behavior is compatible with diffusive shock acceleration in supernova remnants, with subsequent galactic propagation effects. The rigidity-dependent cutoff energies support scenarios where different nuclear species reach maximum acceleration energies proportional to their charge. These results provide crucial constraints for understanding cosmic-ray acceleration mechanisms and propagation in the Galaxy, particularly in the transition region between galactic and extragalactic sources."
  },
  {
    "id": 69,
    "prompt": "The enigma of GCIRS 3 - Constraining the properties of the mid-infrared reference star of the central parsec of the Milky Way with optical long baseline interferometry",
    "HWT": "GCIRS3 is the most prominent MIR source in the central pc of the Galaxy. NIR spectroscopy failed to solve the enigma of its nature. The properties of extreme individual objects of the central stellar cluster contribute to our knowledge of star and dust formation close to a supermassive black hole. We initiated an interferometric experiment to understand IRS3 and investigate its properties as spectroscopic and interferometric reference star at 10um. VISIR imaging separates a compact source from diffuse, surrounding emission. The VLTI/MIDI instrument was used to measure visibilities at 10mas resolution of that compact 10um source, still unresolved by a single VLT. Photometry data were added to enable simple SED- and full radiative transfer-models of the data. The luminosity and size estimates show that IRS3 is probably a cool carbon star enshrouded by a complex dust distribution. Dust temperatures were derived. The coinciding interpretation of multiple datasets confirm dust emission at several spatial scales. The IF data resolve the innermost area of dust formation. Despite observed deep silicate absorption towards IRS3 we favor a carbon rich chemistry of the circumstellar dust shell. The silicate absorption most probably takes place in the outer diffuse dust, which is mostly ignored by MIDI measurements. This indicates physically and chemically distinct conditions of the local dust, changing with the distance to IRS3. We have demonstrated that optical long baseline interferometry at infrared wavelengths is an indispensable tool to investigate sources at the Galactic Center. Our findings suggest further studies of the composition of interstellar dust and the shape of the 10um silicate feature at this outstanding region.",
    "MGT": "GCIRS 3, a prominent mid-infrared source located within the central parsec of the Milky Way, has served as a crucial astrometric reference for studying the supermassive black hole Sagittarius A* and its surrounding stellar environment. Despite its importance in Galactic Center observations, the fundamental physical properties of this enigmatic object remain poorly constrained. We present the first comprehensive study of GCIRS 3 using optical long baseline interferometry observations obtained with the Very Large Telescope Interferometer (VLTI) and auxiliary telescopes. Our high angular resolution measurements, spanning multiple epochs between 2019 and 2023, reveal a complex stellar system with evidence for circumstellar material and potential binarity.\n\nThrough detailed modeling of the interferometric visibilities and closure phases, we derive an angular diameter of 2.8 ± 0.3 milliarcseconds for the primary component, corresponding to a linear radius of 850 ± 90 solar radii at the assumed Galactic Center distance of 8.2 kpc. The observed wavelength-dependent visibility variations indicate significant circumstellar extinction, with an estimated visual extinction of AV = 28 ± 4 magnitudes. Our analysis suggests GCIRS 3 is likely a late-type supergiant or asymptotic giant branch star with an effective temperature of 3200 ± 200 K and a luminosity of approximately 105 solar luminosities.\n\nTime-resolved interferometric observations reveal systematic position angle variations consistent with orbital motion, suggesting the presence of a companion star with a projected separation of ~10 AU and an orbital period of several years. These findings have significant implications for using GCIRS 3 as an astrometric reference, as proper motion corrections must account for the intrinsic orbital motion. Our results provide the first direct constraints on the physical properties of this important Galactic Center reference source and demonstrate the power of optical interferometry for resolving stellar structure in highly extinguished environments."
  },
  {
    "id": 70,
    "prompt": "Subvacuum effects of the quantum field on the dynamics of a test particle",
    "HWT": "We study the effects of the electromagnetic subvacuum fluctuations on the dynamics of a nonrelativistic charged particle in a wavepacket. The influence from the quantum field is expected to give an additional effect to the velocity uncertainty of the particle. In the case of a static wavepacket, the observed velocity dispersion is smaller in the electromagnetic squeezed vacuum background than in the normal vacuum background. This leads to the subvacuum effect. The extent of reduction in velocity dispersion associated with this subvacuum effect is further studied by introducing a switching function. It is shown that the slow switching process may make this subvacuum effect insignificant. We also point out that when the center of the wavepacket undergoes non-inertial motion, reduction in the velocity dispersion becomes less effective with its evolution, no matter how we manipulate the nonstationary quantum noise via the choice of the squeeze parameters. The role of the underlying fluctuation-dissipation relation is discussed.",
    "MGT": "I need to write an academic abstract about \"Subvacuum effects of the quantum field on the dynamics of a test particle\" that is approximately 166 words. This sounds like a theoretical physics paper dealing with quantum field theory and particle dynamics in subvacuum states.\n\nKey elements I should include:\n- Subvacuum states in quantum field theory\n- Effects on test particle dynamics\n- Quantum corrections or modifications to classical motion\n- Possibly some mathematical framework\n- Results or conclusions\n- Methodology\n\nLet me draft an abstract that covers these aspects while staying within the word limit and maintaining academic tone.We investigate the influence of subvacuum quantum field fluctuations on the trajectory and dynamical behavior of a classical test particle. By employing the formalism of squeezed vacuum states and negative energy density configurations, we analyze how quantum fields below the vacuum energy threshold modify the standard equations of motion. Our theoretical framework incorporates the expectation value of the stress-energy tensor in subvacuum states and derives the corresponding force corrections acting on the test particle through the semiclassical Einstein equations. We demonstrate that subvacuum field configurations induce anomalous acceleration patterns and trajectory deviations that cannot be explained by classical field theory alone. Numerical simulations reveal that these quantum corrections become particularly pronounced in regions of high field gradient and negative energy density. The results suggest that subvacuum effects may contribute to observable modifications in particle dynamics under extreme conditions, potentially offering new insights into quantum gravity phenomena and cosmological inflation models. Our findings establish a foundation for experimental verification of subvacuum-induced dynamical effects in controlled laboratory settings."
  },
  {
    "id": 71,
    "prompt": "Quantifying parameter errors due to the peculiar velocities of type Ia supernovae",
    "HWT": "The fitting of the observed redshifts and magnitudes of type Ia supernovae to what we would see in homogeneous cosmological models has led to constraints on cosmological parameters. However, in doing such fits it is assumed that the sampled supernovae are moving with the Hubble flow, i.e. that their peculiar velocities are zero. In reality, peculiar velocities will modify supernova data in a way that can impact best-fit cosmological parameters. We theoretically quantify this effect in the nonlinear regime with a Monte-Carlo analysis, using data from semi-analytic galaxy catalogs that are built from the Millennium N-body simulation. We find scaling relations for the errors in best-fit parameters resulting solely from peculiar velocities, as a function of the total number of sources in a supernova survey N and its maximum redshift z_max. For low redshift surveys, we find that these errors can be of the same order of magnitude as the errors due to an intrinsic magnitude scatter of 0.1 mag. For a survey with N=2000 and z_max=1.7, we estimate that the expected peculiar velocity-induced errors in the best-fit cosmological constant density and equation of state can be sigma_Lambda~0.009 and sigma_w~0.01, respectively, which are subdominant to the errors due to the intrinsic scatter. We further find that throwing away supernova data below a redshift z~0.01-0.02 can reduce the combined error, due to peculiar velocities and the intrinsic scatter, but by only about 10%.",
    "MGT": "# Quantifying parameter errors due to the peculiar velocities of type Ia supernovae\n\nType Ia supernovae (SNe Ia) serve as critical standard candles for cosmological distance measurements, yet their peculiar velocities introduce systematic uncertainties that affect cosmological parameter estimation. In this work, we quantitatively assess the impact of these peculiar velocity-induced errors on cosmological parameters derived from SNe Ia observations. Using a comprehensive simulation framework incorporating realistic peculiar velocity fields based on large-scale structure formation models, we analyze how these motions distort the Hubble diagram and propagate into parameter estimation. Our analysis demonstrates that for low-redshift (z < 0.1) supernovae, peculiar velocities can bias the determination of the Hubble constant by up to 1.8% and introduce additional scatter in distance moduli of approximately 0.13 magnitudes. For intermediate-redshift samples (0.1 < z < 0.5), the effects diminish but remain significant for precision cosmology, particularly for dark energy parameters where we find biases of up to 0.05 in the equation of state parameter w. We develop a statistical framework to correct for these biases by modeling the covariance structure of peculiar velocity fields and implementing it in cosmological fitting procedures. When applied to current supernova catalogs, our correction methodology reduces systematic parameter biases by approximately 65% and improves overall constraints by 20-30%. These findings are particularly relevant for upcoming surveys expected to discover thousands of SNe Ia, where even small systematic effects will dominate the error budget of cosmological parameters."
  },
  {
    "id": 72,
    "prompt": "Smallest 90o domains in epitaxial ferroelectric films",
    "HWT": "Ferroelectrics display spontaneous and switchable electrical polarization. Until recently, ferroelectricity was believed to disappear at the nanoscale; now, nano-ferroelectrics are being considered in numerous applications. This renewed interest was partly fuelled by the observation of ferroelectric domains in films of a few unit cells thickness, promising further size reduction of ferroelectric devices. It turns out that at reduced scales and dimensionalities the material's properties depend crucially on the intricacies of domain formation, that is, the way the crystal splits into regions with polarization oriented along the different energetically equivalent directions, typically at 180o and 90o from each other. Here we present a step forward in the manipulation and control of ferroelectric domains by the growth of thin films with regular self-patterned arrays of 90o domains only 7 nm wide. This is the narrowest width for 90o domains in epitaxial ferroelectrics that preserves the film lateral coherence, independently of the substrate.",
    "MGT": "We investigate the minimum size of 90° domains in epitaxial ferroelectric thin films through a combination of phase-field modeling and experimental characterization. Our theoretical framework incorporates elastic energy contributions from domain wall interactions, substrate constraints, and electrostatic depolarization fields to determine the thermodynamically stable domain configurations. Using high-resolution piezoresponse force microscopy and transmission electron microscopy, we characterized domain structures in PbTiO₃ and BaTiO₃ epitaxial films with thicknesses ranging from 10 to 500 nm grown on SrTiO₃ substrates. Results reveal that the smallest stable 90° domains exhibit widths of approximately 3-5 nm, limited by the finite domain wall thickness and elastic energy penalties associated with highly curved domain boundaries. Below this critical size, domains become unstable and either merge with neighboring domains or transform into alternative polarization configurations. The scaling relationship between minimum domain size and film thickness follows a power law with exponent 0.7, consistent with theoretical predictions accounting for substrate clamping effects. These findings provide fundamental insights for designing ferroelectric nanodevices where domain engineering is crucial for functionality."
  },
  {
    "id": 73,
    "prompt": "Contact processes on random graphs with power law degree distributions have critical value 0",
    "HWT": "If we consider the contact process with infection rate $\\lambda$ on a random graph on $n$ vertices with power law degree distributions, mean field calculations suggest that the critical value $\\lambda_c$ of the infection rate is positive if the power $\\alpha>3$. Physicists seem to regard this as an established fact, since the result has recently been generalized to bipartite graphs by G\\'{o}mez-Garde\\~{n}es et al. [Proc. Natl. Acad. Sci. USA 105 (2008) 1399--1404]. Here, we show that the critical value $\\lambda_c$ is zero for any value of $\\alpha>3$, and the contact process starting from all vertices infected, with a probability tending to 1 as $n\\to\\infty$, maintains a positive density of infected sites for time at least $\\exp(n^{1-\\delta})$ for any $\\delta>0$. Using the last result, together with the contact process duality, we can establish the existence of a quasi-stationary distribution in which a randomly chosen vertex is occupied with probability $\\rho(\\lambda)$. It is expected that $\\rho(\\lambda)\\sim C\\lambda^{\\beta}$ as $\\lambda \\to0$. Here we show that $\\alpha-1\\le\\beta\\le2\\alpha-3$, and so $\\beta>2$ for $\\alpha>3$. Thus even though the graph is locally tree-like, $\\beta$ does not take the mean field critical value $\\beta=1$.",
    "MGT": "We investigate the critical behavior of contact processes on random graphs with power law degree distributions, establishing that the critical infection rate is exactly zero. For random graphs where the degree distribution follows a power law with exponent γ ∈ (2,3), we prove that any positive infection rate leads to survival of the epidemic, while zero infection rate results in extinction. This result contrasts sharply with contact processes on regular lattices and finite graphs, where positive critical values typically exist.\n\nOur analysis employs a novel coupling argument combined with branching process techniques to handle the heavy-tailed degree distribution. We construct a dual process that tracks the genealogy of infected vertices and show that the infinite variance of the degree distribution creates sufficient heterogeneity to sustain infection at arbitrarily small rates. The key insight is that high-degree vertices act as persistent infection reservoirs, continuously reinfecting their neighborhoods even under minimal transmission pressure.\n\nWe establish upper and lower bounds on survival probabilities using martingale methods and demonstrate that the critical threshold exhibits a phase transition at γ = 3. For γ > 3, where the degree distribution has finite variance, we show that standard mean-field arguments apply and a positive critical value emerges. However, for γ ∈ (2,3), the scale-free structure fundamentally alters the epidemic dynamics.\n\nOur results have significant implications for understanding disease spread on real-world networks, which often exhibit power law degree distributions. The zero critical value suggests that any infectious disease, regardless of its transmission rate, can potentially establish persistence in highly heterogeneous populations. We also discuss connections to percolation theory and provide numerical simulations confirming our theoretical predictions across various network configurations."
  },
  {
    "id": 74,
    "prompt": "Comparison of covariant and orthogonal Lyapunov vectors",
    "HWT": "Two sets of vectors, covariant and orthogonal Lyapunov vectors (CLVs/OLVs), are currently used to characterize the linear stability of chaotic systems. A comparison is made to show their similarity and difference, especially with respect to the influence on hydrodynamic Lyapunov modes (HLMs). Our numerical simulations show that in both Hamiltonian and dissipative systems HLMs formerly detected via OLVs survive if CLVs are used instead. Moreover the previous classification of two universality classes works for CLVs as well, i.e. the dispersion relation is linear for Hamiltonian systems and quadratic for dissipative systems respectively. The significance of HLMs changes in different ways for Hamiltonian and dissipative systems with the replacement of OLVs by CLVs. For general dissipative systems with nonhyperbolic dynamics the long wave length structure in Lyapunov vectors corresponding to near-zero Lyapunov exponents is strongly reduced if CLVs are used instead, whereas for highly hyperbolic dissipative systems the significance of HLMs is nearly identical for CLVs and OLVs. In contrast the HLM significance of Hamiltonian systems is always comparable for CLVs and OLVs irrespective of hyperbolicity. We also find that in Hamiltonian systems different symmetry relations between conjugate pairs are observed for CLVs and OLVs. Especially, CLVs in a conjugate pair are statistically indistinguishable in consequence of the micro- reversibility of Hamiltonian systems. Transformation properties of Lyapunov exponents, CLVs and hyperbolicity under changes of coordinate are discussed in appendices.",
    "MGT": "# Comparison of covariant and orthogonal Lyapunov vectors\n\nThis paper presents a comprehensive comparison between covariant Lyapunov vectors (CLVs) and orthogonal Lyapunov vectors (OLVs) in the context of dynamical systems analysis. We examine the mathematical foundations, computational methods, and practical applications of both vector types across various chaotic systems. CLVs provide an intrinsic, coordinate-independent representation of tangent space dynamics, preserving the covariant properties of the system, while OLVs form an orthogonal basis that simplifies numerical analysis but lacks invariance under coordinate transformations. Our numerical experiments on low-dimensional chaotic systems (Lorenz-63, Rössler) and spatially extended systems (Kuramoto-Sivashinsky) reveal significant differences in their ability to identify dynamically relevant subspaces and hyperbolicity properties. We demonstrate that CLVs offer superior performance in detecting tangencies between stable and unstable manifolds, enabling more accurate hyperbolicity testing. Additionally, we analyze the computational efficiency of state-of-the-art algorithms for both vector types, finding that while CLVs require approximately 2-3 times more computational resources, their physical interpretability often justifies this cost. The angular distributions between neighboring CLVs provide crucial insights into the system's dynamical structure that OLVs cannot capture. Our findings suggest that while OLVs remain valuable for standard Lyapunov analysis, CLVs should be preferred for detailed studies of tangent space geometry, predictability limits, and dimension reduction in complex dynamical systems."
  },
  {
    "id": 75,
    "prompt": "Chemical control of orbital polarization in artificially structured transition-metal oxides: La2NiXO6 (X=B, Al, Ga, In) from first principles",
    "HWT": "The application of modern layer-by-layer growth techniques to transition-metal oxide materials raises the possibility of creating new classes of materials with rationally designed correlated electron properties. An important step toward this goal is the demonstration that electronic structure can be controlled by atomic composition. In compounds with partially occupied transition-metal d shells, one important aspect of the electronic structure is the relative occupancy of different d orbitals. Previous work has established that strain and quantum confinement can be used to influence orbital occupancy. In this paper we demonstrate a different modality for orbital control in transition-metal oxide heterostructures, using density-functional band calculations supplemented by a tight-binding analysis to show that the choice of nontransition-metal counterion X in transition-metal oxide heterostructures composed of alternating LaNiO3 and LaXO3 units strongly affects orbital occupancy, changing the magnitude and in some cases the sign of the orbital polarization.",
    "MGT": "We investigate the electronic structure and orbital polarization of double perovskite La2NiXO6 compounds (X = B, Al, Ga, In) using density functional theory calculations. Our first-principles analysis reveals that systematic substitution of the X-site cation provides effective chemical control over the Ni 3d orbital occupancy and polarization. The octahedral crystal field splitting varies significantly with X-site ionic radius, directly influencing the energy separation between eg and t2g orbitals. B-site substitution leads to pronounced changes in the Ni-O bond lengths and angles, modulating the orbital hybridization strength. We demonstrate that smaller X cations (B, Al) enhance orbital polarization through increased structural distortions, while larger cations (Ga, In) promote more isotropic orbital occupancy. The calculated electronic band structures exhibit systematic evolution from insulating to metallic behavior as X-site size increases. Magnetic coupling strengths between Ni sites show strong correlation with orbital polarization degree. Our results establish that X-site chemical substitution represents a viable strategy for tuning orbital degrees of freedom in transition-metal oxide heterostructures, with implications for designing materials with tailored electronic and magnetic properties."
  },
  {
    "id": 76,
    "prompt": "Results and questions on a nonlinear approximation approach for solving high-dimensional partial differential equations",
    "HWT": "We investigate mathematically a nonlinear approximation type approach recently introduced in [A. Ammar et al., J. Non-Newtonian Fluid Mech., 2006] to solve high dimensional partial differential equations. We show the link between the approach and the greedy algorithms of approximation theory studied e.g. in [R. A. DeVore and V. N. Temlyakov, Adv. Comput. Math., 1996]. On the prototypical case of the Poisson equation, we show that a variational version of the approach, based on minimization of energies, converges. On the other hand, we show various theoretical and numerical difficulties arising with the non variational version of the approach, consisting of simply solving the first order optimality equations of the problem. Several unsolved issues are indicated in order to motivate further research.",
    "MGT": "This paper investigates a novel nonlinear approximation framework for addressing the computational challenges inherent in high-dimensional partial differential equations. We develop a method that leverages adaptive basis functions combined with sparse representation techniques to overcome the curse of dimensionality that typically renders traditional numerical approaches intractable for problems with dimension greater than four or five. Our theoretical analysis establishes convergence rates for the proposed algorithm under specific regularity assumptions on the solution space. Numerical experiments demonstrate significant computational advantages over conventional finite element and finite difference methods for problems up to dimension twenty, with particular effectiveness observed for elliptic and parabolic equations. However, several fundamental questions remain unresolved, including optimal parameter selection strategies and extension to hyperbolic systems. We present preliminary results suggesting potential applications to quantum many-body problems and financial mathematics, while identifying key theoretical gaps that require further investigation. The work opens new avenues for tackling previously computationally prohibitive high-dimensional scenarios."
  },
  {
    "id": 77,
    "prompt": "On the correct formula for the lifetime broadened superconducting density of states",
    "HWT": "We argue that the well known Dynes formula [Dynes R C {\\it et al. } 1978 {\\it Phys. Rev. Lett. } {\\bf 41} 1509] for the superconducting quasiparticle density of states, which tries to incorporate the lifetime broadening in an approximate way, cannot be justified microscopically for conventional superconductors. Instead, we propose a new simple formula in which the energy gap has a finite imaginary part $-\\Delta_2$ and the quasiparticle energy is real. We prove that in the quasiparticle approximation 2$\\Delta_2$ gives the quasiparticle decay rate at the gap edge for conventional superconductors. This conclusion does not depend on the nature of interactions that cause the quasiparticle decay. The new formula is tested on the case of a strong coupling superconductor Pb$_{0.9}$Bi$_{0.1}$ and an excellent agreement with theoretical predictions is obtained. While both the Dynes formula and the one proposed in this work give good fits and fit parameters for Pb$_{0.9}$Bi$_{0.1}$, only the latter formula can be justified microscopically.",
    "MGT": "The lifetime broadening of quasiparticle states in superconductors fundamentally alters the density of states near the Fermi level, yet inconsistencies persist in the literature regarding the proper theoretical treatment. We present a comprehensive derivation of the correct formula for the lifetime broadened superconducting density of states, resolving discrepancies that have emerged from various approximation schemes. Starting from the Dyson equation for the single-particle Green's function in the presence of both superconducting correlations and finite quasiparticle lifetimes, we demonstrate that the commonly used phenomenological broadening parameter must be applied consistently within the BCS framework. Our analysis reveals that previous formulations often incorrectly treated the broadening as a simple convolution with a Lorentzian, neglecting the energy dependence of the quasiparticle self-energy. The correct expression involves a self-consistent determination of the broadening parameter that preserves the particle-hole symmetry inherent in the superconducting state. We show that this formulation reduces to the standard BCS result in the zero-broadening limit while providing physically meaningful behavior for finite lifetimes. Comparison with tunneling spectroscopy data from various superconducting materials validates our theoretical predictions. These results have important implications for interpreting experimental measurements of the superconducting gap and understanding transport properties in the presence of disorder or strong electron-phonon coupling."
  },
  {
    "id": 78,
    "prompt": "2006 SQ372: A Likely Long-Period Comet from the Inner Oort Cloud",
    "HWT": "We report the discovery of a minor planet (2006 SQ372) on an orbit with a perihelion of 24 AU and a semimajor axis of 796 AU. Dynamical simulations show that this is a transient orbit and is unstable on a timescale of 200 Myrs. Falling near the upper semimajor axis range of the scattered disk and the lower semimajor axis range of the Oort Cloud, previous membership in either class is possible. By modeling the production of similar orbits from the Oort Cloud as well as from the scattered disk, we find that the Oort Cloud produces 16 times as many objects on SQ372-like orbits as the scattered disk. Given this result, we believe this to be the most distant long-period comet ever discovered. Furthermore, our simulation results also indicate that 2000 OO67 has had a similar dynamical history. Unaffected by the \"Jupiter-Saturn Barrier, \" these two objects are most likely long-period comets from the inner Oort Cloud.",
    "MGT": "We report the discovery of 2006 SQ372, an object with a perihelion of 24.2 AU and a semimajor axis of ~800 AU. This object was detected within data from the Sloan Digital Sky Survey (SDSS) as part of a search for trans-Neptunian objects. Follow-up observations confirm its orbit and reveal that it is currently near perihelion. Its orbital elements are consistent with classification as a returning Oort Cloud comet, though its relatively low inclination (i ≈ 19.5°) distinguishes it from most observed long-period comets. Based on its discovery statistics, we estimate that ~10^4 objects of similar size and orbit populate the inner Oort Cloud, with perihelia located beyond Jupiter. This discovery supports models suggesting that the inner Oort Cloud is a significant source of high-perihelion long-period comets. The orbital characteristics of 2006 SQ372 suggest it may have formed in a region between Uranus and Neptune before being scattered outward by giant planet migration, making it an important probe of early Solar System dynamics and outer planetary formation processes. No cometary activity has been detected, despite its current proximity to perihelion."
  },
  {
    "id": 79,
    "prompt": "An Optimal Algorithm to Generate Pointed Trivalent Diagrams and Pointed Triangular Maps",
    "HWT": "A trivalent diagram is a connected, two-colored bipartite graph (parallel edges allowed but not loops) such that every black vertex is of degree 1 or 3 and every white vertex is of degree 1 or 2, with a cyclic order imposed on every set of edges incident to to a same vertex. A rooted trivalent diagram is a trivalent diagram with a distinguished edge, its root. We shall describe and analyze an algorithm giving an exhaustive list of rooted trivalent diagrams of a given size (number of edges), the list being non-redundant in that no two diagrams of the list are isomorphic. The algorithm will be shown to have optimal performance in that the time necessary to generate a diagram will be seen to be bounded in the amortized sense, the bound being independent of the size of the diagrams. That's what we call the CAT property. One objective of the paper is to provide a reusable theoretical framework for algorithms generating exhaustive lists of complex combinatorial structures with attention paid to the case of unlabeled structures and to those generators having the CAT property.",
    "MGT": "This paper presents an efficient algorithm for the systematic generation of pointed trivalent diagrams and their dual counterparts, pointed triangular maps. These combinatorial structures play a fundamental role in algebraic topology, knot theory, and statistical mechanics, where enumeration and classification problems frequently arise. Our algorithm employs a recursive construction method based on vertex insertion and edge subdivision operations, ensuring complete coverage of all topologically distinct configurations while maintaining optimal time complexity.\n\nThe key innovation lies in the implementation of a canonical ordering scheme that eliminates redundant computations and prevents the generation of isomorphic duplicates. We establish a bijective correspondence between pointed trivalent diagrams and pointed triangular maps through a well-defined duality transformation, enabling simultaneous enumeration of both classes. The algorithm achieves O(n³) time complexity for generating all structures with n vertices, representing a significant improvement over existing brute-force approaches.\n\nComputational experiments demonstrate the algorithm's effectiveness across various parameter ranges, successfully generating complete catalogs up to 12 vertices. We provide explicit formulas for counting these structures and verify our results against known sequences in combinatorial databases. The generated diagrams exhibit applications in quantum field theory calculations and statistical mechanical models. This work establishes a robust computational framework for exploring the rich combinatorial landscape of pointed trivalent structures and their geometric duals."
  },
  {
    "id": 80,
    "prompt": "Gauge invariant approach to low-spin anomalous conformal currents and shadow fields",
    "HWT": "Conformal low-spin anomalous currents and shadow fields in flat space-time of dimension greater than or equal to four are studied. Gauge invariant formulation for such currents and shadow fields is developed. Gauge symmetries are realized by involving Stueckelberg and auxiliary fields. Gauge invariant differential constraints for anomalous currents and shadow fields and realization of global conformal symmetries are obtained. Gauge invariant two-point vertices for anomalous shadow fields are also obtained. In Stueckelberg gauge frame, these gauge invariant vertices become the standard two-point vertices of CFT. Light-cone gauge two-point vertices of the anomalous shadow fields are derived. AdS/CFT correspondence for anomalous currents and shadow fields and the respective normalizable and non-normalizable solutions of massive low-spin AdS fields is studied. The bulk fields are considered in modified de Donder gauge that leads to decoupled equations of motion. We demonstrate that leftover on-shell gauge symmetries of bulk massive fields correspond to gauge symmetries of boundary anomalous currents and shadow fields, while the modified (Lorentz) de Donder gauge conditions for bulk massive fields correspond to differential constraints for boundary anomalous currents and shadow fields.",
    "MGT": "We present a comprehensive analysis of low-spin anomalous conformal currents and their corresponding shadow fields using a gauge invariant formulation. Our approach employs a novel framework that maintains manifest gauge invariance throughout the construction of these fields in arbitrary spacetime dimensions d ≥ 4. By introducing a systematic decomposition of the conformal current algebra, we demonstrate the emergence of anomalous scaling dimensions and establish their relationship to the underlying gauge structure. The shadow field formalism is extended to accommodate these anomalous currents, leading to a consistent description of the operator-shadow field correspondence. We derive explicit expressions for two-point correlation functions of these fields and show how gauge invariance constrains their form. Our results reveal a previously unnoticed connection between the anomalous dimensions and the structure of gauge transformations in the shadow field sector. The framework developed here provides a natural setting for studying quantum corrections to conformal field theories and offers new insights into the interplay between gauge symmetry and conformal invariance. These findings have important implications for understanding the role of anomalous dimensions in holographic descriptions and conformal bootstrap applications."
  },
  {
    "id": 81,
    "prompt": "Low-lying magnetic excitations of doubly-closed-shell nuclei and nucleon-nucleon effective interactions",
    "HWT": "We have studied the low lying magnetic spectra of 12C, 16O, 40Ca, 48Ca and 208Pb nuclei within the Random Phase Approximation (RPA) theory, finding that the description of low-lying magnetic states of doubly-closed-shell nuclei imposes severe constraints on the spin and tensor terms of the nucleon-nucleon effective interaction. We have first made an investigation by using four phenomenological effective interactions and we have obtained good agreement with the experimental magnetic spectra, and, to a lesser extent, with the electron scattering responses. Then we have made self-consistent RPA calculations to test the validity of the finite-range D1 Gogny interaction. For all the nuclei under study we have found that this interaction inverts the energies of all the magnetic states forming isospin doublets.",
    "MGT": "We present a comprehensive investigation of magnetic excitations in doubly-closed-shell nuclei using microscopic nuclear structure calculations based on realistic nucleon-nucleon interactions. Our study focuses on the low-energy spectrum of magnetic transitions in 16O, 40Ca, and 208Pb, employing state-of-the-art effective interactions derived from modern nuclear forces. Through the application of random-phase approximation (RPA) methods, we analyze the structure of magnetic dipole (M1) and magnetic quadrupole (M2) transitions. The calculations reveal significant correlations between the effective interaction parameters and the observed excitation energies. Our results demonstrate that the inclusion of tensor force components substantially improves the description of magnetic properties, particularly for the lowest-lying states. The systematic comparison with experimental data shows excellent agreement for transition strengths and energy levels, providing new insights into the role of spin-orbit coupling and meson-exchange currents in nuclear magnetic responses."
  },
  {
    "id": 82,
    "prompt": "Phase transitions in LaFeAsO: structural, magnetic, elastic, and transport properties, heat capacity and Mossbauer spectra",
    "HWT": "We present results from a detailed experimental investigation of LaFeAsO, the parent material in the series of \"FeAs\" based oxypnictide superconductors. Upon cooling this material undergoes a tetragonal-orthorhombic crystallographic phase transition at ~160 K followed closely by an antiferromagnetic ordering near 145 K. Analysis of these phase transitions using temperature dependent powder X-ray and neutron diffraction measurements is presented. A magnetic moment of ~0.35 Bohr magnetons per iron is derived from Mossbauer spectra in the low temperature phase. Evidence of the structural transition is observed at temperatures well above the structural transition (up to near 200 K) in the diffraction data as well as the polycrystalline elastic moduli probed by resonant ultrasound spectroscopy measurements. The effects of the two phase transitions on the transport properties (resistivity, thermal conductivity, Seebeck coefficient, Hall coefficient), heat capacity, and magnetization of LaFeAsO are also reported, including a dramatic increase in the magnitude of the Hall coefficient below 160 K. The results suggest that the structural distortion leads to a localization of carriers on Fe, producing small local magnetic moments which subsequently order antiferromagnetically upon further cooling. Evidence of strong electron-phonon interactions in the high-temperature tetragonal phase is also observed.",
    "MGT": "# Phase transitions in LaFeAsO: structural, magnetic, elastic, and transport properties, heat capacity and Mossbauer spectra\n\nWe report a comprehensive investigation of phase transitions in LaFeAsO, a parent compound of iron-based superconductors. Through systematic measurements of structural, magnetic, elastic, transport properties, heat capacity, and Mössbauer spectra, we identify two distinct phase transitions. The structural transition from tetragonal to orthorhombic symmetry occurs at TS ≈ 155 K, followed by antiferromagnetic ordering at TN ≈ 137 K. Our high-resolution X-ray diffraction confirms the structural distortion, while neutron scattering reveals a striped antiferromagnetic configuration with an ordered moment of 0.36 μB/Fe. Elastic constants measured by ultrasonic techniques show pronounced softening near TS, indicating strong magneto-elastic coupling. Transport measurements demonstrate anisotropic resistivity below TS and a reduction in carrier concentration at both transitions. Heat capacity data exhibit anomalies at both transition temperatures, with the magnetic transition showing a λ-type peak characteristic of second-order phase transitions. 57Fe Mössbauer spectroscopy confirms the magnetic ordering temperature and provides evidence for strong in-plane magnetic anisotropy. The observed sequence of transitions and their coupling highlight the intimate relationship between lattice and magnetic degrees of freedom in iron pnictides. Our results support theoretical models proposing that the structural transition is driven by magnetic fluctuations, providing crucial insights into the complex interplay of structural and magnetic order parameters in these materials."
  },
  {
    "id": 83,
    "prompt": "Controlling exchange bias in Co-CoOx nanoparticles by oxygen content",
    "HWT": "We report on the occurrence of exchange bias on laser-ablated granular thin films composed of Co nanoparticles embedded in amorphous zirconia matrix. The deposition method allows controlling the degree of oxidation of the Co particles by tuning the oxygen pressure at the vacuum chamber (from 2x10^{-5} to 10^{-1} mbar). The nature of the nanoparticles embedded in the nonmagnetic matrix is monitored from metallic, ferromagnetic (FM) Co to antiferromagnetic (AFM) CoOx, with a FM/AFM intermediate regime for which the percentage of the AFM phase can be increased at the expense of the FM phase, leading to the occurrence of exchange bias in particles of about 2 nm in size. For oxygen pressure of about 10-3 mbar the ratio between the FM and AFM phases is optimum with an exchange bias field about 900 Oe at 1.8 K. The mutual exchange coupling between the AFM and FM is also at the origin of the induced exchange anisotropy on the FM leading to high irreversible hysteresis loops, and the blocking of the AFM clusters due to proximity to the FM phase.",
    "MGT": "This study investigates the correlation between oxygen content and exchange bias in cobalt-cobalt oxide (Co-CoOx) nanoparticles synthesized through controlled oxidation processes. We demonstrate precise control over the exchange bias field (HEB) by manipulating the oxygen content in the core-shell structure of these magnetic nanoparticles. Using a combination of X-ray photoelectron spectroscopy (XPS) and high-resolution transmission electron microscopy (HRTEM), we characterized the oxide shell composition and thickness, revealing a direct relationship between oxidation parameters and magnetic properties. The nanoparticles, with average diameters of 15 ± 2 nm, exhibited tunable exchange bias fields ranging from 0.2 to 1.5 kOe at 5 K. Magnetic measurements showed that increasing oxygen content led to enhanced exchange coupling between the ferromagnetic Co core and antiferromagnetic CoOx shell, resulting in larger HEB values. Temperature-dependent studies revealed a blocking temperature of approximately 180 K, above which the exchange bias effect vanishes. Our findings provide crucial insights into the fundamental mechanisms governing exchange bias in core-shell nanostructures and demonstrate a practical approach for tailoring magnetic properties through controlled oxidation, with potential applications in magnetic storage devices and spintronics."
  },
  {
    "id": 84,
    "prompt": "Holography of the Quark Matter Triple Point",
    "HWT": "The quark matter phase diagram is believed to contain two distinguished points, lying on the boundary of the Quark-Gluon Plasma phase: a critical point and a triple point. In the holographic [\"AdS/QCD\"] approach, the region of relatively low chemical potentials around the phase transition near the critical point may be described using generalizations of the Hawking-Page transition. We propose that the \\emph{other} QGP phase line, beginning at the triple point and rising towards the region of extremely high temperatures and chemical potentials, is described instead by a non-perturbative string effect discovered by Seiberg and Witten. Using an assumed position for the critical point, we are able to use this proposal to obtain a holographic lower bound on the temperature of the triple point. Combined with Shuryak's upper bound on this temperature, this leads to a rough estimate of the location of the triple point, at a temperature of around 70 MeV, and a chemical potential of about 1100 MeV.",
    "MGT": "# Holography of the Quark Matter Triple Point\n\nWe report the first holographic construction of a gauge theory phase diagram containing a triple point where three phases of quark matter coexist: confined hadronic matter, deconfined quark-gluon plasma, and color superconducting quark matter. Our model extends the Sakai-Sugimoto framework by incorporating a chemical potential for baryon number and a mechanism for diquark condensation. The triple point emerges at (T_c, μ_c) ≈ (0.15Λ_QCD, 1.2Λ_QCD), where three distinct holographic backgrounds become degenerate in free energy. Remarkably, critical phenomena near this point are characterized by a dynamical critical exponent z ≈ 3, differing from mean-field expectations. We compute the speed of sound across the phase boundaries, finding a significant dip to c_s^2 ≈ 0.1 near the triple point, potentially observable in neutron star mergers. Analysis of quasinormal modes reveals distinct collective excitations in each phase, with a unique soft mode at the triple point corresponding to fluctuations between the three phases. Our results provide a tractable holographic framework for studying strongly-coupled nuclear matter under extreme conditions relevant to neutron star physics and heavy-ion collision experiments."
  },
  {
    "id": 85,
    "prompt": "Stability of pulsar rotational and orbital periods",
    "HWT": "Millisecond and binary pulsars are the most stable astronomical standards of frequency. They can be applied to solving a number of problems in astronomy and time-keeping metrology including the search for a stochastic gravitational wave background in the early universe, testing general relativity, and establishing a new time-scale. The full exploration of pulsar properties requires that proper unbiased estimates of spin and orbital parameters of the pulsar be obtained. These estimates depend essentially on the random noise components present in pulsar timing residuals. The instrumental white noise has predictable statistical properties and makes no harm for interpretation of timing observations, while the astrophysical/geophysical low-frequency noise corrupts them, thus, reducing the quality of tests of general relativity and decreasing the stability of the pulsar time scale.",
    "MGT": "We present a comprehensive analysis of the long-term stability of pulsar rotational and orbital periods using observational data spanning multiple decades. Our study examines 47 isolated pulsars and 23 binary pulsar systems, focusing on period derivatives and their temporal variations. For isolated pulsars, we observe consistent spin-down rates with timing residuals typically below 10 microseconds over observation periods exceeding 20 years. Binary systems demonstrate remarkable orbital stability, with period derivatives consistent with general relativistic predictions within measurement uncertainties. We identify correlations between rotational stability and pulsar age, magnetic field strength, and spin period. Millisecond pulsars exhibit exceptional timing precision, with fractional frequency stabilities approaching 10^-15 over decade-long baselines. Our results confirm that environmental perturbations and intrinsic timing noise remain the primary sources of period instabilities. These findings have significant implications for pulsar timing arrays and tests of fundamental physics, establishing pulsars as among the most stable natural clocks in the universe."
  },
  {
    "id": 86,
    "prompt": "Ad-hoc Limited Scale-Free Models for Unstructured Peer-to-Peer Networks",
    "HWT": "Several protocol efficiency metrics (e.g., scalability, search success rate, routing reachability and stability) depend on the capability of preserving structure even over the churn caused by the ad-hoc nodes joining or leaving the network. Preserving the structure becomes more prohibitive due to the distributed and potentially uncooperative nature of such networks, as in the peer-to-peer (P2P) networks. Thus, most practical solutions involve unstructured approaches while attempting to maintain the structure at various levels of protocol stack. The primary focus of this paper is to investigate construction and maintenance of scale-free topologies in a distributed manner without requiring global topology information at the time when nodes join or leave. We consider the uncooperative behavior of peers by limiting the number of neighbors to a pre-defined hard cutoff value (i.e., no peer is a major hub), and the ad-hoc behavior of peers by rewiring the neighbors of nodes leaving the network. We also investigate the effect of these hard cutoffs and rewiring of ad-hoc nodes on the P2P search efficiency.",
    "MGT": "This paper presents novel ad-hoc limited scale-free models specifically designed for unstructured peer-to-peer networks, addressing the fundamental challenge of maintaining network connectivity while managing resource constraints in decentralized environments. Traditional scale-free models, while effective for large-scale networks, often prove inadequate for smaller, dynamically changing peer-to-peer systems where nodes frequently join and leave the network. Our proposed models incorporate adaptive degree distribution mechanisms that preserve the beneficial properties of scale-free networks while accommodating the inherent limitations of peer-to-peer architectures, including bandwidth constraints, processing capabilities, and storage limitations. The models feature dynamic hub selection algorithms that redistribute network load based on real-time node availability and performance metrics. Through extensive simulation studies involving networks ranging from 100 to 10,000 nodes, we demonstrate that our ad-hoc limited scale-free approach achieves superior performance compared to conventional random and pure scale-free topologies. Results show improvements of 23% in search efficiency, 31% in fault tolerance, and 18% in load balancing while maintaining lower overhead costs. The proposed models exhibit robust behavior under various churn scenarios and provide practical solutions for implementing resilient unstructured peer-to-peer networks in resource-constrained environments."
  },
  {
    "id": 87,
    "prompt": "DFT-based calculation of Coulomb blockade in molecular junction",
    "HWT": "Quantum transport through single molecules is very sensitive to the strength of the molecule-electrode contact. When a molecular junction weakly coupled to external electrodes, charging effects do play an important role (Coulomb blockade regime). In this regime, the non-equilibrium Green function is usually substituted with master equation approaches, which prevents the density functional theory from describing Coulomb blockade in non-equilibrium case. Last year, we proposed an Ansatz to combine the non-equilibrium Green function technique with the equation of motion method. With help of it, Coulomb blockade was obtained by non-equilibrium Green function, and completely agrees with the master equation results [Phys. Rev. B \\textbf{76}, 045408 (2007)]. Here, by the Ansatz, we show a new way to introduce Coulomb blockade correction to DFT calculation in non-equilibrium case. And the characteristics of Coulomb blockade are obtained in the calculation of a $toy$ molecule correctly.",
    "MGT": "This abstract will focus on the DFT-based calculation of Coulomb blockade in molecular junctions. Let me craft a concise academic abstract of approximately 171 words:\n\nWe present a first-principles approach for calculating Coulomb blockade effects in single-molecule junctions by combining density functional theory (DFT) with many-body techniques. Our method addresses the key challenge of accurately determining the charging energy and level alignment in molecular transport, which standard DFT approaches typically fail to capture. Using a localized basis representation, we compute the electronic structure and subsequently extract the molecular many-body Hamiltonian parameters, including on-site Coulomb interactions and molecule-electrode couplings. We demonstrate the efficacy of our approach by applying it to several benchmark systems, including benzene and porphyrin derivatives between gold electrodes. Our calculations successfully reproduce the experimentally observed Coulomb diamonds and conductance features in the stability diagrams. Notably, the computed addition energies and level spacings show excellent agreement with experimental measurements, with deviations below 0.1 eV. This methodology provides a computationally efficient framework for predicting Coulomb blockade phenomena in molecular electronics and offers insights into designing molecules with tailored electron transport properties for future quantum technologies."
  },
  {
    "id": 88,
    "prompt": "A well-posedness theory in measures for some kinetic models of collective motion",
    "HWT": "We present existence, uniqueness and continuous dependence results for some kinetic equations motivated by models for the collective behavior of large groups of individuals. Models of this kind have been recently proposed to study the behavior of large groups of animals, such as flocks of birds, swarms, or schools of fish. Our aim is to give a well-posedness theory for general models which possibly include a variety of effects: an interaction through a potential, such as a short-range repulsion and long-range attraction; a velocity-averaging effect where individuals try to adapt their own velocity to that of other individuals in their surroundings; and self-propulsion effects, which take into account effects on one individual that are independent of the others. We develop our theory in a space of measures, using mass transportation distances. As consequences of our theory we show also the convergence of particle systems to their corresponding kinetic equations, and the local-in-time convergence to the hydrodynamic limit for one of the models.",
    "MGT": "# A well-posedness theory in measures for some kinetic models of collective motion\n\nThis paper develops a comprehensive well-posedness theory for a class of kinetic equations modeling collective behavior with non-local interactions. We establish existence and uniqueness of measure-valued solutions for a family of first-order aggregation models where the velocity field depends on convolution terms involving the unknown measure. Our approach handles singular interaction potentials including Newtonian and Riesz potentials, extending previous results limited to bounded Lipschitz kernels. By introducing a novel metric combining Wasserstein distance with suitable functional norms, we construct solutions via a fixed-point argument in a carefully chosen space of measures. We demonstrate that this framework accommodates various biological and physical models, including Cucker-Smale flocking dynamics and Keller-Segel chemotaxis systems. Our uniqueness results rely on stability estimates in the proposed metric, avoiding traditional approaches that fail for measure data. Several numerical experiments illustrate the sharp interface dynamics and concentration phenomena captured by our measure-valued solutions, confirming the necessity of this functional setting for accurately describing emergent collective behavior."
  },
  {
    "id": 89,
    "prompt": "The origin of a$_{1g}$ and e$_g$' orderings in Na$_x$CoO$_2$",
    "HWT": "It has often been suggested that correlation effects suppress the small e_g' Fermi surface pockets of NaxCoO_2 that are predicted by LDA, but absent in ARPES measurements. It appears that within the dynamical mean field theory (DMFT) the ARPES can be reproduced only if the on-site energy of the eg' complex is lower than that of the a1g complex at the one-electron level, prior to the addition of local correlation effects. Current estimates regarding the order of the two orbital complexes range from -200 meV to 315 meV in therms of the energy difference. In this work, we perform density functional theory calculations of this one-electron splitting \\Delta= \\epsilon_a1g-\\epsilon_e_g' for the full two-layer compound, Na2xCo2O4, accounting for the effects of Na ordering, interplanar interactions and octahedral distortion. We find that \\epsilon a_1g-\\epsilon e_g' is negative for all Na fillings and that this is primarily due to the strongly positive Coulomb field created by Na+ ions in the intercalant plane. This field disproportionately affects the a_1g orbital which protrudes farther upward from the Co plane than the e_g' orbitals. We discuss also the secondary effects of octahedral compression and multi-orbital filling on the value of \\Delta as a function of Na content. Our results indicate that if the e_g' pockets are indeed suppressed that can only be due to nonlocal correlation effects beyond the standard DMFT.",
    "MGT": "We present a comprehensive theoretical investigation into the electronic structure and orbital ordering mechanisms in the sodium cobalt oxide system NaxCoO2. Through detailed density functional theory calculations complemented by dynamical mean-field theory analysis, we elucidate the origin of the peculiar a1g and eg' orbital ordering observed in this material. Our results demonstrate that the interplay between crystal field effects, Coulomb interactions, and Na-vacancy ordering plays a crucial role in determining the electronic ground state. We find that the trigonal distortion of the CoO6 octahedra splits the t2g manifold into a1g and eg' states, with the magnitude of this splitting strongly dependent on the sodium concentration x. The calculated electronic structure reveals that increasing sodium content leads to a systematic enhancement of the a1g-eg' energy separation, primarily driven by changes in the Co-O bond lengths and angles. Furthermore, we identify a subtle competition between local Coulomb interactions and crystal field effects that ultimately determines the orbital occupation sequence. Our findings provide crucial insights into the microscopic mechanism underlying the unusual orbital physics in NaxCoO2, reconciling various experimental observations including angle-resolved photoemission spectroscopy, X-ray absorption, and neutron scattering data. This work establishes a unified theoretical framework for understanding the complex interplay between structural, electronic, and correlation effects in layered cobalt oxides, with implications for their thermoelectric and superconducting properties."
  },
  {
    "id": 90,
    "prompt": "Optimal power allocation for downstream xDSL with per-modem total power constraints: Broadcast Channel Optimal Spectrum Balancing (BC-OSB)",
    "HWT": "Recently, the duality between Multiple Input Multiple Output (MIMO) Multiple Access Channels (MAC) and MIMO Broadcast Channels (BC) has been established under a total power constraint. The same set of rates for MAC can be achieved in BC exploiting the MAC-BC duality formulas while preserving the total power constraint. In this paper, we describe the BC optimal power allo- cation applying this duality in a downstream x-Digital Subscriber Lines (xDSL) context under a total power constraint for all modems over all tones. Then, a new algorithm called BC-Optimal Spectrum Balancing (BC-OSB) is devised for a more realistic power allocation under per-modem total power constraints. The capacity region of the primal BC problem under per-modem total power constraints is found by the dual optimization problem for the BC under per-modem total power constraints which can be rewritten as a dual optimization problem in the MAC by means of a precoder matrix based on the Lagrange multipliers. We show that the duality gap between the two problems is zero. The multi-user power allocation problem has been solved for interference channels and MAC using the OSB algorithm. In this paper we solve the problem of multi-user power allocation for the BC case using the OSB algorithm as well and we derive a computational efficient algorithm that will be referred to as BC-OSB. Simulation results are provided for two VDSL2 scenarios: the first one with Differential-Mode (DM) transmission only and the second one with both DM and Phantom- Mode (PM) transmissions.",
    "MGT": "This paper addresses the problem of optimal power allocation for downstream xDSL systems operating under per-modem total power constraints, introducing the Broadcast Channel Optimal Spectrum Balancing (BC-OSB) framework. In multi-user xDSL networks, the downstream transmission from the Digital Subscriber Line Access Multiplexer (DSLAM) to multiple Customer Premises Equipment (CPE) units exhibits characteristics of a broadcast channel, where crosstalk interference significantly degrades system performance. The proposed BC-OSB algorithm optimizes power allocation across frequency bins and users to maximize system throughput while maintaining individual power constraints for each modem.\n\nThe mathematical formulation treats the downstream xDSL system as a Gaussian broadcast channel with crosstalk coupling, where the optimization objective seeks to maximize the weighted sum-rate subject to per-modem power constraints and quality-of-service requirements. The BC-OSB algorithm employs convex optimization techniques combined with iterative water-filling procedures to achieve optimal power distribution. Unlike traditional approaches that consider aggregate power constraints, our method accounts for practical limitations where each modem has individual power budgets, reflecting realistic deployment scenarios.\n\nSimulation results demonstrate substantial performance improvements compared to existing spectrum balancing techniques. The BC-OSB algorithm achieves up to 35% higher aggregate throughput while ensuring fairness among users through appropriate weight selection. The convergence analysis shows that the algorithm consistently reaches the global optimum within reasonable computational complexity. Performance evaluations across various loop lengths and crosstalk scenarios confirm the robustness of the proposed method.\n\nThe BC-OSB framework provides a practical solution for xDSL network operators seeking to optimize downstream performance while respecting hardware constraints. The algorithm's effectiveness in mitigating crosstalk interference while maximizing spectral efficiency makes it particularly valuable for dense deployment environments where traditional power allocation methods fall short of achieving optimal performance."
  },
  {
    "id": 91,
    "prompt": "Comparing and interpolating distributions on manifold",
    "HWT": "We are interested in comparing probability distributions defined on Riemannian manifold. The traditional approach to study a distribution relies on locating its mean point and finding the dispersion about that point. On a general manifold however, even if two distributions are sufficiently concentrated and have unique means, a comparison of their covariances is not possible due to the difference in local parametrizations. To circumvent the problem we associate a covariance field with each distribution and compare them at common points by applying a similarity invariant function on their representing matrices. In this way we are able to define distances between distributions. We also propose new approach for interpolating discrete distributions and derive some criteria that assure consistent results. Finally, we illustrate with some experimental results on the unit 2-sphere.",
    "MGT": "# Comparing and interpolating distributions on manifold\n\nThis paper introduces a novel framework for comparing and interpolating probability distributions defined on Riemannian manifolds. We extend the theory of optimal transport to the manifold setting by developing a geodesic-based Wasserstein metric that respects the underlying geometry. Our approach employs parallel transport along geodesics to define a meaningful interpolation between distributions that preserves both geometric and probabilistic structures. We prove existence and uniqueness of solutions to the associated manifold-constrained Monge-Kantorovich problem and provide computational methods for approximating these solutions in practice. Experiments on synthetic data and real-world applications in medical imaging, computer vision, and statistical shape analysis demonstrate the efficacy of our method compared to existing techniques. The proposed framework enables natural interpolation between distributions on curved spaces while maintaining intrinsic manifold constraints, offering a principled approach to distribution alignment problems where the underlying space is non-Euclidean. Theoretical convergence guarantees and computational complexity analyses are provided."
  },
  {
    "id": 92,
    "prompt": "USUM: Update Summary Generation System",
    "HWT": "Huge amount of information is present in the World Wide Web and a large amount is being added to it frequently. A query-specific summary of multiple documents is very helpful to the user in this context. Currently, few systems have been proposed for query-specific, extractive multi-document summarization. If a summary is available for a set of documents on a given query and if a new document is added to the corpus, generating an updated summary from the scratch is time consuming and many a times it is not practical/possible. In this paper we propose a solution to this problem. This is especially useful in a scenario where the source documents are not accessible. We cleverly embed the sentences of the current summary into the new document and then perform query-specific summary generation on that document. Our experimental results show that the performance of the proposed approach is good in terms of both quality and efficiency.",
    "MGT": "Here's an academic abstract based on the title \"USUM: Update Summary Generation System\":\n\nThis paper introduces USUM, a novel system for automatically generating concise summaries of updates across multiple document versions. USUM addresses the challenge of information overload by identifying and synthesizing significant changes in evolving document collections. Our approach combines lexical analysis, semantic modeling, and contextual understanding to distinguish substantive modifications from superficial edits. We evaluate USUM on three datasets: software documentation updates, evolving news stories, and academic paper revisions. Results demonstrate that USUM outperforms existing methods by 17.3% on ROUGE-L and 12.6% on BERTScore metrics. Human evaluations confirm that USUM-generated summaries are preferred for clarity and informativeness compared to baseline approaches. The system's modular architecture allows for domain-specific customization while maintaining generalizability. USUM enables users to efficiently track document evolution without exhaustive manual comparison, with particular benefits in collaborative environments where maintaining awareness of changes is critical. We release our implementation and annotated benchmark datasets to facilitate further research in update summarization."
  },
  {
    "id": 93,
    "prompt": "Twisted generalized Weyl algebras, polynomial Cartan matrices and Serre-type relations",
    "HWT": "Twisted generalized Weyl algebras (TGWAs) are defined as the quotient of a certain graded algebra by the maximal graded ideal I with trivial zero component, analogous to how Kac-Moody algebras can be defined. In this paper we introduce the class of locally finite TGWAs, and show that one can associate to such an algebra a polynomial Cartan matrix (a notion extending the usual generalized Cartan matrices appearing in Kac-Moody algebra theory) and that the corresponding generalized Serre relations hold in the TGWA. We also give an explicit construction of a family of locally finite TGWAs depending on a symmetric generalized Cartan matrix C and some scalars. The polynomial Cartan matrix of an algebra in this family may be regarded as a deformation of the original matrix C and gives rise to quantum Serre relations in the TGWA. We conjecture that these relations generate the graded ideal I for these algebras, and prove it in type A_2.",
    "MGT": "We introduce and study a class of twisted generalized Weyl algebras (tGWA) defined by polynomial Cartan matrices. These algebras arise naturally as generalizations of quantum enveloping algebras and exhibit rich algebraic structures. We establish fundamental properties of tGWAs, including their PBW bases and center characterizations, under certain compatibility conditions between the twist automorphisms and the Cartan matrix entries. Our main result demonstrates that these algebras satisfy generalized Serre-type relations, which emerge from the polynomial nature of the Cartan matrix. We prove that when the Cartan matrix is of finite type, the corresponding tGWA is noetherian and has finite Gelfand-Kirillov dimension. Furthermore, we classify all prime ideals in these algebras and show that they form a stratification compatible with the natural filtration. Using representation theory, we construct families of simple weight modules and determine their character formulas. These results provide a new framework for understanding quantum groups and suggest potential applications in mathematical physics, particularly in the study of quantum integrable systems."
  },
  {
    "id": 94,
    "prompt": "Adjusted Bayesian inference for selected parameters",
    "HWT": "We address the problem of providing inference from a Bayesian perspective for parameters selected after viewing the data. We present a Bayesian framework for providing inference for selected parameters, based on the observation that providing Bayesian inference for selected parameters is a truncated data problem. We show that if the prior for the parameter is non-informative, or if the parameter is a \"fixed\" unknown constant, then it is necessary to adjust the Bayesian inference for selection. Our second contribution is the introduction of Bayesian False Discovery Rate controlling methodology, which generalizes existing Bayesian FDR methods that are only defined in the two-group mixture model. We illustrate our results by applying them to simulated data and data froma microarray experiment.",
    "MGT": "This paper presents a novel approach to Bayesian inference when statistical analysis focuses on a subset of model parameters selected through data-driven procedures. Traditional Bayesian methods often exhibit poor frequentist properties when applied to selected parameters, leading to overconfident posterior distributions and inadequate coverage of credible intervals. We develop an adjustment framework that incorporates the selection process into the posterior computation, accounting for the multiplicity and selection bias inherent in parameter subset identification. Our methodology employs a two-stage procedure: first identifying relevant parameters through regularization techniques, then applying corrected prior specifications that reflect the selection uncertainty. Simulation studies demonstrate substantial improvements in coverage probabilities and posterior calibration compared to standard Bayesian approaches. Applications to high-dimensional regression and variable selection problems show the practical utility of our method, particularly in genomics and econometrics where parameter selection is commonplace. The proposed framework maintains computational tractability while providing theoretically justified inference for selected parameters."
  },
  {
    "id": 95,
    "prompt": "Melting of hexane monolayers adsorbed on graphite: the role of domains and defect formation",
    "HWT": "We present the first large-scale molecular dynamics simulations of hexane on graphite that completely reproduces all experimental features of the melting transition. The canonical ensemble simulations required and used the most realistic model of the system: (i) fully atomistic representation of hexane; (ii) explicit site-by-site interaction with carbon atoms in graphite; (iii) CHARMM force field with carefully chosen adjustable parameters of non-bonded interaction; (iv) numerous $\\ge$ 100 ns runs, requiring a total computation time of ca. 10 CPU-years. This has allowed us to determine correctly the mechanism of the transition: molecular reorientation within lamellae without perturbation of the overall adsorbed film structure. We observe that the melted phase has a dynamically reorienting domain-type structure whose orientations reflect that of graphite.",
    "MGT": "The melting behavior of hexane monolayers physisorbed on graphite surfaces has been investigated using molecular dynamics simulations and experimental neutron scattering techniques. Our results reveal a complex two-stage melting process fundamentally different from bulk hexane phase transitions. At low temperatures, hexane molecules form well-ordered commensurate domains aligned with the graphite lattice structure. As temperature increases, the initial melting stage involves the formation of domain boundaries and point defects within the ordered regions, occurring at approximately 15K below the bulk melting point. The second stage corresponds to complete loss of translational order and increased molecular mobility. The substrate-adsorbate interaction strength critically influences domain size and defect density, with stronger interactions promoting larger coherent domains but also creating higher energy barriers for defect migration. These findings demonstrate that surface-mediated melting in physisorbed systems proceeds through distinct microscopic mechanisms involving topological defects, providing fundamental insights into two-dimensional phase transitions and interfacial phenomena relevant to catalysis and surface science applications."
  },
  {
    "id": 96,
    "prompt": "On $p$-adic Gibbs measures of countable state Potts model on the Cayley tree",
    "HWT": "In the present paper we consider countable state $p$-adic Potts model on the Cayley tree. A construction of $p$-adic Gibbs measures which depends on weights $\\l$ is given, and an investigation of such measures is reduced to examination of an infinite-dimensional recursion equation. Studying of the derived equation under some condition on weights, we prove absence of the phase transition. Note that the condition does not depend on values of the prime $p$, and an analogues fact is not true when the number of spins is finite. For homogeneous model it is shown that the recursive equation has only one solution under that condition on weights. This means that there is only one $p$-adic Gibbs measure $\\m_\\l$. The boundedness of the measure is also established. Moreover, continuous dependence the measure $\\m_\\l$ on $\\l$ is proved. At the end we formulate one limit theorem for $\\m_\\l$.",
    "MGT": "In this paper, we investigate the $p$-adic Gibbs measures of a countable state Potts model on the Cayley tree of order $k \\geq 1$. We establish the existence and uniqueness of $p$-adic Gibbs measures through a systematic analysis of the boundary condition problem. Our approach involves studying the nonlinear functional equations arising from the compatibility conditions of the model. We prove that for sufficiently small values of the prime number $p$ and specific ranges of the coupling constant $J$, there exists a unique $p$-adic Gibbs measure. The proof utilizes methods from $p$-adic analysis and the theory of dynamical systems over non-Archimedean fields. Furthermore, we characterize the phase transition behavior in terms of $p$-adic parameters and demonstrate that the critical temperature exhibits a logarithmic dependence on $p$. Our results extend previous work on finite-state Potts models to the countable state case and provide new insights into the structure of $p$-adic statistical mechanics on hierarchical lattices. These findings have potential applications in the study of complex systems with hierarchical organization and non-Archimedean thermodynamics."
  },
  {
    "id": 97,
    "prompt": "Pattern formation during the evaporation of a colloidal nanoliter drop: a numerical and experimental study",
    "HWT": "An efficient way to precisely pattern particles on solid surfaces is to dispense and evaporate colloidal drops, as for bioassays. The dried deposits often exhibit complex structures exemplified by the coffee ring pattern, where most particles have accumulated at the periphery of the deposit. In this work, the formation of deposits during the drying of nanoliter colloidal drops on a flat substrate is investigated numerically and experimentally. A finite-element numerical model is developed that solves the Navier-Stokes, heat and mass transport equations in a Lagrangian framework. The diffusion of vapor in the atmosphere is solved numerically, providing an exact boundary condition for the evaporative flux at the droplet-air interface. Laplace stresses and thermal Marangoni stresses are accounted for. The particle concentration is tracked by solving a continuum advection-diffusion equation. Wetting line motion and the interaction of the free surface of the drop with the growing deposit are modeled based on criteria on wetting angles. Numerical results for evaporation times and flow field are in very good agreement with published experimental and theoretical results. We also performed transient visualization experiments of water and isopropanol drops loaded with polystyrene microsphere evaporating on respectively glass and polydimethylsiloxane substrates. Measured evaporation times, deposit shape and sizes, and flow fields are in very good agreement with the numerical results. Different flow patterns caused by the competition of Marangoni loops and radial flow are shown to determine the deposit shape to be either a ring-like pattern or a homogeneous bump.",
    "MGT": "The evaporation of colloidal drops represents a fundamental process governing pattern formation in numerous technological applications, from inkjet printing to biosensor fabrication. This study investigates the complex dynamics of particle deposition during the evaporation of nanoliter-sized colloidal drops through combined numerical simulations and experimental observations. We examine aqueous suspensions containing silica nanoparticles with diameters ranging from 20 to 200 nanometers at various initial concentrations. Our experimental setup employs high-resolution optical microscopy to track real-time evaporation dynamics and resulting deposit morphologies on hydrophilic glass substrates.\n\nThe numerical model incorporates multiphysics phenomena including fluid flow driven by differential evaporation rates, Marangoni effects, particle transport via advection and diffusion, and dynamic contact line motion. Finite element simulations reveal that evaporation-induced outward flow concentrates particles near the contact line, leading to characteristic ring-like deposits. However, particle size and concentration significantly influence this coffee-ring effect, with smaller particles exhibiting more uniform deposition patterns due to enhanced Brownian motion.\n\nExperimental results demonstrate excellent agreement with numerical predictions, confirming the dominant role of capillary flow in pattern formation. For 50-nanometer particles at moderate concentrations, distinct ring structures emerge with width proportional to initial particle concentration. Conversely, highly concentrated suspensions undergo gelation during evaporation, suppressing fluid flow and yielding more uniform deposits. Temperature gradient analysis reveals that thermal Marangoni flows become significant for volatile solvents, potentially counteracting coffee-ring formation.\n\nThese findings provide fundamental insights into controlling colloidal deposition patterns and offer design principles for applications requiring precise particle placement. The validated computational framework enables prediction and optimization of pattern formation across various particle systems and substrate conditions."
  },
  {
    "id": 98,
    "prompt": "Quantum Radiation of Oscillons",
    "HWT": "Many classical scalar field theories possess remarkable solutions: coherently oscillating, localized clumps, known as oscillons. In many cases, the decay rate of classical small amplitude oscillons is known to be exponentially suppressed and so they are extremely long lived. In this work we compute the decay rate of quantized oscillons. We find it to be a power law in the amplitude and couplings of the theory. Therefore, the quantum decay rate is very different to the classical decay rate and is often dominant. We show that essentially all oscillons eventually decay by producing outgoing radiation. In single field theories the outgoing radiation has typically linear growth, while if the oscillon is coupled to other bosons the outgoing radiation can have exponential growth. The latter is a form of parametric resonance: explosive energy transfer from a localized clump into daughter fields. This may lead to interesting phenomenology in the early universe. Our results are obtained from a perturbative analysis, a non-perturbative Floquet analysis, and numerics.",
    "MGT": "# Quantum Radiation of Oscillons\n\nWe investigate the quantum radiation properties of oscillons—long-lived, localized, oscillating configurations in nonlinear field theories. Using a combination of numerical simulations and semi-analytical techniques, we calculate the quantum radiation rate of these configurations in (3+1) dimensions. Our analysis reveals that quantum effects significantly enhance the decay rate of oscillons compared to their classical counterparts, with the radiation spectrum exhibiting characteristic peaks corresponding to resonant frequencies of the oscillon's internal modes. We demonstrate that this quantum radiation follows a modified form of Hawking's area theorem, where the effective horizon area of the oscillon's potential well determines the radiation temperature. Furthermore, we establish a connection between the oscillon's quantum radiation and its classical stability properties, showing that classically more stable oscillons exhibit suppressed quantum radiation. Our results indicate that quantum radiation ultimately limits the lifetime of all oscillons, regardless of their classical stability properties, with lifetimes scaling approximately as τ ∝ exp(S), where S represents the configurational entropy of the oscillon. These findings have important implications for oscillon formation in the early universe and their potential role as dark matter candidates."
  },
  {
    "id": 99,
    "prompt": "Experimental Results Related to Discrete Nonlinear Schr\\\"odinger Equations",
    "HWT": "In this chapter, we discuss experiments that realize the discrete nonlinear Schr\\\"odinger (DNLS) equations. The relevance of such descriptions arises from the competition of three common features: nonlinearity, dispersion, and a medium to large level of (periodic, quasiperiodic, or random) discreteness in space. DNLS equations have been especially prevalent in atomic and molecular physics in the study of Bose-Einstein condensates in optical lattices or superlattices; and in nonlinear optics in the description of pulse propagation in waveguide arrays and photorefractive crystals. New experiments in both nonlinear optics and Bose-Einstein condensation provide new challenges for DNLS models, and DNLS and related equations have also recently been used to make important predictions in novel physical settings such as the study of composite metamaterials and arrays of superconducting devices.",
    "MGT": "Here's an academic abstract for the given title:\n\nWe present experimental findings on the dynamics of discrete nonlinear Schrödinger equations (DNLSE) in optical waveguide arrays. Our investigation focuses on the interplay between discreteness and nonlinearity, revealing novel localization phenomena not observed in continuous systems. Using femtosecond laser-written waveguide arrays with precisely controlled coupling coefficients, we demonstrate the formation and propagation of discrete solitons under varying nonlinearity conditions. Measurements of power-dependent beam dynamics confirm theoretical predictions regarding threshold behavior for soliton formation. Additionally, we observe discrete diffraction management and discrete modulation instability in these structures. The experimental results are in excellent agreement with numerical simulations of the DNLSE model. Our findings provide direct evidence for the validity of the DNLSE framework in describing nonlinear discrete optical systems and suggest potential applications in optical switching and routing devices. These results also offer insights into analogous phenomena in Bose-Einstein condensates in optical lattices and other discrete nonlinear systems."
  },
  {
    "id": 100,
    "prompt": "High-Resolution Rotation Curves and Galaxy Mass Models from THINGS",
    "HWT": "We present rotation curves of 19 galaxies from THINGS, The HI Nearby Galaxy Survey. The high spatial and velocity resolution of THINGS make these the highest quality HI rotation curves available to date for a large sample of nearby galaxies, spanning a wide range of HI masses and luminosities. The high quality of the data allows us to derive the geometrical and dynamical parameters using HI data alone. We do not find any declining rotation curves unambiguously associated with a cut-off in the mass distribution out to the last measured point. The rotation curves are combined with 3.6 um data from SINGS (Spitzer Infrared Nearby Galaxies Survey) to construct mass models. Our best-fit, dynamical disk masses, derived from the rotation curves, are in good agreement with photometric disk masses derived from the 3.6 um images in combination with stellar population synthesis arguments and two different assumptions for the stellar Initial Mass Function (IMF). We test the Cold Dark Matter-motivated cusp model, and the observationally motivated central density core model and find that (independent of IMF) for massive, disk-dominated galaxies, all halo models fit apparently equally well; for low-mass galaxies, however, a core-dominated halo is clearly preferred over a cuspy halo. The empirically derived densities of the dark matter halos of the late-type galaxies in our sample are half of what is predicted by CDM simulations, again independent of the assumed IMF.",
    "MGT": "# High-Resolution Rotation Curves and Galaxy Mass Models from THINGS\n\nWe present high-resolution rotation curves and mass models for 19 nearby galaxies from The HI Nearby Galaxy Survey (THINGS). Using 3D tilted-ring modeling on high-quality VLA observations with ~6\" angular resolution and ~2.5 km/s velocity resolution, we derive rotation curves with unprecedented accuracy, extending from the inner regions dominated by baryons to the outer parts dominated by dark matter. Our derived rotation curves show remarkable diversity in shape, including slowly rising, steeply rising, and flat curves, reflecting the varied mass distributions across the sample. We quantitatively analyze the mass distributions by decomposing the rotation curves into contributions from stellar disks, gas components, and dark matter halos using both maximum disk models and models with constrained stellar mass-to-light ratios from population synthesis. Our results demonstrate that while the inner rotation curve shapes are primarily determined by the distribution of baryonic matter, non-baryonic dark matter dominates the outer regions in all galaxies. We find that the NFW dark matter profile generally provides better fits than the pseudo-isothermal profile, particularly for galaxies with higher surface brightness. However, several low surface brightness galaxies show significant deviations from NFW predictions, displaying instead the characteristic features of constant density cores. The high quality of our rotation curves allows us to place strong constraints on the inner density slopes of dark matter halos, with important implications for cosmological simulations. This comprehensive analysis of rotation curves and mass models provides crucial observational constraints for understanding galaxy formation and evolution within the ΛCDM framework."
  },
  {
    "id": 101,
    "prompt": "Are Newly Discovered HI High Velocity Clouds Minihalos in the Local Group?",
    "HWT": "A set of HI sources extracted from the north Galactic polar region by the ongoing ALFALFA survey has properties that are consistent with the interpretation that they are associated with isolated minihalos in the outskirts of the Local Group (LG). Unlike objects detected by previous surveys, such as the Compact High Velocity Clouds of Braun & Burton (1999), the HI clouds found by ALFALFA do not violate any structural requirements or halo scaling laws of the LambdaCDM structure paradigm, nor would they have been detected by extant HI surveys of nearby galaxy groups other than the LG. At a distance of d Mpc, their HI masses range between $5 x 10^4 d^2 and 10^6 d^2 solar and their HI radii between <0.4d and 1.6 d kpc. If they are parts of gravitationally bound halos, the total masses would be on order of 10^8--10^9 solar, their baryonic content would be signifcantly smaller than the cosmic fraction of 0.16 and present in a ionized gas phase of mass well exceeding that of the neutral phase. This study does not however prove that the minihalo interpretation is unique. Among possible alternatives would be that the clouds are shreds of the Leading Arm of the Magellanic Stream.",
    "MGT": "Are Newly Discovered HI High Velocity Clouds Minihalos in the Local Group?\n\nWe present an analysis of recently identified compact high velocity clouds (CHVCs) discovered through deep HI surveys and investigate their potential classification as dark matter minihalos within the Local Group. Using data from the GALFA-HI and FAST HI surveys, we identified 47 previously uncatalogued CHVCs with distinct kinematic signatures and column densities of N_HI ≈ 10^18-10^19 cm^-2. The clouds exhibit a spatial distribution consistent with Local Group membership and velocity dispersions ranging from 5-25 km/s. Through dynamical modeling, we demonstrate that these properties are compatible with dark matter-dominated minihalos having M_tot ≈ 10^6-10^8 M_⊙ and M_HI/M_tot ratios of 1-5%. High-resolution follow-up observations reveal systematic morphological differences between these CHVCs and known Galactic high velocity clouds, including more symmetric HI distributions and sharper density boundaries. We detect tentative stellar counterparts in deep optical imaging for three CHVCs, suggesting they may represent a population of extremely low surface brightness dwarf galaxies. These findings are consistent with ΛCDM predictions regarding the abundance of low-mass dark matter halos in the Local Group and may help resolve the \"missing satellites\" problem. If confirmed as minihalos, these objects would constitute the lowest-mass dark matter-dominated structures identified to date and provide crucial constraints on galaxy formation processes in the lowest mass regime."
  },
  {
    "id": 102,
    "prompt": "The occultation events of the Herbig Ae/Be star V1247 Ori",
    "HWT": "Aims: I study new deep (DeltaV ~ 1.20-1.65 mag) occultation events of the delta Scuti, Herbig Ae/Be star V1247 Ori in the Ori OB1 b association. Methods: I use the V-band ASAS light curve of V1247 Ori, which covers the last nine years, together with photometric data in the near-ultraviolet, visible, near-, and far-infrared taken from the literature. I carry out a periodogram analysis of the \"cleaned\" light curve and construct the spectral energy distribution of the star. Results: The star V1247 Ori is interesting for the study of the UX Orionis phenomenon, in which Herbig Ae/Be stars are occulted by their protoplanetary discs, for three reasons: brightness (V ~ 9.85 mag), large infrared excess at 20-100 mum (F_60 ~ 10 Jy), and photometric stability out of occultation (sigma(V) ~ 0.02 mag), which may help to determine the location and spatial structure of the occulting disc clumps.",
    "MGT": "# The occultation events of the Herbig Ae/Be star V1247 Ori\n\nWe report the discovery of multiple occultation events in the Herbig Ae/Be star V1247 Ori, observed through continuous photometric monitoring spanning 2018-2024. These events, characterized by rapid dimming of up to 0.8 magnitudes with durations ranging from 2-14 days, suggest the presence of transiting circumstellar material. Multi-wavelength observations reveal a wavelength-dependent extinction pattern consistent with micron-sized dust particles. Spectroscopic data obtained during occultation events show no significant changes in accretion signatures, distinguishing these events from typical UX Ori-type variability. Our modeling indicates these occultations likely result from dusty clumps in a highly inclined, asymmetric inner disk region at approximately 0.2-0.4 AU from the star. The quasi-periodic nature of these events (recurring at intervals of 32±4 days) and their evolving morphology suggest a dynamic environment potentially shaped by an unseen companion. These findings provide rare observational constraints on the small-scale structure of protoplanetary disks in the terrestrial planet-forming region and may represent direct evidence of ongoing planet formation processes in this young (∼7 Myr) system."
  },
  {
    "id": 103,
    "prompt": "Towards Multimodal Content Representation",
    "HWT": "Multimodal interfaces, combining the use of speech, graphics, gestures, and facial expressions in input and output, promise to provide new possibilities to deal with information in more effective and efficient ways, supporting for instance: - the understanding of possibly imprecise, partial or ambiguous multimodal input; - the generation of coordinated, cohesive, and coherent multimodal presentations; - the management of multimodal interaction (e.g., task completion, adapting the interface, error prevention) by representing and exploiting models of the user, the domain, the task, the interactive context, and the media (e.g. text, audio, video). The present document is intended to support the discussion on multimodal content representation, its possible objectives and basic constraints, and how the definition of a generic representation framework for multimodal content representation may be approached. It takes into account the results of the Dagstuhl workshop, in particular those of the informal working group on multimodal meaning representation that was active during the workshop (see http: //www. dfki. de/~wahlster/Dagstuhl_Multi_Modality, Working Group 4).",
    "MGT": "This paper presents a comprehensive framework for multimodal content representation that integrates textual, visual, and audio information into unified semantic embeddings. Traditional content representation methods typically focus on single modalities, limiting their ability to capture the rich, interconnected nature of multimedia content. Our approach leverages deep learning architectures, specifically transformer-based models and cross-modal attention mechanisms, to learn joint representations that preserve both intra-modal and inter-modal relationships. We introduce a novel alignment strategy that maps features from different modalities into a shared latent space while maintaining modality-specific characteristics through specialized encoding branches. The framework incorporates contrastive learning objectives to enhance semantic coherence across modalities and employs adaptive fusion techniques to handle varying degrees of modal availability and quality. Experimental evaluation on three benchmark datasets demonstrates significant improvements over existing unimodal and multimodal baselines, achieving 15.3% higher accuracy in content classification tasks and 22.7% improvement in cross-modal retrieval performance. Our method shows particular strength in handling incomplete modal inputs, maintaining robust performance even when one or more modalities are missing or corrupted. The proposed framework offers promising applications in multimedia search, content recommendation systems, and automated content analysis, providing a foundation for more sophisticated multimodal understanding systems."
  },
  {
    "id": 104,
    "prompt": "Modeling of the evolution of dielectric loss with processing temperature in ferroelectric and dielectric thin oxide films",
    "HWT": "It was experimentally found that the evolution of dielectric loss with processing temperature displays a common trend in ferroelectric and dielectric thin oxide films: firstly an increase and then a decrease in dielectric loss when the processing temperature is gradually raised. Such a dielectric response of ferroelectric/dielectric thin films has been theoretically addressed in this work. We propose that at the initial stage of the crystallization process in thin films, the transformation from amorphous to crystalline phase should increase substantially the dielectric loss; then, with further increase in the processing temperature, the coalescent growth of small crystalline grains into big ones could be helpful in reducing the dielectric loss by lowering grain boundary densities. The obtained experimental data for (Ba, Sr)TiO3 thin films with 500 nm in thickness were analyzed in terms of the model developed and shown to be in a reasonable agreement with the theoretical results.",
    "MGT": "This study investigates the temperature-dependent evolution of dielectric loss in ferroelectric and dielectric thin oxide films through comprehensive modeling approaches. We developed a theoretical framework incorporating thermally activated relaxation mechanisms, defect migration, and structural phase transitions to predict dielectric loss behavior across processing temperatures ranging from 300°C to 800°C. The model accounts for oxygen vacancy dynamics, grain boundary effects, and interfacial polarization phenomena that significantly influence loss tangent values. Experimental validation was performed using barium titanate, lead zirconate titanate, and hafnium oxide thin films deposited via atomic layer deposition and pulsed laser deposition. Results demonstrate that dielectric loss exhibits non-monotonic temperature dependence, with distinct peaks corresponding to specific defect activation energies and phase transition temperatures. The model successfully predicts a 40% reduction in dielectric loss when processing temperatures are optimized between 450-550°C for BaTiO₃ films. These findings provide critical insights for optimizing processing conditions in capacitor applications, enabling improved device performance through controlled dielectric loss management in next-generation electronic components."
  },
  {
    "id": 105,
    "prompt": "The Rate Loss of Single-Letter Characterization: The \"Dirty\" Multiple Access Channel",
    "HWT": "For general memoryless systems, the typical information theoretic solution - when exists - has a \"single-letter\" form. This reflects the fact that optimum performance can be approached by a random code (or a random binning scheme), generated using independent and identically distributed copies of some single-letter distribution. Is that the form of the solution of any (information theoretic) problem? In fact, some counter examples are known. The most famous is the \"two help one\" problem: Korner and Marton showed that if we want to decode the modulo-two sum of two binary sources from their independent encodings, then linear coding is better than random coding. In this paper we provide another counter example, the \"doubly-dirty\" multiple access channel (MAC). Like the Korner-Marton problem, this is a multi-terminal scenario where side information is distributed among several terminals; each transmitter knows part of the channel interference but the receiver is not aware of any part of it. We give an explicit solution for the capacity region of a binary version of the doubly-dirty MAC, demonstrate how the capacity region can be approached using a linear coding scheme, and prove that the \"best known single-letter region\" is strictly contained in it. We also state a conjecture regarding a similar rate loss of single letter characterization in the Gaussian case.",
    "MGT": "This paper investigates the fundamental limits of communication over the \"dirty\" multiple access channel, where transmitted signals are corrupted by both additive noise and multiplicative interference known non-causally to the transmitters. We establish a comprehensive single-letter characterization of the capacity region for this channel model and quantify the rate loss incurred when transmitters cannot perfectly coordinate their interference mitigation strategies.\n\nThe dirty multiple access channel extends the classical dirty paper coding framework to multi-user scenarios, where multiple transmitters simultaneously communicate with a common receiver in the presence of known interference. Unlike previous approaches that assume perfect coordination, our analysis considers practical scenarios where transmitters have imperfect knowledge of each other's coding strategies, leading to suboptimal interference cancellation.\n\nWe derive tight inner and outer bounds on the capacity region using novel coding techniques that combine dirty paper coding with successive interference cancellation. The converse proof employs a carefully constructed auxiliary random variable that captures the essential dependencies between transmitted signals and known interference. Our achievability scheme demonstrates that the inner bound is achievable through a combination of rate splitting, superposition coding, and coordinated interference pre-subtraction.\n\nThe main contribution is establishing the exact rate loss characterization, showing that imperfect coordination results in a multiplicative penalty that scales logarithmically with the interference-to-noise ratio. Numerical evaluations demonstrate that this rate loss can be significant in high-interference regimes but becomes negligible when interference is weak relative to noise. These results provide fundamental insights for designing practical multiple access systems operating in interference-rich environments with partial channel state information."
  },
  {
    "id": 106,
    "prompt": "Ionization Equilibrium Timescales in Collisional Plasmas",
    "HWT": "Astrophysical shocks or bursts from a photoionizing source can disturb the typical collisional plasma found in galactic interstellar media or the intergalactic medium. The spectrum emitted by this plasma contains diagnostics that have been used to determine the time since the disturbing event, although this determination becomes uncertain as the elements in the plasma return to ionization equilibrium. A general solution for the equilibrium timescale for each element arises from the elegant eigenvector method of solution to the problem of a non-equilibrium plasma described by Masai (1984) and Hughes & Helfand (1985). In general the ionization evolution of an element Z in a constant electron temperature plasma is given by a coupled set of Z+1 first order differential equations. However, they can be recast as Z uncoupled first order differential equations using an eigenvector basis for the system. The solution is then Z separate exponential functions, with the time constants given by the eigenvalues of the rate matrix. The smallest of these eigenvalues gives the scale of slowest return to equilibrium independent of the initial conditions, while conversely the largest eigenvalue is the scale of the fastest change in the ion population. These results hold for an ionizing plasma, a recombining plasma, or even a plasma with random initial conditions, and will allow users of these diagnostics to determine directly if their best-fit result significantly limits the timescale since a disturbance or is so close to equilibrium as to include an arbitrarily-long time.",
    "MGT": "# Ionization Equilibrium Timescales in Collisional Plasmas\n\nWe present a comprehensive analysis of ionization equilibrium timescales in collisional plasmas across a wide range of temperatures and densities. While previous studies have often assumed instantaneous equilibration, our work demonstrates that the characteristic timescales required to reach ionization equilibrium can vary by orders of magnitude depending on plasma conditions. Using a coupled system of rate equations incorporating electron-impact ionization, radiative and dielectronic recombination, and charge exchange processes, we model the temporal evolution of ionic abundances for elements from hydrogen to iron. Our simulations reveal that low-density astrophysical plasmas (n_e < 10^8 cm^-3) can require equilibration times exceeding 10^5 seconds at temperatures below 10^6 K, with significant implications for the interpretation of spectroscopic observations of supernova remnants, stellar winds, and the warm-hot intergalactic medium. Conversely, laboratory plasmas at densities above 10^19 cm^-3 approach equilibrium within nanoseconds. We identify a critical threshold in the n_e-T_e parameter space where the equilibration timescale equals the dynamical timescale of the system, providing a quantitative criterion for the validity of equilibrium assumptions in plasma modeling. Furthermore, we demonstrate that non-equilibrium ionization can significantly alter inferred elemental abundances and plasma temperatures when derived from line ratio diagnostics. Our results provide correction factors and analytical approximations for equilibration timescales as functions of electron temperature and density, enabling more accurate interpretation of spectroscopic data from both astrophysical and laboratory plasmas. These findings have particular relevance for time-dependent phenomena such as shock waves, rapid heating/cooling processes, and plasma instabilities, where the assumption of ionization equilibrium may lead to substantial systematic errors in derived plasma parameters."
  },
  {
    "id": 107,
    "prompt": "Gene regulation in continuous cultures: A unified theory for bacteria and yeasts",
    "HWT": "During batch growth on mixtures of two growth-limiting substrates, microbes consume the substrates either sequentially or simultaneously. These growth patterns are manifested in all types of bacteria and yeasts. The ubiquity of these growth patterns suggests that they are driven by a universal mechanism common to all microbial species. In previous work, we showed that a minimal model accounting only for enzyme induction and dilution explains the phenotypes observed in batch cultures of various wild-type and mutant/recombinant cells. Here, we examine the extension of the minimal model to continuous cultures. We show that: (1) Several enzymatic trends, usually attributed to specific regulatory mechanisms such as catabolite repression, are completely accounted for by dilution. (2) The bifurcation diagram of the minimal model for continuous cultures, which classifies the substrate consumption pattern at any given dilution rate and feed concentrations, provides a a precise explanation for the empirically observed correlation between the growth patterns in batch and continuous cultures. (3) Numerical simulations of the model are in excellent agreement with the data. The model captures the variation of the steady state substrate concentrations, cell densities, and enzyme levels during the single- and mixed-substrate growth of bacteria and yeasts at various dilution rates and feed concentrations. (4) This variation is well-approximated by simple analytical expressions that furnish physical insights into the steady states of continuous cultures. The minimal model provides a framework for quantitating the effect of regulatory mechanisms. We illustrate this by analyzing several data sets from the literature.",
    "MGT": "# Gene regulation in continuous cultures: A unified theory for bacteria and yeasts\n\nThis study presents a comprehensive theoretical framework for understanding gene regulation mechanisms in continuous cultures across bacterial and yeast systems. We integrate experimental data from chemostat cultures with mathematical modeling to elucidate the fundamental principles governing cellular responses to nutrient limitation. Our unified theory addresses the long-standing question of how microorganisms dynamically regulate gene expression in response to environmental changes while maintaining homeostasis. Through systematic analysis of transcriptomic and proteomic data from Escherichia coli and Saccharomyces cerevisiae grown under carbon, nitrogen, and phosphorus limitations, we identified conserved regulatory motifs that operate across these evolutionarily distant organisms. The mathematical model we developed incorporates feedback control mechanisms, resource allocation constraints, and growth rate-dependent parameters to accurately predict gene expression patterns under various nutrient-limited conditions. Our results reveal that despite differences in cellular complexity, bacteria and yeasts employ remarkably similar strategies for nutrient sensing and metabolic adaptation, including shared transcription factor networks and post-translational modification cascades. We demonstrate that growth rate serves as a global coordinator of gene expression in both organisms, with specific regulatory elements fine-tuning the response to particular limiting nutrients. Furthermore, our model successfully predicts previously unexplained phenomena, such as the paradoxical upregulation of certain metabolic pathways during nutrient limitation. These findings provide a theoretical foundation for understanding microbial adaptation in natural environments and industrial bioprocesses, with implications for metabolic engineering and synthetic biology applications. The unified framework presented here bridges the gap between bacterial and eukaryotic regulatory systems, offering new insights into the evolutionary conservation of fundamental regulatory principles governing cellular growth and adaptation."
  },
  {
    "id": 108,
    "prompt": "Phase diagram of chiral quark matter: Fulde-Ferrell pairing from weak to strong coupling",
    "HWT": "We calculate the phase diagram of two-flavor quark matter in the temperature-flavor asymmetry plane in the case where there are three competing phases: the homogeneous Bardeen-Cooper-Schrieffer (BCS) phase, the unpaired phase, and a phase with broken spatial symmetry, which is here taken to be the counterpart of the Fulde-Ferrell (FF) phase in condensed matter physics. We show that the system belongs to the universality class of paramagnetic-ferromagnetic -helical systems. We vary the coupling constant of the theory, which is obtained from integrating out the gluonic degrees of freedom. In weak coupling, the FF phase is favored at arbitrary flavor asymmetries for sufficiently low temperatures; at intermediate coupling its occupancy domain is shifted towards larger asymmetries. Strong coupling features a new regime of an inhomogeneous FF state, which we identify with a current-carrying Bose-Einstein condensate of tightly bound up and down quarks. We analyze the occupation numbers and the Cooper-pair wave function and show that when the condensate momentum is orthogonal to the particle momentum the minority component contains a blocking region (breach) around the Fermi sphere in the weak-coupling limit, which engulfs more low-momentum modes as the coupling is increased, and eventually leads to a topological change in strong coupling, where the minority Fermi sphere contains either two occupied strips or an empty sphere. For non-orthogonal momenta, the blocking region is either reduced or extinct, i.e., no topological changes are observed.",
    "MGT": "# Phase diagram of chiral quark matter: Fulde-Ferrell pairing from weak to strong coupling\n\nWe investigate the phase diagram of chiral quark matter with an imbalance between different fermion species, focusing on the emergence of Fulde-Ferrell (FF) pairing across coupling regimes. Using a Nambu–Jona-Lasinio model extended with vector interactions, we perform a comprehensive analysis of competing phases at finite temperature, chemical potential, and fermion asymmetry. Our calculations reveal that the FF phase occupies a significant region in the phase diagram, particularly at intermediate coupling strengths. In the weak coupling regime, we observe a BCS-FF-normal phase transition sequence with increasing asymmetry, consistent with BCS theory predictions. As coupling strength increases toward the BEC regime, the FF phase expands substantially, demonstrating enhanced stability against both thermal fluctuations and chemical potential imbalance. Our results indicate that the FF phase serves as a robust intermediate state between homogeneous superfluid and normal phases across a wide parameter range. We identify a critical coupling strength beyond which the FF phase becomes energetically favorable over the homogeneous BCS state even at small asymmetries. The vector interaction is found to significantly modify the phase boundaries, enhancing FF phase stability in specific regions of the phase diagram. These findings have important implications for understanding color superconductivity in dense quark matter, potentially relevant to neutron star cores and heavy-ion collision experiments. Our work provides a unified framework for understanding inhomogeneous pairing from weak to strong coupling regimes, bridging previous theoretical approaches that were limited to specific coupling domains."
  },
  {
    "id": 109,
    "prompt": "Coulomb gas transitions in three-dimensional classical dimer models",
    "HWT": "Close-packed, classical dimer models on three-dimensional, bipartite lattices harbor a Coulomb phase with power-law correlations at infinite temperature. Here, we discuss the nature of the thermal phase transition out of this Coulomb phase for a variety of dimer models which energetically favor crystalline dimer states with columnar ordering. For a family of these models we find a direct thermal transition from the Coulomb phase to the dimer crystal. While some systems exhibit (strong) first-order transitions in correspondence with the Landau-Ginzburg-Wilson paradigm, we also find clear numerical evidence for continuous transitions. A second family of models undergoes two consecutive thermal transitions with an intermediate paramagnetic phase separating the Coulomb phase from the dimer crystal. We can describe all of these phase transitions in one unifying framework of candidate field theories with two complex Ginzburg-Landau fields coupled to a U(1) gauge field. We derive the symmetry-mandated Ginzburg-Landau actions in these field variables for the various dimer models and discuss implications for their respective phase transitions.",
    "MGT": "# Coulomb gas transitions in three-dimensional classical dimer models\n\nWe report a comprehensive study of phase transitions in three-dimensional classical dimer models using Monte Carlo simulations and analytical methods. Our work reveals that these systems exhibit Coulomb gas behavior characterized by algebraic correlations and emergent gauge fields. By introducing a height field representation, we demonstrate that the dimers can be mapped to a compact U(1) gauge theory. The model undergoes a continuous phase transition between a Coulomb phase with gapless, linearly dispersing photons and a confined phase with conventional order. Critical exponents extracted from finite-size scaling analysis (ν = 0.63 ± 0.02, η = 0.02 ± 0.01) suggest the transition belongs to the 3D XY universality class, consistent with the duality between the dimer model and the XY model. We also observe a topological constraint on monopole configurations that leads to an unusual screening of the Coulomb interaction at the transition point. These results establish three-dimensional dimer models as an important platform for studying deconfined quantum criticality and provide experimental predictions for quantum spin liquids in pyrochlore antiferromagnets where the dimer degrees of freedom naturally emerge."
  },
  {
    "id": 110,
    "prompt": "Self-Force Calculations with Matched Expansions and Quasinormal Mode Sums",
    "HWT": "We present the first application of the Poisson-Wiseman-Anderson method of matched expansions, to compute the self-force acting on a point particle moving in a curved spacetime. The method uses two expansions for the Green function, valid in `quasilocal' and `distant past' regimes, which are matched within the normal neighbourhood. We perform our calculation in a static region of the spherically symmetric Nariai spacetime (dS_2 x S^2), on which scalar perturbations are governed by a radial equation with a P\\\"oschl-Teller potential. We combine (i) a very high order quasilocal expansion, and (ii) an expansion in quasinormal modes, to determine the Green function globally. We show it is singular everywhere on the null wavefront (even outside the normal neighbourhood), and apply asymptotic methods to determine its singular structure. We find the Green function undergoes a transition every time the null wavefront passes through a caustic: the singular part follows a repeating four-fold sequence $\\delta(\\sigma)$, $1/\\pi \\sigma$, $-\\delta(\\sigma)$, $-1/\\pi \\sigma$ etc., where $\\sigma$ is Synge's world function. The matched expansion method provides new insight into the non-local properties of the self-force; we find the contribution from the segment of the worldline lying outside the normal neighbourhood is significant. We compute the scalar self-force acting on a static particle, and validate against an alternative method. Finally, we discuss wave propagation on black hole spacetimes (where any expansion in quasinormal modes will be augmented by a branch cut integral) and predict that the Green function in Schwarzschild spacetime will inherit the four-fold singular structure found here.",
    "MGT": "# Self-Force Calculations with Matched Expansions and Quasinormal Mode Sums\n\nWe present a novel computational framework for self-force calculations in black hole perturbation theory, combining matched expansions with quasinormal mode (QNM) summation techniques. This approach addresses longstanding challenges in modeling extreme mass-ratio inspirals (EMRIs), crucial sources for future space-based gravitational wave detectors. Our method resolves the notorious difficulty of calculating the self-force in strong-field regions near black hole horizons, where traditional numerical techniques often struggle with convergence issues.\n\nBy implementing a hybrid scheme that matches near-horizon expansions with QNM sums in intermediate regions, we achieve exponential convergence for the retarded Green function, even in regimes previously requiring prohibitive computational resources. The method decomposes the self-force into regular and singular components, treating the singular field analytically through a careful multiscale expansion that captures the essential geometry near the worldline.\n\nFor Schwarzschild spacetime, we demonstrate that our approach reduces computational costs by two orders of magnitude compared to standard time-domain methods while maintaining accuracy to within 10^(-8) relative error. For Kerr spacetime, where mode coupling presents additional challenges, our technique employs a novel basis of spheroidal harmonics that diagonalizes the perturbation equations to high precision.\n\nParticularly noteworthy is our method's efficiency in calculating dissipative effects for eccentric and inclined orbits, where traditional approaches require extensive mode-sum regularization. We provide explicit analytical formulas for the regularization parameters through fifth order in the coordinate expansion, generalizing previous results limited to equatorial orbits.\n\nThe framework is implemented in an open-source code package that enables rapid calculation of gravitational waveforms for generic orbits around rotating black holes. This development significantly advances our capability to model EMRIs throughout their inspiral phase, producing template banks necessary for signal extraction and parameter estimation with the Laser Interferometer Space Antenna (LISA). Our results demonstrate that accurate self-force calculations are now feasible for the thousands of orbital configurations needed for comprehensive EMRI data analysis."
  },
  {
    "id": 111,
    "prompt": "Nuclear Structure in 146Gd",
    "HWT": "In this work the experimental study of the 144Sm(alpha, 2n) fusion-evaporation reaction is presented. The experiment was carried out at the IKP of the University of Cologne in order to identify double octupole states and two-particle configurations in the 146Gd nucleus. The target was surrounded by a compact array of nine individual Ge detectors and one EUROBALL CLUSTER detector. A total of 44 new states have been identified, as well as new gamma rays corresponding to 26 previously known levels. Among these levels, new candidates for the two-particle configuration states have been found as well as for the (3- x 2+) and (3- x 3-) two phonon multiplets. A very important results of this work is the unequivocal assignment of the 6- member of the two phonon octupole state in 146Gd by identifying the E3 branching to the one phonon 3- state. This result presents the first conclusive observation of a 6+ to 3- to 0+ double E3 cascade in the decay of a two-phonon octupole state.",
    "MGT": "# Nuclear Structure in 146Gd\n\nWe report on a comprehensive investigation of the nuclear structure of the neutron-deficient nucleus 146Gd (Z=64, N=82). High-spin states in 146Gd were populated through the 114Cd(36Ar,4n)146Gd fusion-evaporation reaction at beam energies of 165 and 175 MeV. The level scheme has been significantly extended using γ-γ coincidence analysis, angular correlation measurements, and linear polarization determination. We identified several new excited states up to spin I=25ℏ and excitation energy of approximately 13 MeV. The observed level structure reveals a rich interplay between single-particle excitations across the N=82 shell gap and collective phenomena. The yrast sequence exhibits a transition from spherical structures at low spin to moderately deformed configurations at higher excitation energies. Shell model calculations using a realistic interaction in the πg7/2, πd5/2, πd3/2, πs1/2, πh11/2 proton model space, coupled with neutron excitations across the N=82 gap, reproduce the experimental level scheme remarkably well. Our results provide crucial information about the robustness of the N=82 shell closure in this region and contribute to the systematic understanding of nuclear structure evolution in neutron-deficient nuclei near doubly-magic 146Gd."
  },
  {
    "id": 112,
    "prompt": "Incommensurate spin-density wave and magnetic lock-in transition in CaFe4As3",
    "HWT": "The magnetic structure for the newly discovered iron-arsenide compound \\CaFeAs has been studied by neutron powder diffraction. Long-range magnetic order is detected below 85K, with an incommensurate modulation described by the propagation vector k=(0, $\\delta$,0), $\\delta\\sim$ 0.39. Below $\\sim$ 25K, our measurements detect a first-order phase transition where $\\delta$ locks into the commensurate value 3/8. A model of the magnetic structure is proposed for both temperature regimes, based on Rietveld refinements of the powder data and symmetry considerations. The structures correspond to longitudinal spin-density-waves with magnetic moments directed along the \\textit{b}-axis. A Landau analysis captures the change in thermodynamic quantities observed at the two magnetic transitions, in particular the drop in resistivity at the lock-in transition.",
    "MGT": "We report a comprehensive investigation of the magnetic properties in CaFe4As3 using neutron scattering, magnetization measurements, and theoretical calculations. Below TN = 90 K, CaFe4As3 develops an incommensurate spin-density wave (SDW) with propagation vector q = (0, 0, 0.37) that differs from the commensurate antiferromagnetic ordering observed in related iron-based compounds. The magnetic moments align predominantly along the crystallographic c-axis with an ordered moment of 0.8 μB per iron atom at 5 K. Upon cooling below T* = 26 K, we observe a magnetic lock-in transition where the incommensurate SDW becomes commensurate with q = (0, 0, 1/3), accompanied by a structural distortion and enhancement of magnetic correlations. First-principles calculations reveal that competing exchange interactions and Fermi surface nesting drive the formation of the incommensurate state, while magnetoelastic coupling stabilizes the low-temperature commensurate phase. These results demonstrate the crucial role of magnetic frustration in determining the ground state properties of quasi-one-dimensional iron arsenides."
  },
  {
    "id": 113,
    "prompt": "The Order of Phase Transitions in Barrier Crossing",
    "HWT": "A spatially extended classical system with metastable states subject to weak spatiotemporal noise can exhibit a transition in its activation behavior when one or more external parameters are varied. Depending on the potential, the transition can be first or second-order, but there exists no systematic theory of the relation between the order of the transition and the shape of the potential barrier. In this paper, we address that question in detail for a general class of systems whose order parameter is describable by a classical field that can vary both in space and time, and whose zero-noise dynamics are governed by a smooth polynomial potential. We show that a quartic potential barrier can only have second-order transitions, confirming an earlier conjecture [1]. We then derive, through a combination of analytical and numerical arguments, both necessary conditions and sufficient conditions to have a first-order vs. a second-order transition in noise-induced activation behavior, for a large class of systems with smooth polynomial potentials of arbitrary order. We find in particular that the order of the transition is especially sensitive to the potential behavior near the top of the barrier.",
    "MGT": "# The Order of Phase Transitions in Barrier Crossing\n\nWe investigate the nature of phase transitions in barrier crossing phenomena across diverse physical systems. By analyzing the free energy landscapes of thermal and quantum mechanical barrier crossing processes, we demonstrate that the order of the phase transition depends critically on the barrier geometry and underlying symmetries. Our numerical simulations, based on path integral techniques and transition state theory, reveal that systems with symmetric double-well potentials undergo second-order phase transitions characterized by continuous changes in the order parameter. In contrast, asymmetric barriers exhibit first-order transitions with discontinuous jumps in crossing rates. We develop a universal scaling relation that accurately predicts the critical exponents governing these transitions across temperature regimes. Importantly, we identify a previously unrecognized crossover regime where mixed-order transitions occur, displaying characteristics of both first and second-order behavior. These findings provide a unifying framework for understanding diverse phenomena including protein folding kinetics, chemical reaction dynamics, and quantum tunneling processes. Our results suggest that the apparent differences in transition behaviors across disciplines can be reconciled through careful consideration of the underlying energy landscape topology, offering new opportunities for controlling barrier crossing processes in both classical and quantum systems."
  },
  {
    "id": 114,
    "prompt": "Implication of the observable spectral cutoff energy evolution in XTE J1550-564",
    "HWT": "The physical mechanisms responsible for production of the non-thermal emission in accreting black holes (BH) should be imprinted in the observational apperances of the power law tails in the X-ray spectra from these objects. Different spectral states exhibited by galactic BH binaries allow examination of the photon upscattering under different accretion regimes. We revisit the data collected by Rossi X-ray Timing Explorer (RXTE) from the BH X-ray binary XTE J1550-564 during two periods of X-ray activity in 1998 and 2000 focusing on the behavior of the high energy cutoff of the power law part of the spectrum. For the 1998 outburst the transition from the low-hard state to the intermediate state was accompanied by a gradual decrease in the cutoff energy which then showed an abrupt reversal to a clear increasing trend as the source evolved to the very high and high-soft states. The 2000 outburst showed only the decreasing part of this pattern. Notably, the photon indexes corresponding to the cutoff increase for the 1998 event are much higher than the index values reached during the 2000 rise transition. We attribute this difference in the cutoff energy behavior to the different partial contributions of the thermal and non-thermal (bulk motion) Comptonization in photon upscattering. Namely, during the 1998 event the higher accretion rate presumably provided more cooling to the Comptonizing media and thus reducing the effectiveness of the thermal upscattering process. Under these conditions the bulk motion takes a leading role in boosting the input soft photons. Monte Carlo simulations of the Comptonization in a bulk motion region near an accreting black hole by Laurent & Titarchuk 2010 strongly support this scenario.",
    "MGT": "We present a comprehensive analysis of the spectral evolution of the black hole binary XTE J1550-564 during its 1998-1999 outburst, focusing on the temporal behavior of the high-energy cutoff in its X-ray spectrum. Using archival data from the Rossi X-ray Timing Explorer (RXTE), we systematically tracked the evolution of the exponential cutoff energy (Ecut) throughout different spectral states of the outburst. Our spectral fitting employed a combination of multi-color disk blackbody and Comptonization models to characterize the continuum emission, with particular attention to the high-energy rollover that provides crucial insights into the physical conditions of the Comptonizing corona.\n\nThe analysis reveals a clear correlation between the cutoff energy and the source's spectral state transitions. During the hard state, Ecut remains relatively stable at ~150-200 keV, consistent with a hot, optically thin corona. As the source transitions through the hard-intermediate state, we observe a systematic decrease in the cutoff energy to ~80-120 keV, accompanied by an increase in the soft disk component. The soft state shows the lowest cutoff energies (~50-80 keV), indicating significant cooling of the corona as the accretion rate increases and the disk extends closer to the black hole.\n\nWe interpret these findings within the framework of disk-corona coupling models, where the observed cutoff evolution reflects changes in the coronal temperature and optical depth as the accretion geometry evolves. The systematic decrease in Ecut during state transitions suggests enhanced cooling of the corona through increased soft photon input from the geometrically thin disk. Our results provide strong observational support for models predicting coronal cooling during high-luminosity phases and demonstrate that spectral cutoff monitoring serves as a powerful diagnostic tool for understanding accretion physics in stellar-mass black holes. These findings have broader implications for interpreting similar spectral evolution patterns observed in other black hole transients."
  },
  {
    "id": 115,
    "prompt": "Time Step Expansions and the Invariant Manifold Approach to Lattice Boltzmann Models",
    "HWT": "The classical method for deriving the macroscopic dynamics of a lattice Boltzmann system is to use a combination of different approximations and expansions. Usually a Chapman-Enskog analysis is performed, either on the continuous Boltzmann system, or its discrete velocity counterpart. Separately a discrete time approximation is introduced to the discrete velocity Boltzmann system, to achieve a practically useful approximation to the continuous system, for use in computation. Thereafter, with some additional arguments, the dynamics of the Chapman-Enskog expansion are linked to the discrete time system to produce the dynamics of the completely discrete scheme. In this paper we put forward a different route to the macroscopic dynamics. We begin with the system discrete in both velocity space and time. We hypothesize that the alternating steps of advection and relaxation, common to all lattice Boltzmann schemes, give rise to a slow invariant manifold. We perform a time step expansion of the discrete time dynamics using the invariance of the manifold. Finally we calculate the dynamics arising from this system. By choosing the fully discrete scheme as a starting point we avoid mixing approximations and arrive at a general form of the microscopic dynamics up to the second order in the time step. We calculate the macroscopic dynamics of two commonly used lattice schemes up to the first order, and hence find the precise form of the deviation from the Navier-Stokes equations in the dissipative term, arising from the discretization of velocity space. Finally we perform a short wave perturbation on the dynamics of these example systems, to find the necessary conditions for their stability.",
    "MGT": "# Time Step Expansions and the Invariant Manifold Approach to Lattice Boltzmann Models\n\nThis paper presents a novel theoretical framework unifying time step expansions and invariant manifold techniques for the analysis and construction of lattice Boltzmann models. We demonstrate that the conventional Chapman-Enskog expansion can be reformulated as a special case within our generalized framework, which provides deeper insights into the stability and accuracy limitations of existing lattice Boltzmann methods. By introducing a systematic hierarchy of time-dependent invariant manifolds, we establish formal connections between the microscopic collision dynamics and the emergent macroscopic behavior across multiple time scales. Our analysis reveals that higher-order lattice Boltzmann models can be systematically derived by projecting the full Boltzmann dynamics onto these invariant manifolds, leading to superior numerical stability in regimes previously considered challenging. The theoretical predictions are validated through numerical experiments for flows spanning low to moderate Reynolds numbers, showing excellent agreement with analytical solutions. We further prove that the proposed framework naturally accommodates both single and multiple relaxation time formulations while providing a rigorous mathematical foundation for entropy-based stabilization techniques. A key finding is that the conventional second-order accuracy limitation of lattice Boltzmann methods can be overcome through our manifold-based reconstruction approach, enabling genuine third-order convergence for smooth flows without requiring additional degrees of freedom. The theoretical analysis also elucidates why certain lattice Boltzmann variants exhibit superior performance near boundaries and in multiphase applications. This unified perspective not only enhances our fundamental understanding of lattice Boltzmann methods but also provides practical guidelines for constructing more accurate and stable numerical schemes for complex fluid dynamics simulations."
  },
  {
    "id": 116,
    "prompt": "Azimuthal Anisotropy: Ridges, Recombination and Breaking of Quark Number Scaling",
    "HWT": "Azimuthal anisotropy is studied by taking into account the ridges created by semi-hard scattering, which is sensitive to the initial spatial configuration in non-central heavy-ion collisions. No rapid thermalization is required. Although hydrodynamics is not used in this study, the validity of hydrodynamical expansion is not excluded at later time after equilibration is achieved. Phenomenological properties of the bulk and ridge behaviors are used as inputs to determine the elliptic flow of pion and proton at low p_T. At intermediate p_T the recombination of shower partons with thermal partons becomes more important. The phi dependence arises from the variation of the in-medium path length of the hard parton that generates the shower. The p_T dependence of v_2 is therefore very different at intermediate p_T compared to that at low p_T. Quark number scaling of v_2 is shown to be only approximately valid at low p_T, but is broken at intermediate p_T, even though recombination is the mechanism of hadronization in all p_T regions considered.",
    "MGT": "# Azimuthal Anisotropy: Ridges, Recombination and Breaking of Quark Number Scaling\n\nWe report measurements of azimuthal anisotropy in high-energy heavy-ion collisions at √s<sub>NN</sub> = 200 GeV, focusing on the interplay between ridge-like correlations, quark recombination mechanisms, and the breaking of constituent quark number scaling. Our analysis of Au+Au collision data reveals that while quark number scaling of elliptic flow (v<sub>2</sub>) holds approximately at intermediate transverse momentum (2 < p<sub>T</sub> < 4 GeV/c), significant deviations emerge at higher p<sub>T</sub> ranges. These deviations correlate strongly with the formation of near-side ridge structures in two-particle correlations. Using a multi-phase transport model incorporating both partonic and hadronic interactions, we demonstrate that these phenomena can be understood through a unified framework where initial-state geometry effects are modified by medium-induced energy loss and subsequent hadronization processes. The observed breaking of quark number scaling provides crucial constraints on the temperature dependence of the quark-gluon plasma viscosity and challenges the simple coalescence picture at high p<sub>T</sub>. Our findings suggest that azimuthal anisotropy measurements across different particle species offer a sensitive probe of the transition between hydrodynamic and jet-dominated regimes in relativistic heavy-ion collisions."
  },
  {
    "id": 117,
    "prompt": "Accurate structure factors from pseudopotential methods",
    "HWT": "Highly accurate experimental structure factors of silicon are available in the literature, and these provide the ideal test for any \\emph{ab initio} method for the construction of the all-electron charge density. In a recent paper [J. R. Trail and D. M. Bird, Phys. Rev. B {\\bf 60}, 7863 (1999)] a method has been developed for obtaining an accurate all-electron charge density from a first principles pseudopotential calculation by reconstructing the core region of an atom of choice. Here this method is applied to bulk silicon, and structure factors are derived and compared with experimental and Full-potential Linear Augmented Plane Wave results (FLAPW). We also compare with the result of assuming the core region is spherically symmetric, and with the result of constructing a charge density from the pseudo-valence density + frozen core electrons. Neither of these approximations provide accurate charge densities. The aspherical reconstruction is found to be as accurate as FLAPW results, and reproduces the residual error between the FLAPW and experimental results.",
    "MGT": "The calculation of accurate structure factors remains a fundamental challenge in computational materials science, particularly when employing pseudopotential-based density functional theory methods. Traditional pseudopotential approaches introduce systematic errors in structure factor calculations due to the replacement of core electrons with effective potentials, leading to discrepancies with experimental X-ray and neutron scattering data. This work presents a comprehensive methodology for obtaining highly accurate structure factors from pseudopotential calculations through the implementation of core density reconstruction techniques and all-electron corrections. We demonstrate that by carefully reconstructing the core electron density within the pseudopotential framework and applying systematic corrections for relativistic effects, we can achieve structure factors with accuracy comparable to all-electron methods while maintaining computational efficiency. The proposed approach is validated against experimental structure factors for a diverse set of crystalline materials, including transition metals, semiconductors, and ionic compounds. Our results show that the corrected pseudopotential method reduces errors in structure factor calculations by up to 85% compared to standard pseudopotential approaches, with typical deviations from experiment reduced to less than 2%. This methodology enables accurate prediction of diffraction patterns and charge density distributions, facilitating direct comparison with experimental measurements and enhancing the reliability of pseudopotential-based electronic structure calculations."
  },
  {
    "id": 118,
    "prompt": "Examining the crossover from hadronic to partonic phase in QCD",
    "HWT": "It is argued that, due to the existence of two vacua -- perturbative and physical -- in QCD, the mechanism for the crossover from hadronic to partonic phase is hard to construct. The challenge is: how to realize the transition between the two vacua during the gradual crossover of the two phases. A possible solution of this problem is proposed and a mechanism for crossover, consistent with the principle of QCD, is constructed. The essence of this mechanism is the appearance and growing up of a kind of grape-shape perturbative vacuum inside the physical one. A dynamical percolation model based on a simple dynamics for the delocalization of partons is constructed to exhibit this mechanism. The crossover from hadronic matter to sQGP as well as the transition from sQGP to wQGP in the increasing of temperature is successfully described by using this model with a temperature dependent parameter.",
    "MGT": "This abstract will focus on a study examining the crossover from hadronic to partonic phase in Quantum Chromodynamics (QCD). Let me write a concise, academic abstract of approximately 159 words.\n\nWe present a comprehensive analysis of the crossover transition between hadronic and partonic phases in Quantum Chromodynamics. Using lattice QCD simulations with improved staggered fermions at physical quark masses, we investigate the thermodynamic properties across temperatures ranging from 120 to 400 MeV. Our calculations reveal a smooth crossover characterized by simultaneous deconfinement and chiral symmetry restoration occurring at Tc = 156.5 ± 1.5 MeV. The analysis of quark number susceptibilities, Polyakov loop, and chiral condensate demonstrates that while these observables show inflection points near the same temperature, their scaling behaviors differ significantly, reflecting the complex interplay between deconfinement and chiral dynamics. We observe that remnant hadronic correlations persist well above Tc, while partonic degrees of freedom become increasingly dominant. These findings support an extended crossover region rather than a sharp phase transition, with implications for heavy-ion collision experiments and the early universe. Our results provide crucial constraints for effective models describing the QCD phase diagram at finite temperature and baryon density."
  },
  {
    "id": 119,
    "prompt": "Supersymmetric Leptogenesis with a Light Hidden Sector",
    "HWT": "Supersymmetric scenarios incorporating thermal leptogenesis as the origin of the observed matter-antimatter asymmetry generically predict abundances of the primordial elements which are in conflict with observations. In this paper we propose a simple way to circumvent this tension and accommodate naturally thermal leptogenesis and primordial nucleosynthesis. We postulate the existence of a light hidden sector, coupled very weakly to the Minimal Supersymmetric Standard Model, which opens up new decay channels for the next-to-lightest supersymmetric particle, thus diluting its abundance during nucleosynthesis. We present a general model-independent analysis of this mechanism as well as two concrete realizations, and describe the relevant cosmological and astrophysical bounds and implications for this dark matter scenario. Possible experimental signatures at colliders and in cosmic-ray observations are also discussed.",
    "MGT": "# Supersymmetric Leptogenesis with a Light Hidden Sector\n\nWe present a novel framework for leptogenesis within supersymmetric models featuring a light hidden sector. Our mechanism leverages the interplay between right-handed neutrinos and hidden sector fields, enabling successful baryogenesis while evading conventional constraints. The model introduces supersymmetric particles with masses below the electroweak scale that couple to the visible sector through small portal interactions. We demonstrate that CP-violating decays of heavy right-handed sneutrinos can generate a lepton asymmetry that efficiently transfers to the baryon sector via sphaleron processes. Notably, our scenario accommodates gravitino constraints and maintains consistency with neutrino mass measurements. Numerical simulations reveal that sufficient baryon asymmetry can be generated with right-handed neutrino masses as low as 10^6 GeV, significantly below the Davidson-Ibarra bound. The model predicts distinctive signatures accessible at future collider and fixed-target experiments through the production and decay of light hidden sector particles."
  },
  {
    "id": 120,
    "prompt": "Switching between Hidden Markov Models using Fixed Share",
    "HWT": "In prediction with expert advice the goal is to design online prediction algorithms that achieve small regret (additional loss on the whole data) compared to a reference scheme. In the simplest such scheme one compares to the loss of the best expert in hindsight. A more ambitious goal is to split the data into segments and compare to the best expert on each segment. This is appropriate if the nature of the data changes between segments. The standard fixed-share algorithm is fast and achieves small regret compared to this scheme. Fixed share treats the experts as black boxes: there are no assumptions about how they generate their predictions. But if the experts are learning, the following question arises: should the experts learn from all data or only from data in their own segment? The original algorithm naturally addresses the first case. Here we consider the second option, which is more appropriate exactly when the nature of the data changes between segments. In general extending fixed share to this second case will slow it down by a factor of T on T outcomes. We show, however, that no such slowdown is necessary if the experts are hidden Markov models.",
    "MGT": "This paper presents a novel approach to adaptive sequence prediction using an ensemble of Hidden Markov Models (HMMs) combined with the Fixed Share algorithm. We address the challenge of tracking non-stationary data sequences where the underlying generative model changes over time. Our method dynamically switches between multiple HMM experts using the Fixed Share framework, which allows for efficient weight updates and model selection. We prove theoretical bounds on the regret of our algorithm relative to the best sequence of HMM experts chosen in hindsight, showing that it achieves near-optimal performance in both stationary and non-stationary environments. Empirical evaluations on synthetic data and real-world applications, including speech recognition and financial time series analysis, demonstrate the effectiveness of our approach. Results show that our method consistently outperforms static HMMs and other adaptive algorithms, particularly in scenarios with abrupt model changes. We observe an average improvement of 15% in prediction accuracy compared to baseline methods, while maintaining computational efficiency with a linear time complexity in the number of experts. The theoretical guarantees and practical performance of our algorithm make it particularly suitable for applications where the underlying data distribution exhibits temporal variations or regime shifts. Our work contributes to the growing body of research on adaptive learning algorithms and provides a robust framework for combining multiple HMMs in dynamic environments."
  },
  {
    "id": 121,
    "prompt": "Massive gravity and structure formation",
    "HWT": "We study the growth of cosmological perturbations in the model of Lorentz-violating massive gravity. The Friedman equation in this model acquires an unconventional term due to the Lorentz-breaking condensates which has the equation of state w = -1 / (3 gamma) with gamma being a free parameter taking values outside of the range [0,1/3]. Apart from the standard contributions, the perturbations above the Friedmann background contain an extra piece which is proportional to an arbitrary function theta(x) of the space coordinates. This function appears as an integration constant and corresponds to a non-propagating scalar mode which may, however, become dynamical with the account of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1 the ``anomalous'' perturbations grow slower than the standard ones and thus the model is compatible with observations. Whether the model is experimentally acceptable at other values of \\gamma depends on the value of the function theta(x) at the beginning of the radiation-dominated epoch.",
    "MGT": "# Massive gravity and structure formation\n\nWe investigate the effects of massive gravity theories on cosmic structure formation at cosmological scales. Our analysis introduces a covariant formulation of massive gravity that preserves diffeomorphism invariance while generating graviton mass through spontaneous symmetry breaking. Using N-body simulations calibrated with recent CMB constraints, we demonstrate that massive gravity models predict distinctive signatures in large-scale structure formation compared to ΛCDM. The fifth force mediated by the helicity-0 mode of the massive graviton enhances structure growth at scales below the Compton wavelength while preserving standard evolution at larger scales. Our results show a 12-18% enhancement in the matter power spectrum at k ≈ 0.1 h/Mpc for graviton masses in the range 10⁻³² - 10⁻³⁰ eV. These modifications manifest in the halo mass function and galaxy cluster counts in a manner potentially detectable by upcoming surveys including Euclid and the Vera C. Rubin Observatory. We derive constraints on the graviton mass from existing weak lensing and galaxy clustering data, finding m_g < 1.2 × 10⁻³¹ eV at 95% confidence. These results provide new avenues for testing deviations from general relativity using cosmic structure formation."
  },
  {
    "id": 122,
    "prompt": "From high-mass starless cores to high-mass protostellar objects",
    "HWT": "Aims: Our aim is to understand the evolutionary sequence of high-mass star formation from the earliest evolutionary stage of high-mass starless cores, via high-mass cores with embedded low- to intermediate-mass objects, to finally high-mass protostellar objects. Methods: Herschel far-infrared PACS and SPIRE observations are combined with existing data at longer and shorter wavelengths to characterize the spectral and physical evolution of massive star-forming regions. Results: The new Herschel images spectacularly show the evolution of the youngest and cold high-mass star-forming regions from mid-infrared shadows on the Wien-side of the spectral energy distribution (SED), via structures almost lost in the background emission around 100mum, to strong emission sources at the Rayleigh-Jeans tail. Fits of the SEDs for four exemplary regions covering evolutionary stages from high-mass starless cores to high-mass protostellar objects reveal that the youngest regions can be fitted by single-component black-bodies with temperatures on the order of 17K. More evolved regions show mid-infrared excess emission from an additional warmer component, which however barely contributes to the total luminosities for the youngest regions. Exceptionally low values of the ratio between bolometric and submm luminosity additionally support the youth of the infrared-dark sources. Conclusions: The Herschel observations reveal the spectral and physical properties of young high-mass star-forming regions in detail. The data clearly outline the evolutionary sequence in the images and SEDs. Future work on larger samples as well as incorporating full radiative transfer calculations will characterize the physical nature at the onset of massive star formation in even more depth.",
    "MGT": "We present a comprehensive observational and theoretical investigation of the evolutionary transition from high-mass starless cores to high-mass protostellar objects, examining the physical processes governing the onset of massive star formation. Our study combines multi-wavelength observations from submillimeter to infrared wavelengths of 47 high-mass dense cores in various evolutionary stages, complemented by detailed radiative transfer modeling and magnetohydrodynamic simulations. We identify distinct observational signatures that characterize the transition phase, including systematic changes in dust temperature profiles, molecular line emission patterns, and density structures. Starless cores exhibit centrally concentrated density profiles with temperatures below 15 K, while newly formed protostellar objects display characteristic heating signatures with central temperatures exceeding 20 K and emerging outflow activity. Our analysis reveals that the transition occurs on timescales of approximately 10^4-10^5 years, significantly shorter than previously estimated low-mass analogs. We find that magnetic field configurations play a crucial role in regulating the collapse, with field strengths of 1-10 mG required to maintain quasi-static equilibrium in starless phases. The onset of protostellar activity correlates strongly with increases in accretion rates above 10^-4 solar masses per year, triggering the formation of hot molecular cores and bipolar outflows. Chemical differentiation surveys reveal enhanced abundances of complex organic molecules coincident with protostellar emergence, providing additional evolutionary tracers. Our results suggest that high-mass star formation follows a more rapid and dynamic evolutionary sequence compared to low-mass counterparts, with environmental factors such as turbulence and external pressure playing enhanced roles. These findings provide crucial constraints for theoretical models of massive star formation and establish observational benchmarks for identifying different evolutionary phases in high-mass star-forming regions."
  },
  {
    "id": 123,
    "prompt": "Modeling Vacuum Arcs",
    "HWT": "We are developing a model of vacuum arcs. This model assumes that arcs develop as a result of mechanical failure of the surface due to Coulomb explosions, followed by ionization of fragments by field emission and the development of a small, dense plasma that interacts with the surface primarily through self sputtering and terminates as a unipolar arc capable of producing breakdown sites with high enhancement factors. We have attempted to produce a self consistent picture of triggering, arc evolution and surface damage. We are modeling these mechanisms using Molecular Dynamics (mechanical failure, Coulomb explosions, self sputtering), Particle-In-Cell (PIC) codes (plasma evolution), mesoscale surface thermodynamics (surface evolution), and finite element electrostatic modeling (field enhancements). We can present a variety of numerical results. We identify where our model differs from other descriptions of this phenomenon.",
    "MGT": "Vacuum arcs represent a critical phenomenon in high-voltage electrical systems, occurring when electrical breakdown happens in evacuated environments. This study presents a comprehensive computational model for predicting vacuum arc behavior, incorporating plasma physics principles and electromagnetic field interactions. The model integrates cathode spot dynamics, vapor generation mechanisms, and plasma expansion characteristics to simulate arc initiation and propagation. Key parameters investigated include electrode material properties, gap distance, applied voltage, and vacuum pressure levels. Experimental validation was conducted using a controlled vacuum chamber with copper and tungsten electrodes across voltage ranges of 1-50 kV. Results demonstrate strong correlation between predicted and observed arc characteristics, with model accuracy exceeding 92% for arc current predictions and 89% for plasma expansion velocities. The model successfully captures the transition from Townsend discharge to full arc formation, revealing critical threshold conditions for arc sustainability. These findings provide valuable insights for designing vacuum interrupters, particle accelerators, and space-based electrical systems. The developed framework offers engineers a predictive tool for optimizing vacuum electrical equipment performance and reliability."
  },
  {
    "id": 124,
    "prompt": "Comprehensive Characterization of InGaAs/InP Avalanche Photodiodes at 1550 nm with an Active Quenching ASIC",
    "HWT": "We present an active quenching application specific integrated circuit (ASIC), for use in conjunction with InGaAs/InP avalanche photodiodes (APDs), for 1550 nm single-photon detection. To evaluate its performance, we first compare its operation with that of standard quenching electronics. We then test 4 InGaAs/InP APDs using the ASIC, operating both in the free-running and gated modes, to study more general behavior. We investigate not only the standard parameters under different working conditions but also parameters such as charge persistence and quenching time. We also use the multiple trapping model to account for the afterpulsing behavior in the gated mode, and further propose a model to take account of the afterpulsing effects in the free-running mode. Our results clearly indicate that the performance of APDs with an on-chip quenching circuit significantly surpasses the conventional quenching electronics, and makes them suitable for practical applications, e.g., quantum cryptography.",
    "MGT": "# Comprehensive Characterization of InGaAs/InP Avalanche Photodiodes at 1550 nm with an Active Quenching ASIC\n\nThis work presents a detailed characterization of InGaAs/InP avalanche photodiodes (APDs) operating in Geiger mode at 1550 nm wavelength, utilizing a custom-designed active quenching application-specific integrated circuit (ASIC). We report comprehensive measurements of critical performance parameters including detection efficiency, dark count rate, afterpulsing probability, and timing jitter across various operating conditions. The APDs were characterized at temperatures ranging from -40°C to 20°C and excess bias voltages from 1V to 5V. Our results demonstrate a peak detection efficiency of 28% with corresponding dark count rates below 10 kHz at -30°C. The active quenching ASIC enables programmable dead times from 20 ns to 2 μs, allowing optimization of afterpulsing effects while maintaining high count rates. Timing jitter measurements reveal a full-width at half-maximum of 85 ps at optimal operating conditions. This systematic characterization provides valuable insights for the deployment of these APD systems in practical quantum communication protocols, lidar applications, and other photon-counting scenarios requiring operation at telecom wavelengths."
  },
  {
    "id": 125,
    "prompt": "Coexistence between superconducting and spin density wave states in iron-based superconductors: Ginzburg-Landau analysis",
    "HWT": "We consider the interplay between superconducting (SC) and commensurate spin-density-wave (SDW) orders in iron-pnictides by analyzing a multiple order Ginzburg-Landau free energy. We are particularly interested in whether the doping-induced transition between the two states is first order, or the two pure phases are separated by an intermediate phase with coexisting SC and SDW orders. For perfect nesting, the two orders do not coexist, because SDW order, which comes first, gaps the full Fermi surface leaving no space for SC to develop. When nesting is not perfect due to either ellipticity of electron bands or doping-induced difference in chemical potentials for holes and electrons, SDW order still leaves modified Fermi surfaces for not too strong SDW magnetism and the SC order may develop. We show that the two orders coexist only when certain relations between ellipticity and doping are met. In particular, in a compensated metal, ellipticity alone is not sufficient for coexistence of the two orders.",
    "MGT": "Here's an abstract for the academic article:\n\nWe present a Ginzburg-Landau theoretical framework to analyze the coexistence of superconductivity (SC) and spin density wave (SDW) states in iron-based superconductors. By expanding the free energy to fourth order in the order parameters and their gradients, we derive the coupled equations describing the interaction between these competing phases. Our analysis reveals that the nature of this interaction strongly depends on the symmetry of the superconducting order parameter. For s±-wave pairing, we demonstrate that microscopic coupling parameters can support a robust coexistence regime, consistent with experimental observations in several iron pnictides. We calculate the phase diagram as a function of doping and temperature, showing that the competition between SC and SDW states leads to a suppression of the transition temperatures and the emergence of a tetracritical point. Spatial variations at the interface between pure SC and coexistence regions are examined, revealing characteristic length scales distinct from individual coherence lengths. Our results provide insights into the underlying mechanisms of phase competition and cooperation in these materials, offering a theoretical foundation for understanding their complex phase diagrams."
  },
  {
    "id": 126,
    "prompt": "A Constructive Generalization of Nash Equilibrium for Better Payoffs and Stability",
    "HWT": "In a society of completely selfish individuals where everybody is only interested in maximizing his own payoff, does any equilibrium exist for the society? John Nash proved more than 50 years ago that an equilibrium always exists such that nobody would benefit from unilaterally changing his strategy. Nash Equilibrium is a central concept in game theory, which offers a mathematical foundation for social science and economy. However, it is important from both a theoretical and a practical point of view to understand game playing where individuals are less selfish. This paper offers a constructive generalization of Nash equilibrium to study n-person games where the selfishness of individuals can be defined at any level, including the extreme of complete selfishness. The generalization is constructive since it offers a protocol for individuals in a society to reach an equilibrium. Most importantly, this paper presents experimental results and theoretical investigation to show that the individuals in a society can reduce their selfishness level together to reach a new equilibrium where they can have better payoffs and the society is more stable at the same time. This study suggests that, for the benefit of everyone in a society (including the financial market), the pursuit of maximal payoff by each individual should be controlled at some level either by voluntary good citizenship or by imposed regulations.",
    "MGT": "A Constructive Generalization of Nash Equilibrium for Better Payoffs and Stability\n\nThis paper introduces a novel game-theoretic solution concept called Constructive Equilibrium (CE), which generalizes Nash Equilibrium by incorporating a mechanism for coordinated strategy adjustments among rational agents. While Nash Equilibrium has been fundamental in modeling strategic interactions, it often yields suboptimal outcomes in social dilemmas. Our approach allows players to conditionally modify their strategies when mutual benefits are demonstrable, formalizing the intuition that rational agents should not remain trapped in inefficient equilibria. We provide a rigorous mathematical framework for CE, proving its existence in finite games and demonstrating that every Nash Equilibrium is a CE, but not conversely. The CE concept retains the predictive power of Nash while expanding the solution space to include more efficient outcomes. Using cooperative bargaining theory, we establish bounds on the efficiency gains possible through this mechanism and develop an algorithmic approach to compute CE in polynomial time for a broad class of games. We apply our framework to classic problems including the Prisoner's Dilemma, public goods games, and oligopoly competition, showing that CE consistently outperforms Nash in terms of both individual and collective payoffs. Experimental evidence from human subjects supports our theoretical predictions, suggesting that players naturally gravitate toward constructive equilibria even without explicit coordination mechanisms. This work bridges the gap between non-cooperative and cooperative game theory, offering a more realistic and optimistic model of strategic behavior with significant implications for mechanism design, institutional economics, and multi-agent systems."
  },
  {
    "id": 127,
    "prompt": "High energy emission and polarisation limits for the INTEGRAL burst GRB 061122",
    "HWT": "(Abridged) GRB 061122 is one of the brightest GRBs detected within INTEGRAL's field of view to date. The two gamma-ray detectors on INTEGRAL were used to investigate the spectral characteristics of GRB 061122. A search for linear polarisation in the prompt emission was carried out using the SPI multiple event data in the energy range 100 keV-1 MeV. The prompt spectrum was best fit by a combination of a blackbody and a power--law model (the quasithermal model), with evidence for high energy emission continuing above 8 MeV. A pseudo-redshift value of pz = 0.95 +/- 0.18 was determined using the spectral fit parameters. The isotropic energy at this pseudo-redshift is 8.5 x 10^{52} erg. The jet opening angle was estimated to be smaller than 2.8 deg or larger than 11.9 deg from the X-ray lightcurve. An upper limit of 60% polarisation was determined for the prompt emission of GRB 061122, using the multiple event data. The high energy emission observed in the spectrum may be due to the reverse shock interacting with the GRB ejecta when it is decelerated by the circumburst medium. This behaviour has been observed in a small fraction of GRBs to date, but is expected to be more commonly observed by the Fermi Gamma-ray Space Telescope. The conditions for polarisation are met if the jet opening angle is less than 2.8 deg, but further constraints on the level of polarisation are not possible.",
    "MGT": "# High energy emission and polarisation limits for the INTEGRAL burst GRB 061122\n\nWe present a detailed analysis of the prompt emission and afterglow of GRB 061122, one of the brightest gamma-ray bursts detected by INTEGRAL. Using data from the IBIS and SPI instruments, we characterize the temporal and spectral properties of this event across multiple energy bands. The burst shows a duration of T₉₀ = 12.2 ± 0.5 s with a peak flux of (15.7 ± 1.2) × 10⁻⁶ erg cm⁻² s⁻¹ in the 20-200 keV energy range. Spectral analysis reveals a complex evolution best described by a Band function with mean parameters α = -0.84 ± 0.13, β = -2.53 ± 0.24, and E₀ = 221 ± 36 keV. We also report evidence of high-energy emission extending to ~3 MeV with no spectral cutoff detected within the instrument's sensitivity limits.\n\nOf particular significance, we present the first constraints on polarisation for this burst using the SPI instrument, obtaining an upper limit on the polarisation fraction of P < 60% (90% confidence) in the 100-500 keV range. This measurement provides important constraints for emission models involving highly magnetized jets or structured emission regions.\n\nThe afterglow was monitored with Swift XRT and several ground-based telescopes, revealing a standard temporal decay with a break at t ≈ 2.8 days post-trigger. Host galaxy observations place GRB 061122 at a redshift of z = 1.33 ± 0.11, implying an isotropic-equivalent energy release of Eiso = (7.8 ± 0.9) × 10⁵² erg. Combining our prompt emission analysis with afterglow observations, we find this burst consistent with the external shock model, though internal shock scenarios cannot be excluded.\n\nOur comprehensive analysis of GRB 061122 adds to the growing sample of well-studied gamma-ray bursts with constraints on prompt emission polarisation, providing valuable input for theoretical models of GRB production mechanisms."
  },
  {
    "id": 128,
    "prompt": "A critical layer model for turbulent pipe flow",
    "HWT": "A model-based description of the scaling and radial location of turbulent fluctuations in turbulent pipe flow is presented and used to illuminate the scaling behaviour of the very large scale motions. The model is derived by treating the nonlinearity in the perturbation equation (involving the Reynolds stress) as an unknown forcing, yielding a linear relationship between the velocity field response and this nonlinearity. We do not assume small perturbations. We examine propagating modes, permitting comparison of our results to experimental data, and identify the steady component of the velocity field that varies only in the wall-normal direction as the turbulent mean profile. The \"optimal\" forcing shape, that gives the largest velocity response, is assumed to lead to modes that will be dominant and hence observed in turbulent pipe flow. An investigation of the most amplified velocity response at a given wavenumber-frequency combination reveals critical layer-like behaviour reminiscent of the neutrally stable solutions of the Orr-Sommerfeld equation in linearly unstable flow. Two distinct regions in the flow where the influence of viscosity becomes important can be identified, namely a wall layer that scales with $R^{+1/2}$ and a critical layer, where the propagation velocity is equal to the local mean velocity, that scales with $R^{+2/3}$ in pipe flow. This framework appears to be consistent with several scaling results in wall turbulence and reveals a mechanism by which the effects of viscosity can extend well beyond the immediate vicinity of the wall.",
    "MGT": "I'll write an academic article abstract for the given title without any headers or additional explanations:\n\nA critical layer model for turbulent pipe flow\n\nThis study presents a novel critical layer model for turbulent pipe flow, bridging the gap between classical wall-bounded turbulence theory and empirical observations. We develop a mathematical framework that identifies and characterizes a critical annular region where the local mean velocity equals the phase speed of dominant coherent structures. Through high-resolution direct numerical simulations at Reynolds numbers ranging from 5,000 to 100,000, we demonstrate that this critical layer plays a fundamental role in energy transfer processes and the self-sustaining mechanism of wall turbulence. Our analysis reveals that the radial location of this layer scales with Reynolds number as r⁺ ∼ Re^(0.7), consistent with experimental data but contrary to previous theoretical predictions. The critical layer exhibits distinctive statistical signatures, including pronounced intermittency and non-Gaussian velocity fluctuations that persist regardless of Reynolds number. We derive a simplified model that captures the essential dynamics through a set of coupled nonlinear partial differential equations, yielding good agreement with full simulation results while requiring orders of magnitude less computational resources. The model successfully reproduces key features of the mean velocity profile, Reynolds stresses, and energy spectra across the pipe radius. Additionally, we establish connections between critical layer phenomena and the emergence of large-scale motions and very-large-scale motions in pipe flow. These findings provide new insights into the fundamental mechanisms governing wall-bounded turbulence and offer promising avenues for turbulence control strategies focusing on critical layer manipulation. Our framework also has potential applications in other wall-bounded flows, including boundary layers and channel flows, suggesting a unified approach to understanding wall turbulence across different geometries."
  },
  {
    "id": 129,
    "prompt": "Importance of constraining the dense matter Equation of State in pulsar astrophysics",
    "HWT": "We study the dependence of the surface magnetic fields of radio pulsars on the choice of Equations of State, pulsar masses and the values of the angle between the magnetic axis and the spin axis of the pulsars within simple dipole model. We show that the values of the surface magnetic field can be even order of magnitude different from its canonical values. This difference will effect any magnetosphere related model to explain observational features of radio pulsars and magnetars. We find a significant difference of the value of the surface magnetic field from the commonly quoted value for the faster member of the double pulsar system, i.e. PSR J0737-3039A as here both the mass of the pulsar and the angle between the magnetic axis and the spin axis are known. Our study reveals the importance of constraining the dense matter Equations of State in pulsar astrophysics as well as hints an alternative way to constrain these by independent determination of the pulsar magnetic field.",
    "MGT": "Here's an abstract for the academic article with the given title:\n\nThe equation of state (EoS) of dense nuclear matter remains one of the most significant unsolved problems in nuclear astrophysics. This paper examines the critical importance of constraining the dense matter EoS through pulsar observations, emphasizing how precise measurements of neutron star properties provide unique laboratories for studying matter under extreme conditions inaccessible to terrestrial experiments. We analyze recent data from NICER, gravitational wave detections of neutron star mergers, and radio timing observations of massive pulsars to demonstrate how a multi-messenger approach significantly narrows viable EoS models. Our Bayesian framework combines these observational constraints with theoretical priors from quantum chromodynamics and chiral effective field theory calculations. Results indicate that only EoS models with moderate stiffness at 2-3 times nuclear saturation density remain viable, with implications for the existence of exotic states of matter in neutron star cores. We demonstrate how future observations of rapidly rotating pulsars and post-merger gravitational wave signals will further constrain the high-density regime of the EoS, potentially resolving outstanding questions about the fundamental properties of supranuclear matter."
  },
  {
    "id": 130,
    "prompt": "Noise and nonlinearities in high-throughput data",
    "HWT": "High-throughput data analyses are becoming common in biology, communications, economics and sociology. The vast amounts of data are usually represented in the form of matrices and can be considered as knowledge networks. Spectra-based approaches have proved useful in extracting hidden information within such networks and for estimating missing data, but these methods are based essentially on linear assumptions. The physical models of matching, when applicable, often suggest non-linear mechanisms, that may sometimes be identified as noise. The use of non-linear models in data analysis, however, may require the introduction of many parameters, which lowers the statistical weight of the model. According to the quality of data, a simpler linear analysis may be more convenient than more complex approaches. In this paper, we show how a simple non-parametric Bayesian model may be used to explore the role of non-linearities and noise in synthetic and experimental data sets.",
    "MGT": "# Noise and nonlinearities in high-throughput data\n\nHigh-throughput data generation technologies have revolutionized scientific discovery across disciplines, yet the intrinsic noise and nonlinear relationships within these complex datasets present significant analytical challenges. This study examines the interplay between stochastic noise and nonlinear dependencies in high-dimensional data structures, with particular attention to their impact on downstream analysis pipelines. We introduce a novel computational framework that adaptively characterizes noise distributions while simultaneously modeling nonlinear interactions using a hybridized approach combining manifold learning techniques with robust statistical inference. Our method demonstrates superior performance on synthetic benchmarks compared to conventional approaches that address noise and nonlinearities separately. When applied to real-world genomic, metabolomic, and neuroimaging datasets, our integrated approach revealed previously masked biological signals and significantly reduced false discovery rates by 37%. Furthermore, we provide theoretical guarantees on the conditions under which joint noise-nonlinearity modeling outperforms sequential preprocessing strategies. These findings highlight the critical importance of considering the interdependence of noise characteristics and nonlinear structures when analyzing high-throughput data, offering practical guidelines for improved scientific inference across multiple domains."
  },
  {
    "id": 131,
    "prompt": "Dilatons in Hidden Local Symmetry for Hadrons in Dense Matter",
    "HWT": "With the explicit breaking of scale invariance by the trace anomaly of QCD rephrased in terms of spontaneous breaking, low-energy strong interaction dynamics of dense (and also hot) matter can be effectively captured by -- in addition to the Nambu-Goldstone bosons and the vector mesons -- two dilaton fields, the \"soft\" ($\\chi_s$) field that is locked to chiral symmetry and the \"hard\" ($\\chi_h$) field which remains unaffected by chiral symmetry. The interplay of the soft and hard dilatons plays a subtle role in how chiral symmetry is manifested in hot and/or dense matter. The scale anomaly in which the soft component intervenes vanishes at the chiral transition in a way analogous to the restoration of scale symmetry in the Freund-Nambu model, while that of the hard component remains broken throughout the QCD sector. Most remarkable of all is its role in the chiral anomaly sector through a \"homogeneous Wess-Zumino (hWZ) term\" of the form $\\omega_\\mu B^\\mu$ on the structure of a single baryon as well as dense baryonic matter. It figures crucially in predicting a \"Little Bag\" for the nucleon and a \"quarkyonic phase\" in the form of a half-skyrmion matter at high density. We show how the vanishing of the vector-meson mass at the vector manifestation fixed point in hidden local symmetry theory can be related to the property of the \"matter field\" in the Freund-Nambu model that leaves scale symmetry invariant. The emerging structure of dense hadronic matter in the model so constructed suggests what could be amiss in describing dense matter in holographic dual QCD at its large $N_c$ and 't Hooft limit.",
    "MGT": "# Dilatons in Hidden Local Symmetry for Hadrons in Dense Matter\n\nWe explore the incorporation of a dilaton field into the Hidden Local Symmetry (HLS) framework for describing hadronic matter under extreme density conditions. Our analysis extends previous formulations by explicitly coupling the dilaton, which encodes the spontaneous breaking of scale invariance in QCD, with vector and axial-vector mesons in dense nuclear matter. Using effective field theory techniques, we demonstrate that the dilaton plays a crucial role in preserving chiral symmetry constraints while simultaneously accounting for the modification of the QCD vacuum at high densities. The resulting unified framework successfully reproduces both the Brown-Rho scaling behavior and provides a natural explanation for the observed \"dropping\" of vector meson masses in dense matter. \n\nOur calculations reveal that the dilaton-modified HLS framework predicts a distinctive pattern of spectral function modifications for ρ and ω mesons that differs significantly from conventional many-body approaches. Through careful renormalization group analysis, we show that the coupling between the dilaton and vector mesons exhibits a density-dependent running that reflects the partial restoration of chiral symmetry. We present numerical results for the density dependence of hadron masses up to three times nuclear saturation density, where our model remains reliable before the expected hadron-quark phase transition.\n\nThe formalism developed here has important implications for the interpretation of dilepton spectra in heavy-ion collisions and offers new insights into the equation of state of dense matter relevant for neutron star physics. In particular, our approach provides a consistent framework that connects the thermodynamics of dense hadronic matter with its microscopic degrees of freedom. The interplay between the dilaton field and vector mesons emerges as a key mechanism for understanding how broken scale invariance manifests in the dense nuclear environment, potentially resolving long-standing puzzles in the hadron spectroscopy of compressed nuclear matter. Our work establishes a theoretical foundation for future precision measurements at facilities such as FAIR, NICA, and J-PARC, which will probe the dense QCD matter regime."
  },
  {
    "id": 132,
    "prompt": "Surface magnetic fields on two accreting T Tauri stars: CV Cha and CR Cha",
    "HWT": "We have produced brightness and magnetic field maps of the surfaces of CV Cha and CR Cha: two actively accreting G and K-type T Tauri stars in the Chamaeleon I star-forming cloud with ages of 3-5 Myr. Our magnetic field maps show evidence for strong, complex multi-polar fields similar to those obtained for young rapidly rotating main sequence stars. Brightness maps indicate the presence of dark polar caps and low latitude spots -- these brightness maps are very similar to those obtained for other pre-main sequence and rapidly rotating main sequence stars. Only two other classical T Tauri stars have been studied using similar techniques so far: V2129 Oph and BP Tau. CV Cha and CR Cha show magnetic field patterns that are significantly more complex than those recovered for BP Tau, a fully convective T Tauri star. We discuss possible reasons for this difference and suggest that the complexity of the stellar magnetic field is related to the convection zone; with more complex fields being found in T Tauri stars with radiative cores (V2129 Oph, CV Cha and CR Cha). However, it is clearly necessary to conduct magnetic field studies of T Tauri star systems, exploring a wide range of stellar parameters in order to establish how they affect magnetic field generation, and thus how these magnetic fields are likely to affect the evolution of T Tauri star systems as they approach the main sequence.",
    "MGT": "# Surface magnetic fields on two accreting T Tauri stars: CV Cha and CR Cha\n\nWe present the first detailed characterization of surface magnetic field properties for the classical T Tauri stars CV Chamaeleontis and CR Chamaeleontis using high-resolution spectropolarimetric observations obtained with the ESPaDOnS instrument at the Canada-France-Hawaii Telescope. Using Zeeman-Doppler imaging techniques, we have reconstructed the large-scale magnetic field topologies of both stars with data collected over 14 nights. CV Cha (K0, 2.0 M⊙) exhibits a predominantly poloidal magnetic field with a mean surface strength of 0.9 kG, characterized by a tilted dipolar component (β ≈ 35°) and significant higher-order components. CR Cha (K2, 1.8 M⊙) displays a more complex field configuration with comparable poloidal and toroidal components and a mean field strength of 1.2 kG. Both stars show moderate rotational modulation in their magnetic signatures with periods consistent with previous photometric measurements (2.3 and 2.9 days for CV Cha and CR Cha, respectively). We detect clear signatures of magnetospheric accretion in both stars through time-variable redshifted absorption features in Balmer and He I line profiles. Mass accretion rates derived from multiple emission lines yield values of 5.2(±1.3)×10⁻⁸ M⊙yr⁻¹ for CV Cha and 3.7(±0.9)×10⁻⁸ M⊙yr⁻¹ for CR Cha. The observed field configurations support theoretical models wherein magnetic field complexity influences magnetospheric accretion geometries and inner disk structures. These results add to the growing sample of magnetically-mapped T Tauri stars and provide new constraints for understanding how magnetic field properties correlate with stellar parameters and accretion properties during the crucial pre-main sequence phase of stellar evolution."
  },
  {
    "id": 133,
    "prompt": "Positive and negative streamers in ambient air: modeling evolution and velocities",
    "HWT": "We simulate short positive and negative streamers in air at standard temperature and pressure. They evolve in homogeneous electric fields or emerge from needle electrodes with voltages of 10 to 20 kV. The streamer velocity at given streamer length depends only weakly on the initial ionization seed, except in the case of negative streamers in homogeneous fields. We characterize the streamers by length, head radius, head charge and field enhancement. We show that the velocity of positive streamers is mainly determined by their radius and in quantitative agreement with recent experimental results both for radius and velocity. The velocity of negative streamers is dominated by electron drift in the enhanced field; in the low local fields of the present simulations, it is little influenced by photo-ionization. Though negative streamer fronts always move at least with the electron drift velocity in the local field, this drift motion broadens the streamer head, decreases the field enhancement and ultimately leads to slower propagation or even extinction of the negative streamer.",
    "MGT": "# Positive and Negative Streamers in Ambient Air: Modeling Evolution and Velocities\n\nThis paper presents a comprehensive two-dimensional numerical model for investigating the dynamics of both positive and negative streamers in ambient air. We employ a fluid model approach incorporating photoionization, detailed air chemistry with 16 species and 36 reactions, and adaptive mesh refinement techniques to capture the multiscale nature of streamer discharges. Our simulations reveal fundamental differences in propagation mechanisms between polarities: positive streamers advance primarily through photoionization-driven electron seeding ahead of the streamer head, while negative streamers propagate via electron avalanches developing in the high-field region. The model successfully reproduces experimentally observed velocity disparities, with positive streamers typically propagating 2-3 times faster than negative streamers under identical conditions. We demonstrate that this velocity difference stems from the distinctive field enhancement patterns and electron transport characteristics inherent to each polarity. Furthermore, our results indicate that streamer velocities correlate strongly with applied voltage and gap distance, following a power-law relationship that agrees well with experimental data. These findings provide crucial insights for optimizing applications ranging from plasma-assisted combustion to lightning protection systems and air purification technologies."
  },
  {
    "id": 134,
    "prompt": "Extinction risk and structure of a food web model",
    "HWT": "We investigate in detail the model of a trophic web proposed by Amaral and Meyer [Phys. Rev. Lett. 82, 652 (1999)]. We focused on small-size systems that are relevant for real biological food webs and for which the fluctuations are playing an important role. We show, using Monte Carlo simulations, that such webs can be non-viable, leading to extinction of all species in small and/or weakly coupled systems. Estimations of the extinction times and survival chances are also given. We show that before the extinction the fraction of highly-connected species (\"omnivores\") is increasing. Viable food webs exhibit a pyramidal structure, where the density of occupied niches is higher at lower trophic levels, and moreover the occupations of adjacent levels are closely correlated. We also demonstrate that the distribution of the lengths of food chains has an exponential character and changes weakly with the parameters of the model. On the contrary, the distribution of avalanche sizes of the extinct species depends strongly on the connectedness of the web. For rather loosely connected systems we recover the power-law type of behavior with the same exponent as found in earlier studies, while for densely-connected webs the distribution is not of a power-law type.",
    "MGT": "I'll create an academic abstract for the given title, with approximately 228 words.\n\nExtinction risk and structure of a food web model\n\nFood webs are complex networks describing trophic interactions among species in ecosystems. Understanding how their structure influences extinction cascades remains a central challenge in theoretical ecology. Here, we develop a dynamical food web model incorporating both direct predator-prey interactions and indirect competition effects to investigate extinction risk as a function of network topology. Using numerical simulations on 250 generated food webs with varying connectance (0.05-0.30) and diversity (15-100 species), we demonstrate that certain structural properties significantly influence system robustness. Networks with higher modularity exhibited 37% lower extinction magnitudes following perturbation than their less modular counterparts. Contrary to previous findings, we observed that nestedness correlates positively with extinction risk (r = 0.64, p < 0.001) when controlling for connectance. Primary extinctions triggered by removal of highly connected species (\"hubs\") generated cascades affecting up to 70% of the network, while random extinctions affected only 23% on average. Additionally, we identified a critical connectance threshold (0.15 ± 0.02) where food web stability exhibits a phase transition. Our results suggest that conservation efforts prioritizing species with high betweenness centrality rather than degree centrality may more effectively preserve community integrity. This work integrates network theory with population dynamics to provide a more mechanistic understanding of extinction processes in complex ecological communities and offers quantitative tools for identifying keystone species whose protection would minimize extinction risk."
  },
  {
    "id": 135,
    "prompt": "Dumb-bell swimmers",
    "HWT": "We investigate the way in which oscillating dumb-bells, a simple microscopic model of apolar swimmers, move at low Reynold's number. In accordance with Purcell's Scallop Theorem a single dumb-bell cannot swim because its stroke is reciprocal in time. However the motion of two or more dumb-bells, with mutual phase differences, is not time reversal invariant, and hence swimming is possible. We use analytical and numerical solutions of the Stokes equations to calculate the hydrodynamic interaction between two dumb-bell swimmers and to discuss their relative motion. The cooperative effect of interactions between swimmers is explored by considering first regular, and then random arrays of dumb-bells. We find that a square array acts as a micropump. The long time behaviour of suspensions of dumb-bells is investigated and compared to that of model polar swimmers.",
    "MGT": "# Dumb-bell swimmers\n\nWe present a comprehensive numerical study of self-propelled dumb-bell swimmers in viscous fluids at low Reynolds numbers. Our model consists of two spheres connected by a rigid rod, with one sphere exhibiting catalytic activity that generates asymmetric surface flows. Using boundary element methods, we solve the Stokes equations to characterize the hydrodynamic interactions and emergent locomotion. Results demonstrate that swimming velocity scales non-linearly with the size ratio between spheres and depends critically on the distribution of catalytic activity. We observe distinct swimming regimes corresponding to different aspect ratios, with optimal configurations achieving speeds up to 30% higher than previously reported microswimmers of comparable size. Additionally, we characterize the influence of nearby boundaries on swimming trajectories, revealing complex behaviors including wall attraction, repulsion, and steady orbiting states. Our findings provide insights for designing efficient microrobots for potential applications in targeted drug delivery and environmental remediation, while contributing to fundamental understanding of low-Reynolds number locomotion."
  },
  {
    "id": 136,
    "prompt": "Indirect detection of gravitino dark matter including its three-body decays",
    "HWT": "It was recently pointed out that in supersymmetric scenarios with gravitino dark matter and bilinear R-parity violation, gravitinos with masses below Mw typically decay with a sizable branching ratio into the 3-body final states W^*+lepton and Z^*+neutrino. In this paper we study the indirect detection signatures of gravitino dark matter including such final states. First, we obtain the gamma ray spectrum from gravitino decays, which features a monochromatic contribution from the decay into photon+neutrino and a continuum contribution from the three-body decays. After studying its dependence on supersymmetric parameters, we compute the expected gamma ray fluxes and derive new constraints, from recent FERMI data, on the R-parity breaking parameter and on the gravitino lifetime. Indirect detection via antimatter searches, a new possibility brought about by the three-body final states, is also analyzed. For models compatible with the gamma ray observations, the positron signal is found to be negligible whereas the antiproton one can be significant.",
    "MGT": "Here's an abstract for the academic article:\n\nWe investigate the indirect detection signatures of gravitino dark matter, particularly incorporating previously overlooked three-body decay channels. While two-body decays have been extensively studied in the literature, we demonstrate that three-body processes significantly modify the expected photon and neutrino spectra in certain regions of parameter space. Using a complete effective field theory approach, we calculate decay rates and energy spectra for the dominant channels ψ₃/₂ → γνν̄, Zνν̄, and W±l∓ν, where ψ₃/₂ is the massive gravitino. Our analysis shows that when the gravitino mass lies in the 10-500 GeV range, three-body decays can contribute up to 30% of the total decay width, substantially enhancing signals in gamma-ray telescopes and neutrino observatories. We derive constraints using the latest Fermi-LAT, H.E.S.S., and IceCube data, finding that the inclusion of three-body processes strengthens bounds on the gravitino lifetime by factors of 1.2-1.8, depending on mass. These results have important implications for supersymmetric models with gravitino dark matter, particularly those with compressed spectra where the three-body enhancement is most pronounced."
  },
  {
    "id": 137,
    "prompt": "Impure Thoughts on Inelastic Dark Matter",
    "HWT": "The inelastic dark matter scenario was proposed to reconcile the DAMA annual modulation with null results from other experiments. In this scenario, WIMPs scatter into an excited state, split from the ground state by an energy delta comparable to the available kinetic energy of a Galactic WIMP. We note that for large splittings delta, the dominant scattering at DAMA can occur off of thallium nuclei, with A~205, which are present as a dopant at the 10^-3 level in NaI(Tl) crystals. For a WIMP mass m~100GeV and delta~200keV, we find a region in delta-m-parameter space which is consistent with all experiments. These parameters in particular can be probed in experiments with thallium in their targets, such as KIMS, but are inaccessible to lighter target experiments. Depending on the tail of the WIMP velocity distribution, a highly modulated signal may or may not appear at CRESST-II.",
    "MGT": "# Impure Thoughts on Inelastic Dark Matter\n\nWe present a comprehensive analysis of inelastic dark matter (iDM) models incorporating impurities—subdominant dark matter components that introduce novel detection signatures. Our framework extends traditional iDM scenarios by considering mixed-state dark matter with multiple mass eigenstates that participate in both elastic and inelastic scattering processes. Using a combination of effective field theory and numerical simulations, we demonstrate that even small impurity fractions (≲5%) can significantly alter experimental signatures across direct detection, indirect detection, and collider searches. Particularly noteworthy is the emergence of distinctive spectral features in nuclear recoil spectra that cannot be reproduced by elastic models. We derive constraints on the parameter space from existing experiments and identify regions where impure iDM models can reconcile apparently contradictory experimental results from XENON, DAMA/LIBRA, and CoGeNT. Our findings suggest that dark matter impurities represent a natural consequence of many UV-complete theories and warrant dedicated experimental searches. This work establishes a new paradigm for understanding dark matter phenomenology beyond the standard elastic and inelastic scenarios."
  },
  {
    "id": 138,
    "prompt": "Opportunistic Scheduling and Beamforming for MIMO-OFDMA Downlink Systems with Reduced Feedback",
    "HWT": "Opportunistic scheduling and beamforming schemes with reduced feedback are proposed for MIMO-OFDMA downlink systems. Unlike the conventional beamforming schemes in which beamforming is implemented solely by the base station (BS) in a per-subcarrier fashion, the proposed schemes take advantages of a novel channel decomposition technique to perform beamforming jointly by the BS and the mobile terminal (MT). The resulting beamforming schemes allow the BS to employ only {\\em one} beamforming matrix (BFM) to form beams for {\\em all} subcarriers while each MT completes the beamforming task for each subcarrier locally. Consequently, for a MIMO-OFDMA system with $Q$ subcarriers, the proposed opportunistic scheduling and beamforming schemes require only one BFM index and $Q$ supportable throughputs to be returned from each MT to the BS, in contrast to $Q$ BFM indices and $Q$ supportable throughputs required by the conventional schemes. The advantage of the proposed schemes becomes more evident when a further feedback reduction is achieved by grouping adjacent subcarriers into exclusive clusters and returning only cluster information from each MT. Theoretical analysis and computer simulation confirm the effectiveness of the proposed reduced-feedback schemes.",
    "MGT": "This paper presents a novel approach to opportunistic scheduling and beamforming for MIMO-OFDMA downlink systems that addresses the critical challenge of feedback overhead. We propose a reduced feedback mechanism that significantly decreases system overhead while maintaining near-optimal performance. Our technique employs a two-phase feedback strategy where users first report channel quality indicators for a subset of resource blocks, followed by beamforming information only for those selected blocks. Mathematical analysis demonstrates that this approach achieves a favorable trade-off between system throughput and feedback requirements. Simulations conducted across various channel environments show that our proposed scheme achieves within 5-7% of the performance of full-feedback systems while reducing feedback overhead by up to 85%. We further enhance the algorithm with adaptive threshold selection that dynamically adjusts feedback requirements based on channel conditions and system load. The computational complexity analysis confirms the practical implementability of our approach in real-time systems. Our results indicate that selective feedback combined with opportunistic scheduling provides a robust framework for next-generation wireless networks, particularly for scenarios with large numbers of users and limited feedback channels. This work offers valuable insights for system designers seeking to optimize MIMO-OFDMA performance under practical constraints."
  },
  {
    "id": 139,
    "prompt": "Normal galaxies in the XMM-Newton fields. X-rays as a star formation indicator",
    "HWT": "Context: We use the first XMM serendipitous source catalogue (1XMM) to compile a sample of normal X-ray galaxies Aims: We seek to expand the database of X-ray selected normal galaxies at intermediate redshifts and examine the relation between X-ray emission and star formation for late-type systems Methods: The candidates are selected based on their X-ray (soft spectra), X-ray to optical [log(fx/fo)<-2] and optical (extended sources) properties. 44 candidates are found and 35 are spectroscopically observed with the Australian National University's 2.3m telescope to examine their nature. Results: Of the 35 sources observed, 2 are AGN, 11 emission line galaxies, 12 absorption line galaxies, 6 have featureless spectra while 4 are associated with Galactic stars. We combine our emission line sample with earlier works forming the most comprehensive X-ray selected galaxy sample for the study of the X-ray luminosity to the Halpha luminosity - a well-calibrated star-formation indicator - relation. Conclusions: We find that the X-ray luminosity strongly correlates with the Halpha luminosity, suggesting that the X-rays efficiently trace the star-formation.",
    "MGT": "Here's the academic article abstract for the given title:\n\nThis study examines normal galaxies detected in XMM-Newton fields to evaluate the efficacy of X-ray emission as a star formation indicator. We analyzed 87 normal galaxies selected from the XMM-Newton serendipitous source catalog, focusing on objects with minimal AGN contribution. X-ray luminosities in the 0.5-2 keV and 2-10 keV bands were measured and compared with established star formation indicators including infrared, radio, and optical emission. Our results reveal a strong correlation (r = 0.78, p < 0.001) between soft X-ray luminosity and total star formation rate derived from infrared measurements. This correlation persists across various galaxy morphologies and metallicities, suggesting X-ray emission provides a relatively unbiased tracer of star formation activity. The X-ray emission appears primarily driven by high-mass X-ray binaries and hot gas in star-forming regions, with the L_X/SFR ratio showing a weak dependence on galaxy mass (∝M^0.2±0.05). We establish a calibration for converting X-ray luminosity to star formation rates and discuss its limitations. Our findings demonstrate that X-ray observations offer a valuable complement to traditional star formation indicators, particularly for distant galaxies or those with significant dust obscuration."
  },
  {
    "id": 140,
    "prompt": "Effect of chemical substitution and pressure on YbRh2Si2",
    "HWT": "We carried out electrical resistivity experiments on (Yb, La)Rh2Si2 and on Yb(Rh, Ir)2Si2 under pressure and in magnetic fields. YbRh2Si2 exhibits a weak antiferromagnetic transition at atmospheric pressure with a N\\'eel temperature of only T_N = 70 mK. By applying a small magnetic field T_N can be continuously suppressed to T=0 at B_c = 60 mT (B_|_c) driving the system to a quantum critical point (QCP). On applying external pressure the magnetic phase is stabilized and T_N(p) is increasing as usually observed in Yb-based heavy-fermion metals. Substituting Yb by La or Rh by Ir allows to create a negative chemical pressure, La (Ir) being smaller than Yb (Rh), and eventually to drive YbRh2Si2 to a pressure controlled QCP. In this paper we compare the effect of external hydrostatic pressure and chemical substitution on the ground-state properties of YbRh2Si2.",
    "MGT": "# Effect of chemical substitution and pressure on YbRh2Si2\n\nWe report a comprehensive investigation of the heavy fermion compound YbRh2Si2 under both chemical substitution and hydrostatic pressure. Our experiments reveal that these two tuning parameters induce distinctly different quantum critical behaviors. Chemical substitution studies, focusing on Ge-doping (YbRh2(Si1-xGex)2), demonstrate a continuous suppression of antiferromagnetic order, leading to non-Fermi liquid behavior at the quantum critical point. Hydrostatic pressure measurements up to 2.5 GPa, conducted using diamond anvil cells, show a contrasting response with enhanced Kondo coupling and valence fluctuations. The Hall effect measurements indicate a dramatic change in the Fermi surface topology precisely at the quantum critical point in chemically substituted samples, while pressure-tuned samples maintain Fermi surface coherence. Our thermodynamic data reveal that the Sommerfeld coefficient diverges logarithmically for chemical substitution but follows a power-law for pressure tuning. These findings provide compelling evidence for two distinct types of quantum criticality in the same material system, challenging current theoretical frameworks for quantum phase transitions in heavy fermion systems."
  },
  {
    "id": 141,
    "prompt": "Radiation-Hydrodynamics of Hot Jupiter Atmospheres",
    "HWT": "Radiative transfer in planetary atmospheres is usually treated in the static limit, i.e., neglecting atmospheric motions. We argue that hot Jupiter atmospheres, with possibly fast (sonic) wind speeds, may require a more strongly coupled treatment, formally in the regime of radiation-hydrodynamics. To lowest order in v/c, relativistic Doppler shifts distort line profiles along optical paths with finite wind velocity gradients. This leads to flow-dependent deviations in the effective emission and absorption properties of the atmospheric medium. Evaluating the overall impact of these distortions on the radiative structure of a dynamic atmosphere is non-trivial. We present transmissivity and systematic equivalent width excess calculations which suggest possibly important consequences for radiation transport in hot Jupiter atmospheres. If winds are fast and bulk Doppler shifts are indeed important for the global radiative balance, accurate modeling and reliable data interpretation for hot Jupiter atmospheres may prove challenging: it would involve anisotropic and dynamic radiative transfer in a coupled radiation-hydrodynamical flow. On the bright side, it would also imply that the emergent properties of hot Jupiter atmospheres are more direct tracers of their atmospheric flows than is the case for Solar System planets. Radiation-hydrodynamics may also influence radiative transfer in other classes of hot exoplanetary atmospheres with fast winds.",
    "MGT": "# Radiation-Hydrodynamics of Hot Jupiter Atmospheres\n\nWe present a comprehensive three-dimensional radiation-hydrodynamic model of hot Jupiter atmospheric circulation patterns. Using a newly developed numerical scheme that couples radiative transfer with magnetohydrodynamics, we simulate the complex interplay between incident stellar radiation, atmospheric dynamics, and magnetic effects on these highly irradiated exoplanets. Our simulations focus on the benchmark case of HD 209458b, incorporating high-resolution spectral energy distributions and realistic opacities across 12 wavelength bands. Results reveal a novel equatorial jet structure that deviates significantly from previous purely hydrodynamic models, with peak zonal wind speeds reduced by 30% when magnetic drag effects are properly incorporated. The temperature-pressure profiles derived from our simulations show remarkable agreement with recent spectroscopic observations from JWST, resolving previous discrepancies in day-night temperature contrasts. We identify a previously unrecognized radiative feedback mechanism whereby localized magnetic field structures modify atmospheric opacity, creating self-reinforcing circulation patterns that persist across multiple orbital periods. These findings suggest that accurate interpretations of hot Jupiter phase curves require accounting for magnetohydrodynamic effects, particularly for planets orbiting magnetically active stars. Our work demonstrates that the conventional separation between radiative and dynamical processes in hot Jupiter atmospheric modeling inadequately captures the complex coupling mechanisms that determine their observable properties, with significant implications for atmospheric retrieval techniques and observational strategies with next-generation instruments."
  },
  {
    "id": 142,
    "prompt": "Gemini GMOS spectroscopy of HeII nebulae in M33",
    "HWT": "We have carried out a narrow-band survey of the Local Group galaxy, M33, in the HeII4686 emission line, to identify HeII nebulae in this galaxy. With spectroscopic follow-up observations, we confirm three of seven candidate objects, including identification of two new HeII nebulae, BCLMP651, HBW673. We also obtain spectra of associated ionizing stars for all the HII regions, identifying two new WN stars. We demonstrate that the ionizing source for the known HeII nebula, MA 1, is consistent with being the early-type WN star MC8 (M33-WR14), by carrying out a combined stellar and nebular analysis of MC8 and MA1. We were unable to identify the helium ionizing sources for HBW 673 and BCLMP 651, which do not appear to be Wolf-Rayet stars. According to the [OIII]5007/Hbeta vs [NII]6584/Halpha diagnostic diagram, excitation mechanisms apart from hot stellar continuum are needed to account for the nebular emission in HBW 673, which appears to have no stellar source at all.",
    "MGT": "Here is an abstract for the academic article with the given title:\n\nWe present deep Gemini Multi-Object Spectrograph (GMOS) observations of five HeII nebulae in the nearby spiral galaxy M33. These rare nebulae, identified by their strong HeII λ4686 emission, represent some of the most energetic photoionized regions in the Local Group. Our spectroscopic analysis reveals extreme excitation conditions with HeII/Hβ ratios ranging from 0.08 to 0.15, significantly higher than typical HII regions. We detect multiple diagnostic emission lines including [OIII] λ5007, [NII] λ6584, and [SII] λλ6717,6731, enabling comprehensive photoionization modeling. The nebulae exhibit elevated electron temperatures (15,000-21,000 K) and densities (250-450 cm⁻³) compared to standard HII regions. Photoionization models suggest the primary ionizing sources are either Wolf-Rayet stars of subtype WN3-4 or very massive O-stars (>100 M⊙) with effective temperatures exceeding 50,000 K. Notably, two nebulae show peculiar emission line ratios inconsistent with pure stellar photoionization, suggesting possible contribution from shocks or X-ray ionization. Our results provide new constraints on the formation and evolution of these extreme nebulae and their massive stellar progenitors, with implications for understanding feedback processes in metal-poor environments similar to those in the early universe."
  },
  {
    "id": 143,
    "prompt": "Magnetic Field Properties in High Mass Star Formation from Large to Small Scales - A Statistical Analysis from Polarization Data",
    "HWT": "Polarization data from high mass star formation regions (W51 e2/e8, Orion BN/KL) are used to derive statistical properties of the plane of sky projected magnetic field. Structure function and auto-correlation function are calculated for observations with various resolutions from the BIMA and SMA interferometers, covering a range in physical scales from $\\sim 70$~mpc to $\\sim 2.1$~mpc. Results for the magnetic field turbulent dispersion, its turbulent to mean field strength ratio and the large-scale polarization angle correlation length are presented as a function of the physical scale at the star formation sites. Power law scaling relations emerge for some of these physical quantities. The turbulent to mean field strength ratio is found to be close to constant over the sampled observing range, with a hint of a decrease toward smaller scales, indicating that the role of magnetic field and turbulence is evolving with physical scale. A statistical method is proposed to separate large and small scale correlations from an initial ensemble of polarization segments. This also leads to a definition of a turbulent polarization angle correlation length.",
    "MGT": "# Magnetic Field Properties in High Mass Star Formation from Large to Small Scales - A Statistical Analysis from Polarization Data\n\nWe present a comprehensive statistical analysis of magnetic field properties across multiple spatial scales in high-mass star-forming regions using an unprecedented polarization dataset. By combining observations from the James Clerk Maxwell Telescope (JCMT), Atacama Large Millimeter/submillimeter Array (ALMA), and Submillimeter Array (SMA), we trace magnetic field morphologies from parsec-scale molecular clouds down to individual protostellar cores (0.01 pc). Our sample comprises 25 high-mass star-forming regions at various evolutionary stages. We quantify the magnetic field structure using the polarization angle dispersion function and derive magnetic field strengths via the Davis-Chandrasekhar-Fermi method. Results indicate that magnetic field orientation shows significant scale-dependent behavior, with increasing disorder at smaller scales. Statistical analysis reveals that the mass-to-flux ratio increases from marginally supercritical (1.2±0.3) at cloud scales to strongly supercritical (4.7±1.1) at core scales, suggesting diminishing magnetic support against gravitational collapse at smaller scales. We find a power-law relationship between magnetic field strength and gas density (B ∝ n^0.65±0.08), consistent with theoretical predictions for weakly ionized collapse. These findings provide critical constraints for numerical simulations of magnetized high-mass star formation and demonstrate the importance of multi-scale magnetic field observations in understanding the complex interplay between gravity, turbulence, and magnetic fields during star formation."
  },
  {
    "id": 144,
    "prompt": "Star cluster kinematics with AAOmega",
    "HWT": "The high-resolution setup of the AAOmega spectrograph on the Anglo-Australian Telescope makes it a beautiful radial velocity machine, with which one can measure velocities of up to 350-360 stars per exposure to +/-1--2 km/s in a 2-degree field of view. Here we present three case studies of star cluster kinematics, each based on data obtained on three nights in February 2008. The specific aims included: (i) cluster membership determination for NGC 2451A and B, two nearby open clusters in the same line-of-sight; (ii) a study of possible membership of the planetary nebula NGC 2438 in the open cluster M46; and (iii) the radial velocity dispersion of M4 and NGC 6144, a pair of two globular clusters near Antares. The results which came out of only three nights of AAT time illustrate very nicely the potential of the instrument and, for example, how quickly one can resolve decades of contradiction in less than two hours of net observing time.",
    "MGT": "# Star cluster kinematics with AAOmega\n\nWe present a comprehensive kinematic analysis of globular clusters using data obtained with the AAOmega spectrograph on the Anglo-Australian Telescope. Radial velocities were determined for 2,471 stars across 8 Galactic globular clusters, providing unprecedented kinematic coverage from core to tidal radius. Our multi-object spectroscopic observations achieve velocity precision of 0.5 km/s at V ≈ 16, allowing robust detection of velocity dispersion profiles and rotation signatures. We find significant rotation (2-4 km/s) in 5 clusters, with rotation axes aligned with cluster flattening. Velocity dispersion profiles reveal deviations from the expected King model predictions in the outer regions of NGC 6397 and 47 Tucanae, suggesting the influence of the Galactic tidal field. Mass-to-light ratios derived from our kinematic modeling range from 1.8 to 2.7 M⊙/L⊙, consistent with stellar population models without significant dark matter. The AAOmega dataset also enables metallicity analysis, revealing previously undetected population gradients in two clusters. These results demonstrate the power of wide-field multi-object spectroscopy for understanding the formation and dynamical evolution of Galactic globular clusters in the context of hierarchical galaxy assembly."
  },
  {
    "id": 145,
    "prompt": "The Dependence of Type Ia Supernova Luminosities on their Host Galaxies",
    "HWT": "(Abridged) Precision cosmology with Type Ia supernovae (SNe Ia) makes use of the fact that SN Ia luminosities depend on their light-curve shapes and colours. Using Supernova Legacy Survey (SNLS) and other data, we show that there is an additional dependence on the global characteristics of their host galaxies: events of the same light-curve shape and colour are, on average, 0.08mag (~4.0sigma) brighter in massive host galaxies (presumably metal-rich) and galaxies with low specific star-formation rates (sSFR). SNe Ia in galaxies with a low sSFR also have a smaller slope (\"beta\") between their luminosities and colours with ~2.7sigma significance, and a smaller scatter on SN Ia Hubble diagrams (at 95% confidence), though the significance of these effects is dependent on the reddest SNe. SN Ia colours are similar between low-mass and high-mass hosts, leading us to interpret their luminosity differences as an intrinsic property of the SNe and not of some external factor such as dust. If the host stellar mass is interpreted as a metallicity indicator, the luminosity trends are in qualitative agreement with theoretical predictions. We show that the average stellar mass, and therefore the average metallicity, of our SN Ia host galaxies decreases with redshift. The SN Ia luminosity differences consequently introduce a systematic error in cosmological analyses, comparable to the current statistical uncertainties on parameters such as w. We show that the use of two SN Ia absolute magnitudes, one for events in high-mass (metal-rich) galaxies, and one for events in low-mass (metal-poor) galaxies, adequately corrects for the differences. Cosmological fits incorporating these terms give a significant reduction in chi^2 (3.8-4.5sigma). We conclude that future SN Ia cosmological analyses should use a correction of this (or similar) form to control demographic shifts in the galaxy population.",
    "MGT": "# The Dependence of Type Ia Supernova Luminosities on their Host Galaxies\n\nWe present a comprehensive analysis of the relationship between Type Ia supernova (SN Ia) luminosities and the properties of their host galaxies using a sample of 403 SNe Ia from the combined Pantheon+ and Dark Energy Survey Year 5 datasets. Our study reveals significant correlations between SN Ia standardized luminosities and several host galaxy parameters, most notably stellar mass, specific star formation rate, and metallicity. After standardization with the conventional light-curve width and color corrections, SNe Ia in massive (log(M/M⊙) > 10) galaxies are found to be 0.064 ± 0.013 mag brighter than their counterparts in lower-mass hosts. This \"mass step\" persists even after accounting for additional light-curve properties, suggesting fundamental astrophysical differences in the SN Ia progenitor populations across different galactic environments.\n\nLeveraging deep multi-band photometry and spectroscopic observations of host galaxies, we develop a multivariate model that incorporates galaxy age, metallicity, and dust content as predictors of SN Ia luminosity variations. Our hierarchical Bayesian approach reveals that local metallicity at the SN site exhibits the strongest correlation (ρ = 0.31 ± 0.04) with Hubble residuals, followed by global stellar population age (ρ = 0.26 ± 0.05). These environmental dependencies contribute to a reduction in the intrinsic scatter of standardized SN Ia luminosities from 0.142 ± 0.008 mag to 0.112 ± 0.007 mag when incorporated into the standardization procedure.\n\nThe observed correlations are consistent with theoretical models suggesting that progenitor metallicity influences the 56Ni yield and thus the peak luminosity of SNe Ia. Additionally, our findings indicate that SNe Ia with older progenitors exhibit faster declining light curves and redder colors, aligning with the single-degenerate scenario predictions. We demonstrate that incorporating host galaxy properties into cosmological analyses reduces systematic uncertainties in dark energy constraints by approximately 18%. These results underscore the importance of characterizing host galaxy properties in future cosmological surveys employing SNe Ia as distance indicators, particularly for upcoming missions such as the Nancy Grace Roman Space Telescope and the Vera C. Rubin Observatory's Legacy Survey of Space and Time, which will extend SN Ia observations to higher redshifts where galaxy evolution effects may become increasingly significant."
  },
  {
    "id": 146,
    "prompt": "Radiative emission of solar features in the Ca II K line: comparison of measurements and models",
    "HWT": "We study the radiative emission of various types of solar features, such as quiet Sun, enhanced network, plage, and bright plage regions, identified on filtergrams taken in the Ca II K line. We analysed fulldisk images obtained with the PSPT, by using three interference filters that sample the Ca II K line with different bandpasses. We studied the dependence of the radiative emission of disk features on the filter bandpass. We also performed a NLTE spectral synthesis of the Ca II K line integrated over the bandpass of PSPT filters. The synthesis was carried out by utilizing both the PRD and CRD with the most recent set of semi empirical atmosphere models in the literature and some earlier atmosphere models. We measured the CLV of intensity values for various solar features identified on PSPT images and compared the results obtained with those derived from the synthesis. We find that CRD calculations derived using the most recent quiet Sun model, on average, reproduce the measured values of the quiet Sun regions slightly more accurately than PRD computations with the same model. This may reflect that the utilized atmospheric model was computed assuming CRD. Calculations with PRD on earlier quiet Sun model atmospheres reproduce measured quantities with a similar accuracy as to that achieved here by applying CRD to the recent model. We also find that the median contrast values measured for most of the identified bright features, disk positions, and filter widths are, on average, a factor 1.9 lower than those derived from PRD simulations performed using the recent bright feature models. The discrepancy between measured and modeled values decreases by 12% after taking into account straylight effects on PSPT images. PRD computations on either the most recent or the earlier atmosphere models of bright features reproduce measurements from plage and bright plage regions with a similar accuracy.",
    "MGT": "# Radiative emission of solar features in the Ca II K line: comparison of measurements and models\n\nThe Ca II K line serves as a critical diagnostic tool for examining solar chromospheric activity and its connection to magnetic structures. This study presents a comprehensive comparison between high-resolution spectroscopic measurements and advanced radiative transfer models of Ca II K emission from various solar features. Observations were obtained using the IBIS instrument at the Dunn Solar Observatory, capturing full spectral profiles across multiple solar regions, including quiet Sun, plage, network, and flaring areas. These data were complemented by co-temporal photospheric magnetograms from the Solar Dynamics Observatory's Helioseismic and Magnetic Imager. We developed a semi-empirical modeling framework integrating non-LTE radiative transfer with the RADYN and RH codes to reproduce the observed spectral features. The comparison between measured and synthetic Ca II K profiles reveals that while current models accurately reproduce emission characteristics of quiet Sun regions (agreement within 5%), they systematically underestimate core emission in magnetic concentrations by 15-30%, with discrepancies increasing proportionally with magnetic flux density. Particularly notable is the failure of existing models to reproduce the observed asymmetries in the K2 peaks within plage regions. We identify the treatment of partial redistribution effects and the incomplete incorporation of small-scale magnetic geometry as primary factors limiting model fidelity. Our analysis further demonstrates that the K3 minimum intensity correlates strongly with underlying magnetic flux (correlation coefficient r=0.78), while the K2V/K2R asymmetry shows sensitivity to local velocity gradients. By examining time-series data, we find that oscillatory phenomena produce distinctive signatures in the Ca II K profile that current time-dependent simulations capture qualitatively but not quantitatively. This work establishes quantitative benchmarks for future modeling efforts and highlights specific areas where refinements to non-LTE chromospheric models are needed. Our findings contribute to the interpretation of chromospheric diagnostics and advance our understanding of energy transport in the solar atmosphere, with implications for stellar chromospheric activity studies."
  },
  {
    "id": 147,
    "prompt": "Possible evidence for a common radial structure in nearby AGN tori",
    "HWT": "We present a quantitative and relatively model-independent way to assess the radial structure of nearby AGN tori. These putative tori have been studied with long-baseline infrared (IR) interferometry, but the spatial scales probed are different for different objects. They are at various distances and also have different physical sizes which apparently scale with the luminosity of the central engine. Here we look at interferometric visibilities as a function of spatial scales normalized by the size of the inner torus radius R_in. This approximately eliminates luminosity and distance dependence and, thus, provides a way to uniformly view the visibilities observed for various objects and at different wavelengths. We can construct a composite visibility curve over a large range of spatial scales if different tori share a common radial structure. The currently available observations do suggest model-independently a common radial surface brightness distribution in the mid-IR that is roughly of a power-law form r^-2 as a function of radius r, and extends to ~100 times R_in. Taking into account the temperature decrease toward outer radii with a simple torus model, this corresponds to the radial surface density distribution of dusty material directly illuminated by the central engine roughly in the range between r^0 and r^-1. This should be tested with further data.",
    "MGT": "We present a comprehensive analysis of mid-infrared interferometric observations of 25 nearby Active Galactic Nuclei (AGN), revealing compelling evidence for a common radial structure in their dusty tori. Using high-resolution data from the VLTI/MIDI instrument, combined with spectral energy distribution modeling, we investigate the spatial distribution and physical properties of dust in these systems. Our findings indicate a remarkably consistent radial density profile across the sample, characterized by a power-law index of α = -0.5 ± 0.1, independent of AGN luminosity or black hole mass. The observed dust temperatures range from 200-1500K, with a clear stratification pattern that suggests a universal formation mechanism. Statistical analysis reveals that 80% of the sources exhibit similar geometric parameters, including inclination angles and opening angles, pointing to a standardized torus configuration. We detect a significant correlation (p < 0.01) between the inner radius of the dusty structure and the AGN bolometric luminosity, consistent with dust sublimation physics. These results strongly support the existence of a common formation and evolution pathway for AGN tori in the local universe. Our findings have important implications for unified AGN models and provide new constraints for theoretical simulations of AGN feedback mechanisms. Future observations with next-generation interferometers will be crucial for extending this analysis to higher redshifts and lower luminosity AGN."
  },
  {
    "id": 148,
    "prompt": "Testing Newtonian gravity with distant globular clusters: NGC1851 and NGC1904",
    "HWT": "Globular clusters are useful to test the validity of Newtonian dynamics in the low acceleration regime typical of galaxies, without the complications of non-baryonic dark matter. Specifically, in absence of disturbing effects, e.g. tidal heating, their velocity dispersion is expected to vanish at large radii. If such behaviour is not observed, and in particular if, as observed in elliptical galaxies, the dispersion is found constant at large radii below a certain threshold acceleration, this might indicate a break down of Newtonian dynamics. To minimise the effects of tidal heating in this paper we study the velocity dispersion profile of two distant globular clusters, NGC 1851 and NGC 1904. The velocity dispersion profile is derived from accurate radial velocities measurements, obtained at the ESO 8m VLT telescope. Reliable data for 184 and 146 bona fide cluster star members, respectively for NGC 1851 and NGC 1904, were obtained. These data allow to trace the velocity dispersion profile up to ~2r0, where r0 is the radius at which the cluster internal acceleration of gravity is a0 = 10e-8 cm/s/s. It is found that in both clusters the velocity dispersion becomes constant beyond ~r0. These new results are fully in agreement with those found for other five globular clusters previously investigated as part of this project. Taken all together, these 7 clusters support the claim that the velocity dispersion is constant beyond r0, irrespectively of the specific physical properties of the clusters: mass, size, dynamical history, and distance from the Milky Way. The strong similarly with the constant velocity dispersion observed in elliptical galaxies beyond r0 is suggestive of a common origin for this phenomenon in the two class of objects, and might indicate a breakdown of Newtonian dynamics below a0.",
    "MGT": "We present a comprehensive analysis of the gravitational dynamics in the distant globular clusters NGC 1851 and NGC 1904 to test the validity of Newtonian gravity at large galactic distances. Using high-precision astrometric data from Gaia DR3 combined with ground-based radial velocity measurements spanning fifteen years, we constructed detailed kinematic profiles for both clusters extending to their tidal radii. Our sample includes 2,847 confirmed member stars in NGC 1851 and 1,923 in NGC 1904, with proper motion uncertainties below 0.05 mas/yr for stars brighter than V = 18.5 mag.\n\nWe employed a novel Bayesian framework to simultaneously fit the observed stellar velocity dispersions with predictions from modified Newtonian dynamics (MOND) and standard Newtonian gravity models. The analysis incorporates realistic stellar mass functions derived from deep Hubble Space Telescope photometry and accounts for binary star contamination through statistical deconvolution methods. For NGC 1851, located at a galactocentric distance of 12.1 kpc, we find the velocity dispersion profile exhibits a gradual decline from 4.8 ± 0.2 km/s in the core to 2.1 ± 0.4 km/s at the half-light radius, consistent with Newtonian expectations within 1.2σ. Similarly, NGC 1904 at 8.7 kpc shows dispersions ranging from 5.2 ± 0.3 km/s centrally to 2.8 ± 0.5 km/s at intermediate radii.\n\nRemarkably, both clusters demonstrate velocity dispersion profiles that deviate significantly from MOND predictions at accelerations below 10^-10 m/s^2, with χ^2 values 3.4 times higher than Newtonian models. The observed kinematic anisotropies, quantified through β parameters ranging from -0.15 to +0.25, align well with N-body simulations of tidally evolving clusters in Milky Way-like potentials. Our results provide strong empirical support for Newtonian gravity's continued validity at the distance scales probed by these remote globular clusters, placing stringent constraints on alternative gravity theories that predict deviations in the low-acceleration regime characteristic of galactic outskirts."
  },
  {
    "id": 149,
    "prompt": "Jets and environment of microquasars",
    "HWT": "Two relativistic X-ray jets have been detected with the Chandra X-ray observatory from the black hole X-ray transient XTE J1550-564. We report a full analysis of the evolution of the two jets with a gamma-ray burst external shock model. A plausible scenario suggests a cavity outside the central source and the jets first travelled with constant velocity and then are slowed down by the interactions between the jets and the interstellar medium (ISM). The best fitted radius of the cavity is $\\sim$0.36 pc on the eastern side and $\\sim$0.46 pc on the western side, and the densities also show asymmetry, of $\\sim$0.015 cm$^{-3}$ on the east to $\\sim$0.21 cm$^{-3}$ on the west. A large scale low density region is also found in another microquasar system, H 1743-322. These results are consistent with previous suggestions that the environment of microquasars should be rather vacuous, compared to the normal Galactic environment. A generic scenario for microquasar jets is proposed, classifying the observed jets into three main categories, with different jet morphologies (and sizes) corresponding to different scales of vacuous environments surrounding them.",
    "MGT": "Microquasars are stellar-mass black holes or neutron stars that exhibit relativistic jets similar to those observed in active galactic nuclei, but on much smaller spatial and temporal scales. This review examines the complex interplay between microquasar jets and their surrounding environments, highlighting recent observational and theoretical advances in understanding these systems. We analyze the formation mechanisms of relativistic jets in X-ray binaries, focusing on the role of magnetic fields, accretion disk dynamics, and spin-orbit coupling in jet launching and collimation. The interaction between jets and the interstellar medium produces observable signatures across the electromagnetic spectrum, from radio to gamma-rays, providing crucial insights into jet composition, energetics, and propagation physics. We discuss how environmental factors, including stellar winds from companion stars, ambient density gradients, and magnetic field configurations, influence jet morphology and evolution. Particular attention is given to the formation of jet-blown cavities, shock structures, and particle acceleration mechanisms at jet-environment boundaries. Multi-wavelength observations reveal that microquasar jets can significantly impact their local environments, heating surrounding gas, triggering star formation in some cases, and contributing to cosmic ray populations. We examine the scaling relationships between microquasars and their supermassive counterparts, emphasizing both similarities and fundamental differences. Future observational prospects with next-generation radio interferometers and high-energy telescopes promise to revolutionize our understanding of jet-environment interactions in these fascinating astrophysical laboratories."
  },
  {
    "id": 150,
    "prompt": "Radio and mid-infrared identification of BLAST source counterparts in the Chandra Deep Field South",
    "HWT": "We have identified radio and/or mid-infrared counterparts to 198 out of 350 sources detected at >=5 sigma over ~ 9 square degrees centered on the Chandra Deep Field South (CDFS) by the Balloon-borne Large Aperture Submillimeter Telescope (BLAST) at 250, 350 and 500 um. We have matched 114 of these counterparts to optical sources with previously derived photometric redshifts and fitted SEDs to the BLAST fluxes and fluxes at 70 and 160 um acquired with the Spitzer Space Telescope. In this way, we have constrained dust temperatures, total far-infrared/sub-millimeter luminosities and star formation rates for each source. Our findings show that on average, the BLAST sources lie at significantly lower redshifts and have significantly lower rest-frame dust temperatures compared to submm sources detected in surveys conducted at 850 um. We demonstrate that an apparent increase in dust temperature with redshift in our sample arises as a result of selection effects. Finally, we provide the full multi-wavelength catalog of >= 5 sigma BLAST sources contained within the complete ~ 9 square degree survey area.",
    "MGT": "We present radio and mid-infrared counterpart identification for submillimeter sources detected by the Balloon-borne Large Aperture Submillimeter Telescope (BLAST) in the Chandra Deep Field South. Using deep 1.4 GHz radio observations from the Australia Telescope Compact Array and Spitzer Space Telescope mid-infrared data at 24 μm, we identify counterparts to 43% of the 99 BLAST sources detected at 250, 350, and 500 μm. Radio identification yields counterparts for 35 sources, while mid-infrared identification provides counterparts for an additional 8 sources without radio detections. We employ a likelihood ratio analysis to ensure robust statistical identification, achieving reliability levels exceeding 80% for our counterpart sample. The identified sources exhibit median redshifts of z ~ 2.2, consistent with the peak epoch of cosmic star formation activity. Cross-correlation with X-ray catalogs reveals that 15% of counterparts show evidence for active galactic nucleus activity. We derive infrared luminosities ranging from 10^11 to 10^13 L_☉, classifying most sources as luminous or ultraluminous infrared galaxies. The radio-to-submillimeter flux density ratios suggest these galaxies are undergoing intense star formation episodes with rates of 100-1000 M_☉ yr^-1. Our results provide crucial multi-wavelength constraints for understanding the nature and evolution of dusty star-forming galaxies in the early universe."
  },
  {
    "id": 151,
    "prompt": "Noncommutativity in space-time extended by Liouville field",
    "HWT": "The world-sheet quantum conformal invariance can be realized in the presence of the conformal factor $F$, by inclusion of Liouville term. In the background with linear dilaton field, $\\Phi(x)=\\Phi_0+a_\\mu x^\\mu$, the field $F$ becomes a new noncommutative variable. Therefore, it is natural to extend space-time with a new coordinate, $F$, in order to unify expressions for noncommutativity parameter $\\Theta^{ij}$ of the space-time coordinates $x^i$, with the part $\\Theta^i$ connecting noncommutativity between coordinates $x^i$ and $F$. In this way we solve the problems of Dp-brane noncommutativity in a more elegant way. The technical advantage uses the fact that in the extended space-time the action with dilaton field can be rewritten in dilaton free form. We use canonical method and extend its application to the derivation of boundary conditions. From requirement that Hamiltonian, as the time translation generator, has well defined derivatives in the coordinates and momenta, we obtain boundary conditions directly in the canonical form.",
    "MGT": "We investigate the noncommutative structure of spacetime when extended by the Liouville field, a fundamental component in two-dimensional conformal field theory and string theory. The Liouville field introduces a natural deformation of the classical spacetime geometry, leading to modified commutation relations between coordinate operators. We demonstrate that the inclusion of the Liouville field generates a noncommutative algebra characterized by a parameter θ that depends on the field's coupling constant and background configuration. Through rigorous mathematical analysis, we derive the deformed Heisenberg algebra and show how the noncommutativity manifests in both spatial and temporal coordinates. The resulting spacetime exhibits anisotropic noncommutative properties, with the degree of noncommutativity varying according to the Liouville field profile. We compute the modified dispersion relations for particles propagating in this extended spacetime and find significant deviations from standard relativistic behavior at high energies. The implications for quantum field theory in curved spacetime are explored, revealing modified uncertainty principles and altered causality structures. Our results suggest that Liouville field extensions provide a viable framework for studying quantum gravity effects and may offer insights into the fundamental discreteness of spacetime at the Planck scale. These findings contribute to the broader understanding of noncommutative geometry in theoretical physics."
  },
  {
    "id": 152,
    "prompt": "Concavity for nuclear binding energies, thermodynamical functions and density functionals",
    "HWT": "Sequences of experimental ground-state energies for both odd and even $A$ are mapped onto concave patterns cured from convexities due to pairing and/or shell effects. The same patterns, completed by a list of excitation energies, give numerical estimates of the grand potential $\\Omega(\\beta, \\mu)$ for a mixture of nuclei at low or moderate temperatures $T=\\beta^{-1}$ and at many chemical potentials $\\mu. $ The average nucleon number $<{\\bf A} >(\\beta, \\mu)$ then becomes a continuous variable, allowing extrapolations towards nuclear masses closer to drip lines. We study the possible concavity of several thermodynamical functions, such as the free energy and the average energy, as functions of $<{\\bf A} >. $ Concavity, which always occur for the free energy and is usually present for the average energy, allows easy interpolations and extrapolations providing upper and lower bounds, respectively, to binding energies. Such bounds define an error bar for the prediction of binding energies. Finally we show how concavity and universality are related in the theory of the nuclear density functional.",
    "MGT": "The concavity properties of nuclear binding energies, thermodynamical functions, and density functionals are investigated through a unified mathematical framework. We demonstrate that the binding energy per nucleon exhibits strict concavity as a function of mass number for medium and heavy nuclei, providing fundamental constraints on nuclear stability and fission processes. This concavity behavior is shown to be intrinsically connected to the convexity properties of thermodynamical potentials, particularly the Gibbs free energy and Helmholtz free energy, through the principle of maximum entropy production.\n\nUsing density functional theory, we establish rigorous mathematical relationships between the concavity of exchange-correlation functionals and the thermodynamical stability of nuclear matter. Our analysis reveals that violations of concavity in approximate density functionals directly correlate with unphysical predictions of nuclear properties, including negative heat capacities and unstable phase transitions.\n\nWe derive new sum rules that connect the curvature of binding energy surfaces to measurable thermodynamical quantities such as specific heat and compressibility. Numerical calculations using advanced nuclear density functionals validate our theoretical predictions across the nuclear chart, with particular emphasis on neutron-rich isotopes relevant to r-process nucleosynthesis.\n\nThese findings provide essential theoretical foundations for improving nuclear equation-of-state models and density functional approximations, with direct applications to neutron star physics and heavy element formation in stellar environments."
  },
  {
    "id": 153,
    "prompt": "Quantum corrections to solitons and BPS saturation",
    "HWT": "We review our work of the past decade on one-loop quantum corrections to the mass M and central charge Z of solitons in supersymmetric field theories: the kink, the vortex, and the monopoles (focussing on the kink and the monopoles here). In each case a new feature was needed to obtain BPS saturation: a new anomaly-like contribution to Z for the kink and the N=2 monopole, the effect of classical winding of the quantum vortex contributing to Z, surface terms contributing to M of the N=4 monopole and to Z of the N=2 and N=4 monopoles, and composite operator renormalization for the currents of the \"finite\" N=4 model. We use dimensional regularization, modified to preserve susy and be applicable to solitons, and suitable renormalization conditions. In the mode expansion of bosonic and fermionic quantum fields, zero modes appear then as massless nonzero modes.",
    "MGT": "We investigate quantum corrections to classical soliton solutions in supersymmetric field theories and examine their impact on BPS saturation conditions. Using semiclassical methods, we compute one-loop quantum corrections to the masses and central charges of topological solitons in N=2 supersymmetric gauge theories. Our analysis reveals that quantum fluctuations around classical soliton backgrounds generate corrections that preserve the BPS bound structure while modifying the saturating solutions. We demonstrate that the quantum-corrected soliton masses continue to saturate the Bogomol'nyi bound, but with renormalized central charges that incorporate loop effects. The corrections exhibit a universal structure dependent on the soliton's topological charge and the underlying gauge group. We find that quantum corrections to multi-soliton configurations maintain their non-interaction property in the BPS limit, preserving the classical moduli space geometry at the quantum level. Our results establish that BPS saturation remains a robust feature under quantum corrections, with the corrected solutions forming representations of the quantum-deformed supersymmetry algebra. These findings have important implications for understanding non-perturbative aspects of supersymmetric field theories and their connections to integrable systems."
  },
  {
    "id": 154,
    "prompt": "Generation-by-Generation Dissection of the Response Function in Long Memory Epidemic Processes",
    "HWT": "In a number of natural and social systems, the response to an exogenous shock relaxes back to the average level according to a long-memory kernel $\\sim 1/t^{1+\\theta}$ with $0 \\leq \\theta <1$. In the presence of an epidemic-like process of triggered shocks developing in a cascade of generations at or close to criticality, this \"bare\" kernel is renormalized into an even slower decaying response function $\\sim 1/t^{1-\\theta}$. Surprisingly, this means that the shorter the memory of the bare kernel (the larger $1+\\theta$), the longer the memory of the response function (the smaller $1-\\theta$). Here, we present a detailed investigation of this paradoxical behavior based on a generation-by-generation decomposition of the total response function, the use of Laplace transforms and of \"anomalous\" scaling arguments. The paradox is explained by the fact that the number of triggered generations grows anomalously with time at $\\sim t^\\theta$ so that the contributions of active generations up to time $t$ more than compensate the shorter memory associated with a larger exponent $\\theta$. This anomalous scaling results fundamentally from the property that the expected waiting time is infinite for $0 \\leq \\theta \\leq 1$. The techniques developed here are also applied to the case $\\theta >1$ and we find in this case that the total renormalized response is a {\\bf constant} for $t < 1/(1-n)$ followed by a cross-over to $\\sim 1/t^{1+\\theta}$ for $t \\gg 1/(1-n)$.",
    "MGT": "This study presents a comprehensive analysis of long memory epidemic processes through a novel generation-by-generation dissection methodology that decomposes the response function into its constituent temporal components. Long memory processes in epidemiology exhibit power-law decay characteristics that significantly influence disease transmission dynamics over extended time horizons, yet the underlying mechanisms driving these patterns remain poorly understood. We develop a mathematical framework that systematically partitions the epidemic response function across successive generations of infection, enabling precise identification of how memory effects propagate through transmission networks.\n\nOur approach employs fractional differential equations coupled with branching process theory to model the intergenerational transfer of epidemic memory. The methodology reveals that long memory emerges from the cumulative interaction between generation-specific transmission rates and the temporal correlation structure of infectious contacts. Through rigorous mathematical analysis, we demonstrate that the response function can be decomposed into a weighted sum of generation-specific kernels, each characterized by distinct decay exponents that reflect the heterogeneity in transmission pathways.\n\nEmpirical validation using historical epidemic data from influenza, measles, and COVID-19 outbreaks confirms the theoretical predictions and reveals significant variations in memory persistence across different pathogens. The generation-by-generation analysis identifies critical transition points where memory effects either amplify or diminish, providing insights into optimal intervention timing. Notably, we find that early-generation interventions have disproportionately large effects on long-term epidemic trajectories due to memory amplification mechanisms.\n\nThe findings have important implications for epidemic forecasting and control strategies. By understanding how memory effects accumulate across generations, public health authorities can design more effective intervention protocols that account for the temporal persistence of transmission patterns. The decomposition methodology also provides a new diagnostic tool for identifying the dominant sources of long memory in epidemic systems, facilitating targeted interventions that maximize impact while minimizing resource allocation. This work establishes a foundation for next-generation epidemic models that explicitly incorporate generational memory structures."
  },
  {
    "id": 155,
    "prompt": "Diffusivity bounds for 1D Brownian polymers",
    "HWT": "We study the asymptotic behavior of a self-interacting one-dimensional Brownian polymer first introduced by Durrett and Rogers [Probab. Theory Related Fields 92 (1992) 337--349]. The polymer describes a stochastic process with a drift which is a certain average of its local time. We show that a smeared out version of the local time function as viewed from the actual position of the process is a Markov process in a suitably chosen function space, and that this process has a Gaussian stationary measure. As a first consequence, this enables us to partially prove a conjecture about the law of large numbers for the end-to-end displacement of the polymer formulated in Durrett and Rogers [Probab. Theory Related Fields 92 (1992) 337--349]. Next we give upper and lower bounds for the variance of the process under the stationary measure, in terms of the qualitative infrared behavior of the interaction function. In particular, we show that in the locally self-repelling case (when the process is essentially pushed by the negative gradient of its own local time) the process is super-diffusive.",
    "MGT": "We establish rigorous upper and lower bounds on the effective diffusivity of one-dimensional Brownian polymers in random environments. Using a combination of homogenization theory and large deviation principles, we analyze the long-time behavior of polymer chains subject to both thermal fluctuations and quenched disorder. Our main result provides explicit bounds on the diffusion coefficient D_eff in terms of the polymer length N, temperature T, and disorder strength σ. We prove that D_eff scales as N^(-α) where α ∈ [1/2, 1] depends on the interplay between entropic and disorder effects. For weak disorder (σ << T), we show D_eff ~ N^(-1/2) with logarithmic corrections, consistent with the reptation model. In the strong disorder regime (σ >> T), the diffusivity exhibits anomalous scaling D_eff ~ N^(-1) characteristic of single-file diffusion with disorder-induced correlations. Our bounds are obtained through a novel variational approach that exploits the Gaussian nature of the polymer statistics and the renewal structure of the optimal paths. We complement the theoretical analysis with numerical simulations demonstrating the sharpness of our bounds across different parameter regimes. These results provide new insights into the transport properties of biological polymers and have implications for understanding DNA dynamics in chromatin and protein folding kinetics in crowded cellular environments."
  },
  {
    "id": 156,
    "prompt": "$H^1$ and dyadic $H^1$",
    "HWT": "In this paper we give a simple proof of the fact that the average over all dyadic lattices of the dyadic $H^1$-norm of a function gives an equivalent $H^1$-norm. The proof we present works for both one-parameter and multi-parameter Hardy spaces. The results of such type are known. The first result (for one-parameter Hardy spces) belongs to Burgess Davis (1980). Also, by duality, such results are equivalent to the \"BMO from dyadic BMO\" statements proved by Garnett-Jones(1982} for one parameter case, and by Pipher-Ward (2008) for two-parameter case. While the paper generalizes these results to the multi-parameter setting, this is not its main goal. The purpose of the paper is to present an approach leading to a simple proof, which works in both one-parameter and multi-parameter cases. The main idea of treating square function as a Calderon--Zygmind operator is a commonplace in harmonic analysis; the main observation, on which the paper is based, is that one can treat the random dyadic square function this way. After that, all is proved by using the standard and well-known results about Calderon--Zygmind operators in the Hilbert-space-valued setting. As an added bonus, we get a simple proof of the (equivalent by duality) inclusion $\\text{BMO}\\subset \\text{BMO}_d$, $H^1_d \\subset H^1$ in the multi-parameter case. Note, that unlike the one-parameter case, the inclusions in the general situation are far from trivial.",
    "MGT": "We establish the relationship between the classical Hardy space $H^1(\\mathbb{R}^n)$ and its dyadic counterpart $H^1_d(\\mathbb{R}^n)$, providing a comprehensive analysis of their equivalence and structural properties. The dyadic Hardy space $H^1_d$ is defined using dyadic martingales and square function characterizations based on dyadic cubes, while the classical $H^1$ space employs continuous maximal functions and atomic decompositions. Our main result demonstrates that these two spaces are isomorphic as Banach spaces, with equivalent norms differing by at most universal constants independent of dimension.\n\nWe first develop the atomic theory for dyadic $H^1$, showing that every element can be decomposed into dyadic atoms supported on dyadic cubes with appropriate size and moment conditions. The key technical contribution involves constructing an explicit mapping between classical and dyadic atoms through sophisticated stopping time arguments and martingale techniques. We prove that classical $(1,\\infty)$-atoms can be efficiently approximated by finite linear combinations of dyadic atoms, with the approximation error controlled by geometric series involving the atom's support and cancellation properties.\n\nThe reverse direction requires more delicate analysis. We establish that dyadic atoms, when viewed as distributions, satisfy the classical atomic conditions up to controlled error terms. This is achieved through careful estimation of oscillation integrals and exploitation of the tree structure inherent in dyadic decompositions. Our approach utilizes wavelet-type arguments and relies crucially on the nested property of dyadic cubes.\n\nAs applications, we derive several corollaries including the equivalence of various characterizations of $H^1$, sharp estimates for dyadic maximal operators, and new proofs of classical interpolation theorems. The techniques developed here extend naturally to weighted settings and provide insights into the structure of Hardy spaces on spaces of homogeneous type. Our results have implications for harmonic analysis, particularly in understanding the discrete versus continuous nature of Hardy space theory."
  },
  {
    "id": 157,
    "prompt": "Constraints on the Cosmological Constant due to Scale Invariance",
    "HWT": "We consider the standard model with local scale invariance. The theory shows exact scale invariance of dimensionally regulated action. We show that massless gauge fields, which may be abelian or non-abelian, lead to vanishing contribution to the cosmological constant in this theory. This result follows in the quantum theory, to all orders in the gauge couplings. However we have not considered contributions higher orders in the gravitational coupling. Similarly we also find that massless fermion fields yield null contribution to the cosmological constant. The effective cosmological constant in this theory is non-zero due to the phenomenon of cosmological symmetry breaking, which also gives masses to all the massive fields, besides generating the Planck mass. We find a simple relationship between the curvature scalar and the vacuum value of the Higgs field in the limit when we ignore all other contributions to the energy density besides the vacuum energy.",
    "MGT": "We investigate the implications of scale invariance for the cosmological constant problem in general relativity. By imposing Weyl conformal symmetry on the gravitational action, we derive stringent constraints on the vacuum energy density that contribute to the cosmological constant. Our analysis demonstrates that strict scale invariance requires the cosmological constant to vanish identically, providing a potential resolution to the hierarchy problem between quantum field theory predictions and observational constraints. We examine the consequences of spontaneous symmetry breaking in this framework, showing that small deviations from exact scale invariance can generate cosmological constants consistent with current observations of dark energy. Using dimensional analysis and renormalization group techniques, we establish bounds on the magnitude of scale-breaking parameters that maintain phenomenological viability. The formalism is extended to include scalar field dynamics, revealing natural mechanisms for dynamical dark energy models. Our results suggest that the observed cosmological constant may emerge from subtle violations of scale invariance at high energy scales, offering a unified approach to understanding both the smallness and non-zero value of the cosmological constant in our universe."
  },
  {
    "id": 158,
    "prompt": "Total Variation, Adaptive Total Variation and Nonconvex Smoothly Clipped Absolute Deviation Penalty for Denoising Blocky Images",
    "HWT": "The total variation-based image denoising model has been generalized and extended in numerous ways, improving its performance in different contexts. We propose a new penalty function motivated by the recent progress in the statistical literature on high-dimensional variable selection. Using a particular instantiation of the majorization-minimization algorithm, the optimization problem can be efficiently solved and the computational procedure realized is similar to the spatially adaptive total variation model. Our two-pixel image model shows theoretically that the new penalty function solves the bias problem inherent in the total variation model. The superior performance of the new penalty is demonstrated through several experiments. Our investigation is limited to \"blocky\" images which have small total variation.",
    "MGT": "This paper investigates three penalty-based approaches for denoising blocky images: Total Variation (TV), Adaptive Total Variation (ATV), and Nonconvex Smoothly Clipped Absolute Deviation (SCAD). We propose a unified framework that combines these regularization techniques to address the limitations of traditional TV methods, which often produce staircase artifacts and over-smooth edges in piecewise constant regions. The adaptive total variation approach dynamically adjusts regularization strength based on local image characteristics, while the nonconvex SCAD penalty provides better preservation of sharp discontinuities. Our algorithm employs proximal gradient methods with convergence guarantees for the nonconvex optimization problem. Experimental results on synthetic and real blocky images demonstrate superior performance compared to standard TV denoising, achieving improved edge preservation while effectively removing noise. The proposed method shows particular effectiveness for images with cartoon-like structures and piecewise constant regions."
  },
  {
    "id": 159,
    "prompt": "Graphical Probabilistic Routing Model for OBS Networks with Realistic Traffic Scenario",
    "HWT": "Burst contention is a well-known challenging problem in Optical Burst Switching (OBS) networks. Contention resolution approaches are always reactive and attempt to minimize the BLR based on local information available at the core node. On the other hand, a proactive approach that avoids burst losses before they occur is desirable. To reduce the probability of burst contention, a more robust routing algorithm than the shortest path is needed. This paper proposes a new routing mechanism for JET-based OBS networks, called Graphical Probabilistic Routing Model (GPRM) that selects less utilized links, on a hop-by-hop basis by using a bayesian network. We assume no wavelength conversion and no buffering to be available at the core nodes of the OBS network. We simulate the proposed approach under dynamic load to demonstrate that it reduces the Burst Loss Ratio (BLR) compared to static approaches by using Network Simulator 2 (ns-2) on NSFnet network topology and with realistic traffic matrix. Simulation results clearly show that the proposed approach outperforms static approaches in terms of BLR.",
    "MGT": "This paper presents a novel graphical probabilistic routing model for Optical Burst Switching (OBS) networks that addresses the challenges of dynamic traffic management under realistic network conditions. Traditional OBS routing algorithms often fail to account for the stochastic nature of burst arrivals and the complex interdependencies between network nodes, leading to suboptimal performance in real-world deployments. Our proposed model employs Bayesian networks to capture the probabilistic relationships between burst characteristics, network topology, and resource availability. The graphical representation enables efficient inference of optimal routing paths while considering uncertainty in traffic patterns and network state information. We incorporate realistic traffic scenarios including self-similar traffic models, correlated burst arrivals, and varying Quality of Service requirements. The model utilizes belief propagation algorithms to dynamically update routing decisions based on observed network conditions and predicted traffic behaviors. Extensive simulations demonstrate that our approach achieves significant improvements in burst loss probability, end-to-end delay, and network throughput compared to conventional shortest-path and deflection routing schemes. The results show up to 23% reduction in burst blocking probability and 18% improvement in average network utilization under high-load conditions, making it particularly suitable for next-generation optical networks supporting diverse multimedia applications."
  },
  {
    "id": 160,
    "prompt": "Technicolor and Lattice Gauge Theory",
    "HWT": "Technicolor and other theories of dynamical electroweak symmetry breaking invoke chiral symmetry breaking triggered by strong gauge-dynamics, analogous to that found in QCD, to explain the observed W, Z, and fermion masses. In this talk we describe why a realistic theory of dynamical electroweak symmetry breaking must, relative to QCD, produce an enhanced fermion condensate. We quantify the degree to which the technicolor condensate must be enhanced in order to yield the observed quark masses, and still be consistent with phenomenological constraints on flavor-changing neutral-currents. Lattice studies of technicolor and related theories provide the only way to demonstrate that such enhancements are possible and, hopefully, to discover viable candidate models. We comment briefly on the current status of non-perturbative investigations of dynamical electroweak symmetry breaking, and provide a \"wish-list\" of phenomenologically-relevant properties that are important to calculate in these theories",
    "MGT": "This paper explores the connection between Technicolor theories and lattice gauge theory, presenting novel numerical results from large-scale Monte Carlo simulations of SU(N) gauge theories with dynamical fermions. We investigate the behavior of walking Technicolor theories near the conformal window using lattice regularization techniques. Our calculations focus on the spectrum of composite states, decay constants, and the running of the coupling constant in theories with different numbers of fermion flavors. We find evidence for a slowly running coupling constant and an anomalously light scalar state in theories just below the conformal window, consistent with walking Technicolor scenarios. The results provide important constraints on Technicolor model building and suggest that theories with Nf ≈ 12 flavors exhibit features desirable for dynamical electroweak symmetry breaking while potentially avoiding phenomenological difficulties of traditional Technicolor models. These findings have significant implications for understanding strongly coupled gauge theories and their role in physics beyond the Standard Model."
  },
  {
    "id": 161,
    "prompt": "Characteristics of Anemone Active Regions Appearing in Coronal Holes Observed with {\\it Yohkoh} Soft X-ray Telescope",
    "HWT": "Coronal structure of active regions appearing in coronal holes is studied by using the data obtained with the Soft X-Ray Telescope (SXT) aboard {\\it Yohkoh} from 1991 November to 1993 March. The following characteristics are found; Many of active regions appearing in coronal holes show a structure that looks like a ``sea-anemone''. Such active regions are called {\\it anemone ARs}. About one-forth of all active regions that were observed with SXT from their births showed the anemone structure. For almost all the anemone ARs, the order of magnetic polarities is consistent with the Hale-Nicholson's polarity law. These anemone ARs also showed more or less east-west asymmetry in X-ray intensity distribution, such that the following (eastern) part of the ARs is brighter than its preceding (western) part. This, as well as the anemone shape itself, is consistent with the magnetic polarity distribution around the anemone ARs. These observations also suggest that an active region appearing in coronal holes has simpler (less sheared) and more preceding-spot-dominant magnetic structure than those appearing in other regions.",
    "MGT": "We present a comprehensive analysis of anemone active regions (AARs) observed within coronal holes using data from the Yohkoh Soft X-ray Telescope (SXT) during 1991-2001. Our study identified 28 distinct AARs, characterized by their unique loop structures diverging from a central point, resembling sea anemone tentacles. These features consistently displayed bright, compact cores surrounded by fan-shaped loops extending into the darker coronal hole regions. Statistical analysis reveals that 71% of the observed AARs were associated with emerging magnetic flux regions, while the remaining cases developed from pre-existing active regions. The average lifetime of these structures was found to be 3.2 days, with core temperatures ranging from 2-3 MK. Using potential field extrapolations, we demonstrate that these configurations result from the interaction between emerging bipolar magnetic fields and the unipolar magnetic environment of coronal holes. Our observations indicate that AARs preferentially appear near coronal hole boundaries and exhibit a systematic hemispheric asymmetry, with 64% occurring in the northern hemisphere. These findings provide new insights into the formation and evolution of AARs, contributing to our understanding of solar magnetic field dynamics and coronal hole physics."
  },
  {
    "id": 162,
    "prompt": "The Nearby and Extremely Metal-Poor Galaxy CGCG 269-049",
    "HWT": "We present Hubble Space Telescope (HST) and Spitzer Space Telescope images and photometry of the extremely metal-poor (Z = 0.03 Z_sol) blue dwarf galaxy CGCG 269-049. The HST images reveal a large population of red giant and asymptotic giant branch stars, ruling out the possibility that the galaxy has recently formed. From the magnitude of the tip of the red giant branch, we measure a distance to CGCG 269-049 of only 4.9 +/- 0.4 Mpc. The spectral energy distribution of the galaxy between ~3.6 - 70 microns is also best fitted by emission from predominantly ~10 Gyr old stars, with a component of thermal dust emission having a temperature of 52 +/- 10 K. The HST and Spitzer photometry indicate that more than 60% of CGCG 269-049's stellar mass consists of stars ~10 Gyr old, similar to other local blue dwarf galaxies. Our HST H-alpha image shows no evidence of a supernova-driven outflow that could be removing metals from the galaxy, nor do we find evidence that such outflows occurred in the past. Taken together with CGCG 269-049's large ratio of neutral hydrogen mass to stellar mass (~10), these results are consistent with recent simulations in which the metal deficiency of local dwarf galaxies results mainly from inefficient star formation, rather than youth or the escape of supernova ejecta.",
    "MGT": "We present a detailed spectroscopic and photometric analysis of CGCG 269-049, an extremely metal-poor galaxy located in the nearby Universe at a distance of approximately 4.7 Mpc. Using deep optical spectroscopy from the Gemini North telescope combined with archival HST imaging, we have determined the key physical properties of this remarkable system. Our measurements reveal an oxygen abundance of 12 + log(O/H) = 7.14 ± 0.08, placing CGCG 269-049 among the most metal-deficient galaxies known. The galaxy exhibits intense star formation activity with numerous young stellar clusters and HII regions, suggesting a recent burst of star formation. Analysis of color-magnitude diagrams indicates the presence of both young (<10 Myr) and intermediate-age (100-500 Myr) stellar populations. The total stellar mass is estimated at 2.3 × 10⁶ M⊙, while the neutral hydrogen mass derived from HI observations is 1.8 × 10⁸ M⊙, yielding an unusually high gas-to-stellar mass ratio of ~78. The galaxy's isolation and extremely low metallicity, combined with its proximity, make it an ideal laboratory for studying star formation and chemical evolution in conditions similar to those in the early Universe. We also detect several extended ionized gas filaments, suggesting possible outflows driven by recent stellar feedback. These results provide important constraints on the formation and evolution of extremely metal-poor galaxies in the local Universe and offer insights into the physics of star formation in near-pristine environments."
  },
  {
    "id": 163,
    "prompt": "Spin-Dynamics of the antiferromagnetic S=1/2-Chain at finite magnetic Fields and intermediate Temperatures",
    "HWT": "We present a study of the dynamic structure factor of the antiferromagnetic spin-1/2 Heisenberg chain at finite temperatures and finite magnetic fields. Using Quantum-Monte-Carlo based on the stochastic series expansion and Maximum-Entropy methods we evaluate the longitudinal and the transverse dynamic structure factor from vanishing magnetic fields up to and above the threshold $B_c$ for ferromagnetic saturation, as well as for high and for intermediate temperatures. We study the field-induced redistribution of spectral weight contrasting longitudinal versus transverse excitations. At finite fields below saturation incommensurate low-energy modes are found consistent with zero temperature Bethe-Ansatz. The crossover between the field induced ferromagnet above $B_c$ and the Luttinger liquid below $B_c$ is analyzed in terms of the transverse spin-dynamics. Evaluating sum-rules we assess the quality of the analytic continuation and demonstrate excellent consistency of the Maximum-Entropy results.",
    "MGT": "We present a comprehensive theoretical and numerical investigation of the spin dynamics in one-dimensional S=1/2 antiferromagnetic Heisenberg chains under finite magnetic fields at intermediate temperatures. Using quantum Monte Carlo simulations combined with analytic continuation techniques, we calculate the dynamic structure factor S(q,ω) and analyze the temperature and field dependence of spin excitations. Our results reveal a complex interplay between thermal and quantum fluctuations, leading to significant modifications of the spinon continuum. We observe a field-induced shift of spectral weight and the emergence of novel collective modes at intermediate temperatures. The calculated dynamic correlations show excellent agreement with recent neutron scattering experiments on KCuF3. Additionally, we demonstrate that the system exhibits unique scaling behavior in the temperature range 0.2J < T < J, where J is the exchange coupling constant. These findings provide crucial insights into the thermodynamic properties of quantum spin chains and their experimental signatures."
  },
  {
    "id": 164,
    "prompt": "Millisecond microwave spikes: statistical study and application for plasma diagnostics",
    "HWT": "We analyze a dense cluster of solar radio spikes registered at ~ 4.5 -- 6 GHz by the Purple Mountain Observatory spectrometer (Nanjing, China) operating in the 4.5 -- 7.5 GHz range with the 5 ms temporal resolution. To handle with the data from the spectrometer we developed a new technique utilizing a nonlinear multi-Gaussian spectral fit based on chi-squared criteria to extract individual spikes from the originally recorded spectra. Applying this method to the experimental raw data we eventually identified about 3000 spikes for this event, which allows for a detailed statistical analysis. Various statistical characteristics of the spikes have been evaluated, including intensity distributions, spectral bandwidth distributions, and distribution of the spike mean frequencies. The most striking finding of this analysis is distributions of the spike bandwidth, which are remarkably asymmetric. To reveal the underlaying microphysics we explore the local trap model with the renormalized theory of spectral profile of the electron cyclotron maser (ECM) emission peak in a source with random magnetic irregularities. The distribution of the solar spikes relative bandwidth calculated within the local trap model represents an excellent fit to the experimental data. Accordingly, the developed technique may offer a new tool of studying very low levels of the magnetic turbulence in the spike sources, when the ECM mechanism of the spike cluster is confirmed.",
    "MGT": "This study presents a comprehensive statistical analysis of millisecond microwave spike bursts observed during solar flares and explores their potential as diagnostic tools for plasma conditions. Using high-resolution data from multiple radio observatories collected between 2018-2022, we analyzed 237 distinct spike events in the 1-18 GHz frequency range. The temporal and spectral characteristics of these spikes, including duration, bandwidth, and frequency drift rates, were systematically cataloged and statistically evaluated. Our results reveal that the spike durations follow a log-normal distribution with a mean value of 8.3 ms, while their instantaneous bandwidths exhibit a power-law relationship with frequency. The observed frequency drift rates range from -8 to +12 GHz/s, with asymmetric distributions suggesting different underlying acceleration mechanisms. By comparing these parameters with theoretical models of plasma emission and electron cyclotron maser emission, we developed a novel diagnostic method for determining local plasma parameters, including electron density, temperature, and magnetic field strength in the solar corona. The method was validated using simultaneous X-ray observations and magnetic field extrapolations. Our findings demonstrate that millisecond microwave spikes can serve as effective probes of plasma conditions in solar flare regions, providing spatial resolution superior to traditional imaging techniques. This work establishes a new framework for utilizing high-time-resolution radio observations in solar plasma diagnostics and contributes to our understanding of particle acceleration processes in solar flares."
  },
  {
    "id": 165,
    "prompt": "Antibunching correlations in a strongly coupled exciton - photonic crystal cavity system: Role of off-resonant coupling to multiple excitons",
    "HWT": "We employ a master equation approach to study the second-order quantum autocorrelation functions for up to two independent quantum dot excitons, coupled to an off-resonant cavity in a photonic crystal - single quantum dot system. For a single coupled off-resonant exciton, we observe novel oscillatory behaviour in the early-time dynamics of the cavity autocorrelation function, which leads to decreased antibunching relative to the exciton mode. With a second coupled exciton in the system, we find that the magnitude and the lifetime of these oscillations greatly increases, since the cavity is then able to exchange photons with multiple excitonic resonances. We unambiguously show that this spoils the antibunching characteristics of the cavity quasi-mode, while the autocorrelation of the first exciton is unaffected. We also examine the effects of detector time resolution and make a direct connection to a series of recent experiments.",
    "MGT": "We investigate photon antibunching in a strongly coupled quantum dot-photonic crystal cavity system, focusing on the effects of off-resonant coupling to multiple exciton states. Using a quantum master equation approach, we demonstrate that the presence of additional exciton levels significantly modifies the second-order correlation function g(2)(0) compared to the conventional two-level system model. Our calculations reveal that even weakly coupled off-resonant excitons can enhance antibunching through quantum interference effects, leading to g(2)(0) values below 0.1 under appropriate conditions. We find that the antibunching strength depends non-monotonically on both the detuning and coupling strength of the auxiliary exciton states. Additionally, we show that temperature-dependent dephasing processes can partially suppress these interference effects. Our results provide important insights for optimizing single-photon emission in solid-state cavity quantum electrodynamics systems and highlight the necessity of considering multilevel effects in strongly coupled semiconductor quantum dot devices."
  },
  {
    "id": 166,
    "prompt": "Black hole mass and variability in quasars",
    "HWT": "We report on a study that finds a positive correlation between black hole mass and variability amplitude in quasars. Roughly 100 quasars at z<0.75 were selected by matching objects from the QUEST1 Variability Survey with broad-lined objects from the Sloan Digital Sky Survey. Black hole masses were estimated with the virial method using the broad Hbeta line, and variability was characterized from the QUEST1 light curves. The correlation between black hole mass and variability amplitude is significant at the 99% level or better and does not appear to be caused by obvious selection effects inherent to flux-limited samples. It is most evident for rest frame time lags of the order a few months up to the QUEST1 maximum temporal resolution of about 2 years. The correlation between black hole mass and variability amplitude means that the more massive black holes have larger percentage flux variations. Over 2-3 orders of magnitude in black hole mass, the amplitude increases by approximately 0.2 mag. A likely explanation for the correlation is that the more massive black holes are starving and produce larger flux variations because they do not have a steady inflow of gaseous fuel. Assuming that the variability arises from changes in the accretion rate Li & Cao [8] show that flux variations similar to those observed are expected as a consequence of the more massive black holes having cooler accretion disks.",
    "MGT": "We present a comprehensive analysis of the relationship between black hole mass and variability characteristics in a large sample of quasars observed over multiple epochs. Using data from the Sloan Digital Sky Survey (SDSS) and the Dark Energy Survey (DES), we examine 12,458 quasars spanning a redshift range of 0.2 < z < 3.5 and black hole masses of 10^7 to 10^10 solar masses. Our study reveals a significant correlation between black hole mass and both the amplitude and timescale of quasar variability. We find that more massive black holes exhibit larger amplitude variations on longer characteristic timescales, with a power-law relationship M_BH ∝ τ^{1.3±0.2}, where τ is the characteristic variability timescale. Through detailed spectral analysis and multi-wavelength observations, we demonstrate that this relationship holds across different wavelength bands and is independent of accretion rate and bolometric luminosity. Our results suggest that the observed variability is primarily driven by thermal fluctuations in the accretion disk, whose size scales with black hole mass. We also identify a subset of objects that deviate significantly from the main trend, showing enhanced variability that may be attributed to discrete accretion events or changes in disk structure. These findings provide new constraints on theoretical models of accretion disk dynamics and establish variability as a reliable proxy for black hole mass estimation in active galactic nuclei. The robust correlation we observe has important implications for understanding the physics of accretion processes and may serve as a valuable tool for studying black hole demographics in large-scale surveys."
  },
  {
    "id": 167,
    "prompt": "Determinant Quantum Monte Carlo Study of the Orbitally Selective Mott Transition",
    "HWT": "We study the conductivity, density of states, and magnetic correlations of a two dimensional, two band fermion Hubbard model using determinant Quantum Monte Carlo (DQMC) simulations. We show that an orbitally selective Mott transition (OSMT) occurs in which the more weakly interacting band can be metallic despite complete localization of the strongly interacting band. The DQMC method allows us to test the validity of the use of a momentum independent self-energy which has been a central approximation in previous OSMT studies. In addition, we show that long range antiferromagnetic order (LRAFO) is established in the insulating phase, similar to the single band, square lattice Hubbard Hamiltonian. Because the critical interaction strengths for the onset of insulating behavior are much less than the bandwidth of the itinerant orbital, we suggest that the development of LRAFO plays a key role in the transitions.",
    "MGT": "We present a comprehensive determinant quantum Monte Carlo (DQMC) investigation of the orbitally selective Mott transition (OSMT) in a two-orbital Hubbard model with different bandwidths. By systematically varying the inter-orbital Coulomb interaction U' and Hund's coupling J, we map out the phase diagram and characterize the nature of the OSMT. Our results demonstrate that the narrow band undergoes a Mott transition while the wide band remains metallic, confirming the orbital-selective nature of the phenomenon. We find that increasing Hund's coupling promotes the OSMT by enhancing orbital differentiation, while the inter-orbital Coulomb interaction plays a more subtle role in determining the critical interaction strength. Temperature-dependent studies reveal distinct signatures in the spectral function and orbital-resolved double occupancy across the transition. These findings provide crucial insights into the interplay between orbital degrees of freedom and strong correlations in multi-orbital systems, with implications for understanding the physics of materials such as ruthenates and iron-based superconductors."
  },
  {
    "id": 168,
    "prompt": "Storage of Quantum Coherences as Phase Labeled Local Polarization in Solid State NMR",
    "HWT": "Nuclear spins are promising candidates for quantum information processing because their good isolation from the environment precludes the rapid loss of quantum coherence. Many strategies have been developed to further extend their decoherence times. Some of them make use of decoupling techniques based on the Carr-Purcell and Carr-Purcell-Meiboom-Gill pulse sequences. In many cases, when applied to inhomogeneous samples, they yield a magnetization decay much slower than the Hahn echo. However, we have proved that these decays cannot be associated with longer decoherence times as coherences remain frozen. They result from coherences recovered after their storage as local polarization and thus they can be used as memories. We show here how this freezing of the coherent state, which can subsequently be recovered after times longer than the natural decoherence time of the system, can be generated in a controlled way with the use of field gradients. A similar behaviour of homogeneous samples in inhomogeneous fields are demonstrated. It is emphasized that the effects of inhomogeneities in solid state NMR, independently of their origin, should not be disregarded as they play a crucial role in multipulse sequences.",
    "MGT": "We demonstrate a novel approach for storing quantum coherences as phase-labeled local polarization in solid-state nuclear magnetic resonance (NMR) experiments. This technique enables the preservation of phase information during long storage periods while circumventing the rapid decoherence typically associated with multiple-quantum coherences. By employing carefully designed pulse sequences, we convert quantum coherences into longitudinal magnetization components that are labeled with specific phase information. Our experimental results on a 13C-labeled malonic acid sample show that coherence information can be stored for periods exceeding 1 second at room temperature, representing a significant improvement over conventional storage methods. The phase labeling is achieved through a combination of selective pulses and gradient-enhanced recoupling sequences, allowing for subsequent retrieval of the original coherence with high fidelity. We provide theoretical framework explaining the conversion mechanism and demonstrate practical applications in multidimensional correlation spectroscopy. This storage technique proves particularly valuable for experiments requiring extended evolution periods or multiple-step correlation pathways. The method's robustness against environmental perturbations and its compatibility with existing pulse sequences make it a promising tool for advanced solid-state NMR experiments, potentially extending to quantum information processing applications in solid-state systems."
  },
  {
    "id": 169,
    "prompt": "Heat Transfer in Underground Rail Tunnels",
    "HWT": "The transfer of heat between the air and surrounding soil in underground tunnels ins investigated, as part of the analysis of environmental conditions in underground rail systems. Using standard turbulent modelling assumptions, flow profiles are obtained in both open tunnels and in the annulus between a tunnel wall and a moving train, from which the heat transfer coefficient between the air and tunnel wall is computed. The radial conduction of heat through the surrounding soil resulting from changes in the temperature of air in the tunnel are determined. An impulse change and an oscillating tunnel air temperature are considered separately. The correlations between fluctuations in heat transfer coefficient and air temperature are found to increase the mean soil temperature. Finally, a model for the coupled evolution of the air and surrounding soil temperature along a tunnel of finite length is given.",
    "MGT": "This study investigates the complex thermal dynamics and heat transfer mechanisms within underground rail tunnel systems. Through a combination of computational fluid dynamics (CFD) modeling and field measurements, we analyze the spatiotemporal distribution of heat loads and their impact on tunnel environment. The research examines various heat sources, including train operations, braking systems, passenger traffic, and geothermal influences, while considering the effects of different ventilation strategies and tunnel geometries. Results indicate that train-induced piston effects account for 45% of heat dissipation, while mechanical ventilation systems contribute to 30% of thermal regulation. The study reveals that peak temperatures in deep tunnels can exceed ambient surface temperatures by up to 12°C during rush hours. A novel heat recovery system is proposed, capable of reclaiming up to 25% of waste heat for station heating and cooling applications. These findings provide valuable insights for optimizing thermal comfort in underground rail systems while improving energy efficiency and sustainability in urban transportation infrastructure."
  },
  {
    "id": 170,
    "prompt": "On the fate of vacuum bubbles on matter backgrounds",
    "HWT": "In this letter we discuss cosmological first order phase transitions with de Sitter bubbles nucleating on (inhomogeneous) matter backgrounds. The de Sitter bubble can be a toy model for an inflationary phase of universes like our own. Using the thin wall approximation and the Israel junction method we trace the classical evolution of the formed bubbles within a compound model. We first address homogeneous ambient space (FRW model) and already find that bubbles nucleated in a dust dominated background cannot expand. For an inhomogeneous dust background (LTB model) we describe cases with at least initially expanding bubbles. Yet, an ensuing passage of the bubble wall through ambient curvature inhomogeneities remains unnoticed for observers inside the bubble. Notable effects also for interior observers are found in the case of a rapid background phase transition in a FRW model.",
    "MGT": "We investigate the evolution and stability of vacuum bubbles nucleating on matter backgrounds in the context of false vacuum decay. Through numerical simulations and analytical methods, we demonstrate that the presence of matter significantly modifies the conventional picture of bubble dynamics. Our results reveal that matter density gradients can either enhance or suppress bubble expansion, depending on the specific configuration of the background field. We identify a critical matter density threshold above which bubble growth is inhibited, leading to novel collapse scenarios not present in vacuum-to-vacuum transitions. Furthermore, we discover that matter-bubble interactions can produce unique oscillatory modes in the bubble wall, potentially resulting in gravitational wave signatures distinct from those of standard vacuum decay. These findings have important implications for early universe cosmology, particularly in scenarios involving phase transitions in matter-rich environments, and provide new insights into the possible detection of such events through future gravitational wave observatories."
  },
  {
    "id": 171,
    "prompt": "Steady periodic gravity waves with surface tension",
    "HWT": "In this paper we consider two-dimensional, stratified, steady water waves propagating over an impermeable flat bed and with a free surface. The motion is assumed to be driven by capillarity (that is, surface tension) on the surface and a gravitational force acting on the body of the fluid. We prove the existence of global continua of classical solutions that are periodic and traveling. This is accomplished by first constructing a 1-parameter family of laminar flow solutions, $\\mathcal{T}$, then applying bifurcation theory methods to obtain local curves of small amplitude solutions branching from $\\mathcal{T}$ at an eigenvalue of the linearized problem. Each solution curve is then continued globally by means of a degree theoretic theorem in the spirit of Rabinowitz. Finally, we complement the degree theoretic picture by proving an alternate global bifurcation theorem via the analytic continuation method of Dancer.",
    "MGT": "We investigate the existence of steady periodic gravity waves with surface tension propagating at the surface of an incompressible, inviscid fluid of infinite depth. Using a global bifurcation theory approach, we prove the existence of a connected set of small-amplitude periodic solutions bifurcating from the trivial solution. Our analysis reveals that these solutions possess profiles that are symmetric about the vertical axis and monotone between consecutive crests and troughs. The wave profiles are shown to be smooth and depend analytically on the bifurcation parameter. By incorporating surface tension effects, we demonstrate that the classical pure gravity wave results can be extended to include capillary-gravity waves. The mathematical framework employs functional analysis techniques, particularly the application of the Crandall-Rabinowitz bifurcation theorem, to establish the existence of solutions in appropriate function spaces. Our findings contribute to the understanding of wave phenomena in fluid dynamics and provide a rigorous mathematical foundation for studying more complex wave interactions in the presence of surface tension."
  },
  {
    "id": 172,
    "prompt": "Massive runaway stars in the Large Magellanic Cloud",
    "HWT": "The origin of massive field stars in the Large Magellanic Cloud (LMC) has long been an enigma. The recent measurements of large offsets (~100 km/s) between the heliocentric radial velocities of some very massive (O2-type) field stars and the systemic LMC velocity provides a possible explanation of this enigma and suggests that the field stars are runaway stars ejected from their birth places at the very beginning of their parent cluster's dynamical evolution. A straightforward way to prove this explanation is to measure the proper motions of the field stars and to show that they are moving away from one of the nearby star clusters or OB associations. This approach however is complicated by the large distance to the LMC, which makes accurate proper motion measurements difficult. We use an alternative approach for solving the problem, based on the search for bow shocks produced by runaway stars. The geometry of detected bow shocks would allow us to infer the direction of stellar motion and thereby to determine their possible parent clusters. In this paper we present the results of a search for bow shocks around six massive field stars which were suggested in the literature as candidate runaway stars. Using archival (Spitzer Space Telescope) data, we found a bow shock associated with one of our program stars, the O2 V((f*)) star BI 237, which is the first-ever detection of bow shocks in the LMC. Orientation of the bow shock suggests that BI 237 was ejected from the OB association LH 82 (located at ~120 pc in projection from the star). A by-product of our search is the detection of bow shocks generated by four OB stars in the field of the LMC and an arc-like structure attached to the candidate luminous blue variable R81 (HD 269128). The geometry of two of these bow shocks is consistent with the possibility that their associated stars were ejected from the 30 Doradus star forming complex.",
    "MGT": "We present a comprehensive analysis of runaway massive stars in the Large Magellanic Cloud (LMC) using multi-wavelength observations from the Hubble Space Telescope, VLT/MUSE, and Gaia EDR3. Our study identifies 147 candidate runaway stars with masses exceeding 20 M⊙, representing the largest sample of massive runaways detected in a single galaxy outside the Milky Way. These stars exhibit peculiar velocities greater than 30 km/s relative to the local stellar population, with some reaching velocities up to 150 km/s. Through detailed spectroscopic analysis and evolutionary modeling, we determine that approximately 70% of these runaways originate from dynamical ejection in dense stellar clusters, while the remaining 30% likely result from binary supernova explosions. The spatial distribution of these runaway stars shows a strong correlation with known star-forming regions and massive clusters in the LMC, particularly in the 30 Doradus region. We find that the fraction of runaway stars increases significantly with stellar mass, reaching 25% for stars above 40 M⊙. This trend provides crucial constraints on the formation and evolution of massive stars in dense stellar environments. Our observations reveal that several runaway stars are driving bow shocks and creating wind-blown bubbles in the interstellar medium, suggesting significant feedback effects on their surrounding environment. Additionally, we identify a subset of 12 extremely fast runaways (v > 100 km/s) that appear to have originated from the same cluster, potentially linking them to a specific dynamical ejection event approximately 2 million years ago. These results have important implications for understanding the role of stellar dynamics in massive star formation, the evolution of stellar clusters, and the distribution of stellar feedback across galaxies. Our findings also suggest that runaway massive stars may contribute significantly to the chemical enrichment of the interstellar medium in areas far from active star-forming regions, potentially triggering new episodes of star formation in otherwise quiescent regions of the LMC."
  },
  {
    "id": 173,
    "prompt": "Abundance stratification in Type Ia Supernovae - II: The rapidly declining, spectroscopically normal SN 2004eo",
    "HWT": "The variation of properties of Type Ia supernovae, the thermonuclear explosions of Chandrasekhar-mass carbon-oxygen white dwarfs, is caused by different nucleosynthetic outcomes of these explosions, which can be traced from the distribution of abundances in the ejecta. The composition stratification of the spectroscopically normal but rapidly declining SN2004eo is studied performing spectrum synthesis of a time-series of spectra obtained before and after maximum, and of one nebular spectrum obtained about eight months later. Early-time spectra indicate that the outer ejecta are dominated by oxygen and silicon, and contain other intermediate-mass elements (IME), implying that the outer part of the star was subject only to partial burning. In the inner part, nuclear statistical equilibrium (NSE) material dominates, but the production of 56Ni was limited to ~0.43 \\pm 0.05 Msun. An innermost zone containing ~0.25 Msun of stable Fe-group material is also present. The relatively small amount of NSE material synthesised by SN2004eo explains both the dimness and the rapidly evolving light curve of this SN.",
    "MGT": "We present a detailed analysis of the spectroscopically normal Type Ia supernova SN 2004eo, which exhibited a relatively rapid decline rate. Using a comprehensive set of optical and near-infrared observations spanning from -11 to +86 days relative to B-band maximum, we perform abundance tomography modeling to reconstruct the compositional structure of the ejecta. Our synthetic spectra, generated with the radiative transfer code PHOENIX, reveal distinct abundance stratification patterns. The outer layers are dominated by intermediate-mass elements, primarily Si, S, and Ca, while the inner regions show higher concentrations of Fe-group elements. The derived 56Ni mass of approximately 0.45 M☉ places SN 2004eo at the lower end of the luminosity distribution for normal Type Ia supernovae. The abundance structure suggests a delayed-detonation explosion mechanism, where an initial subsonic deflagration transitions into a supersonic detonation. The relatively low 56Ni yield and rapid decline rate of SN 2004eo provide important constraints on explosion models and contribute to our understanding of the diversity among normal Type Ia supernovae, which are crucial standardizable candles for cosmological distance measurements."
  },
  {
    "id": 174,
    "prompt": "The Computational Power of Symmetric Hamiltonians",
    "HWT": "The presence of symmetries, be they discrete or continuous, in a physical system typically leads to a reduction in the problem to be solved. Here we report that neither translational invariance nor rotational invariance reduce the computational complexity of simulating Hamiltonian dynamics; the problem is still BQP complete, and is believed to be hard on a classical computer. This is achieved by designing a system to implement a Universal Quantum Interface, a device which enables control of an entire computation through the control of a fixed number of spins, and using it as a building-block to entirely remove the need for control, except in the system initialisation. Finally, it is shown that cooling such Hamiltonians to their ground states in the presence of random magnetic fields solves a QMA-complete problem.",
    "MGT": "This study investigates the computational capabilities of symmetric Hamiltonians in quantum systems, focusing on their role in quantum computation and simulation. We demonstrate that symmetric Hamiltonians, despite their inherent constraints, possess remarkable computational power equivalent to universal quantum computation under specific conditions. Through rigorous mathematical analysis and numerical simulations, we establish that a class of symmetric Hamiltonians can efficiently encode and process quantum information while maintaining their symmetry properties. Our findings reveal that these systems can implement arbitrary quantum gates with polynomial overhead, challenging previous assumptions about the limitations of symmetric quantum dynamics. We also identify novel protocols for quantum state preparation and measurement that exploit the natural symmetries of these Hamiltonians. These results have significant implications for quantum computing architecture design and provide new insights into the fundamental relationship between symmetry and computational complexity in quantum systems."
  },
  {
    "id": 175,
    "prompt": "The Variation of the Galaxy Luminosity Function with Group Properties",
    "HWT": "We explore the shape of the galaxy luminosity function (LF) in groups of different mass by creating composite LFs over large numbers of groups. Following previous work using total group luminosity as the mass indicator, here we split our groups by multiplicity and by estimated virial (group halo) mass, and consider red (passive) and blue (star forming) galaxies separately. In addition we utilise two different group catalogues (2PIGG and Yang et al. ) in order to ascertain the impact of the specific grouping algorithm and further investigate the environmental effects via variations in the LF with position in groups. Our main results are that LFs show a steepening faint end for early type galaxies as a function of group mass/ multiplicity, with a much suppressed trend (evident only in high mass groups) for late type galaxies. Variations between LFs as a function of group mass are robust irrespective of which grouping catalogue is used, and broadly speaking what method for determining group `mass' is used. We find in particular that there is a significant deficit of low-mass passive galaxies in low multiplicity groups, as seen in high redshift clusters. Further to this, the variation in the LF appears to only occur in the central regions of systems, and in fact seems to be most strongly dependent on the position in the group relative to the virial radius. Finally, distance-rank magnitude relations were considered. Only the Yang groups demonstrated any evidence of a correlation between a galaxy's position relative to the brightest group member and its luminosity. 2PIGG possessed no such gradient, the conclusion being the FOF algorithm suppresses the signal for weak luminosity--position trends and the Yang grouping algorithm naturally enhances it.",
    "MGT": "We present a comprehensive analysis of how galaxy luminosity functions (GLFs) vary across different group environments using data from the Sloan Digital Sky Survey Data Release 16 (SDSS DR16). Our sample consists of 57,423 galaxies in 12,458 groups spanning a wide range of group masses (12.5 ≤ log(M/M☉) ≤ 15.0) and dynamical states. We derive GLFs for different group mass bins and investigate their dependence on group-centric radius, group concentration, and local galaxy density. The GLFs are well-described by a Schechter function, but with parameters that vary significantly with group properties. We find that the characteristic magnitude M* brightens by 0.5 magnitudes from isolated galaxies to massive clusters, while the faint-end slope α steepens from -1.1 to -1.4. The variation is most pronounced in group-centric radius bins, where the inner regions (R < 0.5R200) show systematically brighter M* values compared to the outskirts. The group concentration, measured as the magnitude gap between the first and fourth brightest galaxies, correlates strongly with both M* and α, suggesting that the GLF evolution is linked to the group's dynamical age. We also observe that groups with higher local galaxy densities exhibit steeper faint-end slopes, indicating enhanced dwarf galaxy formation or survival in dense environments. These results provide strong evidence that both the bright and faint ends of the GLF are shaped by environmental processes. The systematic variations we find can be explained by a combination of merging at the bright end and enhanced tidal stripping of dwarf galaxies in dense regions. Our findings demonstrate that the GLF serves as a sensitive probe of galaxy evolution in different group environments and provides important constraints for galaxy formation models."
  },
  {
    "id": 176,
    "prompt": "Local unitary transformation, long-range quantum entanglement, wave function renormalization, and topological order",
    "HWT": "Two gapped quantum ground states in the same phase are connected by an adiabatic evolution which gives rise to a local unitary transformation that maps between the states. On the other hand, gapped ground states remain within the same phase under local unitary transformations. Therefore, local unitary transformations define an equivalence relation and the equivalence classes are the universality classes that define the different phases for gapped quantum systems. Since local unitary transformations can remove local entanglement, the above equivalence/universality classes correspond to pattern of long range entanglement, which is the essence of topological order. The local unitary transformation also allows us to define a wave function renormalization scheme, under which a wave function can flow to a simpler one within the same equivalence/universality class. Using such a setup, we find conditions on the possible fixed-point wave functions where the local unitary transformations have \\emph{finite} dimensions. The solutions of the conditions allow us to classify this type of topological orders, which generalize the string-net classification of topological orders. We also describe an algorithm of wave function renormalization induced by local unitary transformations. The algorithm allows us to calculate the flow of tensor-product wave functions which are not at the fixed points. This will allow us to calculate topological orders as well as symmetry breaking orders in a generic tensor-product state.",
    "MGT": "We investigate the fundamental relationship between local unitary transformations, quantum entanglement, and topological order in many-body quantum systems. Through rigorous mathematical analysis, we demonstrate that local unitary transformations preserve long-range entanglement properties and can be utilized to classify distinct phases of topologically ordered states. By introducing a novel wave function renormalization scheme, we establish that quantum states connected through local unitary transformations share equivalent topological properties and belong to the same quantum phase. Our approach reveals that the ground state manifold of topologically ordered systems remains invariant under such transformations, while the entanglement structure exhibits universal scaling behavior. We prove that non-trivial topological orders cannot be transformed into product states through any finite-depth local unitary circuit, establishing a fundamental connection between topological order and long-range entanglement. Furthermore, we develop a systematic framework for characterizing topological phases using wave function renormalization group flows, showing that distinct topological orders correspond to different fixed-point wave functions under this renormalization procedure. These results provide a comprehensive theoretical foundation for understanding the stability of topological order against local perturbations and establish a precise mathematical relationship between quantum entanglement patterns and topological invariants. Our findings have significant implications for quantum computation, error correction, and the classification of exotic quantum phases of matter."
  },
  {
    "id": 177,
    "prompt": "Two Models for Noisy Feedback in MIMO Channels",
    "HWT": "Two distinct models of feedback, suited for FDD (Frequency Division Duplex) and TDD (Frequency Division Duplex) systems respectively, have been widely studied in the literature. In this paper, we compare these two models of feedback in terms of the diversity multiplexing tradeoff for varying amount of channel state information at the terminals. We find that, when all imperfections are accounted for, the maximum achievable diversity order in FDD systems matches the diversity order in TDD systems. TDD systems achieve better diversity order at higher multiplexing gains. In FDD systems, the maximum diversity order can be achieved with just a single bit of feedback. Additional bits of feedback (perfect or imperfect) do not affect the diversity order if the receiver does not know the channel state information.",
    "MGT": "This paper investigates two distinct models for characterizing noisy feedback in Multiple-Input Multiple-Output (MIMO) wireless communication systems. We propose a comprehensive framework that accounts for both quantization errors and channel estimation uncertainties in the feedback path. The first model employs a probabilistic approach to analyze the impact of feedback noise on channel state information (CSI), while the second model utilizes a deterministic bounded error representation. Through theoretical analysis and extensive numerical simulations, we demonstrate that both models accurately predict system performance degradation under various feedback conditions. Results show that the probabilistic model offers superior performance in scenarios with random noise characteristics, while the deterministic model proves more effective for structured interference patterns. Our findings indicate that proper model selection can lead to a 15-20% improvement in channel capacity utilization. These insights provide valuable guidance for designing robust MIMO systems with imperfect feedback channels, particularly in high-mobility scenarios where CSI reliability is crucial."
  },
  {
    "id": 178,
    "prompt": "On the Stability of Elliptical Vortices in Accretion Discs",
    "HWT": "(Abriged) The existence of large-scale and long-lived 2D vortices in accretion discs has been debated for more than a decade. They appear spontaneously in several 2D disc simulations and they are known to accelerate planetesimal formation through a dust trapping process. However, the issue of the stability of these structures to the imposition of 3D disturbances is still not fully understood, and it casts doubts on their long term survival. Aim: We present new results on the 3D stability of elliptical vortices embedded in accretion discs, based on a linear analysis and several non-linear simulations. Methods: We derive the linearised equations governing the 3D perturbations in the core of an elliptical vortex, and we show that they can be reduced to a Floquet problem. We solve this problem numerically in the astrophysical regime and we present several analytical limits for which the mechanism responsible for the instability can be explained. Finally, we compare the results of the linear analysis to some high resolution simulations. Results: We show that most anticyclonic vortices are unstable due to a resonance between the turnover time and the local epicyclic oscillation period. In addition, we demonstrate that a strong vertical stratification does not create any additional stable domain of aspect ratio, but it significantly reduces growth rates for relatively weak (and therefore elongated) vortices. Conclusions: Elliptical vortices are always unstable, whatever the horizontal or vertical aspect-ratio is. The instability can however be weak and is often found at small scales, making it difficult to detect in low-order finite-difference simulations.",
    "MGT": "The stability of elliptical vortices in accretion discs has been a subject of ongoing investigation in astrophysical fluid dynamics. In this study, we present a comprehensive analysis of the persistence and evolution of such vortices under various physical conditions typical of protoplanetary and active galactic nucleus (AGN) discs. Using high-resolution numerical simulations incorporating both two-dimensional and three-dimensional hydrodynamic models, we investigate the behavior of elliptical vortices subject to background shear, pressure gradients, and self-gravity. Our results demonstrate that vortex stability is strongly dependent on both the aspect ratio of the elliptical structure and the local disc properties, particularly the radial stratification and temperature gradient. We find that vortices with aspect ratios between 4 and 6 exhibit remarkable longevity, surviving for hundreds of orbital periods, while more elongated or more circular configurations tend to decay rapidly through wave emission and turbulent dissipation. The presence of vertical stratification is shown to play a crucial role in determining vortex lifetime, with three-dimensional effects generally leading to enhanced instability compared to two-dimensional approximations. Additionally, we identify a novel mechanism of vortex stabilization through dust feedback in regions of high particle concentration, potentially explaining the persistent asymmetric features observed in several protoplanetary discs. These findings have significant implications for planet formation theories, as stable vortices may serve as efficient particle traps and facilitate the growth of planetesimals. Our analysis provides new insights into the conditions necessary for vortex survival in accretion discs and establishes a theoretical framework for interpreting observations of non-axisymmetric disc features in both young stellar objects and AGN systems."
  },
  {
    "id": 179,
    "prompt": "Astrophysics with the AMS-02 experiment",
    "HWT": "The Alpha Magnetic Spectrometer (AMS), whose final version AMS-02 is to be installed on the International Space Station (ISS) for at least 3 years, is a detector designed to measure charged cosmic ray spectra with energies up to the TeV region and with high energy photon detection capability up to a few hundred GeV, using state-of-the-art particle identification techniques. Following the successful flight of the detector prototype (AMS-01) aboard the space shuttle, AMS-02 is expected to provide a significant improvement on the current knowledge of the elemental and isotopic composition of hadronic cosmic rays due to its long exposure time (minimum of 3 years) and large acceptance (0.5 m^2 sr) which will enable it to collect a total statistics of more than 10^10 nuclei. Detector capabilities for charge, velocity and mass identification, estimated from ion beam tests and detailed Monte Carlo simulations, are presented. Relevant issues in cosmic ray astrophysics addressed by AMS-02, including the test of cosmic ray propagation models, galactic confinement times and the influence of solar cycles on the local cosmic ray flux, are briefly discussed.",
    "MGT": "The Alpha Magnetic Spectrometer (AMS-02) aboard the International Space Station represents a groundbreaking achievement in cosmic ray physics and the search for dark matter. This paper presents comprehensive analyses of high-precision measurements collected during the first decade of AMS-02 operations, focusing on cosmic ray spectra, antimatter searches, and implications for fundamental physics. Our results demonstrate unprecedented accuracy in measuring the primary cosmic ray fluxes of protons, helium, and heavier nuclei up to iron, revealing fine structures that challenge conventional propagation models. The positron fraction measurements extend to the TeV range, showing a clear excess above astronomical background that could indicate dark matter annihilation or nearby astrophysical sources. We report on the search for antihelium nuclei, providing the strongest constraints to date on the existence of primordial antimatter. The precision measurements of secondary-to-primary ratios, including boron-to-carbon and beryllium isotopes, have enabled refined models of cosmic ray propagation in the galaxy. Additionally, we present time-dependent studies of solar modulation effects on cosmic ray fluxes, contributing to our understanding of solar physics. These results significantly advance our knowledge of cosmic ray physics, dark matter properties, and the fundamental processes governing the high-energy universe, while opening new avenues for theoretical investigations in particle astrophysics."
  },
  {
    "id": 180,
    "prompt": "Supercurrent and multiple singlet-doublet phase transitions of a quantum dot Josephson junction inside an Aharonov-Bohm ring",
    "HWT": "We study a quantum dot Josephson junction inside an Aharonov-Bohm environment. The geometry is modeled by an Anderson impurity coupled to two directly-linked BCS leads. We illustrate that the well-established picture of the low-energy physics being governed by an interplay of two distinct (singlet and doublet) phases is still valid for this interferometric setup. The phase boundary depends, however, non-monotonically on the coupling strength between the superconductors, causing the system to exhibit re-entrance behavior and multiple phase transitions. We compute the zero-temperature Josephson current and demonstrate that it can become negative in the singlet phase by virtue of the Coulomb interaction U. As a starting point, the limit of large superconducting energy gaps \\Delta=\\infty is solved analytically. In order to tackle arbitrary \\Delta<\\infty and U>0, we employ a truncated functional renormalization group scheme which was previously demonstrated to give quantitatively reliable results for the quantum dot Josephson problem.",
    "MGT": "We investigate the transport properties and quantum phase transitions of a quantum dot Josephson junction embedded in an Aharonov-Bohm ring. Using numerical renormalization group calculations, we demonstrate that the supercurrent through the system exhibits distinct oscillations with magnetic flux, reflecting the interference between direct and dot-assisted Cooper pair tunneling processes. Our analysis reveals multiple singlet-doublet quantum phase transitions driven by the interplay between Kondo correlations, superconducting proximity effect, and magnetic flux. We identify three distinct regimes characterized by different ground state configurations: a Kondo-screened singlet, a superconducting singlet, and a magnetic doublet state. The transitions between these phases are marked by discontinuities in the flux-dependent supercurrent and can be tuned by varying the quantum dot energy level and coupling strengths. Furthermore, we show that the critical current displays unique signatures near the transition points, providing an experimental probe for detecting these quantum phase transitions. Our findings establish the Aharonov-Bohm ring geometry as a versatile platform for studying and controlling quantum phase transitions in hybrid superconducting-quantum dot systems."
  },
  {
    "id": 181,
    "prompt": "Tests of analytical hadronisation models using event shape moments in {\\epem} annihilation",
    "HWT": "Predictions of analytical models for hadronisation, namely the dispersive model, the shape function and the single dressed gluon approximation, are compared with moments of hadronic event shape distributions measured in \\epem annihilation at centre-of-mass energies between 14 and 209 GeV. In contrast to Monte Carlo models for hadronisation, analytical models require to adjust only two universal parameters, the strong coupling and a second quantity parametrising nonperturbative corrections. The extracted values of as are consistent with the world average and competitive with previous measurements. The variance of event shape distributions is compared with predictions given by some of these models. Limitations of the models, probably due to unknown higher order corrections, are demonstrated and discussed.",
    "MGT": "We present a comprehensive analysis of event shape moments measured in e+e- annihilation at center-of-mass energies ranging from 45 to 209 GeV. The experimental data from LEP and earlier e+e- experiments are compared with predictions from analytical hadronisation models, including the Dispersive Model and Single Dressed Gluon Approximation. Our study focuses on the first five moments of thrust, heavy jet mass, C-parameter, and total jet broadening distributions. The analytical models, combined with perturbative QCD calculations at next-to-leading-log approximation, show good agreement with the data across all energies. The strong coupling constant αs and the non-perturbative parameter α0 are extracted through a simultaneous fit to all moments. The results provide important constraints on hadronisation models and contribute to our understanding of the transition between perturbative and non-perturbative QCD regimes."
  },
  {
    "id": 182,
    "prompt": "Using a priori knowledge to construct copulas",
    "HWT": "Our purpose is to model the dependence between two random variables, taking into account a priori knowledge on these variables. For example, in many applications (oceanography, finance.. . ), there exists an order relation between the two variables; when one takes high values, the other cannot take low values, but the contrary is possible. The dependence for the high values of the two variables is, therefore, not symmetric. However a minimal dependence also exists: low values of one variable are associated with low values of the other variable. The dependence can also be extreme for the maxima or the minima of the two variables. In this paper, we construct step by step asymmetric copulas with asymptotic minimal dependence, and with or without asymptotic maximal dependence, using mixture variables to get at first asymmetric dependence and then minimal dependence. We fit these models to a real dataset of sea states and compare them using Likelihood Ratio Tests when they are nested, and BIC- criterion (Bayesian Information criterion) otherwise.",
    "MGT": "This paper presents a novel approach to constructing copulas by incorporating a priori knowledge about dependence structures in multivariate distributions. We develop a theoretical framework that enables the systematic integration of domain expertise and empirical observations into the copula construction process. Our method extends traditional copula modeling by introducing a knowledge-driven parameter estimation technique that combines Bayesian inference with expert-elicited constraints. We prove that the resulting copulas maintain mathematical consistency while better reflecting known dependencies in the data-generating process. Through simulation studies and real-world applications in financial risk management and climate modeling, we demonstrate that our approach yields more accurate dependency estimates compared to conventional methods, particularly in scenarios with limited data. The proposed methodology shows a 15% improvement in tail dependency capture and a 20% reduction in parameter estimation uncertainty when tested on both synthetic and empirical datasets. Furthermore, we establish theoretical bounds for the convergence of our estimators and provide practical guidelines for implementing the framework across different domains. Our findings suggest that incorporating a priori knowledge in copula construction can significantly enhance the modeling of complex dependency structures, especially in high-dimensional settings where traditional approaches often fall short."
  },
  {
    "id": 183,
    "prompt": "Wave and ray analysis of a type of cloak exhibiting magnified and shifted scattering effect",
    "HWT": "Ray-tracing exercise and full-wave analysis were performed to validate the performance of a new type of cloak composed of isotropic metamaterials. It is shown that objects inside the folded region of this cloak appear invisible to the incoming light from a ray tracing exercise, but exhibit magnified and shifted scattering under a plane wave illumination from a full wave analysis. Gaussian beams are introduced to resolve this interesting paradox resulted from these two methods. We show that at the time-harmonic state, small energy can be diffracted into the folded region and contribute to the resonant state even when the Gaussian beam is steered away from the cloak with an object inside. A scattering pattern identical to that scattered from the image of the object will be formed, which agrees well with the phenomenon in the plane wave incidence case.",
    "MGT": "This paper presents a comprehensive analysis of a novel electromagnetic cloak design that exhibits unique magnified and shifted scattering characteristics. Using both wave and ray approaches, we investigate the behavior of electromagnetic waves interacting with the proposed cloaking structure. The cloak is constructed using transformation optics principles, resulting in an anisotropic material distribution that creates a magnified scattering signature displaced from the cloaked object's actual position. Through numerical simulations and analytical calculations, we demonstrate that the scattered field pattern can be controllably shifted and amplified while maintaining the object's invisibility. The ray-tracing analysis reveals the underlying mechanism of wave propagation within the cloak, while full-wave simulations confirm the theoretical predictions. Our results show that the proposed design achieves a scattering magnification factor of up to 3.5 with positional shifts of several wavelengths. This work provides new insights into manipulating electromagnetic scattering patterns and has potential applications in radar deception and electromagnetic illusion devices."
  },
  {
    "id": 184,
    "prompt": "Position Dependent Mass Schroedinger Equation and Isospectral Potentials : Intertwining Operator approach",
    "HWT": "Here we have studied first and second-order intertwining approach to generate isospectral partner potentials of position-dependent (effective) mass Schroedinger equation. The second-order intertwiner is constructed directly by taking it as second order linear differential operator with position depndent coefficients and the system of equations arising from the intertwining relationship is solved for the coefficients by taking an ansatz. A complete scheme for obtaining general solution is obtained which is valid for any arbitrary potential and mass function. The proposed technique allows us to generate isospectral potentials with the following spectral modifications: (i) to add new bound state(s), (ii) to remove bound state(s) and (iii) to leave the spectrum unaffected. To explain our findings with the help of an illustration, we have used point canonical transformation (PCT) to obtain the general solution of the position dependent mass Schrodinger equation corresponding to a potential and mass function. It is shown that our results are consistent with the formulation of type A N-fold supersymmetry [14,18] for the particular case N = 1 and N = 2 respectively.",
    "MGT": "We present a comprehensive analysis of the Position Dependent Mass Schrödinger Equation (PDMSE) using the intertwining operator approach to generate isospectral potentials. Our investigation extends the conventional supersymmetric quantum mechanical framework to accommodate systems with spatially varying mass distributions. By developing a modified factorization method that incorporates the position-dependent mass term, we establish a systematic procedure for constructing partner Hamiltonians that share identical energy spectra but exhibit distinct potential profiles. The study demonstrates how the intertwining operators, when properly adapted to account for mass variation, preserve the supersymmetric partnership between different quantum systems. We derive explicit expressions for the transformation functions and analyze their role in generating families of isospectral potentials. Our results reveal novel relationships between the original and transformed wavefunctions, highlighting the impact of mass position dependence on the quantum mechanical properties of these systems. The methodology presented here provides a powerful tool for engineering quantum systems with predetermined spectral characteristics while maintaining physical consistency. Furthermore, we explore specific examples that illustrate the practical application of our approach, including cases with exponential and polynomial mass functions, demonstrating the versatility and effectiveness of the intertwining operator technique in solving PDMSE problems."
  },
  {
    "id": 185,
    "prompt": "PQCD Formulations with Heavy Quark Masses and Global Analysis",
    "HWT": "We critically review heavy quark mass effects in DIS and their impact on global analyses. We lay out all elements of a properly defined general mass variable flavor number scheme (GM VFNS) that are shared by all modern formulations of the problem. We then explain the freedom in choosing specific implementations and spell out, in particular, the current formulations of the CTEQ and MSTW groups. We clarify the approximations in the still widely-used zero mass variable flavor scheme (ZM VFNS), mention the inherent flaws in its conventional implementation, and consider the possibility of mending some of these flaws. We discuss practical issues concerning the use of parton distributions in various physical applications, in view of the different schemes. And we comment on the possible presence of intrinsic heavy flavors.",
    "MGT": "We present a comprehensive analysis of Parton Distribution Functions (PDFs) incorporating heavy quark mass effects within the framework of Perturbative Quantum Chromodynamics (PQCD). Our study implements the General-Mass Variable-Flavor-Number Scheme (GM-VFNS) to systematically account for charm and bottom quark contributions in deep inelastic scattering processes. The global analysis encompasses a wide range of experimental data, including the latest measurements from HERA, LHC, and fixed-target experiments. We demonstrate that proper treatment of heavy quark masses significantly impacts the extraction of PDFs, particularly in the small-x region. Our results show improved agreement with experimental data compared to previous analyses using zero-mass approximations. The study also reveals important correlations between heavy quark masses and strong coupling constant determinations. These findings have important implications for precision phenomenology at hadron colliders and provide crucial insights into the internal structure of the proton at next-to-next-to-leading order accuracy."
  },
  {
    "id": 186,
    "prompt": "Minimum feature size preserving decompositions",
    "HWT": "The minimum feature size of a crossing-free straight line drawing is the minimum distance between a vertex and a non-incident edge. This quantity measures the resolution needed to display a figure or the tool size needed to mill the figure. The spread is the ratio of the diameter to the minimum feature size. While many algorithms (particularly in meshing) depend on the spread of the input, none explicitly consider finding a mesh whose spread is similar to the input. When a polygon is partitioned into smaller regions, such as triangles or quadrangles, the degradation is the ratio of original to final spread (the final spread is always greater). Here we present an algorithm to quadrangulate a simple n-gon, while achieving constant degradation. Note that although all faces have a quadrangular shape, the number of edges bounding each face may be larger. This method uses Theta(n) Steiner points and produces Theta(n) quadrangles. In fact to obtain constant degradation, Omega(n) Steiner points are required by any algorithm. We also show that, for some polygons, a constant factor cannot be achieved by any triangulation, even with an unbounded number of Steiner points. The specific lower bounds depend on whether Steiner vertices are used or not.",
    "MGT": "This paper presents a novel approach to geometric decomposition that preserves minimum feature size (MFS) constraints while partitioning complex shapes into simpler components. We introduce a theoretical framework for analyzing and maintaining minimum feature size during decomposition operations, addressing a critical challenge in computer-aided design, digital fabrication, and computational geometry. Our method employs a hierarchical skeleton-guided decomposition strategy that explicitly considers local geometric features and ensures that no decomposition cut creates features smaller than the input shape's original minimum feature size. We prove that our algorithm guarantees MFS preservation while producing a minimal number of components. Experimental results demonstrate the effectiveness of our approach across a diverse set of 2D and 3D test cases, including mechanical parts, architectural models, and organic shapes. Compared to existing decomposition methods, our technique reduces the occurrence of fabrication-critical small features by 87% while maintaining comparable computational efficiency. The algorithm successfully handles complex geometries with varying feature scales and achieves decompositions that are both geometrically valid and manufacturably robust. We also present a comprehensive analysis of the relationship between MFS preservation and decomposition quality metrics, providing insights for applications in various domains. Our work contributes to the fundamental understanding of geometric decomposition constraints and offers practical solutions for manufacturing-aware shape processing."
  },
  {
    "id": 187,
    "prompt": "Mapping the Geography of Science: Distribution Patterns and Networks of Relations among Cities and Institutes",
    "HWT": "Using Google Earth, Google Maps and/or network visualization programs such as Pajek, one can overlay the network of relations among addresses in scientific publications on the geographic map. We discuss the pros en cons of the various options, and provide software (freeware) for bridging existing gaps between the Science Citation Indices and Scopus, on the one side, and these various visualization tools, on the other. At the level of city names, the global map can be drawn reliably on the basis of the available address information. At the level of the names of organizations and institutes, there are problems of unification both in the ISI-databases and Scopus. Pajek enables us to combine the visualization with statistical analysis, whereas the Google Maps and its derivates provide superior tools at the Internet.",
    "MGT": "This study investigates the spatial organization of scientific activity through a comprehensive analysis of publication patterns and institutional networks across global cities and research institutes. Using bibliometric data from over 10 million scientific publications between 2000-2020, we examine the geographical distribution of research output and collaboration networks at multiple scales. Our findings reveal a highly concentrated pattern of scientific production, with 20 cities accounting for 42% of global publications. We identify emerging regional hubs in Asia and the Global South that challenge the traditional dominance of North American and European centers. Network analysis demonstrates that while physical proximity remains important for collaboration, the strength of institutional ties increasingly transcends geographical distances. The study also uncovers distinct patterns of specialization among cities and institutes, suggesting the emergence of complementary roles within the global scientific system. These results provide new insights into the evolving spatial organization of science and have important implications for research policy and institutional strategy."
  },
  {
    "id": 188,
    "prompt": "The ALICE TPC, a large 3-dimensional tracking device with fast readout for ultra-high multiplicity events",
    "HWT": "The design, construction, and commissioning of the ALICE Time-Projection Chamber (TPC) is described. It is the main device for pattern recognition, tracking, and identification of charged particles in the ALICE experiment at the CERN LHC. The TPC is cylindrical in shape with a volume close to 90 m^3 and is operated in a 0.5 T solenoidal magnetic field parallel to its axis. In this paper we describe in detail the design considerations for this detector for operation in the extreme multiplicity environment of central Pb--Pb collisions at LHC energy. The implementation of the resulting requirements into hardware (field cage, read-out chambers, electronics), infrastructure (gas and cooling system, laser-calibration system), and software led to many technical innovations which are described along with a presentation of all the major components of the detector, as currently realized. We also report on the performance achieved after completion of the first round of stand-alone calibration runs and demonstrate results close to those specified in the TPC Technical Design Report.",
    "MGT": "The ALICE Time Projection Chamber (TPC) is a crucial tracking detector designed for the ALICE experiment at CERN's Large Hadron Collider, specifically optimized for the study of heavy-ion collisions. This paper presents the design, construction, and performance characteristics of this unique detector, which combines large spatial coverage with excellent tracking capabilities. The TPC, with its active volume of 88 m³, provides three-dimensional tracking of charged particles and particle identification through energy loss measurements. Operating in a 0.5 T magnetic field, it achieves a momentum resolution better than 1% at 2 GeV/c and can handle charged particle densities up to 20,000 tracks per unit of rapidity. The readout system, featuring multi-wire proportional chambers with cathode pad readout, enables data acquisition rates of up to 1000 Hz for Pb-Pb central collisions. Advanced gas mixture optimization and temperature control systems ensure stable operation and minimal spatial distortions. The detector's performance has been extensively validated through cosmic ray measurements and beam tests, demonstrating its capability to reconstruct complex events with unprecedented precision, making it an indispensable tool for studying the properties of strongly interacting matter under extreme conditions."
  },
  {
    "id": 189,
    "prompt": "The UV-optical colours of brightest cluster galaxies in optically and X-ray selected clusters",
    "HWT": "Many brightest cluster galaxies (BCGs) at the centers of X-ray selected clusters exhibit clear evidence for recent star formation. However, studies of BCGs in optically-selected clusters show that star formation is not enhanced when compared to control samples of non-BCGs of similar stellar mass. Here we analyze a sample of 113 BCGs in low redshift (z<0.1), optically-selected clusters, a matched control sample of non-BCGs, and a smaller sample of BCGs in X-ray selected clusters. We convolve the SDSS images of the BCGs to match the resolution of the GALEX data and we measure UV-optical colours in their inner and outer regions. We find that optically-selected BCGs exhibit smaller scatter in optical colours and redder inner NUV-r colours than the control galaxies, indicating that they are a homogenous population with very little ongoing star formation. The BCGs in the X-ray selected cluster sample span a similar range in optical colours, but have bluer NUV-r colours. Among X-ray selected BCGs, those located in clusters with central cooling times of less than 1 Gyr are significantly bluer than those located in clusters where the central gas cooling times are long. Our main conclusion is that the location of a galaxy at the centre of its halo is not sufficient to determine whether or not it is currently forming stars. One must also have information about the thermodynamic state of the gas in the core of the halo.",
    "MGT": "We present a comprehensive analysis of UV-optical colours for brightest cluster galaxies (BCGs) in a sample of 981 clusters selected through both optical and X-ray methods at 0.1 < z < 0.3. By combining GALEX UV photometry with SDSS optical data, we investigate the relationship between BCG star formation activity and cluster properties. We find significant differences in the UV-optical colours of BCGs between optically and X-ray selected clusters, with X-ray selected BCGs showing systematically bluer NUV-r colours, indicating higher levels of recent star formation. The fraction of star-forming BCGs (NUV-r < 5.0) in X-ray selected clusters is 23±3%, compared to 9±2% in optically selected clusters. We demonstrate that this difference persists even when controlling for cluster mass and redshift. BCGs with bluer UV-optical colours tend to reside in clusters with shorter cooling times and higher X-ray luminosities, suggesting that the enhanced star formation is linked to the presence of cooling flows. Additionally, we find a weak but significant correlation between BCG UV-optical colour and cluster-centric offset, with BCGs located further from the cluster center showing bluer colours on average. Our results indicate that the selection method of galaxy clusters can introduce significant biases in the observed properties of their BCGs, particularly regarding their star formation histories. These findings have important implications for understanding the co-evolution of BCGs and their host clusters, as well as the role of environmental effects in regulating star formation in the most massive galaxies in the universe."
  },
  {
    "id": 190,
    "prompt": "Shells, jets, and internal working surfaces in the molecular outflow from IRAS 04166+2706",
    "HWT": "Context: IRAS 04166+2706 in Taurus is one of the most nearby young stellar objects whose molecular outflow contains a highly collimated fast component. Methods: We have observed the IRAS 04166+2706 outflow with the IRAM Plateau de Bure interferometer in CO(J=2-1) and SiO(J=2-1) achieving angular resolutions between 2'' and 4''. To improve the quality of the CO(2-1) images, we have added single dish data to the interferometer visibilities. Results: The outflow consists of two distinct components. At velocities <10 km/s, the gas forms two opposed, approximately conical shells that have the YSO at their vertex. These shells coincide with the walls of evacuated cavities and seem to result from the acceleration of the ambient gas by a wide-angle wind. At velocities >30 km/s, the gas forms two opposed jets that travel along the center of the cavities and whose emission is dominated by a symmetric collection of at least 7 pairs of peaks. The velocity field of this component presents a sawtooth pattern with the gas in the tail of each peak moving faster than the gas in the head. This pattern, together with a systematic widening of the peaks with distance to the central source, is consistent with the emission arising from internal working surfaces traveling along the jet and resulting from variations in the velocity field of ejection. We interpret this component as the true protostellar wind, and we find its composition consistent with a chemical model of such type of wind. Conclusions: Our results support outflow wind models that have simultaneously wide-angle and narrow components, and suggest that the EHV peaks seen in a number of outflows consist of internally-shocked wind material.",
    "MGT": "We present high angular resolution observations of the molecular outflow from IRAS 04166+2706, a Class 0 protostar in Taurus, using the Submillimeter Array (SMA) and the IRAM Plateau de Bure Interferometer (PdBI). The CO(2-1) emission reveals a highly collimated outflow with a complex internal structure consisting of multiple shells, jets, and internal working surfaces. The outflow extends over 8000 AU from the central source and shows a clear bipolar morphology with an opening angle of approximately 10 degrees. Our analysis identifies at least six pairs of symmetric emission knots along the outflow axis, with velocities ranging from 10 to 50 km/s. The molecular emission suggests these knots represent internal working surfaces where faster material catches up with slower gas, creating shock waves that compress and heat the molecular gas. The spacing between consecutive knots is remarkably regular, indicating a periodic ejection mechanism with a timescale of approximately 400 years. We also detect evidence of jet rotation in the high-velocity gas, with rotation velocities of 1-2 km/s at distances of 100-500 AU from the jet axis. A comparison of the outflow properties with theoretical models suggests that the observed morphology is consistent with a pulsed jet-driven outflow, where variations in the mass-loss rate or ejection velocity lead to the formation of internal working surfaces. The derived mass-loss rate is approximately 10^-6 solar masses per year, and the mechanical luminosity is 0.3 solar luminosities. These results provide new insights into the launching mechanism of protostellar outflows and support models where episodic ejection events play a crucial role in the early stages of star formation. The regular spacing of the emission knots may be related to periodic perturbations in the accretion disk, possibly caused by disk instabilities or the presence of a close companion."
  },
  {
    "id": 191,
    "prompt": "Parameter Degeneracy in Flavor-Dependent Reconstruction of Supernova Neutrino Fluxes",
    "HWT": "We reexamine the possibility of reconstructing the initial fluxes of supernova neutrinos emitted in a future core-collapse galactic supernova explosion and detected in a Megaton-sized water Cherenkov detector. A novel key element in our method is the inclusion, in addition to the total and the average energies of each neutrino species, of a \"pinching\" parameter characterizing the width of the distribution as a fit parameter. We uncover in this case a continuous degeneracy in the reconstructed parameters of supernova neutrino fluxes at the neutrinosphere. We analyze in detail the features of this degeneracy and show how it occurs irrespective of the parametrization used for the distribution function. Given that this degeneracy is real we briefly comment on possible steps towards resolving it, which necessarily requires going beyond the setting presented here.",
    "MGT": "We investigate the challenges of reconstructing energy-dependent neutrino flavor distributions from core-collapse supernovae, focusing on the inherent parameter degeneracies that arise in multi-flavor analyses. Using a maximum likelihood approach applied to simulated neutrino detector data, we demonstrate that current methods for flavor reconstruction suffer from significant ambiguities when attempting to simultaneously determine multiple spectral parameters. Our results reveal that certain combinations of neutrino energy spectra and flavor mixing parameters can produce nearly identical detector signatures, leading to degenerate solutions in the parameter space. We quantify these degeneracies through detailed statistical analysis and propose a new framework that incorporates prior theoretical constraints to partially break these degeneracies. This work has important implications for future supernova neutrino detection and highlights the need for complementary measurement strategies to fully characterize the flavor-dependent neutrino emission from core-collapse events."
  },
  {
    "id": 192,
    "prompt": "One-dimensional quantum cellular automata over finite, unbounded configurations",
    "HWT": "One-dimensional quantum cellular automata (QCA) consist in a line of identical, finite dimensional quantum systems. These evolve in discrete time steps according to a local, shift-invariant unitary evolution. By local we mean that no instantaneous long-range communication can occur. In order to define these over a Hilbert space we must restrict to a base of finite, yet unbounded configurations. We show that QCA always admit a two-layered block representation, and hence the inverse QCA is again a QCA. This is a striking result since the property does not hold for classical one-dimensional cellular automata as defined over such finite configurations. As an example we discuss a bijective cellular automata which becomes non-local as a QCA, in a rare case of reversible computation which does not admit a straightforward quantization. We argue that a whole class of bijective cellular automata should no longer be considered to be reversible in a physical sense. Note that the same two-layered block representation result applies also over infinite configurations, as was previously shown for one-dimensional systems in the more elaborate formalism of operators algebras [9]. Here the proof is made simpler and self-contained, moreover we discuss a counterexample QCA in higher dimensions.",
    "MGT": "This paper investigates one-dimensional quantum cellular automata (QCA) operating on finite but unbounded configurations of quantum states. We present a formal framework for analyzing the dynamics of such systems, extending classical cellular automata theory to the quantum domain while preserving locality and uniformity conditions. Our main result establishes that any QCA with finite neighborhood radius can be decomposed into a sequence of local unitary operations, enabling efficient simulation on quantum computers. We prove that the set of finite configurations forms a well-defined Hilbert space and demonstrate that the global evolution operator preserves the finiteness of configurations. Through rigorous mathematical analysis, we show that these QCA exhibit novel phenomena not present in classical cellular automata, including entanglement generation and propagation across unbounded distances. We provide explicit constructions of QCA that perform universal quantum computation while maintaining finite support, and characterize the complexity classes of problems solvable by these automata. Additionally, we explore the relationship between our model and continuous-time quantum walks on infinite lattices, establishing conditions under which discrete QCA can approximate continuous quantum dynamics. These results contribute to our understanding of quantum many-body systems and provide new tools for quantum computation with finite resources."
  },
  {
    "id": 193,
    "prompt": "Detection of a Thermal Spectral Component in the Prompt Emission of GRB 100724B",
    "HWT": "Observations of GRB 100724B with the Fermi Gamma-Ray Burst Monitor (GBM) find that the spectrum is dominated by the typical Band functional form, which is usually taken to represent a non-thermal emission component, but also includes a statistically highly significant thermal spectral contribution. The simultaneous observation of the thermal and non-thermal components allows us to confidently identify the two emission components. The fact that these seem to vary independently favors the idea that the thermal component is of photospheric origin while the dominant non-thermal emission occurs at larger radii. Our results imply either a very high efficiency for the non-thermal process, or a very small size of the region at the base of the flow, both quite challenging for the standard fireball model. These problems are resolved if the jet is initially highly magnetized and has a substantial Poynting flux.",
    "MGT": "We present a detailed spectral analysis of GRB 100724B, one of the brightest gamma-ray bursts (GRBs) observed by the Fermi Gamma-ray Space Telescope. Using time-resolved spectroscopy, we detect a significant thermal component in addition to the traditional non-thermal Band function during the burst's prompt emission phase. The thermal component, characterized by temperatures ranging from 15 to 35 keV, contributes approximately 10-15% of the total flux. Our analysis reveals that this thermal emission likely originates from the photosphere of the relativistic outflow, providing crucial insights into the jet composition and emission mechanisms. The temporal evolution of both thermal and non-thermal components shows interesting correlations, suggesting a physical connection between the two emission processes. These findings support theoretical models proposing hybrid emission mechanisms in GRB prompt emission and demonstrate that at least some GRBs contain a distinctive thermal component, challenging purely non-thermal emission scenarios. Our results contribute to the growing evidence for the role of photospheric emission in GRB physics."
  },
  {
    "id": 194,
    "prompt": "Emittance Measurement in MICE",
    "HWT": "Muon ionization cooling provides the only practical solution to prepare high-brilliance beams necessary for a neutrino factory or muon collider. The Muon Ionization Cooling Experiment (MICE), under development at the Rutherford Appleton Laboratory, is installing the first set of particle detectors ever built to measure to 0.1% the emittance of a 200 MeV/c or so muon beam in and out of a cooling cell, and thus measure the cooling cell's performance. Two identical \"emittometers\" (a precise scintillating-fiber tracker in solenoidal magnetic field and a 50 ps time-of-flight station) measure the six phase-space coordinates of each muon. Another TOF plane and two Cherenkov counters assure the purity of the incoming muon beam. A downstream electron/muon calorimeter eliminates contamination from decay electrons.",
    "MGT": "The Muon Ionization Cooling Experiment (MICE) at RAL aims to demonstrate ionization cooling, an essential technology for future muon accelerators. This paper presents precise measurements of emittance using particle tracking detectors in MICE. The experiment utilized a pure muon beam with momentum between 140 and 240 MeV/c. Emittance was measured using a novel method that reconstructs the full phase-space distribution of the beam. The technique employs scintillating fiber trackers to measure particle positions and momenta with high precision. Results show the normalized transverse emittance was determined with an accuracy of better than 1% for various beam configurations. Systematic uncertainties, including detector alignment and momentum reconstruction, were carefully evaluated. These measurements provide crucial validation of simulation codes and represent a significant step toward demonstrating muon cooling for future facilities."
  },
  {
    "id": 195,
    "prompt": "U(1)-Symmetry breaking and violation of axial symmetry in TlCuCl3 and other insulating spin systems",
    "HWT": "We describe the Bose-Einstein condensate of magnetic bosonic quasiparticles in insulating spin systems using a phenomenological standard functional method for T = 0. We show that results that are already known from advanced computational techniques immediately follow. The inclusion of a perturbative anisotropy term that violates the axial symmetry allows us to remarkably well explain a number of experimental features of the dimerized spin-1/2 system TlCuCl3. Based on an energetic argument we predict a general intrinsic instability of an axially symmetric magnetic condensate towards a violation of this symmetry, which leads to the spontaneous formation of an anisotropy gap in the energy spectrum above the critical field. We, therefore, expect that a true Goldstone mode in insulating spin systems, i.e., a strictly linear energy-dispersion relation down to arbitrarily small excitations energies, cannot be observed in any real material.",
    "MGT": "We report theoretical and experimental investigations of symmetry breaking in the quantum spin system TlCuCl3, focusing on the interplay between U(1) symmetry breaking and axial symmetry violation. Through neutron scattering experiments and quantum field theoretical analysis, we demonstrate that the pressure-induced quantum phase transition from a spin liquid to an antiferromagnetically ordered state is accompanied by spontaneous U(1) symmetry breaking. Our results reveal that the violation of axial symmetry occurs simultaneously, leading to observable consequences in the magnetic excitation spectrum. We present a comprehensive theoretical framework that explains the emergence of these symmetry-breaking phenomena and their manifestations in other insulating spin systems. The temperature dependence of the order parameter and the evolution of the magnon dispersion are found to be in excellent agreement with our theoretical predictions. These findings provide crucial insights into the fundamental mechanisms governing quantum phase transitions in strongly correlated spin systems and establish a unified understanding of symmetry breaking in quantum magnets."
  },
  {
    "id": 196,
    "prompt": "Identification of the Lithium Depletion Boundary and Age of the Southern Open Cluster Blanco 1",
    "HWT": "We present results from a spectroscopic study of the very low mass members of the Southern open cluster Blanco 1 using the Gemini-N telescope. We obtained intermediate resolution (R~4400) GMOS spectra for 15 cluster candidate members with I~14-20 mag, and employed a series of membership criteria - proximity to the cluster's sequence in an I/I-Ks color-magnitude diagram (CMD), kinematics agreeing with the cluster systemic motion, magnetic activity as a youth indicator - to classify 10 of these objects as probable cluster members. For these objects, we searched for the presence of the Li I 6708 A feature to identify the lithium depletion boundary (LDB) in Blanco 1. The I/I-Ks CMD shows a clear mass segregation in the Li distribution along the cluster sequence; namely, all higher mass stars are found to be Li-poor, while lower mass stars are found to be Li-rich. The division between Li-poor and Li-rich (i.e., the LDB) in Blanco 1 is found at I=$18.78 \\pm 0.24$ and I-Ks=$3.05 \\pm 0.10$. Using current pre-main-sequence evolutionary models we determine an LDB age of $132 \\pm 24$ Myr. Comparing our derived LDB age to upper-main-sequence isochrone ages for Blanco 1, as well as for other open clusters with identified LDBs, we find good chronometric consistency when using stellar evolution models that incorporate a moderate degree of convective core overshoot.",
    "MGT": "We present high-resolution spectroscopic observations of 45 low-mass stars in the Southern open cluster Blanco 1, obtained using the FLAMES/GIRAFFE spectrograph on the ESO Very Large Telescope. Our analysis focuses on measuring lithium abundances and identifying the lithium depletion boundary (LDB) to derive a precise age for the cluster. The spectra cover the Li I 6708Å resonance doublet with a resolution of R≈17,000. We detect lithium in 27 targets and establish upper limits for the remainder. The data reveal a sharp transition in lithium abundances at M≈0.3M⊙, which we identify as the LDB. Using state-of-the-art evolutionary models that account for magnetic fields and starspots, we derive an LDB age of 115±10 Myr for Blanco 1. This age is significantly younger than previous estimates based on upper main sequence fitting (132±24 Myr) but agrees well with recent gyrochronology studies. We find that the lithium abundances of stars above the LDB show significant scatter, suggesting varying rates of pre-main sequence depletion. The location of the LDB, combined with our proper motion membership analysis, allows us to construct a clean sequence of cluster members down to M≈0.1M⊙. Our results provide a crucial age calibration point for young open clusters in the Southern hemisphere and demonstrate the power of the LDB technique for precise age determination. The revised age for Blanco 1 has important implications for understanding early stellar evolution and the timescales of circumstellar disk dispersal in the cluster."
  },
  {
    "id": 197,
    "prompt": "Solar Gamma Rays Powered by Secluded Dark Matter",
    "HWT": "Secluded dark matter models, in which WIMPs annihilate first into metastable mediators, can present novel indirect detection signatures in the form of gamma rays and fluxes of charged particles arriving from directions correlated with the centers of large astrophysical bodies within the solar system, such as the Sun and larger planets. This naturally occurs if the mean free path of the mediator is in excess of the solar (or planetary) radius. We show that existing constraints from water Cerenkov detectors already provide a novel probe of the parameter space of these models, complementary to other sources, with significant scope for future improvement from high angular resolution gamma-ray telescopes such as Fermi-LAT. Fluxes of charged particles produced in mediator decays are also capable of contributing a significant solar system component to the spectrum of energetic electrons and positrons, a possibility which can be tested with the directional and timing information of PAMELA and Fermi.",
    "MGT": "We propose a novel mechanism for generating solar gamma rays through the interaction of secluded dark matter particles with solar plasma. Our model introduces a light mediator that couples dark matter to Standard Model particles, facilitating dark matter accumulation in the Sun's core. Through numerical simulations and analytical calculations, we demonstrate that dark matter annihilation processes can produce gamma rays in the 1-100 MeV range, consistent with recent solar observations. The model predicts a distinctive spectral signature that differs from conventional astrophysical processes, characterized by a sharp cutoff at higher energies and enhanced emission during solar minimum periods. Our findings suggest that approximately 10^-36 cm^2 dark matter-nucleon cross-section can account for the observed gamma-ray flux while satisfying current experimental constraints. This work provides a new framework for understanding solar gamma-ray production and offers potential insights into the nature of dark matter particles. The predicted correlation between solar activity cycles and gamma-ray flux presents an observationally testable signature for future high-energy solar observations."
  },
  {
    "id": 198,
    "prompt": "P values, confidence intervals, or confidence levels for hypotheses?",
    "HWT": "Null hypothesis significance tests and p values are widely used despite very strong arguments against their use in many contexts. Confidence intervals are often recommended as an alternative, but these do not achieve the objective of assessing the credibility of a hypothesis, and the distinction between confidence and probability is an unnecessary confusion. This paper proposes a more straightforward (probabilistic) definition of confidence, and suggests how the idea can be applied to whatever hypotheses are of interest to researchers. The relative merits of the different approaches are discussed using a series of illustrative examples: usually confidence based approaches seem more transparent and useful, but there are some contexts in which p values may be appropriate. I also suggest some methods for converting results from one format to another. (The attractiveness of the idea of confidence is demonstrated by the widespread persistence of the completely incorrect idea that p=5% is equivalent to 95% confidence in the alternative hypothesis. In this paper I show how p values can be used to derive meaningful confidence statements, and the assumptions underlying the derivation. ) Key words: Confidence interval, Confidence level, Hypothesis testing, Null hypothesis significance tests, P value, User friendliness.",
    "MGT": "This paper examines the ongoing debate regarding the most appropriate methods for statistical inference in scientific research, focusing on three key approaches: p values, confidence intervals, and confidence levels for hypotheses. Through a comprehensive analysis of these methods' theoretical foundations and practical applications, we demonstrate their relative strengths and limitations in different research contexts. Our investigation reveals that while p values remain widely used, they are often misinterpreted and can lead to dichotomous thinking about research findings. Confidence intervals provide more informative measures of uncertainty and effect sizes, but may not always align with researchers' primary questions of interest. We introduce a novel framework for expressing confidence levels directly for scientific hypotheses, which combines the interpretability of confidence intervals with the hypothesis-focused nature of significance testing. Using simulation studies and real-world examples from various scientific disciplines, we show that this approach can provide more nuanced and practically relevant information for research conclusions. Our findings suggest that no single method is universally superior, but rather that the choice of inferential approach should depend on the research context, goals, and intended audience. We conclude by proposing guidelines for selecting appropriate statistical methods and reporting practices that promote clearer communication of scientific uncertainty."
  },
  {
    "id": 199,
    "prompt": "A Non-Cooperative Method for Path Loss Estimation in Femtocell Networks",
    "HWT": "A macrocell superposed by indoor deployed femtocells forms a geography-overlapped and spectrum-shared two tier network, which can efficiently improve coverage and enhance system capacity. It is important for reducing inter-tier co-channel interference that any femtocell user (FU) can select suitable access channel according to the path losses between itself and the macrocell users (MUs). Path loss should be estimated non-cooperatively since information exchange is difficult between macrocell and femtocells. In this paper, a novel method is proposed for FU to estimate the path loss between itself and any MU independently. According to the adaptive modulation and coding (AMC) mode information broadcasted by the macrocell base station (BS), FU first estimates the path loss between BS and a MU by using Maximum a Posteriori (MAP) method. The probability distribution function (PDF) and statistics of the transmission power of the MU is then derived. According to the sequence of received powers from the MU, FU estimates the path loss between itself and the MU by using minimum mean square error (MMSE) method. Simulation results show that the proposed method can efficiently estimate the path loss between any FU and any MU in all kinds of conditions.",
    "MGT": "This paper presents a novel non-cooperative approach for estimating path loss in femtocell networks without requiring explicit coordination between base stations. The proposed method leverages passive measurements of received signal strength from user equipment (UE) to construct accurate path loss models while maintaining network autonomy. By analyzing temporal variations in signal strength patterns across multiple UEs, our algorithm can distinguish between direct and interference signals to estimate path loss exponents and shadow fading parameters. We introduce a maximum likelihood estimation framework that jointly optimizes these parameters while accounting for measurement uncertainty and temporal correlation. Extensive simulations using realistic 3D indoor propagation models demonstrate that our approach achieves mean absolute errors of less than 3 dB in path loss estimation, comparing favorably with conventional cooperative techniques. The method proves particularly effective in dense deployments, where it can characterize up to 85% of relevant propagation paths without requiring inter-cell communication. Field trials conducted in a four-story office building with 12 femtocells validate the simulation results and confirm the algorithm's robustness to real-world propagation effects. Our findings suggest that non-cooperative path loss estimation can significantly reduce deployment complexity while maintaining the accuracy needed for interference management and coverage optimization in femtocell networks."
  }
]